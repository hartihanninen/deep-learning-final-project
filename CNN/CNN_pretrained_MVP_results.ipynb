{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e029d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "#\n",
    "# MVP: create a version that allows us to pass and no more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5e586",
   "metadata": {},
   "source": [
    "Copied from assignment 2. NEEDS WORK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4547e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hartih/opt/anaconda3/envs/deep_learning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Organize data for pytorch DataLoader\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "\n",
    "#DATA_DIR = 'D:/Kurssit/Data Science/Deep learning/dl2021-image-corpus-proj/'\n",
    "DATA_DIR = '/Users/hartih/Documents/School/Deep learning/Final_project/dl2021-image-corpus-proj/'\n",
    "ANNOTATIONS_DIR = DATA_DIR + 'annotations/'\n",
    "IMAGES_DIR = DATA_DIR + 'images/'\n",
    "\n",
    "# New fodlers for train, test, and dev sets\n",
    "TRAIN_DIR = DATA_DIR + 'train/'\n",
    "DEV_DIR = DATA_DIR + 'dev/'\n",
    "TEST_DIR = DATA_DIR + 'test/'\n",
    "\n",
    "annotations = [\"baby\",\n",
    "               \"bird\",\n",
    "               \"car\",\n",
    "               \"clouds\",\n",
    "               \"dog\",\n",
    "               \"female\",\n",
    "               \"flower\",\n",
    "               \"male\",\n",
    "               \"night\",\n",
    "               \"people\",\n",
    "               \"portrait\",\n",
    "               \"river\",\n",
    "               \"sea\",\n",
    "               \"tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0729b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for images\n",
    "image_file_names = os.listdir(IMAGES_DIR)\n",
    "dict_labels = {}\n",
    "for image_file_name in image_file_names:  # Initiate label tensors\n",
    "    if os.path.isfile(IMAGES_DIR + image_file_name):\n",
    "        dict_labels[image_file_name] = torch.zeros(14)\n",
    "for i in range(len(annotations)):  # Fill label tensors with 1's if found in one of the annotations text files\n",
    "    with open(ANNOTATIONS_DIR + annotations[i] + \".txt\") as f:\n",
    "        for row in f:\n",
    "            row = \"im\" + row.strip() + \".jpg\"\n",
    "            dict_labels[row][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fe60c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'im1976.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12710.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17668.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10107.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11219.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19645.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16576.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19123.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16210.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10661.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3807.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8952.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im14407.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9494.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13368.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12076.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15719.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14413.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8946.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9480.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12062.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19137.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16204.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10675.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3813.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18229.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10113.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19889.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19651.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16562.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1962.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12704.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14375.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17654.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4832.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18567.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11225.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3185.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19679.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15043.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13432.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im1792.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13354.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7485.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im598.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6943.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15725.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10885.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11543.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im5292.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17132.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18201.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16238.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10891.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11557.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4198.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10649.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5286.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17126.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im18215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13340.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7491.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6957.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15731.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15057.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12738.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13426.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14349.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1786.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17640.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18573.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4826.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17898.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11231.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3191.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4615.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 'im17873.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19686.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18598.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2264.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9331.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6002.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im201.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im567.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8749.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8991.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im9457.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15902.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6764.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2502.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4173.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5279.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2516.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3608.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4167.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im573.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8985.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im15916.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9443.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6770.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9325.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6016.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1779.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7308.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4601.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17867.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19692.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im2270.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12937.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1751.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15080.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7320.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1989.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8013.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4629.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " 'im16589.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3146.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17697.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im2258.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5537.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19862.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5251.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im3620.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10846.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11580.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im12089.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7446.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8775.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6980.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1037.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13397.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6758.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7452.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8761.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6994.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1023.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im13383.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5245.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im3634.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10852.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11594.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3152.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17683.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19876.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5523.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9319.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12923.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1745.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im15094.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7334.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8007.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im229.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12274.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8588.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9696.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7863.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10463.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16012.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19321.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16774.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5912.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19447.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18981.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10305.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18759.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14163.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12512.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14177.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13618.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12506.jpg': tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15269.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16760.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19453.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5906.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18995.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im10311.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17318.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10477.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11769.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16006.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19335.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12260.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9682.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7877.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18003.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11999.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17330.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5090.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11741.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2927.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9872.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15527.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12248.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7687.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13156.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6599.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14639.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im942.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1590.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13630.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15241.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16748.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3387.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11027.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10339.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16990.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18765.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17456.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2099.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3393.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11033.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im16984.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18771.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17442.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1584.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13624.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15255.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15533.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9866.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 'im7693.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13142.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im956.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18017.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17324.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5084.jpg': tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11755.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2933.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im19309.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4371.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2700.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11966.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6566.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9655.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1209.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7678.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im765.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13817.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6200.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9133.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5709.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2066.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3378.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19484.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4417.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18942.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2072.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19490.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18956.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4403.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8239.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im13803.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6214.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9127.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6572.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9641.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9899.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im771.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4365.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2714.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11972.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9669.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13195.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1235.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im981.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8577.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im759.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14822.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7644.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11782.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3422.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5053.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5735.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16953.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17495.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3344.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8211.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7122.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15282.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1553.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8205.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7136.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im15296.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14188.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1547.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6228.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5721.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16947.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17481.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3350.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11796.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4359.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3436.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2728.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10488.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5047.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13181.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im995.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1221.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7888.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8563.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7650.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7917.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im14771.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12300.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16166.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19255.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11609.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10517.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17278.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10271.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im16600.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19533.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5866.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15309.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12466.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13778.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9084.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im14017.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12472.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9090.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14003.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18639.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10265.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im16614.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5872.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19527.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16172.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19241.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10503.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7903.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14765.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12314.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19269.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3595.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11635.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2853.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18177.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17244.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1382.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13022.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14995.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15453.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9906.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15335.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im188.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7095.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13744.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17522.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5682.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im11153.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17536.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10259.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im5696.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11147.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4588.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16628.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15321.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13988.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7081.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13750.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1396.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14759.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im822.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13036.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14981.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im12328.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9912.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15447.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3581.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11621.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2847.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18163.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17250.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2674.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18188.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11812.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19296.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4205.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6412.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9721.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6374.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9047.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13963.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im177.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8359.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4563.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2112.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4577.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18822.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3218.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2106.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5669.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6360.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9053.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13977.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im163.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7718.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1369.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6406.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9735.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2660.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11806.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19282.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4211.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14956.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8403.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7730.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15490.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1341.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5127.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17287.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2648.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16199.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3556.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4239.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2890.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11190.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5899.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3230.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5641.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16827.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13787.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6348.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1427.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8365.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12499.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7056.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13793.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1433.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8371.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im7042.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11184.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3224.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im5655.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16833.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5133.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17293.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3542.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2884.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8417.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im639.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14942.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7724.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15484.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1355.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " 'im9709.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9286.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1802.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8198.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im12664.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19731.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16402.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10073.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im50.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18349.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10715.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3973.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19057.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16364.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12102.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14573.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8826.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15679.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12116.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13208.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8832.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14567.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10701.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3967.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19043.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16370.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.]),\n",
       " 'im19725.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16416.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11379.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10067.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im44.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17708.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14201.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9292.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1816.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12670.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11351.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5480.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17720.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18413.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4946.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12880.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14229.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13546.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6189.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12658.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7297.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15137.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6837.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15651.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13220.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15889.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1180.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17046.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2489.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18375.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10729.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11437.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16358.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3797.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17052.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11423.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]),\n",
       " 'im3783.jpg': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6823.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15645.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13234.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1194.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12894.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13552.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7283.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15123.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19719.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11345.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5494.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17734.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4952.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im78.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18407.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im93.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2310.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4761.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17907.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im375.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7268.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1619.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9245.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6176.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im15876.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9523.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6610.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im413.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4007.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19094.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3768.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2476.jpg': tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5319.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4013.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im19080.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2462.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9537.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15862.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6604.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im407.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8629.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9251.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6162.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im87.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2304.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4775.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17913.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7254.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8167.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im349.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12843.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1625.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13585.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9279.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im19916.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5443.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4985.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3032.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11392.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im3754.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10932.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17085.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5325.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1143.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im15692.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im7532.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8601.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6638.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1157.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]),\n",
       " 'im14598.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15686.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7526.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8615.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im3740.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10926.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17091.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3998.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5331.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10098.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5457.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19902.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2338.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4991.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3026.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11386.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4749.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7240.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8173.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12857.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1631.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13591.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5330.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3999.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im17090.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10927.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3741.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8614.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7527.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15687.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1156.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14599.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6639.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13590.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1630.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12856.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8172.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7241.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11387.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4748.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3027.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4990.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2339.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10099.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5456.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19903.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11393.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3033.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4984.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19917.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5442.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9278.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " 'im13584.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1624.jpg': tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12842.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8166.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im348.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7255.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8600.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7533.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15693.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1142.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5324.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17084.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10933.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3755.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im406.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8628.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9536.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15863.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2463.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19081.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4012.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17912.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4774.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2305.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im86.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6163.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9250.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im360.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6177.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9244.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1618.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7269.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im374.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17906.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4760.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2311.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im92.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im5318.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2477.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3769.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19095.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4006.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im412.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15877.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9522.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1195.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13235.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15644.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im6822.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3782.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11422.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18360.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17053.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im79.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im4953.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18406.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17735.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5495.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11344.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19718.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15122.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7282.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13553.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12895.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15136.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12659.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7296.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13547.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6188.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14228.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12881.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18412.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4947.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17721.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5481.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11350.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16359.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3796.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11436.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10728.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18374.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im17047.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2488.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1181.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15888.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13221.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15650.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16371.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19042.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3966.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10700.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8833.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14566.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13209.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12117.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15678.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12671.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1817.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9293.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14200.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " 'im17709.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im45.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10066.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11378.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16417.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19724.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im51.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10072.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16403.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im19730.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12665.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1803.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im8199.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9287.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im14214.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im14572.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im8827.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12103.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16365.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19056.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3972.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10714.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18348.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " 'im16832.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5654.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3225.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11185.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7043.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8370.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im1432.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13792.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9708.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1354.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15485.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7725.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8416.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14943.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im638.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2885.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3543.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17292.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5132.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2891.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im4238.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16198.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3557.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17286.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2649.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5126.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1340.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15491.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7731.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14957.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8402.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12498.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7057.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8364.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im1426.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13786.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6349.jpg': tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16826.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5640.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3231.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5898.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11191.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im162.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13976.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9052.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5668.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2107.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3219.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4576.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18823.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4210.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19283.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11807.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2661.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9734.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6407.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1368.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im604.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7719.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9720.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im6413.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im610.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4204.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19297.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18189.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11813.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2675.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2113.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18837.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4562.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im176.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8358.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13962.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9046.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6375.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13751.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im7080.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13989.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15320.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16629.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im11146.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4589.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10258.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im5697.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17537.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18604.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17251.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18162.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2846.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11620.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3580.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9913.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15446.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12329.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14980.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im13037.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im823.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1397.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14758.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15452.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9907.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14994.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13023.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1383.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im837.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17245.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18176.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2852.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11634.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3594.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19268.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11152.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5683.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17523.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18610.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13745.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7094.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im189.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15334.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5873.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19526.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16615.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10264.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18638.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14002.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9091.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12473.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im12315.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14764.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7902.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10502.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19240.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16173.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17279.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10516.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11608.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19254.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16167.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12301.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im14770.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7916.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14016.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9085.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13779.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12467.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15308.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19532.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5867.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im16601.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im10270.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3351.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17480.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16946.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5720.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im6229.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14189.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1546.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15297.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7137.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8204.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7651.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14837.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8562.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7889.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1220.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im994.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13180.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10489.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5046.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2729.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3437.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11797.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4358.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5052.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3423.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11783.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7645.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8576.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14823.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im758.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im980.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im1234.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13194.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9668.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1552.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15283.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7123.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8210.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3345.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17494.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16952.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5734.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im9126.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13802.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8238.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18957.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4402.jpg': tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19491.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im2073.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11973.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2715.jpg': tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4364.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im770.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9898.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9640.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6573.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im764.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7679.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1208.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9654.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6567.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11967.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im2701.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4370.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4416.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18943.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19485.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3379.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2067.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im5708.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9132.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6201.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13816.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15254.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13625.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1585.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17443.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18770.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16985.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021ccf07",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/hartih/Documents/School/Deep learning/Final_project/dl2021-image-corpus-proj/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Split the data to train, test, and dev\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(TEST_DIR)\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(DEV_DIR)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deep_learning/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/hartih/Documents/School/Deep learning/Final_project/dl2021-image-corpus-proj/train/'"
     ]
    }
   ],
   "source": [
    "# Split the data to train, test, and dev\n",
    "os.makedirs(TRAIN_DIR)\n",
    "os.makedirs(TEST_DIR)\n",
    "os.makedirs(DEV_DIR)\n",
    "for image_file_name in image_file_names:\n",
    "    if os.path.isfile(IMAGES_DIR + image_file_name):\n",
    "        division = random.randint(1, 3)\n",
    "        if division == 1:\n",
    "            shutil.copyfile(IMAGES_DIR + image_file_name, TRAIN_DIR + image_file_name)\n",
    "        if division == 2:\n",
    "            shutil.copyfile(IMAGES_DIR + image_file_name, DEV_DIR + image_file_name)\n",
    "        if division == 3:\n",
    "            shutil.copyfile(IMAGES_DIR + image_file_name, TEST_DIR + image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b380180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "6786\n",
      "6697\n",
      "6517\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print( len(os.listdir(TEST_DIR)) + len(os.listdir(TRAIN_DIR)) + len( os.listdir(DEV_DIR)) == len(os.listdir(IMAGES_DIR)) )\n",
    "print(len(os.listdir(TEST_DIR)))\n",
    "print(len(os.listdir(TRAIN_DIR)))\n",
    "print(len(os.listdir(DEV_DIR)))\n",
    "print(len(os.listdir(IMAGES_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db46e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "\n",
    "# Enable creating train, test, and dev test datasets for PyTorch\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir=IMAGES_DIR, transform=None):\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.images = [root_dir + img for img in os.listdir(root_dir)]                \n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.images)       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img = img = Image.open(img_path)     \n",
    "       \n",
    "        if self.transform:\n",
    "            img = self.transform(img)     \n",
    "\n",
    "        return img, dict_labels[img_path.split(\"/\")[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f19ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.485, 0.456, 0.406]\n",
      "std: [0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "#Calculate mean and std with whole dataset\n",
    "imageNet = True  # If imageNet is True, then we use the values from imagenet, else we calculate them from the dataset\n",
    "\n",
    "if imageNet:\n",
    "  mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]  # Imagenet mean and std\n",
    "else:\n",
    "  def mean_std(loader):\n",
    "    images, labels = next(iter(loader))\n",
    "    # shape of images = [b,c,w,h]\n",
    "    mean, std = images.mean([0,2,3]), images.std([0,2,3])\n",
    "    return mean, std\n",
    "\n",
    "  mean_transform = transforms.Compose([\n",
    "                                          transforms.Grayscale(num_output_channels=3),\n",
    "                                          transforms.Resize(256),                    \n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "  #Splitting these was the easiest due to memory allocation problem, you could only used IMAGES_DIR if this is not a problem, note the equal divide\n",
    "  train_mean_set = myDataset(TRAIN_DIR, transform=mean_transform)\n",
    "  train_data_loader = torch.utils.data.DataLoader(dataset=train_mean_set, batch_size=len(train_mean_set), shuffle=False, num_workers=0)\n",
    "  dev_mean_set = myDataset(DEV_DIR, transform=mean_transform)\n",
    "  dev_data_loader = torch.utils.data.DataLoader(dataset=dev_mean_set, batch_size=len(dev_mean_set), shuffle=False, num_workers=0)\n",
    "  test_mean_set = myDataset(TEST_DIR, transform=mean_transform)\n",
    "  test_data_loader = torch.utils.data.DataLoader(dataset=test_mean_set, batch_size=len(test_mean_set), shuffle=False, num_workers=0)\n",
    "\n",
    "  mean_train, std_train = mean_std(train_data_loader)\n",
    "  mean_dev, std_dev = mean_std(dev_data_loader)\n",
    "  mean_test, std_test = mean_std(test_data_loader)\n",
    "  mean = list((np.array(mean_train)+np.array(mean_dev)+np.array(mean_test))/3)\n",
    "  std = list((np.array(std_train)+np.array(std_dev)+np.array(std_test))/3)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"std:\", std)\n",
    "\n",
    "#Imagenet mean and std\n",
    "# mean = [0.485, 0.456, 0.406]\n",
    "# std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                                        #transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.Grayscale(num_output_channels=3),\n",
    "                                        transforms.RandomCrop(128),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.RandomRotation(2),\n",
    "                                        transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([\n",
    "                                        transforms.Grayscale(num_output_channels=3),\n",
    "                                        transforms.ToTensor()])\n",
    "\n",
    "transform = transforms.Compose([            #[1]\n",
    " transforms.Grayscale(num_output_channels=3),\n",
    " transforms.Resize(256),                    #[2]\n",
    " transforms.CenterCrop(224),                #[3]\n",
    " transforms.ToTensor(),                     #[4]\n",
    " transforms.Normalize(                      #[5]\n",
    " mean=mean,                #[6]\n",
    " std=std                 #[7]\n",
    " )]\n",
    ")\n",
    "\n",
    "# Create datasets for CNN\n",
    "train_set = myDataset(TRAIN_DIR, transform=transform)\n",
    "test_set = myDataset(TEST_DIR, transform=transform)\n",
    "dev_set = myDataset(DEV_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e04313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5543a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# Calculate the amount of correctly predicted as well as total predictions done\n",
    "def calc_correct(pred: torch.Tensor, target: torch.Tensor):\n",
    "    pred = torch.sigmoid(pred)  # Since our neural network does not apply sigmoid\n",
    "    correct_dict = {'tot': [0,0]}  # First number in value is correct ones, the second one is total amount\n",
    "    correct_dict['tot_strict'] = [0,0] # All correct\n",
    "    for i in range(len(pred)): # [100,14]\n",
    "        all_correct = 0\n",
    "        total = 0\n",
    "        # estim_pred_array = []\n",
    "        for j in range(len(pred[i])):\n",
    "            estim_pred = 0 if float(pred[i][j]) < 0.5 else 1\n",
    "            # estim_pred_array.append(estim_pred)\n",
    "            if annotations[j] not in correct_dict.keys():\n",
    "                correct_dict[annotations[j]] = [0,0]\n",
    "            correct_dict['tot'][1] += 1\n",
    "            correct_dict[annotations[j]][1] += 1\n",
    "            correct_dict['tot'][0] += int(estim_pred == target[i][j])\n",
    "            correct_dict[annotations[j]][0] += int(estim_pred == target[i][j])\n",
    "            all_correct += int(estim_pred == target[i][j])\n",
    "            total += 1\n",
    "        correct_dict['tot_strict'][1] += 1\n",
    "        correct_dict['tot_strict'][0] += int(total==all_correct)\n",
    "    # To-do how many pictures were entirely correct (accuracy)\n",
    "    return correct_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e7e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_evaluation(pred: torch.Tensor, target: torch.Tensor):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    \n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    negative = 0\n",
    "    positive = 0\n",
    "    \n",
    "    for i in range(len(pred)): # [100,14]\n",
    "        for j in range(len(pred[i])):\n",
    "            estim_pred = 0 if float(pred[i][j]) < 0.5 else 1\n",
    "            \n",
    "            # Negative target values\n",
    "            if target[i][j] == 0:\n",
    "                negative += 1\n",
    "                if estim_pred == 1:\n",
    "                    false_positive += 1\n",
    "                if estim_pred == 0:\n",
    "                    true_negative += 1\n",
    "            \n",
    "            # Positive target values\n",
    "            if target[i][j] == 1:\n",
    "                positive += 1\n",
    "                if estim_pred == 1:\n",
    "                    true_positive += 1\n",
    "                if estim_pred == 0:\n",
    "                    false_negative += 1\n",
    "    \n",
    "    result = {\"true_positive\": true_positive,\n",
    "            \"false_positive\": false_positive,\n",
    "            \"true_negative\": true_negative,\n",
    "            \"false_negative\": false_negative,\n",
    "            \"negative\": negative,\n",
    "            \"positive\": positive}\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9035bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_evaluation_by_annotation(pred: torch.Tensor, target: torch.Tensor):\n",
    "    \n",
    "    pred = torch.sigmoid(pred)\n",
    "    \n",
    "    # Initiate vslues for every annotation\n",
    "    eval_dict = {}\n",
    "    for a in range(len(annotations)):\n",
    "        eval_dict[annotations[a]] = {\"true_positive\": 0,\n",
    "                                        \"false_positive\": 0,\n",
    "                                        \"true_negative\": 0,\n",
    "                                        \"false_negative\": 0,\n",
    "                                        \"negative\": 0,\n",
    "                                        \"positive\": 0}\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        for j in range(len(pred[i])):\n",
    "            estim_pred = 0 if float(pred[i][j]) < 0.5 else 1\n",
    "            \n",
    "            # Negative target values\n",
    "            if target[i][j] == 0:\n",
    "                eval_dict[annotations[j]][\"negative\"] += 1\n",
    "                if estim_pred == 1:\n",
    "                    eval_dict[annotations[j]][\"false_positive\"] += 1\n",
    "                if estim_pred == 0:\n",
    "                    eval_dict[annotations[j]][\"true_negative\"] += 1\n",
    "            \n",
    "            # Positive target values\n",
    "            if target[i][j] == 1:\n",
    "                eval_dict[annotations[j]][\"positive\"] += 1\n",
    "                if estim_pred == 1:\n",
    "                    eval_dict[annotations[j]][\"true_positive\"] += 1\n",
    "                if estim_pred == 0:\n",
    "                    eval_dict[annotations[j]][\"false_negative\"] += 1\n",
    "                    \n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd4ed4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 1 - Batch 1/67: Loss: 0.7020 | Train Acc: 44.571% (624/1400) | Strict Acc: 0.000% (0/100)\n",
      "True positive rate: 65.116% (56/86)\n",
      "False negative rate: 34.884% (30/86)\n",
      "True negative rate: 43.227% (568/1314)\n",
      "False positive rate: 56.773% (746/1314)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 2/67: Loss: 0.5554 | Train Acc: 66.143% (1852/2800) | Strict Acc: 9.500% (19/200)\n",
      "True positive rate: 30.729% (59/192)\n",
      "False negative rate: 69.271% (133/192)\n",
      "True negative rate: 68.750% (1793/2608)\n",
      "False positive rate: 31.250% (815/2608)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 3/67: Loss: 0.4533 | Train Acc: 75.143% (3156/4200) | Strict Acc: 21.333% (64/300)\n",
      "True positive rate: 26.246% (79/301)\n",
      "False negative rate: 73.754% (222/301)\n",
      "True negative rate: 78.918% (3077/3899)\n",
      "False positive rate: 21.082% (822/3899)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 4/67: Loss: 0.3927 | Train Acc: 79.839% (4471/5600) | Strict Acc: 28.750% (115/400)\n",
      "True positive rate: 24.318% (98/403)\n",
      "False negative rate: 75.682% (305/403)\n",
      "True negative rate: 84.145% (4373/5197)\n",
      "False positive rate: 15.855% (824/5197)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 5/67: Loss: 0.3675 | Train Acc: 82.357% (5765/7000) | Strict Acc: 31.600% (158/500)\n",
      "True positive rate: 25.954% (136/524)\n",
      "False negative rate: 74.046% (388/524)\n",
      "True negative rate: 86.921% (5629/6476)\n",
      "False positive rate: 13.079% (847/6476)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 6/67: Loss: 0.3513 | Train Acc: 83.869% (7045/8400) | Strict Acc: 31.167% (187/600)\n",
      "True positive rate: 29.257% (189/646)\n",
      "False negative rate: 70.743% (457/646)\n",
      "True negative rate: 88.419% (6856/7754)\n",
      "False positive rate: 11.581% (898/7754)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 7/67: Loss: 0.3351 | Train Acc: 85.357% (8365/9800) | Strict Acc: 33.857% (237/700)\n",
      "True positive rate: 29.317% (219/747)\n",
      "False negative rate: 70.683% (528/747)\n",
      "True negative rate: 89.981% (8146/9053)\n",
      "False positive rate: 10.019% (907/9053)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 8/67: Loss: 0.3163 | Train Acc: 86.589% (9698/11200) | Strict Acc: 37.000% (296/800)\n",
      "True positive rate: 29.581% (247/835)\n",
      "False negative rate: 70.419% (588/835)\n",
      "True negative rate: 91.182% (9451/10365)\n",
      "False positive rate: 8.818% (914/10365)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 9/67: Loss: 0.3045 | Train Acc: 87.429% (11016/12600) | Strict Acc: 38.778% (349/900)\n",
      "True positive rate: 31.718% (301/949)\n",
      "False negative rate: 68.282% (648/949)\n",
      "True negative rate: 91.966% (10715/11651)\n",
      "False positive rate: 8.034% (936/11651)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 10/67: Loss: 0.2921 | Train Acc: 88.107% (12335/14000) | Strict Acc: 40.300% (403/1000)\n",
      "True positive rate: 33.460% (352/1052)\n",
      "False negative rate: 66.540% (700/1052)\n",
      "True negative rate: 92.547% (11983/12948)\n",
      "False positive rate: 7.453% (965/12948)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 11/67: Loss: 0.2804 | Train Acc: 88.617% (13647/15400) | Strict Acc: 40.364% (444/1100)\n",
      "True positive rate: 35.986% (416/1156)\n",
      "False negative rate: 64.014% (740/1156)\n",
      "True negative rate: 92.888% (13231/14244)\n",
      "False positive rate: 7.112% (1013/14244)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 12/67: Loss: 0.2723 | Train Acc: 89.036% (14958/16800) | Strict Acc: 40.583% (487/1200)\n",
      "True positive rate: 36.704% (461/1256)\n",
      "False negative rate: 63.296% (795/1256)\n",
      "True negative rate: 93.264% (14497/15544)\n",
      "False positive rate: 6.736% (1047/15544)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 13/67: Loss: 0.2632 | Train Acc: 89.500% (16289/18200) | Strict Acc: 42.154% (548/1300)\n",
      "True positive rate: 37.574% (508/1352)\n",
      "False negative rate: 62.426% (844/1352)\n",
      "True negative rate: 93.667% (15781/16848)\n",
      "False positive rate: 6.333% (1067/16848)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 14/67: Loss: 0.2562 | Train Acc: 89.857% (17612/19600) | Strict Acc: 42.500% (595/1400)\n",
      "True positive rate: 37.698% (547/1451)\n",
      "False negative rate: 62.302% (904/1451)\n",
      "True negative rate: 94.027% (17065/18149)\n",
      "False positive rate: 5.973% (1084/18149)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 15/67: Loss: 0.2506 | Train Acc: 90.162% (18934/21000) | Strict Acc: 43.000% (645/1500)\n",
      "True positive rate: 37.436% (584/1560)\n",
      "False negative rate: 62.564% (976/1560)\n",
      "True negative rate: 94.393% (18350/19440)\n",
      "False positive rate: 5.607% (1090/19440)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 16/67: Loss: 0.2438 | Train Acc: 90.464% (20264/22400) | Strict Acc: 43.438% (695/1600)\n",
      "True positive rate: 37.636% (624/1658)\n",
      "False negative rate: 62.364% (1034/1658)\n",
      "True negative rate: 94.687% (19640/20742)\n",
      "False positive rate: 5.313% (1102/20742)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 17/67: Loss: 0.2396 | Train Acc: 90.706% (21588/23800) | Strict Acc: 43.706% (743/1700)\n",
      "True positive rate: 38.103% (671/1761)\n",
      "False negative rate: 61.897% (1090/1761)\n",
      "True negative rate: 94.909% (20917/22039)\n",
      "False positive rate: 5.091% (1122/22039)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 18/67: Loss: 0.2348 | Train Acc: 90.913% (22910/25200) | Strict Acc: 44.222% (796/1800)\n",
      "True positive rate: 38.478% (713/1853)\n",
      "False negative rate: 61.522% (1140/1853)\n",
      "True negative rate: 95.074% (22197/23347)\n",
      "False positive rate: 4.926% (1150/23347)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 19/67: Loss: 0.2290 | Train Acc: 91.117% (24237/26600) | Strict Acc: 44.737% (850/1900)\n",
      "True positive rate: 38.944% (752/1931)\n",
      "False negative rate: 61.056% (1179/1931)\n",
      "True negative rate: 95.200% (23485/24669)\n",
      "False positive rate: 4.800% (1184/24669)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 20/67: Loss: 0.2237 | Train Acc: 91.329% (25572/28000) | Strict Acc: 45.450% (909/2000)\n",
      "True positive rate: 39.597% (805/2033)\n",
      "False negative rate: 60.403% (1228/2033)\n",
      "True negative rate: 95.379% (24767/25967)\n",
      "False positive rate: 4.621% (1200/25967)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 21/67: Loss: 0.2204 | Train Acc: 91.459% (26889/29400) | Strict Acc: 45.429% (954/2100)\n",
      "True positive rate: 39.654% (849/2141)\n",
      "False negative rate: 60.346% (1292/2141)\n",
      "True negative rate: 95.528% (26040/27259)\n",
      "False positive rate: 4.472% (1219/27259)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 22/67: Loss: 0.2170 | Train Acc: 91.588% (28209/30800) | Strict Acc: 45.682% (1005/2200)\n",
      "True positive rate: 40.124% (908/2263)\n",
      "False negative rate: 59.876% (1355/2263)\n",
      "True negative rate: 95.669% (27301/28537)\n",
      "False positive rate: 4.331% (1236/28537)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 23/67: Loss: 0.2123 | Train Acc: 91.776% (29552/32200) | Strict Acc: 46.304% (1065/2300)\n",
      "True positive rate: 40.494% (950/2346)\n",
      "False negative rate: 59.506% (1396/2346)\n",
      "True negative rate: 95.806% (28602/29854)\n",
      "False positive rate: 4.194% (1252/29854)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 24/67: Loss: 0.2097 | Train Acc: 91.866% (30867/33600) | Strict Acc: 46.167% (1108/2400)\n",
      "True positive rate: 40.213% (982/2442)\n",
      "False negative rate: 59.787% (1460/2442)\n",
      "True negative rate: 95.914% (29885/31158)\n",
      "False positive rate: 4.086% (1273/31158)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 25/67: Loss: 0.2075 | Train Acc: 91.980% (32193/35000) | Strict Acc: 46.280% (1157/2500)\n",
      "True positive rate: 40.447% (1031/2549)\n",
      "False negative rate: 59.553% (1518/2549)\n",
      "True negative rate: 96.028% (31162/32451)\n",
      "False positive rate: 3.972% (1289/32451)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 26/67: Loss: 0.2043 | Train Acc: 92.121% (33532/36400) | Strict Acc: 46.769% (1216/2600)\n",
      "True positive rate: 40.765% (1077/2642)\n",
      "False negative rate: 59.235% (1565/2642)\n",
      "True negative rate: 96.140% (32455/33758)\n",
      "False positive rate: 3.860% (1303/33758)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 1 - Batch 27/67: Loss: 0.2007 | Train Acc: 92.272% (34879/37800) | Strict Acc: 47.481% (1282/2700)\n",
      "True positive rate: 41.566% (1141/2745)\n",
      "False negative rate: 58.434% (1604/2745)\n",
      "True negative rate: 96.243% (33738/35055)\n",
      "False positive rate: 3.757% (1317/35055)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 28/67: Loss: 0.1982 | Train Acc: 92.360% (36205/39200) | Strict Acc: 47.679% (1335/2800)\n",
      "True positive rate: 41.891% (1196/2855)\n",
      "False negative rate: 58.109% (1659/2855)\n",
      "True negative rate: 96.324% (35009/36345)\n",
      "False positive rate: 3.676% (1336/36345)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 29/67: Loss: 0.1958 | Train Acc: 92.470% (37543/40600) | Strict Acc: 47.862% (1388/2900)\n",
      "True positive rate: 42.284% (1244/2942)\n",
      "False negative rate: 57.716% (1698/2942)\n",
      "True negative rate: 96.391% (36299/37658)\n",
      "False positive rate: 3.609% (1359/37658)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 30/67: Loss: 0.1938 | Train Acc: 92.564% (38877/42000) | Strict Acc: 48.100% (1443/3000)\n",
      "True positive rate: 42.969% (1314/3058)\n",
      "False negative rate: 57.031% (1744/3058)\n",
      "True negative rate: 96.459% (37563/38942)\n",
      "False positive rate: 3.541% (1379/38942)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 31/67: Loss: 0.1906 | Train Acc: 92.700% (40232/43400) | Strict Acc: 48.710% (1510/3100)\n",
      "True positive rate: 43.299% (1357/3134)\n",
      "False negative rate: 56.701% (1777/3134)\n",
      "True negative rate: 96.545% (38875/40266)\n",
      "False positive rate: 3.455% (1391/40266)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 32/67: Loss: 0.1891 | Train Acc: 92.739% (41547/44800) | Strict Acc: 48.656% (1557/3200)\n",
      "True positive rate: 43.353% (1412/3257)\n",
      "False negative rate: 56.647% (1845/3257)\n",
      "True negative rate: 96.611% (40135/41543)\n",
      "False positive rate: 3.389% (1408/41543)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 33/67: Loss: 0.1868 | Train Acc: 92.827% (42886/46200) | Strict Acc: 48.879% (1613/3300)\n",
      "True positive rate: 44.014% (1478/3358)\n",
      "False negative rate: 55.986% (1880/3358)\n",
      "True negative rate: 96.653% (41408/42842)\n",
      "False positive rate: 3.347% (1434/42842)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 34/67: Loss: 0.1846 | Train Acc: 92.891% (44216/47600) | Strict Acc: 49.029% (1667/3400)\n",
      "True positive rate: 44.290% (1528/3450)\n",
      "False negative rate: 55.710% (1922/3450)\n",
      "True negative rate: 96.689% (42688/44150)\n",
      "False positive rate: 3.311% (1462/44150)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 35/67: Loss: 0.1833 | Train Acc: 92.931% (45536/49000) | Strict Acc: 48.971% (1714/3500)\n",
      "True positive rate: 44.615% (1595/3575)\n",
      "False negative rate: 55.385% (1980/3575)\n",
      "True negative rate: 96.733% (43941/45425)\n",
      "False positive rate: 3.267% (1484/45425)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 36/67: Loss: 0.1816 | Train Acc: 92.992% (46868/50400) | Strict Acc: 49.083% (1767/3600)\n",
      "True positive rate: 44.834% (1649/3678)\n",
      "False negative rate: 55.166% (2029/3678)\n",
      "True negative rate: 96.783% (45219/46722)\n",
      "False positive rate: 3.217% (1503/46722)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 37/67: Loss: 0.1800 | Train Acc: 93.046% (48198/51800) | Strict Acc: 49.243% (1822/3700)\n",
      "True positive rate: 45.298% (1715/3786)\n",
      "False negative rate: 54.702% (2071/3786)\n",
      "True negative rate: 96.811% (46483/48014)\n",
      "False positive rate: 3.189% (1531/48014)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 38/67: Loss: 0.1794 | Train Acc: 93.077% (49517/53200) | Strict Acc: 49.316% (1874/3800)\n",
      "True positive rate: 45.361% (1765/3891)\n",
      "False negative rate: 54.639% (2126/3891)\n",
      "True negative rate: 96.842% (47752/49309)\n",
      "False positive rate: 3.158% (1557/49309)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 39/67: Loss: 0.1777 | Train Acc: 93.147% (50858/54600) | Strict Acc: 49.564% (1933/3900)\n",
      "True positive rate: 45.455% (1805/3971)\n",
      "False negative rate: 54.545% (2166/3971)\n",
      "True negative rate: 96.887% (49053/50629)\n",
      "False positive rate: 3.113% (1576/50629)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 40/67: Loss: 0.1761 | Train Acc: 93.214% (52200/56000) | Strict Acc: 49.775% (1991/4000)\n",
      "True positive rate: 45.656% (1855/4063)\n",
      "False negative rate: 54.344% (2208/4063)\n",
      "True negative rate: 96.935% (50345/51937)\n",
      "False positive rate: 3.065% (1592/51937)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 41/67: Loss: 0.1745 | Train Acc: 93.275% (53540/57400) | Strict Acc: 49.902% (2046/4100)\n",
      "True positive rate: 45.650% (1894/4149)\n",
      "False negative rate: 54.350% (2255/4149)\n",
      "True negative rate: 96.986% (51646/53251)\n",
      "False positive rate: 3.014% (1605/53251)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 42/67: Loss: 0.1731 | Train Acc: 93.323% (54874/58800) | Strict Acc: 49.905% (2096/4200)\n",
      "True positive rate: 45.679% (1945/4258)\n",
      "False negative rate: 54.321% (2313/4258)\n",
      "True negative rate: 97.043% (52929/54542)\n",
      "False positive rate: 2.957% (1613/54542)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 43/67: Loss: 0.1714 | Train Acc: 93.382% (56216/60200) | Strict Acc: 50.233% (2160/4300)\n",
      "True positive rate: 45.668% (1982/4340)\n",
      "False negative rate: 54.332% (2358/4340)\n",
      "True negative rate: 97.089% (54234/55860)\n",
      "False positive rate: 2.911% (1626/55860)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 44/67: Loss: 0.1704 | Train Acc: 93.409% (57540/61600) | Strict Acc: 50.273% (2212/4400)\n",
      "True positive rate: 45.583% (2028/4449)\n",
      "False negative rate: 54.417% (2421/4449)\n",
      "True negative rate: 97.132% (55512/57151)\n",
      "False positive rate: 2.868% (1639/57151)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 45/67: Loss: 0.1701 | Train Acc: 93.414% (58851/63000) | Strict Acc: 50.200% (2259/4500)\n",
      "True positive rate: 45.425% (2075/4568)\n",
      "False negative rate: 54.575% (2493/4568)\n",
      "True negative rate: 97.166% (56776/58432)\n",
      "False positive rate: 2.834% (1656/58432)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 46/67: Loss: 0.1687 | Train Acc: 93.461% (60189/64400) | Strict Acc: 50.435% (2320/4600)\n",
      "True positive rate: 45.819% (2137/4664)\n",
      "False negative rate: 54.181% (2527/4664)\n",
      "True negative rate: 97.181% (58052/59736)\n",
      "False positive rate: 2.819% (1684/59736)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 47/67: Loss: 0.1675 | Train Acc: 93.503% (61525/65800) | Strict Acc: 50.447% (2371/4700)\n",
      "True positive rate: 46.039% (2185/4746)\n",
      "False negative rate: 53.961% (2561/4746)\n",
      "True negative rate: 97.193% (59340/61054)\n",
      "False positive rate: 2.807% (1714/61054)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 48/67: Loss: 0.1667 | Train Acc: 93.533% (62854/67200) | Strict Acc: 50.521% (2425/4800)\n",
      "True positive rate: 46.349% (2247/4848)\n",
      "False negative rate: 53.651% (2601/4848)\n",
      "True negative rate: 97.201% (60607/62352)\n",
      "False positive rate: 2.799% (1745/62352)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 49/67: Loss: 0.1655 | Train Acc: 93.580% (64196/68600) | Strict Acc: 50.694% (2484/4900)\n",
      "True positive rate: 46.677% (2311/4951)\n",
      "False negative rate: 53.323% (2640/4951)\n",
      "True negative rate: 97.229% (61885/63649)\n",
      "False positive rate: 2.771% (1764/63649)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 50/67: Loss: 0.1641 | Train Acc: 93.646% (65552/70000) | Strict Acc: 51.020% (2551/5000)\n",
      "True positive rate: 46.852% (2359/5035)\n",
      "False negative rate: 53.148% (2676/5035)\n",
      "True negative rate: 97.272% (63193/64965)\n",
      "False positive rate: 2.728% (1772/64965)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 51/67: Loss: 0.1644 | Train Acc: 93.639% (66858/71400) | Strict Acc: 50.941% (2598/5100)\n",
      "True positive rate: 46.772% (2420/5174)\n",
      "False negative rate: 53.228% (2754/5174)\n",
      "True negative rate: 97.300% (64438/66226)\n",
      "False positive rate: 2.700% (1788/66226)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 1 - Batch 52/67: Loss: 0.1629 | Train Acc: 93.695% (68210/72800) | Strict Acc: 51.231% (2664/5200)\n",
      "True positive rate: 47.167% (2489/5277)\n",
      "False negative rate: 52.833% (2788/5277)\n",
      "True negative rate: 97.331% (65721/67523)\n",
      "False positive rate: 2.669% (1802/67523)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 53/67: Loss: 0.1621 | Train Acc: 93.725% (69544/74200) | Strict Acc: 51.283% (2718/5300)\n",
      "True positive rate: 47.441% (2549/5373)\n",
      "False negative rate: 52.559% (2824/5373)\n",
      "True negative rate: 97.338% (66995/68827)\n",
      "False positive rate: 2.662% (1832/68827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 54/67: Loss: 0.1617 | Train Acc: 93.733% (70862/75600) | Strict Acc: 51.093% (2759/5400)\n",
      "True positive rate: 47.358% (2590/5469)\n",
      "False negative rate: 52.642% (2879/5469)\n",
      "True negative rate: 97.349% (68272/70131)\n",
      "False positive rate: 2.651% (1859/70131)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 55/67: Loss: 0.1611 | Train Acc: 93.760% (72195/77000) | Strict Acc: 51.109% (2811/5500)\n",
      "True positive rate: 47.473% (2640/5561)\n",
      "False negative rate: 52.527% (2921/5561)\n",
      "True negative rate: 97.363% (69555/71439)\n",
      "False positive rate: 2.637% (1884/71439)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 56/67: Loss: 0.1606 | Train Acc: 93.784% (73527/78400) | Strict Acc: 51.179% (2866/5600)\n",
      "True positive rate: 47.485% (2691/5667)\n",
      "False negative rate: 52.515% (2976/5667)\n",
      "True negative rate: 97.392% (70836/72733)\n",
      "False positive rate: 2.608% (1897/72733)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 57/67: Loss: 0.1604 | Train Acc: 93.798% (74851/79800) | Strict Acc: 51.228% (2920/5700)\n",
      "True positive rate: 47.490% (2744/5778)\n",
      "False negative rate: 52.510% (3034/5778)\n",
      "True negative rate: 97.413% (72107/74022)\n",
      "False positive rate: 2.587% (1915/74022)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 58/67: Loss: 0.1592 | Train Acc: 93.844% (76201/81200) | Strict Acc: 51.362% (2979/5800)\n",
      "True positive rate: 47.716% (2799/5866)\n",
      "False negative rate: 52.284% (3067/5866)\n",
      "True negative rate: 97.435% (73402/75334)\n",
      "False positive rate: 2.565% (1932/75334)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 59/67: Loss: 0.1583 | Train Acc: 93.885% (77549/82600) | Strict Acc: 51.559% (3042/5900)\n",
      "True positive rate: 48.050% (2871/5975)\n",
      "False negative rate: 51.950% (3104/5975)\n",
      "True negative rate: 97.459% (74678/76625)\n",
      "False positive rate: 2.541% (1947/76625)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 60/67: Loss: 0.1576 | Train Acc: 93.914% (78888/84000) | Strict Acc: 51.750% (3105/6000)\n",
      "True positive rate: 48.198% (2928/6075)\n",
      "False negative rate: 51.802% (3147/6075)\n",
      "True negative rate: 97.478% (75960/77925)\n",
      "False positive rate: 2.522% (1965/77925)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 61/67: Loss: 0.1569 | Train Acc: 93.944% (80228/85400) | Strict Acc: 51.951% (3169/6100)\n",
      "True positive rate: 48.232% (2974/6166)\n",
      "False negative rate: 51.768% (3192/6166)\n",
      "True negative rate: 97.501% (77254/79234)\n",
      "False positive rate: 2.499% (1980/79234)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 62/67: Loss: 0.1560 | Train Acc: 93.972% (81568/86800) | Strict Acc: 52.097% (3230/6200)\n",
      "True positive rate: 48.315% (3025/6261)\n",
      "False negative rate: 51.685% (3236/6261)\n",
      "True negative rate: 97.522% (78543/80539)\n",
      "False positive rate: 2.478% (1996/80539)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 63/67: Loss: 0.1554 | Train Acc: 93.986% (82896/88200) | Strict Acc: 52.111% (3283/6300)\n",
      "True positive rate: 48.390% (3080/6365)\n",
      "False negative rate: 51.610% (3285/6365)\n",
      "True negative rate: 97.533% (79816/81835)\n",
      "False positive rate: 2.467% (2019/81835)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 64/67: Loss: 0.1549 | Train Acc: 94.002% (84226/89600) | Strict Acc: 52.172% (3339/6400)\n",
      "True positive rate: 48.299% (3123/6466)\n",
      "False negative rate: 51.701% (3343/6466)\n",
      "True negative rate: 97.557% (81103/83134)\n",
      "False positive rate: 2.443% (2031/83134)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 65/67: Loss: 0.1541 | Train Acc: 94.038% (85575/91000) | Strict Acc: 52.369% (3404/6500)\n",
      "True positive rate: 48.461% (3180/6562)\n",
      "False negative rate: 51.539% (3382/6562)\n",
      "True negative rate: 97.580% (82395/84438)\n",
      "False positive rate: 2.420% (2043/84438)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 66/67: Loss: 0.1533 | Train Acc: 94.073% (86923/92400) | Strict Acc: 52.515% (3466/6600)\n",
      "True positive rate: 48.625% (3236/6655)\n",
      "False negative rate: 51.375% (3419/6655)\n",
      "True negative rate: 97.600% (83687/85745)\n",
      "False positive rate: 2.400% (2058/85745)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 67/67: Loss: 0.1530 | Train Acc: 94.077% (88205/93758) | Strict Acc: 52.531% (3518/6697)\n",
      "True positive rate: 48.607% (3281/6750)\n",
      "False negative rate: 51.393% (3469/6750)\n",
      "True negative rate: 97.605% (84924/87008)\n",
      "False positive rate: 2.395% (2084/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1522 | Dev Acc: 94.445% (86170/91238) | Strict Acc: 48.857% (3184/6517)\n",
      "True positive rate: 32.117% (2113/6579)\n",
      "False negative rate: 67.883% (4466/6579)\n",
      "True negative rate: 99.289% (84057/84659)\n",
      "False positive rate: 0.711% (602/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 1/67: Loss: 0.1076 | Train Acc: 96.214% (1347/1400) | Strict Acc: 63.000% (63/100)\n",
      "True positive rate: 62.500% (65/104)\n",
      "False negative rate: 37.500% (39/104)\n",
      "True negative rate: 98.920% (1282/1296)\n",
      "False positive rate: 1.080% (14/1296)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 2/67: Loss: 0.0995 | Train Acc: 96.286% (2696/2800) | Strict Acc: 61.000% (122/200)\n",
      "True positive rate: 63.068% (111/176)\n",
      "False negative rate: 36.932% (65/176)\n",
      "True negative rate: 98.514% (2585/2624)\n",
      "False positive rate: 1.486% (39/2624)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 3/67: Loss: 0.1036 | Train Acc: 96.262% (4043/4200) | Strict Acc: 61.333% (184/300)\n",
      "True positive rate: 60.153% (157/261)\n",
      "False negative rate: 39.847% (104/261)\n",
      "True negative rate: 98.654% (3886/3939)\n",
      "False positive rate: 1.346% (53/3939)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 4/67: Loss: 0.1054 | Train Acc: 96.232% (5389/5600) | Strict Acc: 61.750% (247/400)\n",
      "True positive rate: 57.759% (201/348)\n",
      "False negative rate: 42.241% (147/348)\n",
      "True negative rate: 98.781% (5188/5252)\n",
      "False positive rate: 1.219% (64/5252)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 5/67: Loss: 0.1056 | Train Acc: 96.229% (6736/7000) | Strict Acc: 62.600% (313/500)\n",
      "True positive rate: 59.140% (275/465)\n",
      "False negative rate: 40.860% (190/465)\n",
      "True negative rate: 98.868% (6461/6535)\n",
      "False positive rate: 1.132% (74/6535)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 6/67: Loss: 0.1032 | Train Acc: 96.298% (8089/8400) | Strict Acc: 63.333% (380/600)\n",
      "True positive rate: 59.567% (330/554)\n",
      "False negative rate: 40.433% (224/554)\n",
      "True negative rate: 98.891% (7759/7846)\n",
      "False positive rate: 1.109% (87/7846)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 7/67: Loss: 0.1019 | Train Acc: 96.306% (9438/9800) | Strict Acc: 63.571% (445/700)\n",
      "True positive rate: 59.513% (391/657)\n",
      "False negative rate: 40.487% (266/657)\n",
      "True negative rate: 98.950% (9047/9143)\n",
      "False positive rate: 1.050% (96/9143)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 8/67: Loss: 0.1017 | Train Acc: 96.312% (10787/11200) | Strict Acc: 63.875% (511/800)\n",
      "True positive rate: 60.105% (458/762)\n",
      "False negative rate: 39.895% (304/762)\n",
      "True negative rate: 98.956% (10329/10438)\n",
      "False positive rate: 1.044% (109/10438)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 9/67: Loss: 0.1008 | Train Acc: 96.357% (12141/12600) | Strict Acc: 64.333% (579/900)\n",
      "True positive rate: 61.565% (535/869)\n",
      "False negative rate: 38.435% (334/869)\n",
      "True negative rate: 98.934% (11606/11731)\n",
      "False positive rate: 1.066% (125/11731)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 2 - Batch 10/67: Loss: 0.1016 | Train Acc: 96.307% (13483/14000) | Strict Acc: 64.400% (644/1000)\n",
      "True positive rate: 61.990% (592/955)\n",
      "False negative rate: 38.010% (363/955)\n",
      "True negative rate: 98.819% (12891/13045)\n",
      "False positive rate: 1.181% (154/13045)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 11/67: Loss: 0.1014 | Train Acc: 96.312% (14832/15400) | Strict Acc: 64.364% (708/1100)\n",
      "True positive rate: 62.677% (665/1061)\n",
      "False negative rate: 37.323% (396/1061)\n",
      "True negative rate: 98.800% (14167/14339)\n",
      "False positive rate: 1.200% (172/14339)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 12/67: Loss: 0.1033 | Train Acc: 96.268% (16173/16800) | Strict Acc: 63.833% (766/1200)\n",
      "True positive rate: 62.650% (733/1170)\n",
      "False negative rate: 37.350% (437/1170)\n",
      "True negative rate: 98.784% (15440/15630)\n",
      "False positive rate: 1.216% (190/15630)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 13/67: Loss: 0.1031 | Train Acc: 96.247% (17517/18200) | Strict Acc: 64.077% (833/1300)\n",
      "True positive rate: 62.708% (792/1263)\n",
      "False negative rate: 37.292% (471/1263)\n",
      "True negative rate: 98.748% (16725/16937)\n",
      "False positive rate: 1.252% (212/16937)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 14/67: Loss: 0.1055 | Train Acc: 96.102% (18836/19600) | Strict Acc: 62.857% (880/1400)\n",
      "True positive rate: 61.733% (855/1385)\n",
      "False negative rate: 38.267% (530/1385)\n",
      "True negative rate: 98.715% (17981/18215)\n",
      "False positive rate: 1.285% (234/18215)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 15/67: Loss: 0.1064 | Train Acc: 96.010% (20162/21000) | Strict Acc: 62.400% (936/1500)\n",
      "True positive rate: 60.916% (918/1507)\n",
      "False negative rate: 39.084% (589/1507)\n",
      "True negative rate: 98.723% (19244/19493)\n",
      "False positive rate: 1.277% (249/19493)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 16/67: Loss: 0.1065 | Train Acc: 95.996% (21503/22400) | Strict Acc: 62.125% (994/1600)\n",
      "True positive rate: 60.938% (975/1600)\n",
      "False negative rate: 39.062% (625/1600)\n",
      "True negative rate: 98.692% (20528/20800)\n",
      "False positive rate: 1.308% (272/20800)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 17/67: Loss: 0.1064 | Train Acc: 95.987% (22845/23800) | Strict Acc: 62.235% (1058/1700)\n",
      "True positive rate: 61.404% (1050/1710)\n",
      "False negative rate: 38.596% (660/1710)\n",
      "True negative rate: 98.665% (21795/22090)\n",
      "False positive rate: 1.335% (295/22090)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 18/67: Loss: 0.1067 | Train Acc: 95.988% (24189/25200) | Strict Acc: 62.333% (1122/1800)\n",
      "True positive rate: 61.615% (1114/1808)\n",
      "False negative rate: 38.385% (694/1808)\n",
      "True negative rate: 98.645% (23075/23392)\n",
      "False positive rate: 1.355% (317/23392)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 19/67: Loss: 0.1070 | Train Acc: 95.974% (25529/26600) | Strict Acc: 62.000% (1178/1900)\n",
      "True positive rate: 61.652% (1172/1901)\n",
      "False negative rate: 38.348% (729/1901)\n",
      "True negative rate: 98.615% (24357/24699)\n",
      "False positive rate: 1.385% (342/24699)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 20/67: Loss: 0.1065 | Train Acc: 96.018% (26885/28000) | Strict Acc: 62.350% (1247/2000)\n",
      "True positive rate: 62.060% (1235/1990)\n",
      "False negative rate: 37.940% (755/1990)\n",
      "True negative rate: 98.616% (25650/26010)\n",
      "False positive rate: 1.384% (360/26010)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 21/67: Loss: 0.1057 | Train Acc: 96.054% (28240/29400) | Strict Acc: 62.667% (1316/2100)\n",
      "True positive rate: 62.200% (1295/2082)\n",
      "False negative rate: 37.800% (787/2082)\n",
      "True negative rate: 98.635% (26945/27318)\n",
      "False positive rate: 1.365% (373/27318)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 22/67: Loss: 0.1061 | Train Acc: 96.049% (29583/30800) | Strict Acc: 62.591% (1377/2200)\n",
      "True positive rate: 62.037% (1358/2189)\n",
      "False negative rate: 37.963% (831/2189)\n",
      "True negative rate: 98.651% (28225/28611)\n",
      "False positive rate: 1.349% (386/28611)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 23/67: Loss: 0.1063 | Train Acc: 96.022% (30919/32200) | Strict Acc: 62.435% (1436/2300)\n",
      "True positive rate: 61.371% (1406/2291)\n",
      "False negative rate: 38.629% (885/2291)\n",
      "True negative rate: 98.676% (29513/29909)\n",
      "False positive rate: 1.324% (396/29909)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 24/67: Loss: 0.1064 | Train Acc: 96.003% (32257/33600) | Strict Acc: 62.375% (1497/2400)\n",
      "True positive rate: 61.076% (1464/2397)\n",
      "False negative rate: 38.924% (933/2397)\n",
      "True negative rate: 98.686% (30793/31203)\n",
      "False positive rate: 1.314% (410/31203)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 25/67: Loss: 0.1057 | Train Acc: 96.023% (33608/35000) | Strict Acc: 62.520% (1563/2500)\n",
      "True positive rate: 61.213% (1534/2506)\n",
      "False negative rate: 38.787% (972/2506)\n",
      "True negative rate: 98.707% (32074/32494)\n",
      "False positive rate: 1.293% (420/32494)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 26/67: Loss: 0.1057 | Train Acc: 96.036% (34957/36400) | Strict Acc: 62.385% (1622/2600)\n",
      "True positive rate: 61.390% (1590/2590)\n",
      "False negative rate: 38.610% (1000/2590)\n",
      "True negative rate: 98.690% (33367/33810)\n",
      "False positive rate: 1.310% (443/33810)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 27/67: Loss: 0.1057 | Train Acc: 96.026% (36298/37800) | Strict Acc: 62.296% (1682/2700)\n",
      "True positive rate: 61.501% (1655/2691)\n",
      "False negative rate: 38.499% (1036/2691)\n",
      "True negative rate: 98.673% (34643/35109)\n",
      "False positive rate: 1.327% (466/35109)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 28/67: Loss: 0.1053 | Train Acc: 96.043% (37649/39200) | Strict Acc: 62.250% (1743/2800)\n",
      "True positive rate: 61.946% (1732/2796)\n",
      "False negative rate: 38.054% (1064/2796)\n",
      "True negative rate: 98.662% (35917/36404)\n",
      "False positive rate: 1.338% (487/36404)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 29/67: Loss: 0.1052 | Train Acc: 96.037% (38991/40600) | Strict Acc: 62.207% (1804/2900)\n",
      "True positive rate: 61.854% (1782/2881)\n",
      "False negative rate: 38.146% (1099/2881)\n",
      "True negative rate: 98.648% (37209/37719)\n",
      "False positive rate: 1.352% (510/37719)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 30/67: Loss: 0.1051 | Train Acc: 96.043% (40338/42000) | Strict Acc: 62.400% (1872/3000)\n",
      "True positive rate: 61.814% (1847/2988)\n",
      "False negative rate: 38.186% (1141/2988)\n",
      "True negative rate: 98.665% (38491/39012)\n",
      "False positive rate: 1.335% (521/39012)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 31/67: Loss: 0.1050 | Train Acc: 96.041% (41682/43400) | Strict Acc: 62.516% (1938/3100)\n",
      "True positive rate: 61.765% (1911/3094)\n",
      "False negative rate: 38.235% (1183/3094)\n",
      "True negative rate: 98.673% (39771/40306)\n",
      "False positive rate: 1.327% (535/40306)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 32/67: Loss: 0.1050 | Train Acc: 96.040% (43026/44800) | Strict Acc: 62.562% (2002/3200)\n",
      "True positive rate: 61.575% (1963/3188)\n",
      "False negative rate: 38.425% (1225/3188)\n",
      "True negative rate: 98.681% (41063/41612)\n",
      "False positive rate: 1.319% (549/41612)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 33/67: Loss: 0.1049 | Train Acc: 96.032% (44367/46200) | Strict Acc: 62.455% (2061/3300)\n",
      "True positive rate: 61.608% (2038/3308)\n",
      "False negative rate: 38.392% (1270/3308)\n",
      "True negative rate: 98.687% (42329/42892)\n",
      "False positive rate: 1.313% (563/42892)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 34/67: Loss: 0.1050 | Train Acc: 96.023% (45707/47600) | Strict Acc: 62.235% (2116/3400)\n",
      "True positive rate: 61.657% (2113/3427)\n",
      "False negative rate: 38.343% (1314/3427)\n",
      "True negative rate: 98.689% (43594/44173)\n",
      "False positive rate: 1.311% (579/44173)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 35/67: Loss: 0.1056 | Train Acc: 96.004% (47042/49000) | Strict Acc: 62.143% (2175/3500)\n",
      "True positive rate: 61.780% (2200/3561)\n",
      "False negative rate: 38.220% (1361/3561)\n",
      "True negative rate: 98.686% (44842/45439)\n",
      "False positive rate: 1.314% (597/45439)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 2 - Batch 36/67: Loss: 0.1056 | Train Acc: 95.990% (48379/50400) | Strict Acc: 61.972% (2231/3600)\n",
      "True positive rate: 61.858% (2251/3639)\n",
      "False negative rate: 38.142% (1388/3639)\n",
      "True negative rate: 98.646% (46128/46761)\n",
      "False positive rate: 1.354% (633/46761)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 37/67: Loss: 0.1057 | Train Acc: 95.981% (49718/51800) | Strict Acc: 62.000% (2294/3700)\n",
      "True positive rate: 61.851% (2312/3738)\n",
      "False negative rate: 38.149% (1426/3738)\n",
      "True negative rate: 98.635% (47406/48062)\n",
      "False positive rate: 1.365% (656/48062)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 38/67: Loss: 0.1054 | Train Acc: 95.992% (51068/53200) | Strict Acc: 62.000% (2356/3800)\n",
      "True positive rate: 62.146% (2392/3849)\n",
      "False negative rate: 37.854% (1457/3849)\n",
      "True negative rate: 98.632% (48676/49351)\n",
      "False positive rate: 1.368% (675/49351)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 39/67: Loss: 0.1053 | Train Acc: 95.989% (52410/54600) | Strict Acc: 61.897% (2414/3900)\n",
      "True positive rate: 62.126% (2449/3942)\n",
      "False negative rate: 37.874% (1493/3942)\n",
      "True negative rate: 98.624% (49961/50658)\n",
      "False positive rate: 1.376% (697/50658)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 40/67: Loss: 0.1054 | Train Acc: 95.984% (53751/56000) | Strict Acc: 61.875% (2475/4000)\n",
      "True positive rate: 61.990% (2505/4041)\n",
      "False negative rate: 38.010% (1536/4041)\n",
      "True negative rate: 98.628% (51246/51959)\n",
      "False positive rate: 1.372% (713/51959)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 41/67: Loss: 0.1056 | Train Acc: 95.997% (55102/57400) | Strict Acc: 62.000% (2542/4100)\n",
      "True positive rate: 61.867% (2552/4125)\n",
      "False negative rate: 38.133% (1573/4125)\n",
      "True negative rate: 98.639% (52550/53275)\n",
      "False positive rate: 1.361% (725/53275)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 42/67: Loss: 0.1056 | Train Acc: 95.998% (56447/58800) | Strict Acc: 61.976% (2603/4200)\n",
      "True positive rate: 61.737% (2609/4226)\n",
      "False negative rate: 38.263% (1617/4226)\n",
      "True negative rate: 98.651% (53838/54574)\n",
      "False positive rate: 1.349% (736/54574)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 43/67: Loss: 0.1058 | Train Acc: 95.988% (57785/60200) | Strict Acc: 61.907% (2662/4300)\n",
      "True positive rate: 61.558% (2671/4339)\n",
      "False negative rate: 38.442% (1668/4339)\n",
      "True negative rate: 98.663% (55114/55861)\n",
      "False positive rate: 1.337% (747/55861)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 44/67: Loss: 0.1054 | Train Acc: 96.006% (59140/61600) | Strict Acc: 62.091% (2732/4400)\n",
      "True positive rate: 61.535% (2718/4417)\n",
      "False negative rate: 38.465% (1699/4417)\n",
      "True negative rate: 98.669% (56422/57183)\n",
      "False positive rate: 1.331% (761/57183)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 45/67: Loss: 0.1058 | Train Acc: 95.992% (60475/63000) | Strict Acc: 61.956% (2788/4500)\n",
      "True positive rate: 61.472% (2789/4537)\n",
      "False negative rate: 38.528% (1748/4537)\n",
      "True negative rate: 98.671% (57686/58463)\n",
      "False positive rate: 1.329% (777/58463)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 46/67: Loss: 0.1059 | Train Acc: 95.994% (61820/64400) | Strict Acc: 61.978% (2851/4600)\n",
      "True positive rate: 61.384% (2847/4638)\n",
      "False negative rate: 38.616% (1791/4638)\n",
      "True negative rate: 98.680% (58973/59762)\n",
      "False positive rate: 1.320% (789/59762)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 47/67: Loss: 0.1057 | Train Acc: 95.998% (63167/65800) | Strict Acc: 62.021% (2915/4700)\n",
      "True positive rate: 61.459% (2907/4730)\n",
      "False negative rate: 38.541% (1823/4730)\n",
      "True negative rate: 98.674% (60260/61070)\n",
      "False positive rate: 1.326% (810/61070)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 48/67: Loss: 0.1055 | Train Acc: 96.007% (64517/67200) | Strict Acc: 61.979% (2975/4800)\n",
      "True positive rate: 61.607% (2975/4829)\n",
      "False negative rate: 38.393% (1854/4829)\n",
      "True negative rate: 98.671% (61542/62371)\n",
      "False positive rate: 1.329% (829/62371)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 49/67: Loss: 0.1055 | Train Acc: 95.990% (65849/68600) | Strict Acc: 61.898% (3033/4900)\n",
      "True positive rate: 61.428% (3029/4931)\n",
      "False negative rate: 38.572% (1902/4931)\n",
      "True negative rate: 98.667% (62820/63669)\n",
      "False positive rate: 1.333% (849/63669)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 50/67: Loss: 0.1053 | Train Acc: 95.991% (67194/70000) | Strict Acc: 61.900% (3095/5000)\n",
      "True positive rate: 61.454% (3085/5020)\n",
      "False negative rate: 38.546% (1935/5020)\n",
      "True negative rate: 98.660% (64109/64980)\n",
      "False positive rate: 1.340% (871/64980)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 51/67: Loss: 0.1053 | Train Acc: 95.980% (68530/71400) | Strict Acc: 61.824% (3153/5100)\n",
      "True positive rate: 61.356% (3150/5134)\n",
      "False negative rate: 38.644% (1984/5134)\n",
      "True negative rate: 98.663% (65380/66266)\n",
      "False positive rate: 1.337% (886/66266)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 52/67: Loss: 0.1053 | Train Acc: 95.985% (69877/72800) | Strict Acc: 61.885% (3218/5200)\n",
      "True positive rate: 61.441% (3214/5231)\n",
      "False negative rate: 38.559% (2017/5231)\n",
      "True negative rate: 98.659% (66663/67569)\n",
      "False positive rate: 1.341% (906/67569)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 53/67: Loss: 0.1052 | Train Acc: 95.989% (71224/74200) | Strict Acc: 61.981% (3285/5300)\n",
      "True positive rate: 61.481% (3280/5335)\n",
      "False negative rate: 38.519% (2055/5335)\n",
      "True negative rate: 98.663% (67944/68865)\n",
      "False positive rate: 1.337% (921/68865)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 54/67: Loss: 0.1050 | Train Acc: 96.000% (72576/75600) | Strict Acc: 62.093% (3353/5400)\n",
      "True positive rate: 61.764% (3355/5432)\n",
      "False negative rate: 38.236% (2077/5432)\n",
      "True negative rate: 98.650% (69221/70168)\n",
      "False positive rate: 1.350% (947/70168)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 55/67: Loss: 0.1051 | Train Acc: 95.990% (73912/77000) | Strict Acc: 61.909% (3405/5500)\n",
      "True positive rate: 61.889% (3433/5547)\n",
      "False negative rate: 38.111% (2114/5547)\n",
      "True negative rate: 98.637% (70479/71453)\n",
      "False positive rate: 1.363% (974/71453)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 56/67: Loss: 0.1051 | Train Acc: 95.990% (75256/78400) | Strict Acc: 61.875% (3465/5600)\n",
      "True positive rate: 61.863% (3494/5648)\n",
      "False negative rate: 38.137% (2154/5648)\n",
      "True negative rate: 98.639% (71762/72752)\n",
      "False positive rate: 1.361% (990/72752)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 57/67: Loss: 0.1049 | Train Acc: 96.001% (76609/79800) | Strict Acc: 61.930% (3530/5700)\n",
      "True positive rate: 61.943% (3558/5744)\n",
      "False negative rate: 38.057% (2186/5744)\n",
      "True negative rate: 98.643% (73051/74056)\n",
      "False positive rate: 1.357% (1005/74056)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 58/67: Loss: 0.1051 | Train Acc: 95.980% (77936/81200) | Strict Acc: 61.793% (3584/5800)\n",
      "True positive rate: 61.739% (3621/5865)\n",
      "False negative rate: 38.261% (2244/5865)\n",
      "True negative rate: 98.646% (74315/75335)\n",
      "False positive rate: 1.354% (1020/75335)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 59/67: Loss: 0.1051 | Train Acc: 95.984% (79283/82600) | Strict Acc: 61.746% (3643/5900)\n",
      "True positive rate: 61.812% (3684/5960)\n",
      "False negative rate: 38.188% (2276/5960)\n",
      "True negative rate: 98.642% (75599/76640)\n",
      "False positive rate: 1.358% (1041/76640)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 60/67: Loss: 0.1056 | Train Acc: 95.962% (80608/84000) | Strict Acc: 61.617% (3697/6000)\n",
      "True positive rate: 61.755% (3751/6074)\n",
      "False negative rate: 38.245% (2323/6074)\n",
      "True negative rate: 98.628% (76857/77926)\n",
      "False positive rate: 1.372% (1069/77926)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 2 - Batch 61/67: Loss: 0.1056 | Train Acc: 95.961% (81951/85400) | Strict Acc: 61.574% (3756/6100)\n",
      "True positive rate: 61.856% (3819/6174)\n",
      "False negative rate: 38.144% (2355/6174)\n",
      "True negative rate: 98.619% (78132/79226)\n",
      "False positive rate: 1.381% (1094/79226)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 62/67: Loss: 0.1052 | Train Acc: 95.980% (83311/86800) | Strict Acc: 61.710% (3826/6200)\n",
      "True positive rate: 62.112% (3900/6279)\n",
      "False negative rate: 37.888% (2379/6279)\n",
      "True negative rate: 98.621% (79411/80521)\n",
      "False positive rate: 1.379% (1110/80521)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 63/67: Loss: 0.1054 | Train Acc: 95.967% (84643/88200) | Strict Acc: 61.619% (3882/6300)\n",
      "True positive rate: 62.062% (3972/6400)\n",
      "False negative rate: 37.938% (2428/6400)\n",
      "True negative rate: 98.620% (80671/81800)\n",
      "False positive rate: 1.380% (1129/81800)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 64/67: Loss: 0.1054 | Train Acc: 95.971% (85990/89600) | Strict Acc: 61.625% (3944/6400)\n",
      "True positive rate: 62.015% (4026/6492)\n",
      "False negative rate: 37.985% (2466/6492)\n",
      "True negative rate: 98.623% (81964/83108)\n",
      "False positive rate: 1.377% (1144/83108)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 65/67: Loss: 0.1051 | Train Acc: 95.986% (87347/91000) | Strict Acc: 61.738% (4013/6500)\n",
      "True positive rate: 62.051% (4073/6564)\n",
      "False negative rate: 37.949% (2491/6564)\n",
      "True negative rate: 98.624% (83274/84436)\n",
      "False positive rate: 1.376% (1162/84436)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 66/67: Loss: 0.1047 | Train Acc: 96.005% (88709/92400) | Strict Acc: 61.848% (4082/6600)\n",
      "True positive rate: 62.141% (4138/6659)\n",
      "False negative rate: 37.859% (2521/6659)\n",
      "True negative rate: 98.635% (84571/85741)\n",
      "False positive rate: 1.365% (1170/85741)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 67/67: Loss: 0.1046 | Train Acc: 96.011% (90018/93758) | Strict Acc: 61.849% (4142/6697)\n",
      "True positive rate: 62.163% (4196/6750)\n",
      "False negative rate: 37.837% (2554/6750)\n",
      "True negative rate: 98.637% (85822/87008)\n",
      "False positive rate: 1.363% (1186/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1561 | Dev Acc: 94.302% (86039/91238) | Strict Acc: 49.333% (3215/6517)\n",
      "True positive rate: 25.931% (1706/6579)\n",
      "False negative rate: 74.069% (4873/6579)\n",
      "True negative rate: 99.615% (84333/84659)\n",
      "False positive rate: 0.385% (326/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 1/67: Loss: 0.1114 | Train Acc: 95.429% (1336/1400) | Strict Acc: 57.000% (57/100)\n",
      "True positive rate: 56.780% (67/118)\n",
      "False negative rate: 43.220% (51/118)\n",
      "True negative rate: 98.986% (1269/1282)\n",
      "False positive rate: 1.014% (13/1282)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 2/67: Loss: 0.1056 | Train Acc: 95.500% (2674/2800) | Strict Acc: 58.500% (117/200)\n",
      "True positive rate: 53.881% (118/219)\n",
      "False negative rate: 46.119% (101/219)\n",
      "True negative rate: 99.031% (2556/2581)\n",
      "False positive rate: 0.969% (25/2581)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 3/67: Loss: 0.0981 | Train Acc: 96.167% (4039/4200) | Strict Acc: 62.667% (188/300)\n",
      "True positive rate: 58.224% (177/304)\n",
      "False negative rate: 41.776% (127/304)\n",
      "True negative rate: 99.127% (3862/3896)\n",
      "False positive rate: 0.873% (34/3896)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 4/67: Loss: 0.0981 | Train Acc: 96.107% (5382/5600) | Strict Acc: 62.500% (250/400)\n",
      "True positive rate: 58.040% (231/398)\n",
      "False negative rate: 41.960% (167/398)\n",
      "True negative rate: 99.020% (5151/5202)\n",
      "False positive rate: 0.980% (51/5202)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 5/67: Loss: 0.0934 | Train Acc: 96.343% (6744/7000) | Strict Acc: 64.000% (320/500)\n",
      "True positive rate: 60.808% (301/495)\n",
      "False negative rate: 39.192% (194/495)\n",
      "True negative rate: 99.047% (6443/6505)\n",
      "False positive rate: 0.953% (62/6505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 6/67: Loss: 0.0901 | Train Acc: 96.512% (8107/8400) | Strict Acc: 65.500% (393/600)\n",
      "True positive rate: 62.287% (365/586)\n",
      "False negative rate: 37.713% (221/586)\n",
      "True negative rate: 99.079% (7742/7814)\n",
      "False positive rate: 0.921% (72/7814)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 7/67: Loss: 0.0915 | Train Acc: 96.439% (9451/9800) | Strict Acc: 65.000% (455/700)\n",
      "True positive rate: 61.933% (423/683)\n",
      "False negative rate: 38.067% (260/683)\n",
      "True negative rate: 99.024% (9028/9117)\n",
      "False positive rate: 0.976% (89/9117)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 8/67: Loss: 0.0936 | Train Acc: 96.330% (10789/11200) | Strict Acc: 64.000% (512/800)\n",
      "True positive rate: 61.635% (490/795)\n",
      "False negative rate: 38.365% (305/795)\n",
      "True negative rate: 98.981% (10299/10405)\n",
      "False positive rate: 1.019% (106/10405)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 9/67: Loss: 0.0958 | Train Acc: 96.286% (12132/12600) | Strict Acc: 63.778% (574/900)\n",
      "True positive rate: 62.377% (572/917)\n",
      "False negative rate: 37.623% (345/917)\n",
      "True negative rate: 98.947% (11560/11683)\n",
      "False positive rate: 1.053% (123/11683)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 10/67: Loss: 0.0939 | Train Acc: 96.343% (13488/14000) | Strict Acc: 63.700% (637/1000)\n",
      "True positive rate: 63.824% (651/1020)\n",
      "False negative rate: 36.176% (369/1020)\n",
      "True negative rate: 98.898% (12837/12980)\n",
      "False positive rate: 1.102% (143/12980)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 11/67: Loss: 0.0916 | Train Acc: 96.455% (14854/15400) | Strict Acc: 64.545% (710/1100)\n",
      "True positive rate: 64.964% (712/1096)\n",
      "False negative rate: 35.036% (384/1096)\n",
      "True negative rate: 98.867% (14142/14304)\n",
      "False positive rate: 1.133% (162/14304)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 12/67: Loss: 0.0925 | Train Acc: 96.381% (16192/16800) | Strict Acc: 64.167% (770/1200)\n",
      "True positive rate: 64.887% (778/1199)\n",
      "False negative rate: 35.113% (421/1199)\n",
      "True negative rate: 98.801% (15414/15601)\n",
      "False positive rate: 1.199% (187/15601)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 13/67: Loss: 0.0922 | Train Acc: 96.396% (17544/18200) | Strict Acc: 64.538% (839/1300)\n",
      "True positive rate: 65.475% (861/1315)\n",
      "False negative rate: 34.525% (454/1315)\n",
      "True negative rate: 98.804% (16683/16885)\n",
      "False positive rate: 1.196% (202/16885)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 14/67: Loss: 0.0910 | Train Acc: 96.434% (18901/19600) | Strict Acc: 64.929% (909/1400)\n",
      "True positive rate: 65.731% (913/1389)\n",
      "False negative rate: 34.269% (476/1389)\n",
      "True negative rate: 98.775% (17988/18211)\n",
      "False positive rate: 1.225% (223/18211)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 15/67: Loss: 0.0908 | Train Acc: 96.490% (20263/21000) | Strict Acc: 65.333% (980/1500)\n",
      "True positive rate: 66.016% (981/1486)\n",
      "False negative rate: 33.984% (505/1486)\n",
      "True negative rate: 98.811% (19282/19514)\n",
      "False positive rate: 1.189% (232/19514)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 16/67: Loss: 0.0894 | Train Acc: 96.536% (21624/22400) | Strict Acc: 65.875% (1054/1600)\n",
      "True positive rate: 66.139% (1045/1580)\n",
      "False negative rate: 33.861% (535/1580)\n",
      "True negative rate: 98.842% (20579/20820)\n",
      "False positive rate: 1.158% (241/20820)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 17/67: Loss: 0.0911 | Train Acc: 96.462% (22958/23800) | Strict Acc: 65.471% (1113/1700)\n",
      "True positive rate: 65.431% (1094/1672)\n",
      "False negative rate: 34.569% (578/1672)\n",
      "True negative rate: 98.807% (21864/22128)\n",
      "False positive rate: 1.193% (264/22128)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 18/67: Loss: 0.0913 | Train Acc: 96.448% (24305/25200) | Strict Acc: 65.389% (1177/1800)\n",
      "True positive rate: 65.144% (1155/1773)\n",
      "False negative rate: 34.856% (618/1773)\n",
      "True negative rate: 98.818% (23150/23427)\n",
      "False positive rate: 1.182% (277/23427)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 3 - Batch 19/67: Loss: 0.0902 | Train Acc: 96.474% (25662/26600) | Strict Acc: 65.737% (1249/1900)\n",
      "True positive rate: 65.338% (1229/1881)\n",
      "False negative rate: 34.662% (652/1881)\n",
      "True negative rate: 98.843% (24433/24719)\n",
      "False positive rate: 1.157% (286/24719)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 20/67: Loss: 0.0902 | Train Acc: 96.461% (27009/28000) | Strict Acc: 65.400% (1308/2000)\n",
      "True positive rate: 65.126% (1296/1990)\n",
      "False negative rate: 34.874% (694/1990)\n",
      "True negative rate: 98.858% (25713/26010)\n",
      "False positive rate: 1.142% (297/26010)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 21/67: Loss: 0.0894 | Train Acc: 96.490% (28368/29400) | Strict Acc: 65.667% (1379/2100)\n",
      "True positive rate: 65.744% (1378/2096)\n",
      "False negative rate: 34.256% (718/2096)\n",
      "True negative rate: 98.850% (26990/27304)\n",
      "False positive rate: 1.150% (314/27304)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 22/67: Loss: 0.0897 | Train Acc: 96.510% (29725/30800) | Strict Acc: 65.818% (1448/2200)\n",
      "True positive rate: 65.923% (1447/2195)\n",
      "False negative rate: 34.077% (748/2195)\n",
      "True negative rate: 98.857% (28278/28605)\n",
      "False positive rate: 1.143% (327/28605)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 23/67: Loss: 0.0910 | Train Acc: 96.463% (31061/32200) | Strict Acc: 65.696% (1511/2300)\n",
      "True positive rate: 65.869% (1513/2297)\n",
      "False negative rate: 34.131% (784/2297)\n",
      "True negative rate: 98.813% (29548/29903)\n",
      "False positive rate: 1.187% (355/29903)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 24/67: Loss: 0.0913 | Train Acc: 96.438% (32403/33600) | Strict Acc: 65.417% (1570/2400)\n",
      "True positive rate: 66.065% (1573/2381)\n",
      "False negative rate: 33.935% (808/2381)\n",
      "True negative rate: 98.754% (30830/31219)\n",
      "False positive rate: 1.246% (389/31219)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 25/67: Loss: 0.0920 | Train Acc: 96.423% (33748/35000) | Strict Acc: 65.400% (1635/2500)\n",
      "True positive rate: 66.014% (1651/2501)\n",
      "False negative rate: 33.986% (850/2501)\n",
      "True negative rate: 98.763% (32097/32499)\n",
      "False positive rate: 1.237% (402/32499)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 26/67: Loss: 0.0923 | Train Acc: 96.396% (35088/36400) | Strict Acc: 65.346% (1699/2600)\n",
      "True positive rate: 65.823% (1716/2607)\n",
      "False negative rate: 34.177% (891/2607)\n",
      "True negative rate: 98.754% (33372/33793)\n",
      "False positive rate: 1.246% (421/33793)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 27/67: Loss: 0.0916 | Train Acc: 96.429% (36450/37800) | Strict Acc: 65.630% (1772/2700)\n",
      "True positive rate: 65.984% (1773/2687)\n",
      "False negative rate: 34.016% (914/2687)\n",
      "True negative rate: 98.758% (34677/35113)\n",
      "False positive rate: 1.242% (436/35113)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 28/67: Loss: 0.0915 | Train Acc: 96.418% (37796/39200) | Strict Acc: 65.464% (1833/2800)\n",
      "True positive rate: 65.891% (1841/2794)\n",
      "False negative rate: 34.109% (953/2794)\n",
      "True negative rate: 98.761% (35955/36406)\n",
      "False positive rate: 1.239% (451/36406)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 29/67: Loss: 0.0918 | Train Acc: 96.387% (39133/40600) | Strict Acc: 65.379% (1896/2900)\n",
      "True positive rate: 65.623% (1907/2906)\n",
      "False negative rate: 34.377% (999/2906)\n",
      "True negative rate: 98.758% (37226/37694)\n",
      "False positive rate: 1.242% (468/37694)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 30/67: Loss: 0.0915 | Train Acc: 96.410% (40492/42000) | Strict Acc: 65.500% (1965/3000)\n",
      "True positive rate: 65.835% (1979/3006)\n",
      "False negative rate: 34.165% (1027/3006)\n",
      "True negative rate: 98.766% (38513/38994)\n",
      "False positive rate: 1.234% (481/38994)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 31/67: Loss: 0.0923 | Train Acc: 96.373% (41826/43400) | Strict Acc: 65.258% (2023/3100)\n",
      "True positive rate: 65.494% (2048/3127)\n",
      "False negative rate: 34.506% (1079/3127)\n",
      "True negative rate: 98.771% (39778/40273)\n",
      "False positive rate: 1.229% (495/40273)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 32/67: Loss: 0.0926 | Train Acc: 96.366% (43172/44800) | Strict Acc: 65.312% (2090/3200)\n",
      "True positive rate: 65.675% (2120/3228)\n",
      "False negative rate: 34.325% (1108/3228)\n",
      "True negative rate: 98.749% (41052/41572)\n",
      "False positive rate: 1.251% (520/41572)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 33/67: Loss: 0.0928 | Train Acc: 96.357% (44517/46200) | Strict Acc: 65.182% (2151/3300)\n",
      "True positive rate: 65.802% (2182/3316)\n",
      "False negative rate: 34.198% (1134/3316)\n",
      "True negative rate: 98.720% (42335/42884)\n",
      "False positive rate: 1.280% (549/42884)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 34/67: Loss: 0.0931 | Train Acc: 96.353% (45864/47600) | Strict Acc: 65.118% (2214/3400)\n",
      "True positive rate: 65.806% (2242/3407)\n",
      "False negative rate: 34.194% (1165/3407)\n",
      "True negative rate: 98.708% (43622/44193)\n",
      "False positive rate: 1.292% (571/44193)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 35/67: Loss: 0.0937 | Train Acc: 96.343% (47208/49000) | Strict Acc: 64.971% (2274/3500)\n",
      "True positive rate: 65.739% (2314/3520)\n",
      "False negative rate: 34.261% (1206/3520)\n",
      "True negative rate: 98.712% (44894/45480)\n",
      "False positive rate: 1.288% (586/45480)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 36/67: Loss: 0.0936 | Train Acc: 96.351% (48561/50400) | Strict Acc: 64.972% (2339/3600)\n",
      "True positive rate: 65.820% (2384/3622)\n",
      "False negative rate: 34.180% (1238/3622)\n",
      "True negative rate: 98.715% (46177/46778)\n",
      "False positive rate: 1.285% (601/46778)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 37/67: Loss: 0.0931 | Train Acc: 96.367% (49918/51800) | Strict Acc: 65.054% (2407/3700)\n",
      "True positive rate: 65.717% (2444/3719)\n",
      "False negative rate: 34.283% (1275/3719)\n",
      "True negative rate: 98.738% (47474/48081)\n",
      "False positive rate: 1.262% (607/48081)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 38/67: Loss: 0.0929 | Train Acc: 96.385% (51277/53200) | Strict Acc: 65.211% (2478/3800)\n",
      "True positive rate: 65.718% (2494/3795)\n",
      "False negative rate: 34.282% (1301/3795)\n",
      "True negative rate: 98.741% (48783/49405)\n",
      "False positive rate: 1.259% (622/49405)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 39/67: Loss: 0.0921 | Train Acc: 96.419% (52645/54600) | Strict Acc: 65.385% (2550/3900)\n",
      "True positive rate: 65.927% (2556/3877)\n",
      "False negative rate: 34.073% (1321/3877)\n",
      "True negative rate: 98.750% (50089/50723)\n",
      "False positive rate: 1.250% (634/50723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 40/67: Loss: 0.0927 | Train Acc: 96.411% (53990/56000) | Strict Acc: 65.325% (2613/4000)\n",
      "True positive rate: 65.696% (2618/3985)\n",
      "False negative rate: 34.304% (1367/3985)\n",
      "True negative rate: 98.764% (51372/52015)\n",
      "False positive rate: 1.236% (643/52015)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 41/67: Loss: 0.0929 | Train Acc: 96.399% (55333/57400) | Strict Acc: 65.220% (2674/4100)\n",
      "True positive rate: 65.400% (2667/4078)\n",
      "False negative rate: 34.600% (1411/4078)\n",
      "True negative rate: 98.770% (52666/53322)\n",
      "False positive rate: 1.230% (656/53322)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 42/67: Loss: 0.0936 | Train Acc: 96.376% (56669/58800) | Strict Acc: 65.071% (2733/4200)\n",
      "True positive rate: 65.135% (2735/4199)\n",
      "False negative rate: 34.865% (1464/4199)\n",
      "True negative rate: 98.778% (53934/54601)\n",
      "False positive rate: 1.222% (667/54601)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 43/67: Loss: 0.0937 | Train Acc: 96.367% (58013/60200) | Strict Acc: 64.953% (2793/4300)\n",
      "True positive rate: 65.206% (2813/4314)\n",
      "False negative rate: 34.794% (1501/4314)\n",
      "True negative rate: 98.773% (55200/55886)\n",
      "False positive rate: 1.227% (686/55886)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 44/67: Loss: 0.0936 | Train Acc: 96.380% (59370/61600) | Strict Acc: 65.000% (2860/4400)\n",
      "True positive rate: 65.351% (2882/4410)\n",
      "False negative rate: 34.649% (1528/4410)\n",
      "True negative rate: 98.773% (56488/57190)\n",
      "False positive rate: 1.227% (702/57190)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 3 - Batch 45/67: Loss: 0.0937 | Train Acc: 96.383% (60721/63000) | Strict Acc: 65.022% (2926/4500)\n",
      "True positive rate: 65.601% (2956/4506)\n",
      "False negative rate: 34.399% (1550/4506)\n",
      "True negative rate: 98.754% (57765/58494)\n",
      "False positive rate: 1.246% (729/58494)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 46/67: Loss: 0.0936 | Train Acc: 96.387% (62073/64400) | Strict Acc: 64.891% (2985/4600)\n",
      "True positive rate: 65.885% (3036/4608)\n",
      "False negative rate: 34.115% (1572/4608)\n",
      "True negative rate: 98.737% (59037/59792)\n",
      "False positive rate: 1.263% (755/59792)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 47/67: Loss: 0.0940 | Train Acc: 96.380% (63418/65800) | Strict Acc: 64.830% (3047/4700)\n",
      "True positive rate: 65.952% (3105/4708)\n",
      "False negative rate: 34.048% (1603/4708)\n",
      "True negative rate: 98.725% (60313/61092)\n",
      "False positive rate: 1.275% (779/61092)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 48/67: Loss: 0.0937 | Train Acc: 96.393% (64776/67200) | Strict Acc: 64.875% (3114/4800)\n",
      "True positive rate: 66.036% (3177/4811)\n",
      "False negative rate: 33.964% (1634/4811)\n",
      "True negative rate: 98.734% (61599/62389)\n",
      "False positive rate: 1.266% (790/62389)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 49/67: Loss: 0.0937 | Train Acc: 96.407% (66135/68600) | Strict Acc: 65.020% (3186/4900)\n",
      "True positive rate: 66.033% (3233/4896)\n",
      "False negative rate: 33.967% (1663/4896)\n",
      "True negative rate: 98.741% (62902/63704)\n",
      "False positive rate: 1.259% (802/63704)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 50/67: Loss: 0.0942 | Train Acc: 96.401% (67481/70000) | Strict Acc: 65.020% (3251/5000)\n",
      "True positive rate: 65.941% (3303/5009)\n",
      "False negative rate: 34.059% (1706/5009)\n",
      "True negative rate: 98.749% (64178/64991)\n",
      "False positive rate: 1.251% (813/64991)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 51/67: Loss: 0.0946 | Train Acc: 96.394% (68825/71400) | Strict Acc: 65.039% (3317/5100)\n",
      "True positive rate: 65.715% (3360/5113)\n",
      "False negative rate: 34.285% (1753/5113)\n",
      "True negative rate: 98.760% (65465/66287)\n",
      "False positive rate: 1.240% (822/66287)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 52/67: Loss: 0.0944 | Train Acc: 96.393% (70174/72800) | Strict Acc: 65.038% (3382/5200)\n",
      "True positive rate: 65.670% (3428/5220)\n",
      "False negative rate: 34.330% (1792/5220)\n",
      "True negative rate: 98.766% (66746/67580)\n",
      "False positive rate: 1.234% (834/67580)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 53/67: Loss: 0.0944 | Train Acc: 96.392% (71523/74200) | Strict Acc: 65.038% (3447/5300)\n",
      "True positive rate: 65.744% (3491/5310)\n",
      "False negative rate: 34.256% (1819/5310)\n",
      "True negative rate: 98.755% (68032/68890)\n",
      "False positive rate: 1.245% (858/68890)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 54/67: Loss: 0.0946 | Train Acc: 96.392% (72872/75600) | Strict Acc: 65.093% (3515/5400)\n",
      "True positive rate: 65.823% (3563/5413)\n",
      "False negative rate: 34.177% (1850/5413)\n",
      "True negative rate: 98.749% (69309/70187)\n",
      "False positive rate: 1.251% (878/70187)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 55/67: Loss: 0.0945 | Train Acc: 96.386% (74217/77000) | Strict Acc: 65.018% (3576/5500)\n",
      "True positive rate: 65.905% (3632/5511)\n",
      "False negative rate: 34.095% (1879/5511)\n",
      "True negative rate: 98.735% (70585/71489)\n",
      "False positive rate: 1.265% (904/71489)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 56/67: Loss: 0.0947 | Train Acc: 96.376% (75559/78400) | Strict Acc: 64.929% (3636/5600)\n",
      "True positive rate: 65.998% (3717/5632)\n",
      "False negative rate: 34.002% (1915/5632)\n",
      "True negative rate: 98.727% (71842/72768)\n",
      "False positive rate: 1.273% (926/72768)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 57/67: Loss: 0.0948 | Train Acc: 96.371% (76904/79800) | Strict Acc: 64.877% (3698/5700)\n",
      "True positive rate: 66.022% (3791/5742)\n",
      "False negative rate: 33.978% (1951/5742)\n",
      "True negative rate: 98.724% (73113/74058)\n",
      "False positive rate: 1.276% (945/74058)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 58/67: Loss: 0.0949 | Train Acc: 96.369% (78252/81200) | Strict Acc: 64.879% (3763/5800)\n",
      "True positive rate: 66.006% (3866/5857)\n",
      "False negative rate: 33.994% (1991/5857)\n",
      "True negative rate: 98.730% (74386/75343)\n",
      "False positive rate: 1.270% (957/75343)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 59/67: Loss: 0.0951 | Train Acc: 96.355% (79589/82600) | Strict Acc: 64.780% (3822/5900)\n",
      "True positive rate: 65.832% (3915/5947)\n",
      "False negative rate: 34.168% (2032/5947)\n",
      "True negative rate: 98.723% (75674/76653)\n",
      "False positive rate: 1.277% (979/76653)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 60/67: Loss: 0.0952 | Train Acc: 96.358% (80941/84000) | Strict Acc: 64.817% (3889/6000)\n",
      "True positive rate: 65.684% (3964/6035)\n",
      "False negative rate: 34.316% (2071/6035)\n",
      "True negative rate: 98.733% (76977/77965)\n",
      "False positive rate: 1.267% (988/77965)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 61/67: Loss: 0.0949 | Train Acc: 96.362% (82293/85400) | Strict Acc: 64.934% (3961/6100)\n",
      "True positive rate: 65.543% (4006/6112)\n",
      "False negative rate: 34.457% (2106/6112)\n",
      "True negative rate: 98.738% (78287/79288)\n",
      "False positive rate: 1.262% (1001/79288)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 62/67: Loss: 0.0949 | Train Acc: 96.361% (83641/86800) | Strict Acc: 64.952% (4027/6200)\n",
      "True positive rate: 65.416% (4063/6211)\n",
      "False negative rate: 34.584% (2148/6211)\n",
      "True negative rate: 98.745% (79578/80589)\n",
      "False positive rate: 1.255% (1011/80589)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 63/67: Loss: 0.0952 | Train Acc: 96.357% (84987/88200) | Strict Acc: 64.921% (4090/6300)\n",
      "True positive rate: 65.279% (4123/6316)\n",
      "False negative rate: 34.721% (2193/6316)\n",
      "True negative rate: 98.754% (80864/81884)\n",
      "False positive rate: 1.246% (1020/81884)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 64/67: Loss: 0.0959 | Train Acc: 96.326% (86308/89600) | Strict Acc: 64.781% (4146/6400)\n",
      "True positive rate: 64.953% (4181/6437)\n",
      "False negative rate: 35.047% (2256/6437)\n",
      "True negative rate: 98.754% (82127/83163)\n",
      "False positive rate: 1.246% (1036/83163)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 65/67: Loss: 0.0960 | Train Acc: 96.315% (87647/91000) | Strict Acc: 64.754% (4209/6500)\n",
      "True positive rate: 64.916% (4252/6550)\n",
      "False negative rate: 35.084% (2298/6550)\n",
      "True negative rate: 98.751% (83395/84450)\n",
      "False positive rate: 1.249% (1055/84450)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 66/67: Loss: 0.0959 | Train Acc: 96.324% (89003/92400) | Strict Acc: 64.894% (4283/6600)\n",
      "True positive rate: 65.054% (4330/6656)\n",
      "False negative rate: 34.946% (2326/6656)\n",
      "True negative rate: 98.751% (84673/85744)\n",
      "False positive rate: 1.249% (1071/85744)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 67/67: Loss: 0.0959 | Train Acc: 96.329% (90316/93758) | Strict Acc: 64.925% (4348/6697)\n",
      "True positive rate: 65.200% (4401/6750)\n",
      "False negative rate: 34.800% (2349/6750)\n",
      "True negative rate: 98.744% (85915/87008)\n",
      "False positive rate: 1.256% (1093/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1758 | Dev Acc: 93.582% (85382/91238) | Strict Acc: 39.221% (2556/6517)\n",
      "True positive rate: 53.990% (3552/6579)\n",
      "False negative rate: 46.010% (3027/6579)\n",
      "True negative rate: 96.658% (81830/84659)\n",
      "False positive rate: 3.342% (2829/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 1/67: Loss: 0.0910 | Train Acc: 96.714% (1354/1400) | Strict Acc: 63.000% (63/100)\n",
      "True positive rate: 78.899% (86/109)\n",
      "False negative rate: 21.101% (23/109)\n",
      "True negative rate: 98.218% (1268/1291)\n",
      "False positive rate: 1.782% (23/1291)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 2/67: Loss: 0.0963 | Train Acc: 96.286% (2696/2800) | Strict Acc: 60.500% (121/200)\n",
      "True positive rate: 75.000% (165/220)\n",
      "False negative rate: 25.000% (55/220)\n",
      "True negative rate: 98.101% (2531/2580)\n",
      "False positive rate: 1.899% (49/2580)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 4 - Batch 3/67: Loss: 0.0879 | Train Acc: 96.714% (4062/4200) | Strict Acc: 64.333% (193/300)\n",
      "True positive rate: 75.896% (233/307)\n",
      "False negative rate: 24.104% (74/307)\n",
      "True negative rate: 98.356% (3829/3893)\n",
      "False positive rate: 1.644% (64/3893)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 4/67: Loss: 0.0816 | Train Acc: 96.857% (5424/5600) | Strict Acc: 66.250% (265/400)\n",
      "True positive rate: 74.873% (295/394)\n",
      "False negative rate: 25.127% (99/394)\n",
      "True negative rate: 98.521% (5129/5206)\n",
      "False positive rate: 1.479% (77/5206)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 5/67: Loss: 0.0824 | Train Acc: 96.714% (6770/7000) | Strict Acc: 66.200% (331/500)\n",
      "True positive rate: 71.116% (357/502)\n",
      "False negative rate: 28.884% (145/502)\n",
      "True negative rate: 98.692% (6413/6498)\n",
      "False positive rate: 1.308% (85/6498)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 6/67: Loss: 0.0900 | Train Acc: 96.440% (8101/8400) | Strict Acc: 64.833% (389/600)\n",
      "True positive rate: 67.141% (425/633)\n",
      "False negative rate: 32.859% (208/633)\n",
      "True negative rate: 98.828% (7676/7767)\n",
      "False positive rate: 1.172% (91/7767)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 7/67: Loss: 0.0923 | Train Acc: 96.347% (9442/9800) | Strict Acc: 64.286% (450/700)\n",
      "True positive rate: 65.981% (481/729)\n",
      "False negative rate: 34.019% (248/729)\n",
      "True negative rate: 98.787% (8961/9071)\n",
      "False positive rate: 1.213% (110/9071)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 8/67: Loss: 0.0927 | Train Acc: 96.304% (10786/11200) | Strict Acc: 64.250% (514/800)\n",
      "True positive rate: 66.159% (565/854)\n",
      "False negative rate: 33.841% (289/854)\n",
      "True negative rate: 98.792% (10221/10346)\n",
      "False positive rate: 1.208% (125/10346)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 9/67: Loss: 0.0928 | Train Acc: 96.365% (12142/12600) | Strict Acc: 64.778% (583/900)\n",
      "True positive rate: 67.015% (642/958)\n",
      "False negative rate: 32.985% (316/958)\n",
      "True negative rate: 98.780% (11500/11642)\n",
      "False positive rate: 1.220% (142/11642)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 10/67: Loss: 0.0907 | Train Acc: 96.436% (13501/14000) | Strict Acc: 65.200% (652/1000)\n",
      "True positive rate: 67.985% (722/1062)\n",
      "False negative rate: 32.015% (340/1062)\n",
      "True negative rate: 98.771% (12779/12938)\n",
      "False positive rate: 1.229% (159/12938)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 11/67: Loss: 0.0920 | Train Acc: 96.396% (14845/15400) | Strict Acc: 65.000% (715/1100)\n",
      "True positive rate: 68.151% (796/1168)\n",
      "False negative rate: 31.849% (372/1168)\n",
      "True negative rate: 98.714% (14049/14232)\n",
      "False positive rate: 1.286% (183/14232)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 12/67: Loss: 0.0916 | Train Acc: 96.429% (16200/16800) | Strict Acc: 65.000% (780/1200)\n",
      "True positive rate: 69.134% (878/1270)\n",
      "False negative rate: 30.866% (392/1270)\n",
      "True negative rate: 98.661% (15322/15530)\n",
      "False positive rate: 1.339% (208/15530)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 13/67: Loss: 0.0913 | Train Acc: 96.440% (17552/18200) | Strict Acc: 65.154% (847/1300)\n",
      "True positive rate: 69.455% (955/1375)\n",
      "False negative rate: 30.545% (420/1375)\n",
      "True negative rate: 98.645% (16597/16825)\n",
      "False positive rate: 1.355% (228/16825)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 14/67: Loss: 0.0905 | Train Acc: 96.490% (18912/19600) | Strict Acc: 65.857% (922/1400)\n",
      "True positive rate: 69.952% (1029/1471)\n",
      "False negative rate: 30.048% (442/1471)\n",
      "True negative rate: 98.643% (17883/18129)\n",
      "False positive rate: 1.357% (246/18129)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 15/67: Loss: 0.0898 | Train Acc: 96.529% (20271/21000) | Strict Acc: 65.867% (988/1500)\n",
      "True positive rate: 69.803% (1098/1573)\n",
      "False negative rate: 30.197% (475/1573)\n",
      "True negative rate: 98.693% (19173/19427)\n",
      "False positive rate: 1.307% (254/19427)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 16/67: Loss: 0.0907 | Train Acc: 96.442% (21603/22400) | Strict Acc: 65.188% (1043/1600)\n",
      "True positive rate: 68.477% (1160/1694)\n",
      "False negative rate: 31.523% (534/1694)\n",
      "True negative rate: 98.730% (20443/20706)\n",
      "False positive rate: 1.270% (263/20706)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 17/67: Loss: 0.0909 | Train Acc: 96.420% (22948/23800) | Strict Acc: 65.235% (1109/1700)\n",
      "True positive rate: 67.980% (1225/1802)\n",
      "False negative rate: 32.020% (577/1802)\n",
      "True negative rate: 98.750% (21723/21998)\n",
      "False positive rate: 1.250% (275/21998)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 18/67: Loss: 0.0899 | Train Acc: 96.460% (24308/25200) | Strict Acc: 65.611% (1181/1800)\n",
      "True positive rate: 68.182% (1290/1892)\n",
      "False negative rate: 31.818% (602/1892)\n",
      "True negative rate: 98.756% (23018/23308)\n",
      "False positive rate: 1.244% (290/23308)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 19/67: Loss: 0.0891 | Train Acc: 96.504% (25670/26600) | Strict Acc: 65.895% (1252/1900)\n",
      "True positive rate: 68.069% (1343/1973)\n",
      "False negative rate: 31.931% (630/1973)\n",
      "True negative rate: 98.782% (24327/24627)\n",
      "False positive rate: 1.218% (300/24627)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 20/67: Loss: 0.0890 | Train Acc: 96.500% (27020/28000) | Strict Acc: 66.000% (1320/2000)\n",
      "True positive rate: 67.950% (1412/2078)\n",
      "False negative rate: 32.050% (666/2078)\n",
      "True negative rate: 98.789% (25608/25922)\n",
      "False positive rate: 1.211% (314/25922)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 21/67: Loss: 0.0882 | Train Acc: 96.541% (28383/29400) | Strict Acc: 66.381% (1394/2100)\n",
      "True positive rate: 68.370% (1485/2172)\n",
      "False negative rate: 31.630% (687/2172)\n",
      "True negative rate: 98.788% (26898/27228)\n",
      "False positive rate: 1.212% (330/27228)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 22/67: Loss: 0.0888 | Train Acc: 96.490% (29719/30800) | Strict Acc: 66.000% (1452/2200)\n",
      "True positive rate: 68.101% (1567/2301)\n",
      "False negative rate: 31.899% (734/2301)\n",
      "True negative rate: 98.782% (28152/28499)\n",
      "False positive rate: 1.218% (347/28499)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 23/67: Loss: 0.0887 | Train Acc: 96.509% (31076/32200) | Strict Acc: 66.261% (1524/2300)\n",
      "True positive rate: 68.507% (1638/2391)\n",
      "False negative rate: 31.493% (753/2391)\n",
      "True negative rate: 98.755% (29438/29809)\n",
      "False positive rate: 1.245% (371/29809)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 24/67: Loss: 0.0893 | Train Acc: 96.494% (32422/33600) | Strict Acc: 66.083% (1586/2400)\n",
      "True positive rate: 68.326% (1702/2491)\n",
      "False negative rate: 31.674% (789/2491)\n",
      "True negative rate: 98.750% (30720/31109)\n",
      "False positive rate: 1.250% (389/31109)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 25/67: Loss: 0.0885 | Train Acc: 96.523% (33783/35000) | Strict Acc: 66.400% (1660/2500)\n",
      "True positive rate: 68.472% (1757/2566)\n",
      "False negative rate: 31.528% (809/2566)\n",
      "True negative rate: 98.742% (32026/32434)\n",
      "False positive rate: 1.258% (408/32434)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 26/67: Loss: 0.0886 | Train Acc: 96.519% (35133/36400) | Strict Acc: 66.346% (1725/2600)\n",
      "True positive rate: 68.470% (1822/2661)\n",
      "False negative rate: 31.530% (839/2661)\n",
      "True negative rate: 98.731% (33311/33739)\n",
      "False positive rate: 1.269% (428/33739)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 27/67: Loss: 0.0883 | Train Acc: 96.508% (36480/37800) | Strict Acc: 66.259% (1789/2700)\n",
      "True positive rate: 68.083% (1875/2754)\n",
      "False negative rate: 31.917% (879/2754)\n",
      "True negative rate: 98.742% (34605/35046)\n",
      "False positive rate: 1.258% (441/35046)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 28/67: Loss: 0.0882 | Train Acc: 96.503% (37829/39200) | Strict Acc: 66.286% (1856/2800)\n",
      "True positive rate: 67.792% (1928/2844)\n",
      "False negative rate: 32.208% (916/2844)\n",
      "True negative rate: 98.748% (35901/36356)\n",
      "False positive rate: 1.252% (455/36356)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 4 - Batch 29/67: Loss: 0.0878 | Train Acc: 96.522% (39188/40600) | Strict Acc: 66.379% (1925/2900)\n",
      "True positive rate: 67.746% (1987/2933)\n",
      "False negative rate: 32.254% (946/2933)\n",
      "True negative rate: 98.763% (37201/37667)\n",
      "False positive rate: 1.237% (466/37667)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 30/67: Loss: 0.0874 | Train Acc: 96.536% (40545/42000) | Strict Acc: 66.433% (1993/3000)\n",
      "True positive rate: 67.678% (2052/3032)\n",
      "False negative rate: 32.322% (980/3032)\n",
      "True negative rate: 98.781% (38493/38968)\n",
      "False positive rate: 1.219% (475/38968)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 31/67: Loss: 0.0877 | Train Acc: 96.525% (41892/43400) | Strict Acc: 66.387% (2058/3100)\n",
      "True positive rate: 67.394% (2100/3116)\n",
      "False negative rate: 32.606% (1016/3116)\n",
      "True negative rate: 98.779% (39792/40284)\n",
      "False positive rate: 1.221% (492/40284)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 32/67: Loss: 0.0885 | Train Acc: 96.482% (43224/44800) | Strict Acc: 66.094% (2115/3200)\n",
      "True positive rate: 66.811% (2154/3224)\n",
      "False negative rate: 33.189% (1070/3224)\n",
      "True negative rate: 98.783% (41070/41576)\n",
      "False positive rate: 1.217% (506/41576)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 33/67: Loss: 0.0889 | Train Acc: 96.478% (44573/46200) | Strict Acc: 66.000% (2178/3300)\n",
      "True positive rate: 66.968% (2224/3321)\n",
      "False negative rate: 33.032% (1097/3321)\n",
      "True negative rate: 98.764% (42349/42879)\n",
      "False positive rate: 1.236% (530/42879)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 34/67: Loss: 0.0884 | Train Acc: 96.494% (45931/47600) | Strict Acc: 66.147% (2249/3400)\n",
      "True positive rate: 67.406% (2310/3427)\n",
      "False negative rate: 32.594% (1117/3427)\n",
      "True negative rate: 98.750% (43621/44173)\n",
      "False positive rate: 1.250% (552/44173)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 35/67: Loss: 0.0880 | Train Acc: 96.512% (47291/49000) | Strict Acc: 66.286% (2320/3500)\n",
      "True positive rate: 67.720% (2379/3513)\n",
      "False negative rate: 32.280% (1134/3513)\n",
      "True negative rate: 98.736% (44912/45487)\n",
      "False positive rate: 1.264% (575/45487)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 36/67: Loss: 0.0882 | Train Acc: 96.500% (48636/50400) | Strict Acc: 66.250% (2385/3600)\n",
      "True positive rate: 68.011% (2462/3620)\n",
      "False negative rate: 31.989% (1158/3620)\n",
      "True negative rate: 98.705% (46174/46780)\n",
      "False positive rate: 1.295% (606/46780)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 37/67: Loss: 0.0882 | Train Acc: 96.531% (50003/51800) | Strict Acc: 66.432% (2458/3700)\n",
      "True positive rate: 68.099% (2519/3699)\n",
      "False negative rate: 31.901% (1180/3699)\n",
      "True negative rate: 98.717% (47484/48101)\n",
      "False positive rate: 1.283% (617/48101)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 38/67: Loss: 0.0883 | Train Acc: 96.536% (51357/53200) | Strict Acc: 66.474% (2526/3800)\n",
      "True positive rate: 68.150% (2589/3799)\n",
      "False negative rate: 31.850% (1210/3799)\n",
      "True negative rate: 98.719% (48768/49401)\n",
      "False positive rate: 1.281% (633/49401)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 39/67: Loss: 0.0880 | Train Acc: 96.553% (52718/54600) | Strict Acc: 66.564% (2596/3900)\n",
      "True positive rate: 68.157% (2652/3891)\n",
      "False negative rate: 31.843% (1239/3891)\n",
      "True negative rate: 98.732% (50066/50709)\n",
      "False positive rate: 1.268% (643/50709)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 40/67: Loss: 0.0877 | Train Acc: 96.579% (54084/56000) | Strict Acc: 66.875% (2675/4000)\n",
      "True positive rate: 68.266% (2717/3980)\n",
      "False negative rate: 31.734% (1263/3980)\n",
      "True negative rate: 98.745% (51367/52020)\n",
      "False positive rate: 1.255% (653/52020)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 41/67: Loss: 0.0878 | Train Acc: 96.580% (55437/57400) | Strict Acc: 66.878% (2742/4100)\n",
      "True positive rate: 68.167% (2786/4087)\n",
      "False negative rate: 31.833% (1301/4087)\n",
      "True negative rate: 98.758% (52651/53313)\n",
      "False positive rate: 1.242% (662/53313)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 42/67: Loss: 0.0877 | Train Acc: 96.578% (56788/58800) | Strict Acc: 66.857% (2808/4200)\n",
      "True positive rate: 68.119% (2861/4200)\n",
      "False negative rate: 31.881% (1339/4200)\n",
      "True negative rate: 98.767% (53927/54600)\n",
      "False positive rate: 1.233% (673/54600)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 43/67: Loss: 0.0881 | Train Acc: 96.560% (58129/60200) | Strict Acc: 66.767% (2871/4300)\n",
      "True positive rate: 67.812% (2920/4306)\n",
      "False negative rate: 32.188% (1386/4306)\n",
      "True negative rate: 98.774% (55209/55894)\n",
      "False positive rate: 1.226% (685/55894)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 44/67: Loss: 0.0879 | Train Acc: 96.573% (59489/61600) | Strict Acc: 66.886% (2943/4400)\n",
      "True positive rate: 68.000% (3009/4425)\n",
      "False negative rate: 32.000% (1416/4425)\n",
      "True negative rate: 98.784% (56480/57175)\n",
      "False positive rate: 1.216% (695/57175)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 45/67: Loss: 0.0886 | Train Acc: 96.541% (60821/63000) | Strict Acc: 66.711% (3002/4500)\n",
      "True positive rate: 67.973% (3088/4543)\n",
      "False negative rate: 32.027% (1455/4543)\n",
      "True negative rate: 98.761% (57733/58457)\n",
      "False positive rate: 1.239% (724/58457)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 46/67: Loss: 0.0889 | Train Acc: 96.519% (62158/64400) | Strict Acc: 66.630% (3065/4600)\n",
      "True positive rate: 67.967% (3153/4639)\n",
      "False negative rate: 32.033% (1486/4639)\n",
      "True negative rate: 98.735% (59005/59761)\n",
      "False positive rate: 1.265% (756/59761)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 47/67: Loss: 0.0892 | Train Acc: 96.520% (63510/65800) | Strict Acc: 66.681% (3134/4700)\n",
      "True positive rate: 68.043% (3230/4747)\n",
      "False negative rate: 31.957% (1517/4747)\n",
      "True negative rate: 98.734% (60280/61053)\n",
      "False positive rate: 1.266% (773/61053)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 48/67: Loss: 0.0893 | Train Acc: 96.513% (64857/67200) | Strict Acc: 66.521% (3193/4800)\n",
      "True positive rate: 68.126% (3300/4844)\n",
      "False negative rate: 31.874% (1544/4844)\n",
      "True negative rate: 98.719% (61557/62356)\n",
      "False positive rate: 1.281% (799/62356)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 49/67: Loss: 0.0892 | Train Acc: 96.519% (66212/68600) | Strict Acc: 66.531% (3260/4900)\n",
      "True positive rate: 68.277% (3392/4968)\n",
      "False negative rate: 31.723% (1576/4968)\n",
      "True negative rate: 98.724% (62820/63632)\n",
      "False positive rate: 1.276% (812/63632)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 50/67: Loss: 0.0893 | Train Acc: 96.526% (67568/70000) | Strict Acc: 66.540% (3327/5000)\n",
      "True positive rate: 68.347% (3470/5077)\n",
      "False negative rate: 31.653% (1607/5077)\n",
      "True negative rate: 98.729% (64098/64923)\n",
      "False positive rate: 1.271% (825/64923)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 51/67: Loss: 0.0893 | Train Acc: 96.514% (68911/71400) | Strict Acc: 66.431% (3388/5100)\n",
      "True positive rate: 68.254% (3526/5166)\n",
      "False negative rate: 31.746% (1640/5166)\n",
      "True negative rate: 98.718% (65385/66234)\n",
      "False positive rate: 1.282% (849/66234)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 52/67: Loss: 0.0895 | Train Acc: 96.504% (70255/72800) | Strict Acc: 66.308% (3448/5200)\n",
      "True positive rate: 67.973% (3589/5280)\n",
      "False negative rate: 32.027% (1691/5280)\n",
      "True negative rate: 98.735% (66666/67520)\n",
      "False positive rate: 1.265% (854/67520)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 53/67: Loss: 0.0895 | Train Acc: 96.509% (71610/74200) | Strict Acc: 66.245% (3511/5300)\n",
      "True positive rate: 67.941% (3660/5387)\n",
      "False negative rate: 32.059% (1727/5387)\n",
      "True negative rate: 98.746% (67950/68813)\n",
      "False positive rate: 1.254% (863/68813)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 4 - Batch 54/67: Loss: 0.0892 | Train Acc: 96.519% (72968/75600) | Strict Acc: 66.296% (3580/5400)\n",
      "True positive rate: 68.107% (3735/5484)\n",
      "False negative rate: 31.893% (1749/5484)\n",
      "True negative rate: 98.741% (69233/70116)\n",
      "False positive rate: 1.259% (883/70116)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 55/67: Loss: 0.0889 | Train Acc: 96.532% (74330/77000) | Strict Acc: 66.436% (3654/5500)\n",
      "True positive rate: 68.163% (3796/5569)\n",
      "False negative rate: 31.837% (1773/5569)\n",
      "True negative rate: 98.744% (70534/71431)\n",
      "False positive rate: 1.256% (897/71431)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 56/67: Loss: 0.0892 | Train Acc: 96.522% (75673/78400) | Strict Acc: 66.357% (3716/5600)\n",
      "True positive rate: 68.101% (3862/5671)\n",
      "False negative rate: 31.899% (1809/5671)\n",
      "True negative rate: 98.738% (71811/72729)\n",
      "False positive rate: 1.262% (918/72729)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 57/67: Loss: 0.0892 | Train Acc: 96.521% (77024/79800) | Strict Acc: 66.351% (3782/5700)\n",
      "True positive rate: 68.150% (3935/5774)\n",
      "False negative rate: 31.850% (1839/5774)\n",
      "True negative rate: 98.734% (73089/74026)\n",
      "False positive rate: 1.266% (937/74026)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 58/67: Loss: 0.0892 | Train Acc: 96.525% (78378/81200) | Strict Acc: 66.397% (3851/5800)\n",
      "True positive rate: 68.074% (3983/5851)\n",
      "False negative rate: 31.926% (1868/5851)\n",
      "True negative rate: 98.734% (74395/75349)\n",
      "False positive rate: 1.266% (954/75349)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 59/67: Loss: 0.0890 | Train Acc: 96.536% (79739/82600) | Strict Acc: 66.458% (3921/5900)\n",
      "True positive rate: 68.166% (4062/5959)\n",
      "False negative rate: 31.834% (1897/5959)\n",
      "True negative rate: 98.742% (75677/76641)\n",
      "False positive rate: 1.258% (964/76641)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 60/67: Loss: 0.0891 | Train Acc: 96.535% (81089/84000) | Strict Acc: 66.450% (3987/6000)\n",
      "True positive rate: 68.179% (4148/6084)\n",
      "False negative rate: 31.821% (1936/6084)\n",
      "True negative rate: 98.749% (76941/77916)\n",
      "False positive rate: 1.251% (975/77916)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 61/67: Loss: 0.0891 | Train Acc: 96.534% (82440/85400) | Strict Acc: 66.410% (4051/6100)\n",
      "True positive rate: 68.074% (4209/6183)\n",
      "False negative rate: 31.926% (1974/6183)\n",
      "True negative rate: 98.755% (78231/79217)\n",
      "False positive rate: 1.245% (986/79217)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 62/67: Loss: 0.0891 | Train Acc: 96.536% (83793/86800) | Strict Acc: 66.532% (4125/6200)\n",
      "True positive rate: 67.988% (4271/6282)\n",
      "False negative rate: 32.012% (2011/6282)\n",
      "True negative rate: 98.763% (79522/80518)\n",
      "False positive rate: 1.237% (996/80518)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 63/67: Loss: 0.0888 | Train Acc: 96.537% (85146/88200) | Strict Acc: 66.571% (4194/6300)\n",
      "True positive rate: 68.058% (4336/6371)\n",
      "False negative rate: 31.942% (2035/6371)\n",
      "True negative rate: 98.755% (80810/81829)\n",
      "False positive rate: 1.245% (1019/81829)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 64/67: Loss: 0.0887 | Train Acc: 96.547% (86506/89600) | Strict Acc: 66.656% (4266/6400)\n",
      "True positive rate: 68.118% (4397/6455)\n",
      "False negative rate: 31.882% (2058/6455)\n",
      "True negative rate: 98.754% (82109/83145)\n",
      "False positive rate: 1.246% (1036/83145)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 65/67: Loss: 0.0889 | Train Acc: 96.543% (87854/91000) | Strict Acc: 66.631% (4331/6500)\n",
      "True positive rate: 68.090% (4466/6559)\n",
      "False negative rate: 31.910% (2093/6559)\n",
      "True negative rate: 98.753% (83388/84441)\n",
      "False positive rate: 1.247% (1053/84441)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 66/67: Loss: 0.0888 | Train Acc: 96.544% (89207/92400) | Strict Acc: 66.652% (4399/6600)\n",
      "True positive rate: 68.050% (4526/6651)\n",
      "False negative rate: 31.950% (2125/6651)\n",
      "True negative rate: 98.755% (84681/85749)\n",
      "False positive rate: 1.245% (1068/85749)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 67/67: Loss: 0.0889 | Train Acc: 96.542% (90516/93758) | Strict Acc: 66.642% (4463/6697)\n",
      "True positive rate: 67.970% (4588/6750)\n",
      "False negative rate: 32.030% (2162/6750)\n",
      "True negative rate: 98.759% (85928/87008)\n",
      "False positive rate: 1.241% (1080/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1553 | Dev Acc: 94.289% (86027/91238) | Strict Acc: 50.667% (3302/6517)\n",
      "True positive rate: 27.983% (1841/6579)\n",
      "False negative rate: 72.017% (4738/6579)\n",
      "True negative rate: 99.441% (84186/84659)\n",
      "False positive rate: 0.559% (473/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 1/67: Loss: 0.0801 | Train Acc: 97.000% (1358/1400) | Strict Acc: 69.000% (69/100)\n",
      "True positive rate: 68.317% (69/101)\n",
      "False negative rate: 31.683% (32/101)\n",
      "True negative rate: 99.230% (1289/1299)\n",
      "False positive rate: 0.770% (10/1299)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 2/67: Loss: 0.0772 | Train Acc: 96.964% (2715/2800) | Strict Acc: 70.000% (140/200)\n",
      "True positive rate: 69.302% (149/215)\n",
      "False negative rate: 30.698% (66/215)\n",
      "True negative rate: 99.265% (2566/2585)\n",
      "False positive rate: 0.735% (19/2585)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 3/67: Loss: 0.0813 | Train Acc: 96.714% (4062/4200) | Strict Acc: 69.333% (208/300)\n",
      "True positive rate: 65.763% (194/295)\n",
      "False negative rate: 34.237% (101/295)\n",
      "True negative rate: 99.052% (3868/3905)\n",
      "False positive rate: 0.948% (37/3905)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 4/67: Loss: 0.0788 | Train Acc: 97.036% (5434/5600) | Strict Acc: 72.000% (288/400)\n",
      "True positive rate: 69.543% (274/394)\n",
      "False negative rate: 30.457% (120/394)\n",
      "True negative rate: 99.116% (5160/5206)\n",
      "False positive rate: 0.884% (46/5206)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 5/67: Loss: 0.0776 | Train Acc: 97.100% (6797/7000) | Strict Acc: 72.800% (364/500)\n",
      "True positive rate: 70.935% (349/492)\n",
      "False negative rate: 29.065% (143/492)\n",
      "True negative rate: 99.078% (6448/6508)\n",
      "False positive rate: 0.922% (60/6508)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 6/67: Loss: 0.0807 | Train Acc: 96.917% (8141/8400) | Strict Acc: 70.833% (425/600)\n",
      "True positive rate: 70.432% (424/602)\n",
      "False negative rate: 29.568% (178/602)\n",
      "True negative rate: 98.961% (7717/7798)\n",
      "False positive rate: 1.039% (81/7798)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 7/67: Loss: 0.0806 | Train Acc: 96.857% (9492/9800) | Strict Acc: 70.429% (493/700)\n",
      "True positive rate: 70.798% (497/702)\n",
      "False negative rate: 29.202% (205/702)\n",
      "True negative rate: 98.868% (8995/9098)\n",
      "False positive rate: 1.132% (103/9098)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 8/67: Loss: 0.0787 | Train Acc: 96.964% (10860/11200) | Strict Acc: 71.125% (569/800)\n",
      "True positive rate: 71.591% (567/792)\n",
      "False negative rate: 28.409% (225/792)\n",
      "True negative rate: 98.895% (10293/10408)\n",
      "False positive rate: 1.105% (115/10408)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 9/67: Loss: 0.0774 | Train Acc: 96.992% (12221/12600) | Strict Acc: 71.111% (640/900)\n",
      "True positive rate: 71.946% (636/884)\n",
      "False negative rate: 28.054% (248/884)\n",
      "True negative rate: 98.882% (11585/11716)\n",
      "False positive rate: 1.118% (131/11716)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 10/67: Loss: 0.0764 | Train Acc: 97.036% (13585/14000) | Strict Acc: 71.400% (714/1000)\n",
      "True positive rate: 72.081% (710/985)\n",
      "False negative rate: 27.919% (275/985)\n",
      "True negative rate: 98.924% (12875/13015)\n",
      "False positive rate: 1.076% (140/13015)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 11/67: Loss: 0.0758 | Train Acc: 97.045% (14945/15400) | Strict Acc: 71.273% (784/1100)\n",
      "True positive rate: 71.536% (759/1061)\n",
      "False negative rate: 28.464% (302/1061)\n",
      "True negative rate: 98.933% (14186/14339)\n",
      "False positive rate: 1.067% (153/14339)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 5 - Batch 12/67: Loss: 0.0745 | Train Acc: 97.089% (16311/16800) | Strict Acc: 71.500% (858/1200)\n",
      "True positive rate: 71.152% (809/1137)\n",
      "False negative rate: 28.848% (328/1137)\n",
      "True negative rate: 98.972% (15502/15663)\n",
      "False positive rate: 1.028% (161/15663)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 13/67: Loss: 0.0784 | Train Acc: 96.945% (17644/18200) | Strict Acc: 70.231% (913/1300)\n",
      "True positive rate: 69.059% (866/1254)\n",
      "False negative rate: 30.941% (388/1254)\n",
      "True negative rate: 99.009% (16778/16946)\n",
      "False positive rate: 0.991% (168/16946)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 14/67: Loss: 0.0788 | Train Acc: 96.944% (19001/19600) | Strict Acc: 70.071% (981/1400)\n",
      "True positive rate: 68.421% (923/1349)\n",
      "False negative rate: 31.579% (426/1349)\n",
      "True negative rate: 99.052% (18078/18251)\n",
      "False positive rate: 0.948% (173/18251)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 15/67: Loss: 0.0793 | Train Acc: 96.905% (20350/21000) | Strict Acc: 69.733% (1046/1500)\n",
      "True positive rate: 68.061% (976/1434)\n",
      "False negative rate: 31.939% (458/1434)\n",
      "True negative rate: 99.019% (19374/19566)\n",
      "False positive rate: 0.981% (192/19566)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 16/67: Loss: 0.0796 | Train Acc: 96.911% (21708/22400) | Strict Acc: 69.688% (1115/1600)\n",
      "True positive rate: 68.345% (1045/1529)\n",
      "False negative rate: 31.655% (484/1529)\n",
      "True negative rate: 99.003% (20663/20871)\n",
      "False positive rate: 0.997% (208/20871)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 17/67: Loss: 0.0804 | Train Acc: 96.861% (23053/23800) | Strict Acc: 69.176% (1176/1700)\n",
      "True positive rate: 68.207% (1122/1645)\n",
      "False negative rate: 31.793% (523/1645)\n",
      "True negative rate: 98.989% (21931/22155)\n",
      "False positive rate: 1.011% (224/22155)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 18/67: Loss: 0.0805 | Train Acc: 96.869% (24411/25200) | Strict Acc: 69.111% (1244/1800)\n",
      "True positive rate: 68.418% (1198/1751)\n",
      "False negative rate: 31.582% (553/1751)\n",
      "True negative rate: 98.994% (23213/23449)\n",
      "False positive rate: 1.006% (236/23449)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 19/67: Loss: 0.0806 | Train Acc: 96.868% (25767/26600) | Strict Acc: 69.211% (1315/1900)\n",
      "True positive rate: 68.567% (1263/1842)\n",
      "False negative rate: 31.433% (579/1842)\n",
      "True negative rate: 98.974% (24504/24758)\n",
      "False positive rate: 1.026% (254/24758)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 20/67: Loss: 0.0799 | Train Acc: 96.921% (27138/28000) | Strict Acc: 69.650% (1393/2000)\n",
      "True positive rate: 69.028% (1335/1934)\n",
      "False negative rate: 30.972% (599/1934)\n",
      "True negative rate: 98.991% (25803/26066)\n",
      "False positive rate: 1.009% (263/26066)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 21/67: Loss: 0.0794 | Train Acc: 96.952% (28504/29400) | Strict Acc: 69.857% (1467/2100)\n",
      "True positive rate: 69.473% (1411/2031)\n",
      "False negative rate: 30.527% (620/2031)\n",
      "True negative rate: 98.992% (27093/27369)\n",
      "False positive rate: 1.008% (276/27369)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 22/67: Loss: 0.0795 | Train Acc: 96.945% (29859/30800) | Strict Acc: 69.818% (1536/2200)\n",
      "True positive rate: 69.775% (1489/2134)\n",
      "False negative rate: 30.225% (645/2134)\n",
      "True negative rate: 98.967% (28370/28666)\n",
      "False positive rate: 1.033% (296/28666)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 23/67: Loss: 0.0800 | Train Acc: 96.919% (31208/32200) | Strict Acc: 69.522% (1599/2300)\n",
      "True positive rate: 69.505% (1559/2243)\n",
      "False negative rate: 30.495% (684/2243)\n",
      "True negative rate: 98.972% (29649/29957)\n",
      "False positive rate: 1.028% (308/29957)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 24/67: Loss: 0.0798 | Train Acc: 96.929% (32568/33600) | Strict Acc: 69.583% (1670/2400)\n",
      "True positive rate: 69.556% (1629/2342)\n",
      "False negative rate: 30.444% (713/2342)\n",
      "True negative rate: 98.979% (30939/31258)\n",
      "False positive rate: 1.021% (319/31258)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 25/67: Loss: 0.0796 | Train Acc: 96.900% (33915/35000) | Strict Acc: 69.520% (1738/2500)\n",
      "True positive rate: 69.319% (1699/2451)\n",
      "False negative rate: 30.681% (752/2451)\n",
      "True negative rate: 98.977% (32216/32549)\n",
      "False positive rate: 1.023% (333/32549)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 26/67: Loss: 0.0792 | Train Acc: 96.898% (35271/36400) | Strict Acc: 69.423% (1805/2600)\n",
      "True positive rate: 69.324% (1765/2546)\n",
      "False negative rate: 30.676% (781/2546)\n",
      "True negative rate: 98.972% (33506/33854)\n",
      "False positive rate: 1.028% (348/33854)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 27/67: Loss: 0.0798 | Train Acc: 96.860% (36613/37800) | Strict Acc: 69.111% (1866/2700)\n",
      "True positive rate: 69.309% (1836/2649)\n",
      "False negative rate: 30.691% (813/2649)\n",
      "True negative rate: 98.936% (34777/35151)\n",
      "False positive rate: 1.064% (374/35151)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 28/67: Loss: 0.0797 | Train Acc: 96.870% (37973/39200) | Strict Acc: 69.179% (1937/2800)\n",
      "True positive rate: 69.656% (1903/2732)\n",
      "False negative rate: 30.344% (829/2732)\n",
      "True negative rate: 98.909% (36070/36468)\n",
      "False positive rate: 1.091% (398/36468)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 29/67: Loss: 0.0798 | Train Acc: 96.869% (39329/40600) | Strict Acc: 69.207% (2007/2900)\n",
      "True positive rate: 69.859% (1984/2840)\n",
      "False negative rate: 30.141% (856/2840)\n",
      "True negative rate: 98.901% (37345/37760)\n",
      "False positive rate: 1.099% (415/37760)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 30/67: Loss: 0.0794 | Train Acc: 96.886% (40692/42000) | Strict Acc: 69.200% (2076/3000)\n",
      "True positive rate: 70.061% (2057/2936)\n",
      "False negative rate: 29.939% (879/2936)\n",
      "True negative rate: 98.902% (38635/39064)\n",
      "False positive rate: 1.098% (429/39064)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 31/67: Loss: 0.0792 | Train Acc: 96.903% (42056/43400) | Strict Acc: 69.419% (2152/3100)\n",
      "True positive rate: 70.020% (2109/3012)\n",
      "False negative rate: 29.980% (903/3012)\n",
      "True negative rate: 98.908% (39947/40388)\n",
      "False positive rate: 1.092% (441/40388)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 32/67: Loss: 0.0797 | Train Acc: 96.884% (43404/44800) | Strict Acc: 69.188% (2214/3200)\n",
      "True positive rate: 69.878% (2183/3124)\n",
      "False negative rate: 30.122% (941/3124)\n",
      "True negative rate: 98.908% (41221/41676)\n",
      "False positive rate: 1.092% (455/41676)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 33/67: Loss: 0.0804 | Train Acc: 96.864% (44751/46200) | Strict Acc: 69.061% (2279/3300)\n",
      "True positive rate: 69.661% (2241/3217)\n",
      "False negative rate: 30.339% (976/3217)\n",
      "True negative rate: 98.900% (42510/42983)\n",
      "False positive rate: 1.100% (473/42983)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 34/67: Loss: 0.0806 | Train Acc: 96.855% (46103/47600) | Strict Acc: 68.971% (2345/3400)\n",
      "True positive rate: 69.616% (2305/3311)\n",
      "False negative rate: 30.384% (1006/3311)\n",
      "True negative rate: 98.891% (43798/44289)\n",
      "False positive rate: 1.109% (491/44289)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 35/67: Loss: 0.0808 | Train Acc: 96.839% (47451/49000) | Strict Acc: 68.886% (2411/3500)\n",
      "True positive rate: 69.558% (2390/3436)\n",
      "False negative rate: 30.442% (1046/3436)\n",
      "True negative rate: 98.896% (45061/45564)\n",
      "False positive rate: 1.104% (503/45564)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 36/67: Loss: 0.0806 | Train Acc: 96.837% (48806/50400) | Strict Acc: 68.917% (2481/3600)\n",
      "True positive rate: 69.611% (2467/3544)\n",
      "False negative rate: 30.389% (1077/3544)\n",
      "True negative rate: 98.897% (46339/46856)\n",
      "False positive rate: 1.103% (517/46856)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 37/67: Loss: 0.0810 | Train Acc: 96.828% (50157/51800) | Strict Acc: 68.865% (2548/3700)\n",
      "True positive rate: 69.649% (2538/3644)\n",
      "False negative rate: 30.351% (1106/3644)\n",
      "True negative rate: 98.885% (47619/48156)\n",
      "False positive rate: 1.115% (537/48156)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 5 - Batch 38/67: Loss: 0.0809 | Train Acc: 96.829% (51513/53200) | Strict Acc: 68.816% (2615/3800)\n",
      "True positive rate: 69.845% (2622/3754)\n",
      "False negative rate: 30.155% (1132/3754)\n",
      "True negative rate: 98.878% (48891/49446)\n",
      "False positive rate: 1.122% (555/49446)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 39/67: Loss: 0.0810 | Train Acc: 96.835% (52872/54600) | Strict Acc: 68.795% (2683/3900)\n",
      "True positive rate: 69.912% (2693/3852)\n",
      "False negative rate: 30.088% (1159/3852)\n",
      "True negative rate: 98.879% (50179/50748)\n",
      "False positive rate: 1.121% (569/50748)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 40/67: Loss: 0.0811 | Train Acc: 96.827% (54223/56000) | Strict Acc: 68.625% (2745/4000)\n",
      "True positive rate: 69.985% (2784/3978)\n",
      "False negative rate: 30.015% (1194/3978)\n",
      "True negative rate: 98.879% (51439/52022)\n",
      "False positive rate: 1.121% (583/52022)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 41/67: Loss: 0.0810 | Train Acc: 96.834% (55583/57400) | Strict Acc: 68.707% (2817/4100)\n",
      "True positive rate: 70.142% (2866/4086)\n",
      "False negative rate: 29.858% (1220/4086)\n",
      "True negative rate: 98.880% (52717/53314)\n",
      "False positive rate: 1.120% (597/53314)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 42/67: Loss: 0.0812 | Train Acc: 96.825% (56933/58800) | Strict Acc: 68.714% (2886/4200)\n",
      "True positive rate: 70.007% (2934/4191)\n",
      "False negative rate: 29.993% (1257/4191)\n",
      "True negative rate: 98.883% (53999/54609)\n",
      "False positive rate: 1.117% (610/54609)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 43/67: Loss: 0.0814 | Train Acc: 96.824% (58288/60200) | Strict Acc: 68.721% (2955/4300)\n",
      "True positive rate: 69.883% (2998/4290)\n",
      "False negative rate: 30.117% (1292/4290)\n",
      "True negative rate: 98.891% (55290/55910)\n",
      "False positive rate: 1.109% (620/55910)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 44/67: Loss: 0.0807 | Train Acc: 96.854% (59662/61600) | Strict Acc: 69.023% (3037/4400)\n",
      "True positive rate: 70.160% (3066/4370)\n",
      "False negative rate: 29.840% (1304/4370)\n",
      "True negative rate: 98.892% (56596/57230)\n",
      "False positive rate: 1.108% (634/57230)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 45/67: Loss: 0.0809 | Train Acc: 96.854% (61018/63000) | Strict Acc: 69.044% (3107/4500)\n",
      "True positive rate: 70.076% (3124/4458)\n",
      "False negative rate: 29.924% (1334/4458)\n",
      "True negative rate: 98.893% (57894/58542)\n",
      "False positive rate: 1.107% (648/58542)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 46/67: Loss: 0.0808 | Train Acc: 96.860% (62378/64400) | Strict Acc: 69.065% (3177/4600)\n",
      "True positive rate: 70.181% (3215/4581)\n",
      "False negative rate: 29.819% (1366/4581)\n",
      "True negative rate: 98.903% (59163/59819)\n",
      "False positive rate: 1.097% (656/59819)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 47/67: Loss: 0.0807 | Train Acc: 96.863% (63736/65800) | Strict Acc: 69.106% (3248/4700)\n",
      "True positive rate: 70.316% (3295/4686)\n",
      "False negative rate: 29.684% (1391/4686)\n",
      "True negative rate: 98.899% (60441/61114)\n",
      "False positive rate: 1.101% (673/61114)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 48/67: Loss: 0.0804 | Train Acc: 96.872% (65098/67200) | Strict Acc: 69.167% (3320/4800)\n",
      "True positive rate: 70.379% (3362/4777)\n",
      "False negative rate: 29.621% (1415/4777)\n",
      "True negative rate: 98.899% (61736/62423)\n",
      "False positive rate: 1.101% (687/62423)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 49/67: Loss: 0.0808 | Train Acc: 96.857% (66444/68600) | Strict Acc: 69.082% (3385/4900)\n",
      "True positive rate: 70.321% (3438/4889)\n",
      "False negative rate: 29.679% (1451/4889)\n",
      "True negative rate: 98.893% (63006/63711)\n",
      "False positive rate: 1.107% (705/63711)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 50/67: Loss: 0.0806 | Train Acc: 96.867% (67807/70000) | Strict Acc: 69.120% (3456/5000)\n",
      "True positive rate: 70.494% (3512/4982)\n",
      "False negative rate: 29.506% (1470/4982)\n",
      "True negative rate: 98.888% (64295/65018)\n",
      "False positive rate: 1.112% (723/65018)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 51/67: Loss: 0.0807 | Train Acc: 96.861% (69159/71400) | Strict Acc: 69.020% (3520/5100)\n",
      "True positive rate: 70.464% (3581/5082)\n",
      "False negative rate: 29.536% (1501/5082)\n",
      "True negative rate: 98.884% (65578/66318)\n",
      "False positive rate: 1.116% (740/66318)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 52/67: Loss: 0.0805 | Train Acc: 96.853% (70509/72800) | Strict Acc: 68.923% (3584/5200)\n",
      "True positive rate: 70.383% (3655/5193)\n",
      "False negative rate: 29.617% (1538/5193)\n",
      "True negative rate: 98.886% (66854/67607)\n",
      "False positive rate: 1.114% (753/67607)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 53/67: Loss: 0.0805 | Train Acc: 96.852% (71864/74200) | Strict Acc: 68.849% (3649/5300)\n",
      "True positive rate: 70.371% (3717/5282)\n",
      "False negative rate: 29.629% (1565/5282)\n",
      "True negative rate: 98.881% (68147/68918)\n",
      "False positive rate: 1.119% (771/68918)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 54/67: Loss: 0.0807 | Train Acc: 96.851% (73219/75600) | Strict Acc: 68.870% (3719/5400)\n",
      "True positive rate: 70.478% (3803/5396)\n",
      "False negative rate: 29.522% (1593/5396)\n",
      "True negative rate: 98.878% (69416/70204)\n",
      "False positive rate: 1.122% (788/70204)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 55/67: Loss: 0.0805 | Train Acc: 96.860% (74582/77000) | Strict Acc: 68.927% (3791/5500)\n",
      "True positive rate: 70.523% (3871/5489)\n",
      "False negative rate: 29.477% (1618/5489)\n",
      "True negative rate: 98.881% (70711/71511)\n",
      "False positive rate: 1.119% (800/71511)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 56/67: Loss: 0.0807 | Train Acc: 96.865% (75942/78400) | Strict Acc: 69.018% (3865/5600)\n",
      "True positive rate: 70.566% (3951/5599)\n",
      "False negative rate: 29.434% (1648/5599)\n",
      "True negative rate: 98.887% (71991/72801)\n",
      "False positive rate: 1.113% (810/72801)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 57/67: Loss: 0.0807 | Train Acc: 96.862% (77296/79800) | Strict Acc: 68.930% (3929/5700)\n",
      "True positive rate: 70.637% (4027/5701)\n",
      "False negative rate: 29.363% (1674/5701)\n",
      "True negative rate: 98.880% (73269/74099)\n",
      "False positive rate: 1.120% (830/74099)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 58/67: Loss: 0.0809 | Train Acc: 96.865% (78654/81200) | Strict Acc: 68.914% (3997/5800)\n",
      "True positive rate: 70.649% (4092/5792)\n",
      "False negative rate: 29.351% (1700/5792)\n",
      "True negative rate: 98.878% (74562/75408)\n",
      "False positive rate: 1.122% (846/75408)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 59/67: Loss: 0.0809 | Train Acc: 96.862% (80008/82600) | Strict Acc: 68.864% (4063/5900)\n",
      "True positive rate: 70.667% (4163/5891)\n",
      "False negative rate: 29.333% (1728/5891)\n",
      "True negative rate: 98.874% (75845/76709)\n",
      "False positive rate: 1.126% (864/76709)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 60/67: Loss: 0.0808 | Train Acc: 96.864% (81366/84000) | Strict Acc: 68.967% (4138/6000)\n",
      "True positive rate: 70.653% (4230/5987)\n",
      "False negative rate: 29.347% (1757/5987)\n",
      "True negative rate: 98.876% (77136/78013)\n",
      "False positive rate: 1.124% (877/78013)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 61/67: Loss: 0.0807 | Train Acc: 96.867% (82724/85400) | Strict Acc: 69.000% (4209/6100)\n",
      "True positive rate: 70.702% (4310/6096)\n",
      "False negative rate: 29.298% (1786/6096)\n",
      "True negative rate: 98.878% (78414/79304)\n",
      "False positive rate: 1.122% (890/79304)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 62/67: Loss: 0.0810 | Train Acc: 96.854% (84069/86800) | Strict Acc: 68.984% (4277/6200)\n",
      "True positive rate: 70.566% (4392/6224)\n",
      "False negative rate: 29.434% (1832/6224)\n",
      "True negative rate: 98.884% (79677/80576)\n",
      "False positive rate: 1.116% (899/80576)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 5 - Batch 63/67: Loss: 0.0809 | Train Acc: 96.862% (85432/88200) | Strict Acc: 69.048% (4350/6300)\n",
      "True positive rate: 70.604% (4465/6324)\n",
      "False negative rate: 29.396% (1859/6324)\n",
      "True negative rate: 98.890% (80967/81876)\n",
      "False positive rate: 1.110% (909/81876)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 64/67: Loss: 0.0810 | Train Acc: 96.862% (86788/89600) | Strict Acc: 69.031% (4418/6400)\n",
      "True positive rate: 70.654% (4548/6437)\n",
      "False negative rate: 29.346% (1889/6437)\n",
      "True negative rate: 98.890% (82240/83163)\n",
      "False positive rate: 1.110% (923/83163)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 65/67: Loss: 0.0808 | Train Acc: 96.867% (88149/91000) | Strict Acc: 69.123% (4493/6500)\n",
      "True positive rate: 70.760% (4627/6539)\n",
      "False negative rate: 29.240% (1912/6539)\n",
      "True negative rate: 98.888% (83522/84461)\n",
      "False positive rate: 1.112% (939/84461)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 66/67: Loss: 0.0812 | Train Acc: 96.854% (89493/92400) | Strict Acc: 69.000% (4554/6600)\n",
      "True positive rate: 70.774% (4710/6655)\n",
      "False negative rate: 29.226% (1945/6655)\n",
      "True negative rate: 98.878% (84783/85745)\n",
      "False positive rate: 1.122% (962/85745)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 67/67: Loss: 0.0814 | Train Acc: 96.847% (90802/93758) | Strict Acc: 68.971% (4619/6697)\n",
      "True positive rate: 70.785% (4778/6750)\n",
      "False negative rate: 29.215% (1972/6750)\n",
      "True negative rate: 98.869% (86024/87008)\n",
      "False positive rate: 1.131% (984/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1613 | Dev Acc: 94.159% (85909/91238) | Strict Acc: 47.322% (3084/6517)\n",
      "True positive rate: 41.374% (2722/6579)\n",
      "False negative rate: 58.626% (3857/6579)\n",
      "True negative rate: 98.261% (83187/84659)\n",
      "False positive rate: 1.739% (1472/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 1/67: Loss: 0.0715 | Train Acc: 97.286% (1362/1400) | Strict Acc: 71.000% (71/100)\n",
      "True positive rate: 81.443% (79/97)\n",
      "False negative rate: 18.557% (18/97)\n",
      "True negative rate: 98.465% (1283/1303)\n",
      "False positive rate: 1.535% (20/1303)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 2/67: Loss: 0.0694 | Train Acc: 97.464% (2729/2800) | Strict Acc: 74.000% (148/200)\n",
      "True positive rate: 85.083% (154/181)\n",
      "False negative rate: 14.917% (27/181)\n",
      "True negative rate: 98.320% (2575/2619)\n",
      "False positive rate: 1.680% (44/2619)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 3/67: Loss: 0.0757 | Train Acc: 97.190% (4082/4200) | Strict Acc: 70.333% (211/300)\n",
      "True positive rate: 81.979% (232/283)\n",
      "False negative rate: 18.021% (51/283)\n",
      "True negative rate: 98.290% (3850/3917)\n",
      "False positive rate: 1.710% (67/3917)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 4/67: Loss: 0.0724 | Train Acc: 97.304% (5449/5600) | Strict Acc: 72.000% (288/400)\n",
      "True positive rate: 79.784% (296/371)\n",
      "False negative rate: 20.216% (75/371)\n",
      "True negative rate: 98.547% (5153/5229)\n",
      "False positive rate: 1.453% (76/5229)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 5/67: Loss: 0.0762 | Train Acc: 97.171% (6802/7000) | Strict Acc: 71.400% (357/500)\n",
      "True positive rate: 76.101% (363/477)\n",
      "False negative rate: 23.899% (114/477)\n",
      "True negative rate: 98.712% (6439/6523)\n",
      "False positive rate: 1.288% (84/6523)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 6/67: Loss: 0.0742 | Train Acc: 97.167% (8162/8400) | Strict Acc: 72.000% (432/600)\n",
      "True positive rate: 75.510% (444/588)\n",
      "False negative rate: 24.490% (144/588)\n",
      "True negative rate: 98.797% (7718/7812)\n",
      "False positive rate: 1.203% (94/7812)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 7/67: Loss: 0.0752 | Train Acc: 97.112% (9517/9800) | Strict Acc: 71.429% (500/700)\n",
      "True positive rate: 73.958% (497/672)\n",
      "False negative rate: 26.042% (175/672)\n",
      "True negative rate: 98.817% (9020/9128)\n",
      "False positive rate: 1.183% (108/9128)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 8/67: Loss: 0.0745 | Train Acc: 97.152% (10881/11200) | Strict Acc: 71.625% (573/800)\n",
      "True positive rate: 73.526% (561/763)\n",
      "False negative rate: 26.474% (202/763)\n",
      "True negative rate: 98.879% (10320/10437)\n",
      "False positive rate: 1.121% (117/10437)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 9/67: Loss: 0.0740 | Train Acc: 97.143% (12240/12600) | Strict Acc: 71.444% (643/900)\n",
      "True positive rate: 73.379% (645/879)\n",
      "False negative rate: 26.621% (234/879)\n",
      "True negative rate: 98.925% (11595/11721)\n",
      "False positive rate: 1.075% (126/11721)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 10/67: Loss: 0.0744 | Train Acc: 97.143% (13600/14000) | Strict Acc: 71.500% (715/1000)\n",
      "True positive rate: 73.856% (726/983)\n",
      "False negative rate: 26.144% (257/983)\n",
      "True negative rate: 98.901% (12874/13017)\n",
      "False positive rate: 1.099% (143/13017)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 11/67: Loss: 0.0747 | Train Acc: 97.123% (14957/15400) | Strict Acc: 71.182% (783/1100)\n",
      "True positive rate: 73.763% (790/1071)\n",
      "False negative rate: 26.237% (281/1071)\n",
      "True negative rate: 98.869% (14167/14329)\n",
      "False positive rate: 1.131% (162/14329)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 12/67: Loss: 0.0742 | Train Acc: 97.143% (16320/16800) | Strict Acc: 71.167% (854/1200)\n",
      "True positive rate: 74.264% (883/1189)\n",
      "False negative rate: 25.736% (306/1189)\n",
      "True negative rate: 98.885% (15437/15611)\n",
      "False positive rate: 1.115% (174/15611)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 13/67: Loss: 0.0764 | Train Acc: 97.082% (17669/18200) | Strict Acc: 71.000% (923/1300)\n",
      "True positive rate: 73.916% (955/1292)\n",
      "False negative rate: 26.084% (337/1292)\n",
      "True negative rate: 98.853% (16714/16908)\n",
      "False positive rate: 1.147% (194/16908)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 14/67: Loss: 0.0773 | Train Acc: 97.041% (19020/19600) | Strict Acc: 70.643% (989/1400)\n",
      "True positive rate: 73.500% (1029/1400)\n",
      "False negative rate: 26.500% (371/1400)\n",
      "True negative rate: 98.852% (17991/18200)\n",
      "False positive rate: 1.148% (209/18200)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 15/67: Loss: 0.0772 | Train Acc: 97.043% (20379/21000) | Strict Acc: 70.733% (1061/1500)\n",
      "True positive rate: 73.391% (1106/1507)\n",
      "False negative rate: 26.609% (401/1507)\n",
      "True negative rate: 98.871% (19273/19493)\n",
      "False positive rate: 1.129% (220/19493)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 16/67: Loss: 0.0763 | Train Acc: 97.107% (21752/22400) | Strict Acc: 71.312% (1141/1600)\n",
      "True positive rate: 73.777% (1176/1594)\n",
      "False negative rate: 26.223% (418/1594)\n",
      "True negative rate: 98.895% (20576/20806)\n",
      "False positive rate: 1.105% (230/20806)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 17/67: Loss: 0.0759 | Train Acc: 97.113% (23113/23800) | Strict Acc: 71.412% (1214/1700)\n",
      "True positive rate: 73.666% (1256/1705)\n",
      "False negative rate: 26.334% (449/1705)\n",
      "True negative rate: 98.923% (21857/22095)\n",
      "False positive rate: 1.077% (238/22095)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 18/67: Loss: 0.0760 | Train Acc: 97.103% (24470/25200) | Strict Acc: 71.500% (1287/1800)\n",
      "True positive rate: 73.348% (1321/1801)\n",
      "False negative rate: 26.652% (480/1801)\n",
      "True negative rate: 98.932% (23149/23399)\n",
      "False positive rate: 1.068% (250/23399)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 19/67: Loss: 0.0757 | Train Acc: 97.102% (25829/26600) | Strict Acc: 71.579% (1360/1900)\n",
      "True positive rate: 73.225% (1392/1901)\n",
      "False negative rate: 26.775% (509/1901)\n",
      "True negative rate: 98.939% (24437/24699)\n",
      "False positive rate: 1.061% (262/24699)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 20/67: Loss: 0.0757 | Train Acc: 97.111% (27191/28000) | Strict Acc: 71.650% (1433/2000)\n",
      "True positive rate: 73.554% (1488/2023)\n",
      "False negative rate: 26.446% (535/2023)\n",
      "True negative rate: 98.945% (25703/25977)\n",
      "False positive rate: 1.055% (274/25977)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 6 - Batch 21/67: Loss: 0.0761 | Train Acc: 97.088% (28544/29400) | Strict Acc: 71.429% (1500/2100)\n",
      "True positive rate: 73.538% (1559/2120)\n",
      "False negative rate: 26.462% (561/2120)\n",
      "True negative rate: 98.919% (26985/27280)\n",
      "False positive rate: 1.081% (295/27280)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 22/67: Loss: 0.0756 | Train Acc: 97.088% (29903/30800) | Strict Acc: 71.591% (1575/2200)\n",
      "True positive rate: 73.634% (1631/2215)\n",
      "False negative rate: 26.366% (584/2215)\n",
      "True negative rate: 98.905% (28272/28585)\n",
      "False positive rate: 1.095% (313/28585)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 23/67: Loss: 0.0755 | Train Acc: 97.099% (31266/32200) | Strict Acc: 71.609% (1647/2300)\n",
      "True positive rate: 73.879% (1714/2320)\n",
      "False negative rate: 26.121% (606/2320)\n",
      "True negative rate: 98.902% (29552/29880)\n",
      "False positive rate: 1.098% (328/29880)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 24/67: Loss: 0.0752 | Train Acc: 97.110% (32629/33600) | Strict Acc: 71.583% (1718/2400)\n",
      "True positive rate: 73.909% (1779/2407)\n",
      "False negative rate: 26.091% (628/2407)\n",
      "True negative rate: 98.900% (30850/31193)\n",
      "False positive rate: 1.100% (343/31193)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 25/67: Loss: 0.0752 | Train Acc: 97.103% (33986/35000) | Strict Acc: 71.440% (1786/2500)\n",
      "True positive rate: 73.841% (1863/2523)\n",
      "False negative rate: 26.159% (660/2523)\n",
      "True negative rate: 98.910% (32123/32477)\n",
      "False positive rate: 1.090% (354/32477)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 26/67: Loss: 0.0752 | Train Acc: 97.107% (35347/36400) | Strict Acc: 71.385% (1856/2600)\n",
      "True positive rate: 73.820% (1940/2628)\n",
      "False negative rate: 26.180% (688/2628)\n",
      "True negative rate: 98.919% (33407/33772)\n",
      "False positive rate: 1.081% (365/33772)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 27/67: Loss: 0.0752 | Train Acc: 97.093% (36701/37800) | Strict Acc: 71.222% (1923/2700)\n",
      "True positive rate: 73.832% (2023/2740)\n",
      "False negative rate: 26.168% (717/2740)\n",
      "True negative rate: 98.910% (34678/35060)\n",
      "False positive rate: 1.090% (382/35060)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 28/67: Loss: 0.0753 | Train Acc: 97.074% (38053/39200) | Strict Acc: 71.107% (1991/2800)\n",
      "True positive rate: 73.509% (2095/2850)\n",
      "False negative rate: 26.491% (755/2850)\n",
      "True negative rate: 98.922% (35958/36350)\n",
      "False positive rate: 1.078% (392/36350)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 29/67: Loss: 0.0750 | Train Acc: 97.084% (39416/40600) | Strict Acc: 71.138% (2063/2900)\n",
      "True positive rate: 73.607% (2167/2944)\n",
      "False negative rate: 26.393% (777/2944)\n",
      "True negative rate: 98.919% (37249/37656)\n",
      "False positive rate: 1.081% (407/37656)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 30/67: Loss: 0.0753 | Train Acc: 97.071% (40770/42000) | Strict Acc: 70.900% (2127/3000)\n",
      "True positive rate: 73.612% (2240/3043)\n",
      "False negative rate: 26.388% (803/3043)\n",
      "True negative rate: 98.904% (38530/38957)\n",
      "False positive rate: 1.096% (427/38957)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 31/67: Loss: 0.0752 | Train Acc: 97.071% (42129/43400) | Strict Acc: 70.871% (2197/3100)\n",
      "True positive rate: 73.672% (2317/3145)\n",
      "False negative rate: 26.328% (828/3145)\n",
      "True negative rate: 98.900% (39812/40255)\n",
      "False positive rate: 1.100% (443/40255)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 32/67: Loss: 0.0746 | Train Acc: 97.098% (43500/44800) | Strict Acc: 71.062% (2274/3200)\n",
      "True positive rate: 73.986% (2389/3229)\n",
      "False negative rate: 26.014% (840/3229)\n",
      "True negative rate: 98.893% (41111/41571)\n",
      "False positive rate: 1.107% (460/41571)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 33/67: Loss: 0.0743 | Train Acc: 97.100% (44860/46200) | Strict Acc: 71.091% (2346/3300)\n",
      "True positive rate: 73.938% (2454/3319)\n",
      "False negative rate: 26.062% (865/3319)\n",
      "True negative rate: 98.892% (42406/42881)\n",
      "False positive rate: 1.108% (475/42881)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 34/67: Loss: 0.0746 | Train Acc: 97.099% (46219/47600) | Strict Acc: 71.147% (2419/3400)\n",
      "True positive rate: 73.527% (2508/3411)\n",
      "False negative rate: 26.473% (903/3411)\n",
      "True negative rate: 98.918% (43711/44189)\n",
      "False positive rate: 1.082% (478/44189)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 35/67: Loss: 0.0753 | Train Acc: 97.059% (47559/49000) | Strict Acc: 70.886% (2481/3500)\n",
      "True positive rate: 73.040% (2571/3520)\n",
      "False negative rate: 26.960% (949/3520)\n",
      "True negative rate: 98.918% (44988/45480)\n",
      "False positive rate: 1.082% (492/45480)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 36/67: Loss: 0.0754 | Train Acc: 97.050% (48913/50400) | Strict Acc: 70.833% (2550/3600)\n",
      "True positive rate: 72.936% (2641/3621)\n",
      "False negative rate: 27.064% (980/3621)\n",
      "True negative rate: 98.916% (46272/46779)\n",
      "False positive rate: 1.084% (507/46779)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 37/67: Loss: 0.0752 | Train Acc: 97.064% (50279/51800) | Strict Acc: 70.892% (2623/3700)\n",
      "True positive rate: 73.065% (2718/3720)\n",
      "False negative rate: 26.935% (1002/3720)\n",
      "True negative rate: 98.921% (47561/48080)\n",
      "False positive rate: 1.079% (519/48080)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 38/67: Loss: 0.0751 | Train Acc: 97.060% (51636/53200) | Strict Acc: 70.789% (2690/3800)\n",
      "True positive rate: 73.217% (2802/3827)\n",
      "False negative rate: 26.783% (1025/3827)\n",
      "True negative rate: 98.908% (48834/49373)\n",
      "False positive rate: 1.092% (539/49373)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 39/67: Loss: 0.0751 | Train Acc: 97.049% (52989/54600) | Strict Acc: 70.718% (2758/3900)\n",
      "True positive rate: 73.343% (2889/3939)\n",
      "False negative rate: 26.657% (1050/3939)\n",
      "True negative rate: 98.893% (50100/50661)\n",
      "False positive rate: 1.107% (561/50661)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 40/67: Loss: 0.0753 | Train Acc: 97.055% (54351/56000) | Strict Acc: 70.700% (2828/4000)\n",
      "True positive rate: 73.507% (2966/4035)\n",
      "False negative rate: 26.493% (1069/4035)\n",
      "True negative rate: 98.884% (51385/51965)\n",
      "False positive rate: 1.116% (580/51965)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 41/67: Loss: 0.0755 | Train Acc: 97.049% (55706/57400) | Strict Acc: 70.634% (2896/4100)\n",
      "True positive rate: 73.585% (3042/4134)\n",
      "False negative rate: 26.415% (1092/4134)\n",
      "True negative rate: 98.870% (52664/53266)\n",
      "False positive rate: 1.130% (602/53266)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 42/67: Loss: 0.0758 | Train Acc: 97.037% (57058/58800) | Strict Acc: 70.571% (2964/4200)\n",
      "True positive rate: 73.443% (3114/4240)\n",
      "False negative rate: 26.557% (1126/4240)\n",
      "True negative rate: 98.871% (53944/54560)\n",
      "False positive rate: 1.129% (616/54560)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 43/67: Loss: 0.0760 | Train Acc: 97.035% (58415/60200) | Strict Acc: 70.628% (3037/4300)\n",
      "True positive rate: 73.343% (3186/4344)\n",
      "False negative rate: 26.657% (1158/4344)\n",
      "True negative rate: 98.877% (55229/55856)\n",
      "False positive rate: 1.123% (627/55856)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 44/67: Loss: 0.0761 | Train Acc: 97.028% (59769/61600) | Strict Acc: 70.568% (3105/4400)\n",
      "True positive rate: 73.117% (3242/4434)\n",
      "False negative rate: 26.883% (1192/4434)\n",
      "True negative rate: 98.882% (56527/57166)\n",
      "False positive rate: 1.118% (639/57166)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 45/67: Loss: 0.0761 | Train Acc: 97.029% (61128/63000) | Strict Acc: 70.600% (3177/4500)\n",
      "True positive rate: 73.105% (3308/4525)\n",
      "False negative rate: 26.895% (1217/4525)\n",
      "True negative rate: 98.880% (57820/58475)\n",
      "False positive rate: 1.120% (655/58475)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 46/67: Loss: 0.0761 | Train Acc: 97.028% (62486/64400) | Strict Acc: 70.587% (3247/4600)\n",
      "True positive rate: 73.000% (3358/4600)\n",
      "False negative rate: 27.000% (1242/4600)\n",
      "True negative rate: 98.876% (59128/59800)\n",
      "False positive rate: 1.124% (672/59800)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 6 - Batch 47/67: Loss: 0.0760 | Train Acc: 97.029% (63845/65800) | Strict Acc: 70.553% (3316/4700)\n",
      "True positive rate: 72.952% (3420/4688)\n",
      "False negative rate: 27.048% (1268/4688)\n",
      "True negative rate: 98.876% (60425/61112)\n",
      "False positive rate: 1.124% (687/61112)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 48/67: Loss: 0.0761 | Train Acc: 97.019% (65197/67200) | Strict Acc: 70.375% (3378/4800)\n",
      "True positive rate: 72.915% (3497/4796)\n",
      "False negative rate: 27.085% (1299/4796)\n",
      "True negative rate: 98.872% (61700/62404)\n",
      "False positive rate: 1.128% (704/62404)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 49/67: Loss: 0.0762 | Train Acc: 97.015% (66552/68600) | Strict Acc: 70.347% (3447/4900)\n",
      "True positive rate: 72.733% (3569/4907)\n",
      "False negative rate: 27.267% (1338/4907)\n",
      "True negative rate: 98.885% (62983/63693)\n",
      "False positive rate: 1.115% (710/63693)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 50/67: Loss: 0.0760 | Train Acc: 97.020% (67914/70000) | Strict Acc: 70.380% (3519/5000)\n",
      "True positive rate: 72.687% (3630/4994)\n",
      "False negative rate: 27.313% (1364/4994)\n",
      "True negative rate: 98.889% (64284/65006)\n",
      "False positive rate: 1.111% (722/65006)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 51/67: Loss: 0.0761 | Train Acc: 97.011% (69266/71400) | Strict Acc: 70.314% (3586/5100)\n",
      "True positive rate: 72.633% (3705/5101)\n",
      "False negative rate: 27.367% (1396/5101)\n",
      "True negative rate: 98.887% (65561/66299)\n",
      "False positive rate: 1.113% (738/66299)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 52/67: Loss: 0.0764 | Train Acc: 96.997% (70614/72800) | Strict Acc: 70.231% (3652/5200)\n",
      "True positive rate: 72.591% (3774/5199)\n",
      "False negative rate: 27.409% (1425/5199)\n",
      "True negative rate: 98.874% (66840/67601)\n",
      "False positive rate: 1.126% (761/67601)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 53/67: Loss: 0.0763 | Train Acc: 96.995% (71970/74200) | Strict Acc: 70.226% (3722/5300)\n",
      "True positive rate: 72.623% (3849/5300)\n",
      "False negative rate: 27.377% (1451/5300)\n",
      "True negative rate: 98.869% (68121/68900)\n",
      "False positive rate: 1.131% (779/68900)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 54/67: Loss: 0.0763 | Train Acc: 96.995% (73328/75600) | Strict Acc: 70.185% (3790/5400)\n",
      "True positive rate: 72.467% (3898/5379)\n",
      "False negative rate: 27.533% (1481/5379)\n",
      "True negative rate: 98.874% (69430/70221)\n",
      "False positive rate: 1.126% (791/70221)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 55/67: Loss: 0.0760 | Train Acc: 97.012% (74699/77000) | Strict Acc: 70.364% (3870/5500)\n",
      "True positive rate: 72.559% (3961/5459)\n",
      "False negative rate: 27.441% (1498/5459)\n",
      "True negative rate: 98.878% (70738/71541)\n",
      "False positive rate: 1.122% (803/71541)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 56/67: Loss: 0.0759 | Train Acc: 97.011% (76057/78400) | Strict Acc: 70.393% (3942/5600)\n",
      "True positive rate: 72.554% (4034/5560)\n",
      "False negative rate: 27.446% (1526/5560)\n",
      "True negative rate: 98.878% (72023/72840)\n",
      "False positive rate: 1.122% (817/72840)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 57/67: Loss: 0.0759 | Train Acc: 97.011% (77415/79800) | Strict Acc: 70.351% (4010/5700)\n",
      "True positive rate: 72.541% (4108/5663)\n",
      "False negative rate: 27.459% (1555/5663)\n",
      "True negative rate: 98.880% (73307/74137)\n",
      "False positive rate: 1.120% (830/74137)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 58/67: Loss: 0.0759 | Train Acc: 97.002% (78766/81200) | Strict Acc: 70.259% (4075/5800)\n",
      "True positive rate: 72.386% (4181/5776)\n",
      "False negative rate: 27.614% (1595/5776)\n",
      "True negative rate: 98.888% (74585/75424)\n",
      "False positive rate: 1.112% (839/75424)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 59/67: Loss: 0.0759 | Train Acc: 96.998% (80120/82600) | Strict Acc: 70.254% (4145/5900)\n",
      "True positive rate: 72.312% (4257/5887)\n",
      "False negative rate: 27.688% (1630/5887)\n",
      "True negative rate: 98.892% (75863/76713)\n",
      "False positive rate: 1.108% (850/76713)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 60/67: Loss: 0.0756 | Train Acc: 97.008% (81487/84000) | Strict Acc: 70.367% (4222/6000)\n",
      "True positive rate: 72.513% (4345/5992)\n",
      "False negative rate: 27.487% (1647/5992)\n",
      "True negative rate: 98.890% (77142/78008)\n",
      "False positive rate: 1.110% (866/78008)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 61/67: Loss: 0.0754 | Train Acc: 97.019% (82854/85400) | Strict Acc: 70.459% (4298/6100)\n",
      "True positive rate: 72.690% (4445/6115)\n",
      "False negative rate: 27.310% (1670/6115)\n",
      "True negative rate: 98.895% (78409/79285)\n",
      "False positive rate: 1.105% (876/79285)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 62/67: Loss: 0.0755 | Train Acc: 97.006% (84201/86800) | Strict Acc: 70.290% (4358/6200)\n",
      "True positive rate: 72.720% (4529/6228)\n",
      "False negative rate: 27.280% (1699/6228)\n",
      "True negative rate: 98.883% (79672/80572)\n",
      "False positive rate: 1.117% (900/80572)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 63/67: Loss: 0.0755 | Train Acc: 96.997% (85551/88200) | Strict Acc: 70.238% (4425/6300)\n",
      "True positive rate: 72.796% (4616/6341)\n",
      "False negative rate: 27.204% (1725/6341)\n",
      "True negative rate: 98.871% (80935/81859)\n",
      "False positive rate: 1.129% (924/81859)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 64/67: Loss: 0.0754 | Train Acc: 96.999% (86911/89600) | Strict Acc: 70.312% (4500/6400)\n",
      "True positive rate: 73.030% (4709/6448)\n",
      "False negative rate: 26.970% (1739/6448)\n",
      "True negative rate: 98.858% (82202/83152)\n",
      "False positive rate: 1.142% (950/83152)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 65/67: Loss: 0.0755 | Train Acc: 97.004% (88274/91000) | Strict Acc: 70.308% (4570/6500)\n",
      "True positive rate: 73.043% (4777/6540)\n",
      "False negative rate: 26.957% (1763/6540)\n",
      "True negative rate: 98.860% (83497/84460)\n",
      "False positive rate: 1.140% (963/84460)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 66/67: Loss: 0.0758 | Train Acc: 96.991% (89620/92400) | Strict Acc: 70.197% (4633/6600)\n",
      "True positive rate: 72.895% (4849/6652)\n",
      "False negative rate: 27.105% (1803/6652)\n",
      "True negative rate: 98.861% (84771/85748)\n",
      "False positive rate: 1.139% (977/85748)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 67/67: Loss: 0.0759 | Train Acc: 96.989% (90935/93758) | Strict Acc: 70.151% (4698/6697)\n",
      "True positive rate: 72.800% (4914/6750)\n",
      "False negative rate: 27.200% (1836/6750)\n",
      "True negative rate: 98.866% (86021/87008)\n",
      "False positive rate: 1.134% (987/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1600 | Dev Acc: 94.115% (85869/91238) | Strict Acc: 49.333% (3215/6517)\n",
      "True positive rate: 29.974% (1972/6579)\n",
      "False negative rate: 70.026% (4607/6579)\n",
      "True negative rate: 99.100% (83897/84659)\n",
      "False positive rate: 0.900% (762/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 1/67: Loss: 0.0646 | Train Acc: 97.500% (1365/1400) | Strict Acc: 75.000% (75/100)\n",
      "True positive rate: 78.788% (78/99)\n",
      "False negative rate: 21.212% (21/99)\n",
      "True negative rate: 98.924% (1287/1301)\n",
      "False positive rate: 1.076% (14/1301)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 2/67: Loss: 0.0743 | Train Acc: 96.821% (2711/2800) | Strict Acc: 69.500% (139/200)\n",
      "True positive rate: 72.897% (156/214)\n",
      "False negative rate: 27.103% (58/214)\n",
      "True negative rate: 98.801% (2555/2586)\n",
      "False positive rate: 1.199% (31/2586)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 3/67: Loss: 0.0728 | Train Acc: 96.762% (4064/4200) | Strict Acc: 68.333% (205/300)\n",
      "True positive rate: 71.835% (227/316)\n",
      "False negative rate: 28.165% (89/316)\n",
      "True negative rate: 98.790% (3837/3884)\n",
      "False positive rate: 1.210% (47/3884)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 4/67: Loss: 0.0746 | Train Acc: 96.839% (5423/5600) | Strict Acc: 67.500% (270/400)\n",
      "True positive rate: 70.398% (283/402)\n",
      "False negative rate: 29.602% (119/402)\n",
      "True negative rate: 98.884% (5140/5198)\n",
      "False positive rate: 1.116% (58/5198)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 7 - Batch 5/67: Loss: 0.0716 | Train Acc: 97.014% (6791/7000) | Strict Acc: 69.200% (346/500)\n",
      "True positive rate: 72.414% (357/493)\n",
      "False negative rate: 27.586% (136/493)\n",
      "True negative rate: 98.878% (6434/6507)\n",
      "False positive rate: 1.122% (73/6507)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 6/67: Loss: 0.0679 | Train Acc: 97.167% (8162/8400) | Strict Acc: 70.167% (421/600)\n",
      "True positive rate: 73.822% (423/573)\n",
      "False negative rate: 26.178% (150/573)\n",
      "True negative rate: 98.876% (7739/7827)\n",
      "False positive rate: 1.124% (88/7827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 7/67: Loss: 0.0691 | Train Acc: 97.214% (9527/9800) | Strict Acc: 70.429% (493/700)\n",
      "True positive rate: 73.404% (483/658)\n",
      "False negative rate: 26.596% (175/658)\n",
      "True negative rate: 98.928% (9044/9142)\n",
      "False positive rate: 1.072% (98/9142)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 8/67: Loss: 0.0704 | Train Acc: 97.179% (10884/11200) | Strict Acc: 69.875% (559/800)\n",
      "True positive rate: 71.974% (547/760)\n",
      "False negative rate: 28.026% (213/760)\n",
      "True negative rate: 99.013% (10337/10440)\n",
      "False positive rate: 0.987% (103/10440)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 9/67: Loss: 0.0706 | Train Acc: 97.119% (12237/12600) | Strict Acc: 69.444% (625/900)\n",
      "True positive rate: 71.429% (620/868)\n",
      "False negative rate: 28.571% (248/868)\n",
      "True negative rate: 99.020% (11617/11732)\n",
      "False positive rate: 0.980% (115/11732)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 10/67: Loss: 0.0711 | Train Acc: 97.129% (13598/14000) | Strict Acc: 69.600% (696/1000)\n",
      "True positive rate: 71.164% (691/971)\n",
      "False negative rate: 28.836% (280/971)\n",
      "True negative rate: 99.064% (12907/13029)\n",
      "False positive rate: 0.936% (122/13029)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 11/67: Loss: 0.0702 | Train Acc: 97.091% (14952/15400) | Strict Acc: 69.364% (763/1100)\n",
      "True positive rate: 71.175% (763/1072)\n",
      "False negative rate: 28.825% (309/1072)\n",
      "True negative rate: 99.030% (14189/14328)\n",
      "False positive rate: 0.970% (139/14328)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 12/67: Loss: 0.0696 | Train Acc: 97.143% (16320/16800) | Strict Acc: 70.000% (840/1200)\n",
      "True positive rate: 71.912% (850/1182)\n",
      "False negative rate: 28.088% (332/1182)\n",
      "True negative rate: 99.052% (15470/15618)\n",
      "False positive rate: 0.948% (148/15618)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 13/67: Loss: 0.0701 | Train Acc: 97.104% (17673/18200) | Strict Acc: 69.692% (906/1300)\n",
      "True positive rate: 72.510% (939/1295)\n",
      "False negative rate: 27.490% (356/1295)\n",
      "True negative rate: 98.988% (16734/16905)\n",
      "False positive rate: 1.012% (171/16905)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 14/67: Loss: 0.0687 | Train Acc: 97.158% (19043/19600) | Strict Acc: 69.929% (979/1400)\n",
      "True positive rate: 73.069% (1012/1385)\n",
      "False negative rate: 26.931% (373/1385)\n",
      "True negative rate: 98.990% (18031/18215)\n",
      "False positive rate: 1.010% (184/18215)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 15/67: Loss: 0.0683 | Train Acc: 97.167% (20405/21000) | Strict Acc: 69.800% (1047/1500)\n",
      "True positive rate: 73.225% (1083/1479)\n",
      "False negative rate: 26.775% (396/1479)\n",
      "True negative rate: 98.981% (19322/19521)\n",
      "False positive rate: 1.019% (199/19521)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 16/67: Loss: 0.0679 | Train Acc: 97.210% (21775/22400) | Strict Acc: 70.062% (1121/1600)\n",
      "True positive rate: 74.161% (1194/1610)\n",
      "False negative rate: 25.839% (416/1610)\n",
      "True negative rate: 98.995% (20581/20790)\n",
      "False positive rate: 1.005% (209/20790)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 17/67: Loss: 0.0678 | Train Acc: 97.214% (23137/23800) | Strict Acc: 70.059% (1191/1700)\n",
      "True positive rate: 74.695% (1287/1723)\n",
      "False negative rate: 25.305% (436/1723)\n",
      "True negative rate: 98.972% (21850/22077)\n",
      "False positive rate: 1.028% (227/22077)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 18/67: Loss: 0.0679 | Train Acc: 97.206% (24496/25200) | Strict Acc: 70.278% (1265/1800)\n",
      "True positive rate: 74.670% (1359/1820)\n",
      "False negative rate: 25.330% (461/1820)\n",
      "True negative rate: 98.961% (23137/23380)\n",
      "False positive rate: 1.039% (243/23380)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 19/67: Loss: 0.0673 | Train Acc: 97.244% (25867/26600) | Strict Acc: 70.632% (1342/1900)\n",
      "True positive rate: 74.789% (1418/1896)\n",
      "False negative rate: 25.211% (478/1896)\n",
      "True negative rate: 98.968% (24449/24704)\n",
      "False positive rate: 1.032% (255/24704)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 20/67: Loss: 0.0679 | Train Acc: 97.204% (27217/28000) | Strict Acc: 70.450% (1409/2000)\n",
      "True positive rate: 74.610% (1484/1989)\n",
      "False negative rate: 25.390% (505/1989)\n",
      "True negative rate: 98.931% (25733/26011)\n",
      "False positive rate: 1.069% (278/26011)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 21/67: Loss: 0.0674 | Train Acc: 97.238% (28588/29400) | Strict Acc: 70.810% (1487/2100)\n",
      "True positive rate: 74.964% (1557/2077)\n",
      "False negative rate: 25.036% (520/2077)\n",
      "True negative rate: 98.931% (27031/27323)\n",
      "False positive rate: 1.069% (292/27323)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 22/67: Loss: 0.0675 | Train Acc: 97.214% (29942/30800) | Strict Acc: 70.727% (1556/2200)\n",
      "True positive rate: 74.633% (1627/2180)\n",
      "False negative rate: 25.367% (553/2180)\n",
      "True negative rate: 98.934% (28315/28620)\n",
      "False positive rate: 1.066% (305/28620)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 23/67: Loss: 0.0666 | Train Acc: 97.252% (31315/32200) | Strict Acc: 71.130% (1636/2300)\n",
      "True positive rate: 74.746% (1693/2265)\n",
      "False negative rate: 25.254% (572/2265)\n",
      "True negative rate: 98.954% (29622/29935)\n",
      "False positive rate: 1.046% (313/29935)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 24/67: Loss: 0.0665 | Train Acc: 97.271% (32683/33600) | Strict Acc: 71.250% (1710/2400)\n",
      "True positive rate: 74.874% (1776/2372)\n",
      "False negative rate: 25.126% (596/2372)\n",
      "True negative rate: 98.972% (30907/31228)\n",
      "False positive rate: 1.028% (321/31228)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 25/67: Loss: 0.0673 | Train Acc: 97.246% (34036/35000) | Strict Acc: 71.080% (1777/2500)\n",
      "True positive rate: 74.374% (1843/2478)\n",
      "False negative rate: 25.626% (635/2478)\n",
      "True negative rate: 98.988% (32193/32522)\n",
      "False positive rate: 1.012% (329/32522)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 26/67: Loss: 0.0663 | Train Acc: 97.294% (35415/36400) | Strict Acc: 71.500% (1859/2600)\n",
      "True positive rate: 74.961% (1940/2588)\n",
      "False negative rate: 25.039% (648/2588)\n",
      "True negative rate: 99.003% (33475/33812)\n",
      "False positive rate: 0.997% (337/33812)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 27/67: Loss: 0.0662 | Train Acc: 97.310% (36783/37800) | Strict Acc: 71.593% (1933/2700)\n",
      "True positive rate: 75.467% (2018/2674)\n",
      "False negative rate: 24.533% (656/2674)\n",
      "True negative rate: 98.972% (34765/35126)\n",
      "False positive rate: 1.028% (361/35126)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 28/67: Loss: 0.0669 | Train Acc: 97.283% (38135/39200) | Strict Acc: 71.321% (1997/2800)\n",
      "True positive rate: 75.458% (2100/2783)\n",
      "False negative rate: 24.542% (683/2783)\n",
      "True negative rate: 98.951% (36035/36417)\n",
      "False positive rate: 1.049% (382/36417)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 29/67: Loss: 0.0666 | Train Acc: 97.308% (39507/40600) | Strict Acc: 71.586% (2076/2900)\n",
      "True positive rate: 75.660% (2179/2880)\n",
      "False negative rate: 24.340% (701/2880)\n",
      "True negative rate: 98.961% (37328/37720)\n",
      "False positive rate: 1.039% (392/37720)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 30/67: Loss: 0.0661 | Train Acc: 97.336% (40881/42000) | Strict Acc: 71.933% (2158/3000)\n",
      "True positive rate: 75.754% (2234/2949)\n",
      "False negative rate: 24.246% (715/2949)\n",
      "True negative rate: 98.965% (38647/39051)\n",
      "False positive rate: 1.035% (404/39051)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 7 - Batch 31/67: Loss: 0.0666 | Train Acc: 97.329% (42241/43400) | Strict Acc: 71.871% (2228/3100)\n",
      "True positive rate: 75.644% (2320/3067)\n",
      "False negative rate: 24.356% (747/3067)\n",
      "True negative rate: 98.979% (39921/40333)\n",
      "False positive rate: 1.021% (412/40333)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 32/67: Loss: 0.0666 | Train Acc: 97.339% (43608/44800) | Strict Acc: 72.000% (2304/3200)\n",
      "True positive rate: 75.733% (2403/3173)\n",
      "False negative rate: 24.267% (770/3173)\n",
      "True negative rate: 98.986% (41205/41627)\n",
      "False positive rate: 1.014% (422/41627)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 33/67: Loss: 0.0665 | Train Acc: 97.333% (44968/46200) | Strict Acc: 72.000% (2376/3300)\n",
      "True positive rate: 75.468% (2461/3261)\n",
      "False negative rate: 24.532% (800/3261)\n",
      "True negative rate: 98.994% (42507/42939)\n",
      "False positive rate: 1.006% (432/42939)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 34/67: Loss: 0.0667 | Train Acc: 97.332% (46330/47600) | Strict Acc: 72.059% (2450/3400)\n",
      "True positive rate: 75.246% (2526/3357)\n",
      "False negative rate: 24.754% (831/3357)\n",
      "True negative rate: 99.008% (43804/44243)\n",
      "False positive rate: 0.992% (439/44243)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 35/67: Loss: 0.0671 | Train Acc: 97.314% (47684/49000) | Strict Acc: 71.857% (2515/3500)\n",
      "True positive rate: 75.115% (2602/3464)\n",
      "False negative rate: 24.885% (862/3464)\n",
      "True negative rate: 99.003% (45082/45536)\n",
      "False positive rate: 0.997% (454/45536)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 36/67: Loss: 0.0669 | Train Acc: 97.321% (49050/50400) | Strict Acc: 71.917% (2589/3600)\n",
      "True positive rate: 75.196% (2689/3576)\n",
      "False negative rate: 24.804% (887/3576)\n",
      "True negative rate: 99.011% (46361/46824)\n",
      "False positive rate: 0.989% (463/46824)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 37/67: Loss: 0.0666 | Train Acc: 97.344% (50424/51800) | Strict Acc: 72.135% (2669/3700)\n",
      "True positive rate: 75.554% (2763/3657)\n",
      "False negative rate: 24.446% (894/3657)\n",
      "True negative rate: 98.999% (47661/48143)\n",
      "False positive rate: 1.001% (482/48143)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 38/67: Loss: 0.0666 | Train Acc: 97.333% (51781/53200) | Strict Acc: 72.079% (2739/3800)\n",
      "True positive rate: 75.544% (2848/3770)\n",
      "False negative rate: 24.456% (922/3770)\n",
      "True negative rate: 98.995% (48933/49430)\n",
      "False positive rate: 1.005% (497/49430)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 39/67: Loss: 0.0667 | Train Acc: 97.330% (53142/54600) | Strict Acc: 72.051% (2810/3900)\n",
      "True positive rate: 75.600% (2931/3877)\n",
      "False negative rate: 24.400% (946/3877)\n",
      "True negative rate: 98.991% (50211/50723)\n",
      "False positive rate: 1.009% (512/50723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 40/67: Loss: 0.0674 | Train Acc: 97.302% (54489/56000) | Strict Acc: 71.950% (2878/4000)\n",
      "True positive rate: 75.588% (3019/3994)\n",
      "False negative rate: 24.412% (975/3994)\n",
      "True negative rate: 98.969% (51470/52006)\n",
      "False positive rate: 1.031% (536/52006)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 41/67: Loss: 0.0673 | Train Acc: 97.310% (55856/57400) | Strict Acc: 72.024% (2953/4100)\n",
      "True positive rate: 75.704% (3091/4083)\n",
      "False negative rate: 24.296% (992/4083)\n",
      "True negative rate: 98.965% (52765/53317)\n",
      "False positive rate: 1.035% (552/53317)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 42/67: Loss: 0.0672 | Train Acc: 97.318% (57223/58800) | Strict Acc: 72.048% (3026/4200)\n",
      "True positive rate: 75.789% (3171/4184)\n",
      "False negative rate: 24.211% (1013/4184)\n",
      "True negative rate: 98.967% (54052/54616)\n",
      "False positive rate: 1.033% (564/54616)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 43/67: Loss: 0.0676 | Train Acc: 97.297% (58573/60200) | Strict Acc: 71.977% (3095/4300)\n",
      "True positive rate: 75.623% (3245/4291)\n",
      "False negative rate: 24.377% (1046/4291)\n",
      "True negative rate: 98.961% (55328/55909)\n",
      "False positive rate: 1.039% (581/55909)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 44/67: Loss: 0.0681 | Train Acc: 97.282% (59926/61600) | Strict Acc: 71.864% (3162/4400)\n",
      "True positive rate: 75.518% (3319/4395)\n",
      "False negative rate: 24.482% (1076/4395)\n",
      "True negative rate: 98.955% (56607/57205)\n",
      "False positive rate: 1.045% (598/57205)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 45/67: Loss: 0.0687 | Train Acc: 97.259% (61273/63000) | Strict Acc: 71.689% (3226/4500)\n",
      "True positive rate: 75.377% (3395/4504)\n",
      "False negative rate: 24.623% (1109/4504)\n",
      "True negative rate: 98.944% (57878/58496)\n",
      "False positive rate: 1.056% (618/58496)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 46/67: Loss: 0.0684 | Train Acc: 97.276% (62646/64400) | Strict Acc: 71.870% (3306/4600)\n",
      "True positive rate: 75.414% (3463/4592)\n",
      "False negative rate: 24.586% (1129/4592)\n",
      "True negative rate: 98.955% (59183/59808)\n",
      "False positive rate: 1.045% (625/59808)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 47/67: Loss: 0.0688 | Train Acc: 97.269% (64003/65800) | Strict Acc: 71.745% (3372/4700)\n",
      "True positive rate: 75.483% (3559/4715)\n",
      "False negative rate: 24.517% (1156/4715)\n",
      "True negative rate: 98.951% (60444/61085)\n",
      "False positive rate: 1.049% (641/61085)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 48/67: Loss: 0.0689 | Train Acc: 97.256% (65356/67200) | Strict Acc: 71.625% (3438/4800)\n",
      "True positive rate: 75.500% (3624/4800)\n",
      "False negative rate: 24.500% (1176/4800)\n",
      "True negative rate: 98.929% (61732/62400)\n",
      "False positive rate: 1.071% (668/62400)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 49/67: Loss: 0.0691 | Train Acc: 97.243% (66709/68600) | Strict Acc: 71.510% (3504/4900)\n",
      "True positive rate: 75.480% (3694/4894)\n",
      "False negative rate: 24.520% (1200/4894)\n",
      "True negative rate: 98.915% (63015/63706)\n",
      "False positive rate: 1.085% (691/63706)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 50/67: Loss: 0.0695 | Train Acc: 97.217% (68052/70000) | Strict Acc: 71.340% (3567/5000)\n",
      "True positive rate: 75.325% (3770/5005)\n",
      "False negative rate: 24.675% (1235/5005)\n",
      "True negative rate: 98.903% (64282/64995)\n",
      "False positive rate: 1.097% (713/64995)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 51/67: Loss: 0.0697 | Train Acc: 97.200% (69401/71400) | Strict Acc: 71.235% (3633/5100)\n",
      "True positive rate: 75.181% (3850/5121)\n",
      "False negative rate: 24.819% (1271/5121)\n",
      "True negative rate: 98.902% (65551/66279)\n",
      "False positive rate: 1.098% (728/66279)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 52/67: Loss: 0.0699 | Train Acc: 97.196% (70759/72800) | Strict Acc: 71.308% (3708/5200)\n",
      "True positive rate: 75.019% (3913/5216)\n",
      "False negative rate: 24.981% (1303/5216)\n",
      "True negative rate: 98.908% (66846/67584)\n",
      "False positive rate: 1.092% (738/67584)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 53/67: Loss: 0.0702 | Train Acc: 97.186% (72112/74200) | Strict Acc: 71.208% (3774/5300)\n",
      "True positive rate: 74.769% (3971/5311)\n",
      "False negative rate: 25.231% (1340/5311)\n",
      "True negative rate: 98.914% (68141/68889)\n",
      "False positive rate: 1.086% (748/68889)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 54/67: Loss: 0.0701 | Train Acc: 97.188% (73474/75600) | Strict Acc: 71.259% (3848/5400)\n",
      "True positive rate: 74.722% (4038/5404)\n",
      "False negative rate: 25.278% (1366/5404)\n",
      "True negative rate: 98.917% (69436/70196)\n",
      "False positive rate: 1.083% (760/70196)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 55/67: Loss: 0.0703 | Train Acc: 97.175% (74825/77000) | Strict Acc: 71.164% (3914/5500)\n",
      "True positive rate: 74.582% (4108/5508)\n",
      "False negative rate: 25.418% (1400/5508)\n",
      "True negative rate: 98.916% (70717/71492)\n",
      "False positive rate: 1.084% (775/71492)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 56/67: Loss: 0.0706 | Train Acc: 97.163% (76176/78400) | Strict Acc: 71.036% (3978/5600)\n",
      "True positive rate: 74.418% (4186/5625)\n",
      "False negative rate: 25.582% (1439/5625)\n",
      "True negative rate: 98.921% (71990/72775)\n",
      "False positive rate: 1.079% (785/72775)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 7 - Batch 57/67: Loss: 0.0707 | Train Acc: 97.163% (77536/79800) | Strict Acc: 71.000% (4047/5700)\n",
      "True positive rate: 74.442% (4270/5736)\n",
      "False negative rate: 25.558% (1466/5736)\n",
      "True negative rate: 98.923% (73266/74064)\n",
      "False positive rate: 1.077% (798/74064)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 58/67: Loss: 0.0709 | Train Acc: 97.158% (78892/81200) | Strict Acc: 70.879% (4111/5800)\n",
      "True positive rate: 74.503% (4345/5832)\n",
      "False negative rate: 25.497% (1487/5832)\n",
      "True negative rate: 98.911% (74547/75368)\n",
      "False positive rate: 1.089% (821/75368)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 59/67: Loss: 0.0712 | Train Acc: 97.144% (80241/82600) | Strict Acc: 70.746% (4174/5900)\n",
      "True positive rate: 74.478% (4424/5940)\n",
      "False negative rate: 25.522% (1516/5940)\n",
      "True negative rate: 98.900% (75817/76660)\n",
      "False positive rate: 1.100% (843/76660)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 60/67: Loss: 0.0713 | Train Acc: 97.144% (81601/84000) | Strict Acc: 70.767% (4246/6000)\n",
      "True positive rate: 74.501% (4517/6063)\n",
      "False negative rate: 25.499% (1546/6063)\n",
      "True negative rate: 98.906% (77084/77937)\n",
      "False positive rate: 1.094% (853/77937)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 61/67: Loss: 0.0712 | Train Acc: 97.150% (82966/85400) | Strict Acc: 70.787% (4318/6100)\n",
      "True positive rate: 74.594% (4595/6160)\n",
      "False negative rate: 25.406% (1565/6160)\n",
      "True negative rate: 98.903% (78371/79240)\n",
      "False positive rate: 1.097% (869/79240)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 62/67: Loss: 0.0711 | Train Acc: 97.156% (84331/86800) | Strict Acc: 70.839% (4392/6200)\n",
      "True positive rate: 74.704% (4672/6254)\n",
      "False negative rate: 25.296% (1582/6254)\n",
      "True negative rate: 98.899% (79659/80546)\n",
      "False positive rate: 1.101% (887/80546)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 63/67: Loss: 0.0711 | Train Acc: 97.159% (85694/88200) | Strict Acc: 70.889% (4466/6300)\n",
      "True positive rate: 74.657% (4740/6349)\n",
      "False negative rate: 25.343% (1609/6349)\n",
      "True negative rate: 98.904% (80954/81851)\n",
      "False positive rate: 1.096% (897/81851)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 64/67: Loss: 0.0712 | Train Acc: 97.162% (87057/89600) | Strict Acc: 70.922% (4539/6400)\n",
      "True positive rate: 74.632% (4822/6461)\n",
      "False negative rate: 25.368% (1639/6461)\n",
      "True negative rate: 98.913% (82235/83139)\n",
      "False positive rate: 1.087% (904/83139)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 65/67: Loss: 0.0713 | Train Acc: 97.158% (88414/91000) | Strict Acc: 70.877% (4607/6500)\n",
      "True positive rate: 74.571% (4906/6579)\n",
      "False negative rate: 25.429% (1673/6579)\n",
      "True negative rate: 98.919% (83508/84421)\n",
      "False positive rate: 1.081% (913/84421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 66/67: Loss: 0.0713 | Train Acc: 97.160% (89776/92400) | Strict Acc: 70.833% (4675/6600)\n",
      "True positive rate: 74.527% (4968/6666)\n",
      "False negative rate: 25.473% (1698/6666)\n",
      "True negative rate: 98.920% (84808/85734)\n",
      "False positive rate: 1.080% (926/85734)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 67/67: Loss: 0.0711 | Train Acc: 97.163% (91098/93758) | Strict Acc: 70.897% (4748/6697)\n",
      "True positive rate: 74.519% (5030/6750)\n",
      "False negative rate: 25.481% (1720/6750)\n",
      "True negative rate: 98.920% (86068/87008)\n",
      "False positive rate: 1.080% (940/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1762 | Dev Acc: 93.666% (85459/91238) | Strict Acc: 46.264% (3015/6517)\n",
      "True positive rate: 28.120% (1850/6579)\n",
      "False negative rate: 71.880% (4729/6579)\n",
      "True negative rate: 98.760% (83609/84659)\n",
      "False positive rate: 1.240% (1050/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 1/67: Loss: 0.0570 | Train Acc: 97.429% (1364/1400) | Strict Acc: 75.000% (75/100)\n",
      "True positive rate: 83.065% (103/124)\n",
      "False negative rate: 16.935% (21/124)\n",
      "True negative rate: 98.824% (1261/1276)\n",
      "False positive rate: 1.176% (15/1276)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 2/67: Loss: 0.0578 | Train Acc: 97.714% (2736/2800) | Strict Acc: 77.000% (154/200)\n",
      "True positive rate: 83.857% (187/223)\n",
      "False negative rate: 16.143% (36/223)\n",
      "True negative rate: 98.913% (2549/2577)\n",
      "False positive rate: 1.087% (28/2577)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 3/67: Loss: 0.0584 | Train Acc: 97.714% (4104/4200) | Strict Acc: 77.000% (231/300)\n",
      "True positive rate: 83.495% (258/309)\n",
      "False negative rate: 16.505% (51/309)\n",
      "True negative rate: 98.843% (3846/3891)\n",
      "False positive rate: 1.157% (45/3891)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 4/67: Loss: 0.0582 | Train Acc: 97.750% (5474/5600) | Strict Acc: 76.500% (306/400)\n",
      "True positive rate: 82.809% (342/413)\n",
      "False negative rate: 17.191% (71/413)\n",
      "True negative rate: 98.940% (5132/5187)\n",
      "False positive rate: 1.060% (55/5187)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 5/67: Loss: 0.0586 | Train Acc: 97.686% (6838/7000) | Strict Acc: 75.600% (378/500)\n",
      "True positive rate: 81.644% (427/523)\n",
      "False negative rate: 18.356% (96/523)\n",
      "True negative rate: 98.981% (6411/6477)\n",
      "False positive rate: 1.019% (66/6477)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 6/67: Loss: 0.0599 | Train Acc: 97.631% (8201/8400) | Strict Acc: 74.333% (446/600)\n",
      "True positive rate: 80.906% (500/618)\n",
      "False negative rate: 19.094% (118/618)\n",
      "True negative rate: 98.959% (7701/7782)\n",
      "False positive rate: 1.041% (81/7782)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 7/67: Loss: 0.0597 | Train Acc: 97.592% (9564/9800) | Strict Acc: 73.857% (517/700)\n",
      "True positive rate: 79.704% (593/744)\n",
      "False negative rate: 20.296% (151/744)\n",
      "True negative rate: 99.061% (8971/9056)\n",
      "False positive rate: 0.939% (85/9056)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 8/67: Loss: 0.0600 | Train Acc: 97.598% (10931/11200) | Strict Acc: 74.000% (592/800)\n",
      "True positive rate: 79.858% (674/844)\n",
      "False negative rate: 20.142% (170/844)\n",
      "True negative rate: 99.044% (10257/10356)\n",
      "False positive rate: 0.956% (99/10356)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 9/67: Loss: 0.0599 | Train Acc: 97.627% (12301/12600) | Strict Acc: 74.444% (670/900)\n",
      "True positive rate: 79.894% (755/945)\n",
      "False negative rate: 20.106% (190/945)\n",
      "True negative rate: 99.065% (11546/11655)\n",
      "False positive rate: 0.935% (109/11655)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 10/67: Loss: 0.0591 | Train Acc: 97.650% (13671/14000) | Strict Acc: 74.900% (749/1000)\n",
      "True positive rate: 79.884% (826/1034)\n",
      "False negative rate: 20.116% (208/1034)\n",
      "True negative rate: 99.067% (12845/12966)\n",
      "False positive rate: 0.933% (121/12966)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 11/67: Loss: 0.0624 | Train Acc: 97.526% (15019/15400) | Strict Acc: 73.909% (813/1100)\n",
      "True positive rate: 78.731% (918/1166)\n",
      "False negative rate: 21.269% (248/1166)\n",
      "True negative rate: 99.066% (14101/14234)\n",
      "False positive rate: 0.934% (133/14234)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 12/67: Loss: 0.0623 | Train Acc: 97.548% (16388/16800) | Strict Acc: 73.833% (886/1200)\n",
      "True positive rate: 79.124% (1012/1279)\n",
      "False negative rate: 20.876% (267/1279)\n",
      "True negative rate: 99.066% (15376/15521)\n",
      "False positive rate: 0.934% (145/15521)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 13/67: Loss: 0.0617 | Train Acc: 97.582% (17760/18200) | Strict Acc: 74.154% (964/1300)\n",
      "True positive rate: 79.578% (1095/1376)\n",
      "False negative rate: 20.422% (281/1376)\n",
      "True negative rate: 99.055% (16665/16824)\n",
      "False positive rate: 0.945% (159/16824)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 14/67: Loss: 0.0616 | Train Acc: 97.582% (19126/19600) | Strict Acc: 74.571% (1044/1400)\n",
      "True positive rate: 79.303% (1161/1464)\n",
      "False negative rate: 20.697% (303/1464)\n",
      "True negative rate: 99.057% (17965/18136)\n",
      "False positive rate: 0.943% (171/18136)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 8 - Batch 15/67: Loss: 0.0626 | Train Acc: 97.524% (20480/21000) | Strict Acc: 74.067% (1111/1500)\n",
      "True positive rate: 78.730% (1240/1575)\n",
      "False negative rate: 21.270% (335/1575)\n",
      "True negative rate: 99.048% (19240/19425)\n",
      "False positive rate: 0.952% (185/19425)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 16/67: Loss: 0.0632 | Train Acc: 97.487% (21837/22400) | Strict Acc: 73.812% (1181/1600)\n",
      "True positive rate: 78.500% (1340/1707)\n",
      "False negative rate: 21.500% (367/1707)\n",
      "True negative rate: 99.053% (20497/20693)\n",
      "False positive rate: 0.947% (196/20693)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 17/67: Loss: 0.0632 | Train Acc: 97.517% (23209/23800) | Strict Acc: 74.176% (1261/1700)\n",
      "True positive rate: 78.930% (1431/1813)\n",
      "False negative rate: 21.070% (382/1813)\n",
      "True negative rate: 99.049% (21778/21987)\n",
      "False positive rate: 0.951% (209/21987)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 18/67: Loss: 0.0632 | Train Acc: 97.500% (24570/25200) | Strict Acc: 74.222% (1336/1800)\n",
      "True positive rate: 78.992% (1504/1904)\n",
      "False negative rate: 21.008% (400/1904)\n",
      "True negative rate: 99.013% (23066/23296)\n",
      "False positive rate: 0.987% (230/23296)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 19/67: Loss: 0.0638 | Train Acc: 97.455% (25923/26600) | Strict Acc: 73.632% (1399/1900)\n",
      "True positive rate: 78.795% (1583/2009)\n",
      "False negative rate: 21.205% (426/2009)\n",
      "True negative rate: 98.979% (24340/24591)\n",
      "False positive rate: 1.021% (251/24591)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 20/67: Loss: 0.0635 | Train Acc: 97.457% (27288/28000) | Strict Acc: 73.700% (1474/2000)\n",
      "True positive rate: 79.057% (1676/2120)\n",
      "False negative rate: 20.943% (444/2120)\n",
      "True negative rate: 98.964% (25612/25880)\n",
      "False positive rate: 1.036% (268/25880)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 21/67: Loss: 0.0626 | Train Acc: 97.490% (28662/29400) | Strict Acc: 73.857% (1551/2100)\n",
      "True positive rate: 79.050% (1747/2210)\n",
      "False negative rate: 20.950% (463/2210)\n",
      "True negative rate: 98.989% (26915/27190)\n",
      "False positive rate: 1.011% (275/27190)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 22/67: Loss: 0.0632 | Train Acc: 97.451% (30015/30800) | Strict Acc: 73.409% (1615/2200)\n",
      "True positive rate: 78.565% (1829/2328)\n",
      "False negative rate: 21.435% (499/2328)\n",
      "True negative rate: 98.996% (28186/28472)\n",
      "False positive rate: 1.004% (286/28472)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 23/67: Loss: 0.0631 | Train Acc: 97.472% (31386/32200) | Strict Acc: 73.565% (1692/2300)\n",
      "True positive rate: 78.699% (1888/2399)\n",
      "False negative rate: 21.301% (511/2399)\n",
      "True negative rate: 98.983% (29498/29801)\n",
      "False positive rate: 1.017% (303/29801)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 24/67: Loss: 0.0624 | Train Acc: 97.503% (32761/33600) | Strict Acc: 73.792% (1771/2400)\n",
      "True positive rate: 78.861% (1966/2493)\n",
      "False negative rate: 21.139% (527/2493)\n",
      "True negative rate: 98.997% (30795/31107)\n",
      "False positive rate: 1.003% (312/31107)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 25/67: Loss: 0.0629 | Train Acc: 97.477% (34117/35000) | Strict Acc: 73.600% (1840/2500)\n",
      "True positive rate: 78.714% (2045/2598)\n",
      "False negative rate: 21.286% (553/2598)\n",
      "True negative rate: 98.982% (32072/32402)\n",
      "False positive rate: 1.018% (330/32402)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 26/67: Loss: 0.0636 | Train Acc: 97.448% (35471/36400) | Strict Acc: 73.423% (1909/2600)\n",
      "True positive rate: 78.176% (2117/2708)\n",
      "False negative rate: 21.824% (591/2708)\n",
      "True negative rate: 98.997% (33354/33692)\n",
      "False positive rate: 1.003% (338/33692)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 27/67: Loss: 0.0635 | Train Acc: 97.468% (36843/37800) | Strict Acc: 73.556% (1986/2700)\n",
      "True positive rate: 78.290% (2189/2796)\n",
      "False negative rate: 21.710% (607/2796)\n",
      "True negative rate: 99.000% (34654/35004)\n",
      "False positive rate: 1.000% (350/35004)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 28/67: Loss: 0.0637 | Train Acc: 97.459% (38204/39200) | Strict Acc: 73.464% (2057/2800)\n",
      "True positive rate: 78.321% (2276/2906)\n",
      "False negative rate: 21.679% (630/2906)\n",
      "True negative rate: 98.992% (35928/36294)\n",
      "False positive rate: 1.008% (366/36294)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 29/67: Loss: 0.0635 | Train Acc: 97.473% (39574/40600) | Strict Acc: 73.655% (2136/2900)\n",
      "True positive rate: 78.320% (2359/3012)\n",
      "False negative rate: 21.680% (653/3012)\n",
      "True negative rate: 99.008% (37215/37588)\n",
      "False positive rate: 0.992% (373/37588)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 30/67: Loss: 0.0636 | Train Acc: 97.474% (40939/42000) | Strict Acc: 73.600% (2208/3000)\n",
      "True positive rate: 78.500% (2417/3079)\n",
      "False negative rate: 21.500% (662/3079)\n",
      "True negative rate: 98.975% (38522/38921)\n",
      "False positive rate: 1.025% (399/38921)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 31/67: Loss: 0.0634 | Train Acc: 97.482% (42307/43400) | Strict Acc: 73.710% (2285/3100)\n",
      "True positive rate: 78.711% (2503/3180)\n",
      "False negative rate: 21.289% (677/3180)\n",
      "True negative rate: 98.966% (39804/40220)\n",
      "False positive rate: 1.034% (416/40220)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 32/67: Loss: 0.0637 | Train Acc: 97.475% (43669/44800) | Strict Acc: 73.719% (2359/3200)\n",
      "True positive rate: 78.377% (2559/3265)\n",
      "False negative rate: 21.623% (706/3265)\n",
      "True negative rate: 98.977% (41110/41535)\n",
      "False positive rate: 1.023% (425/41535)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 33/67: Loss: 0.0638 | Train Acc: 97.494% (45042/46200) | Strict Acc: 73.970% (2441/3300)\n",
      "True positive rate: 78.367% (2630/3356)\n",
      "False negative rate: 21.633% (726/3356)\n",
      "True negative rate: 98.992% (42412/42844)\n",
      "False positive rate: 1.008% (432/42844)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 34/67: Loss: 0.0637 | Train Acc: 97.487% (46404/47600) | Strict Acc: 73.912% (2513/3400)\n",
      "True positive rate: 78.125% (2700/3456)\n",
      "False negative rate: 21.875% (756/3456)\n",
      "True negative rate: 99.003% (43704/44144)\n",
      "False positive rate: 0.997% (440/44144)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 35/67: Loss: 0.0636 | Train Acc: 97.492% (47771/49000) | Strict Acc: 73.971% (2589/3500)\n",
      "True positive rate: 78.150% (2779/3556)\n",
      "False negative rate: 21.850% (777/3556)\n",
      "True negative rate: 99.005% (44992/45444)\n",
      "False positive rate: 0.995% (452/45444)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 36/67: Loss: 0.0639 | Train Acc: 97.476% (49128/50400) | Strict Acc: 73.889% (2660/3600)\n",
      "True positive rate: 78.115% (2859/3660)\n",
      "False negative rate: 21.885% (801/3660)\n",
      "True negative rate: 98.992% (46269/46740)\n",
      "False positive rate: 1.008% (471/46740)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 37/67: Loss: 0.0636 | Train Acc: 97.483% (50496/51800) | Strict Acc: 73.892% (2734/3700)\n",
      "True positive rate: 78.275% (2940/3756)\n",
      "False negative rate: 21.725% (816/3756)\n",
      "True negative rate: 98.984% (47556/48044)\n",
      "False positive rate: 1.016% (488/48044)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 38/67: Loss: 0.0640 | Train Acc: 97.459% (51848/53200) | Strict Acc: 73.632% (2798/3800)\n",
      "True positive rate: 78.177% (3027/3872)\n",
      "False negative rate: 21.823% (845/3872)\n",
      "True negative rate: 98.972% (48821/49328)\n",
      "False positive rate: 1.028% (507/49328)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 39/67: Loss: 0.0639 | Train Acc: 97.447% (53206/54600) | Strict Acc: 73.513% (2867/3900)\n",
      "True positive rate: 78.096% (3084/3949)\n",
      "False negative rate: 21.904% (865/3949)\n",
      "True negative rate: 98.956% (50122/50651)\n",
      "False positive rate: 1.044% (529/50651)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 40/67: Loss: 0.0637 | Train Acc: 97.452% (54573/56000) | Strict Acc: 73.600% (2944/4000)\n",
      "True positive rate: 78.092% (3176/4067)\n",
      "False negative rate: 21.908% (891/4067)\n",
      "True negative rate: 98.968% (51397/51933)\n",
      "False positive rate: 1.032% (536/51933)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 8 - Batch 41/67: Loss: 0.0637 | Train Acc: 97.453% (55938/57400) | Strict Acc: 73.610% (3018/4100)\n",
      "True positive rate: 78.097% (3259/4173)\n",
      "False negative rate: 21.903% (914/4173)\n",
      "True negative rate: 98.970% (52679/53227)\n",
      "False positive rate: 1.030% (548/53227)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 42/67: Loss: 0.0637 | Train Acc: 97.459% (57306/58800) | Strict Acc: 73.667% (3094/4200)\n",
      "True positive rate: 78.066% (3342/4281)\n",
      "False negative rate: 21.934% (939/4281)\n",
      "True negative rate: 98.982% (53964/54519)\n",
      "False positive rate: 1.018% (555/54519)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 43/67: Loss: 0.0636 | Train Acc: 97.465% (58674/60200) | Strict Acc: 73.721% (3170/4300)\n",
      "True positive rate: 78.042% (3412/4372)\n",
      "False negative rate: 21.958% (960/4372)\n",
      "True negative rate: 98.986% (55262/55828)\n",
      "False positive rate: 1.014% (566/55828)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 44/67: Loss: 0.0636 | Train Acc: 97.472% (60043/61600) | Strict Acc: 73.750% (3245/4400)\n",
      "True positive rate: 78.098% (3498/4479)\n",
      "False negative rate: 21.902% (981/4479)\n",
      "True negative rate: 98.992% (56545/57121)\n",
      "False positive rate: 1.008% (576/57121)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 45/67: Loss: 0.0634 | Train Acc: 97.475% (61409/63000) | Strict Acc: 73.800% (3321/4500)\n",
      "True positive rate: 78.110% (3579/4582)\n",
      "False negative rate: 21.890% (1003/4582)\n",
      "True negative rate: 98.993% (57830/58418)\n",
      "False positive rate: 1.007% (588/58418)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 46/67: Loss: 0.0633 | Train Acc: 97.478% (62776/64400) | Strict Acc: 73.804% (3395/4600)\n",
      "True positive rate: 78.185% (3670/4694)\n",
      "False negative rate: 21.815% (1024/4694)\n",
      "True negative rate: 98.995% (59106/59706)\n",
      "False positive rate: 1.005% (600/59706)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 47/67: Loss: 0.0637 | Train Acc: 97.462% (64130/65800) | Strict Acc: 73.660% (3462/4700)\n",
      "True positive rate: 78.026% (3739/4792)\n",
      "False negative rate: 21.974% (1053/4792)\n",
      "True negative rate: 98.989% (60391/61008)\n",
      "False positive rate: 1.011% (617/61008)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 48/67: Loss: 0.0637 | Train Acc: 97.461% (65494/67200) | Strict Acc: 73.667% (3536/4800)\n",
      "True positive rate: 78.050% (3826/4902)\n",
      "False negative rate: 21.950% (1076/4902)\n",
      "True negative rate: 98.989% (61668/62298)\n",
      "False positive rate: 1.011% (630/62298)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 49/67: Loss: 0.0638 | Train Acc: 97.455% (66854/68600) | Strict Acc: 73.592% (3606/4900)\n",
      "True positive rate: 77.998% (3896/4995)\n",
      "False negative rate: 22.002% (1099/4995)\n",
      "True negative rate: 98.983% (62958/63605)\n",
      "False positive rate: 1.017% (647/63605)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 50/67: Loss: 0.0637 | Train Acc: 97.461% (68223/70000) | Strict Acc: 73.660% (3683/5000)\n",
      "True positive rate: 78.102% (3966/5078)\n",
      "False negative rate: 21.898% (1112/5078)\n",
      "True negative rate: 98.976% (64257/64922)\n",
      "False positive rate: 1.024% (665/64922)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 51/67: Loss: 0.0636 | Train Acc: 97.466% (69591/71400) | Strict Acc: 73.725% (3760/5100)\n",
      "True positive rate: 78.181% (4049/5179)\n",
      "False negative rate: 21.819% (1130/5179)\n",
      "True negative rate: 98.975% (65542/66221)\n",
      "False positive rate: 1.025% (679/66221)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 52/67: Loss: 0.0634 | Train Acc: 97.468% (70957/72800) | Strict Acc: 73.827% (3839/5200)\n",
      "True positive rate: 78.077% (4117/5273)\n",
      "False negative rate: 21.923% (1156/5273)\n",
      "True negative rate: 98.983% (66840/67527)\n",
      "False positive rate: 1.017% (687/67527)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 53/67: Loss: 0.0631 | Train Acc: 97.476% (72327/74200) | Strict Acc: 73.868% (3915/5300)\n",
      "True positive rate: 78.064% (4185/5361)\n",
      "False negative rate: 21.936% (1176/5361)\n",
      "True negative rate: 98.987% (68142/68839)\n",
      "False positive rate: 1.013% (697/68839)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 54/67: Loss: 0.0632 | Train Acc: 97.475% (73691/75600) | Strict Acc: 73.852% (3988/5400)\n",
      "True positive rate: 77.954% (4268/5475)\n",
      "False negative rate: 22.046% (1207/5475)\n",
      "True negative rate: 98.999% (69423/70125)\n",
      "False positive rate: 1.001% (702/70125)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 55/67: Loss: 0.0632 | Train Acc: 97.478% (75058/77000) | Strict Acc: 73.873% (4063/5500)\n",
      "True positive rate: 77.951% (4352/5583)\n",
      "False negative rate: 22.049% (1231/5583)\n",
      "True negative rate: 99.004% (70706/71417)\n",
      "False positive rate: 0.996% (711/71417)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 56/67: Loss: 0.0631 | Train Acc: 97.486% (76429/78400) | Strict Acc: 73.982% (4143/5600)\n",
      "True positive rate: 77.944% (4421/5672)\n",
      "False negative rate: 22.056% (1251/5672)\n",
      "True negative rate: 99.010% (72008/72728)\n",
      "False positive rate: 0.990% (720/72728)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 57/67: Loss: 0.0632 | Train Acc: 97.479% (77788/79800) | Strict Acc: 73.947% (4215/5700)\n",
      "True positive rate: 77.847% (4498/5778)\n",
      "False negative rate: 22.153% (1280/5778)\n",
      "True negative rate: 99.011% (73290/74022)\n",
      "False positive rate: 0.989% (732/74022)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 58/67: Loss: 0.0633 | Train Acc: 97.468% (79144/81200) | Strict Acc: 73.759% (4278/5800)\n",
      "True positive rate: 77.797% (4562/5864)\n",
      "False negative rate: 22.203% (1302/5864)\n",
      "True negative rate: 98.999% (74582/75336)\n",
      "False positive rate: 1.001% (754/75336)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 59/67: Loss: 0.0633 | Train Acc: 97.470% (80510/82600) | Strict Acc: 73.831% (4356/5900)\n",
      "True positive rate: 77.828% (4630/5949)\n",
      "False negative rate: 22.172% (1319/5949)\n",
      "True negative rate: 98.994% (75880/76651)\n",
      "False positive rate: 1.006% (771/76651)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 60/67: Loss: 0.0630 | Train Acc: 97.483% (81886/84000) | Strict Acc: 73.933% (4436/6000)\n",
      "True positive rate: 78.022% (4718/6047)\n",
      "False negative rate: 21.978% (1329/6047)\n",
      "True negative rate: 98.993% (77168/77953)\n",
      "False positive rate: 1.007% (785/77953)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 61/67: Loss: 0.0631 | Train Acc: 97.475% (83244/85400) | Strict Acc: 73.918% (4509/6100)\n",
      "True positive rate: 77.944% (4792/6148)\n",
      "False negative rate: 22.056% (1356/6148)\n",
      "True negative rate: 98.991% (78452/79252)\n",
      "False positive rate: 1.009% (800/79252)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 62/67: Loss: 0.0636 | Train Acc: 97.464% (84599/86800) | Strict Acc: 73.823% (4577/6200)\n",
      "True positive rate: 77.707% (4852/6244)\n",
      "False negative rate: 22.293% (1392/6244)\n",
      "True negative rate: 98.996% (79747/80556)\n",
      "False positive rate: 1.004% (809/80556)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 63/67: Loss: 0.0635 | Train Acc: 97.476% (85974/88200) | Strict Acc: 73.921% (4657/6300)\n",
      "True positive rate: 77.697% (4919/6331)\n",
      "False negative rate: 22.303% (1412/6331)\n",
      "True negative rate: 99.006% (81055/81869)\n",
      "False positive rate: 0.994% (814/81869)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 64/67: Loss: 0.0634 | Train Acc: 97.480% (87342/89600) | Strict Acc: 73.922% (4731/6400)\n",
      "True positive rate: 77.733% (4999/6431)\n",
      "False negative rate: 22.267% (1432/6431)\n",
      "True negative rate: 99.007% (82343/83169)\n",
      "False positive rate: 0.993% (826/83169)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 65/67: Loss: 0.0633 | Train Acc: 97.477% (88704/91000) | Strict Acc: 73.862% (4801/6500)\n",
      "True positive rate: 77.810% (5088/6539)\n",
      "False negative rate: 22.190% (1451/6539)\n",
      "True negative rate: 99.000% (83616/84461)\n",
      "False positive rate: 1.000% (845/84461)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 8 - Batch 66/67: Loss: 0.0635 | Train Acc: 97.461% (90054/92400) | Strict Acc: 73.682% (4863/6600)\n",
      "True positive rate: 77.841% (5171/6643)\n",
      "False negative rate: 22.159% (1472/6643)\n",
      "True negative rate: 98.981% (84883/85757)\n",
      "False positive rate: 1.019% (874/85757)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 67/67: Loss: 0.0635 | Train Acc: 97.460% (91377/93758) | Strict Acc: 73.660% (4933/6697)\n",
      "True positive rate: 77.867% (5256/6750)\n",
      "False negative rate: 22.133% (1494/6750)\n",
      "True negative rate: 98.981% (86121/87008)\n",
      "False positive rate: 1.019% (887/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1701 | Dev Acc: 93.889% (85662/91238) | Strict Acc: 45.588% (2971/6517)\n",
      "True positive rate: 37.696% (2480/6579)\n",
      "False negative rate: 62.304% (4099/6579)\n",
      "True negative rate: 98.255% (83182/84659)\n",
      "False positive rate: 1.745% (1477/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 1/67: Loss: 0.0519 | Train Acc: 98.143% (1374/1400) | Strict Acc: 77.000% (77/100)\n",
      "True positive rate: 77.895% (74/95)\n",
      "False negative rate: 22.105% (21/95)\n",
      "True negative rate: 99.617% (1300/1305)\n",
      "False positive rate: 0.383% (5/1305)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 2/67: Loss: 0.0473 | Train Acc: 98.429% (2756/2800) | Strict Acc: 81.500% (163/200)\n",
      "True positive rate: 82.222% (148/180)\n",
      "False negative rate: 17.778% (32/180)\n",
      "True negative rate: 99.542% (2608/2620)\n",
      "False positive rate: 0.458% (12/2620)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 3/67: Loss: 0.0543 | Train Acc: 98.048% (4118/4200) | Strict Acc: 78.667% (236/300)\n",
      "True positive rate: 78.986% (218/276)\n",
      "False negative rate: 21.014% (58/276)\n",
      "True negative rate: 99.388% (3900/3924)\n",
      "False positive rate: 0.612% (24/3924)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 4/67: Loss: 0.0558 | Train Acc: 97.911% (5483/5600) | Strict Acc: 77.500% (310/400)\n",
      "True positive rate: 77.095% (276/358)\n",
      "False negative rate: 22.905% (82/358)\n",
      "True negative rate: 99.332% (5207/5242)\n",
      "False positive rate: 0.668% (35/5242)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 5/67: Loss: 0.0547 | Train Acc: 98.000% (6860/7000) | Strict Acc: 78.400% (392/500)\n",
      "True positive rate: 77.828% (344/442)\n",
      "False negative rate: 22.172% (98/442)\n",
      "True negative rate: 99.360% (6516/6558)\n",
      "False positive rate: 0.640% (42/6558)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 6/67: Loss: 0.0538 | Train Acc: 98.036% (8235/8400) | Strict Acc: 79.000% (474/600)\n",
      "True positive rate: 77.966% (414/531)\n",
      "False negative rate: 22.034% (117/531)\n",
      "True negative rate: 99.390% (7821/7869)\n",
      "False positive rate: 0.610% (48/7869)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 7/67: Loss: 0.0526 | Train Acc: 98.092% (9613/9800) | Strict Acc: 79.714% (558/700)\n",
      "True positive rate: 78.378% (493/629)\n",
      "False negative rate: 21.622% (136/629)\n",
      "True negative rate: 99.444% (9120/9171)\n",
      "False positive rate: 0.556% (51/9171)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 8/67: Loss: 0.0538 | Train Acc: 98.036% (10980/11200) | Strict Acc: 78.875% (631/800)\n",
      "True positive rate: 78.796% (576/731)\n",
      "False negative rate: 21.204% (155/731)\n",
      "True negative rate: 99.379% (10404/10469)\n",
      "False positive rate: 0.621% (65/10469)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 9/67: Loss: 0.0558 | Train Acc: 97.873% (12332/12600) | Strict Acc: 78.000% (702/900)\n",
      "True positive rate: 77.844% (657/844)\n",
      "False negative rate: 22.156% (187/844)\n",
      "True negative rate: 99.311% (11675/11756)\n",
      "False positive rate: 0.689% (81/11756)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 10/67: Loss: 0.0554 | Train Acc: 97.857% (13700/14000) | Strict Acc: 77.800% (778/1000)\n",
      "True positive rate: 78.429% (749/955)\n",
      "False negative rate: 21.571% (206/955)\n",
      "True negative rate: 99.279% (12951/13045)\n",
      "False positive rate: 0.721% (94/13045)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 11/67: Loss: 0.0544 | Train Acc: 97.903% (15077/15400) | Strict Acc: 78.273% (861/1100)\n",
      "True positive rate: 79.072% (835/1056)\n",
      "False negative rate: 20.928% (221/1056)\n",
      "True negative rate: 99.289% (14242/14344)\n",
      "False positive rate: 0.711% (102/14344)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 12/67: Loss: 0.0536 | Train Acc: 97.935% (16453/16800) | Strict Acc: 78.417% (941/1200)\n",
      "True positive rate: 79.814% (945/1184)\n",
      "False negative rate: 20.186% (239/1184)\n",
      "True negative rate: 99.308% (15508/15616)\n",
      "False positive rate: 0.692% (108/15616)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 13/67: Loss: 0.0532 | Train Acc: 97.934% (17824/18200) | Strict Acc: 78.308% (1018/1300)\n",
      "True positive rate: 80.062% (1032/1289)\n",
      "False negative rate: 19.938% (257/1289)\n",
      "True negative rate: 99.296% (16792/16911)\n",
      "False positive rate: 0.704% (119/16911)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 14/67: Loss: 0.0530 | Train Acc: 97.954% (19199/19600) | Strict Acc: 78.571% (1100/1400)\n",
      "True positive rate: 80.444% (1123/1396)\n",
      "False negative rate: 19.556% (273/1396)\n",
      "True negative rate: 99.297% (18076/18204)\n",
      "False positive rate: 0.703% (128/18204)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 15/67: Loss: 0.0525 | Train Acc: 97.981% (20576/21000) | Strict Acc: 78.667% (1180/1500)\n",
      "True positive rate: 80.514% (1190/1478)\n",
      "False negative rate: 19.486% (288/1478)\n",
      "True negative rate: 99.303% (19386/19522)\n",
      "False positive rate: 0.697% (136/19522)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 16/67: Loss: 0.0520 | Train Acc: 98.004% (21953/22400) | Strict Acc: 78.938% (1263/1600)\n",
      "True positive rate: 80.808% (1280/1584)\n",
      "False negative rate: 19.192% (304/1584)\n",
      "True negative rate: 99.313% (20673/20816)\n",
      "False positive rate: 0.687% (143/20816)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 17/67: Loss: 0.0525 | Train Acc: 97.983% (23320/23800) | Strict Acc: 78.765% (1339/1700)\n",
      "True positive rate: 80.202% (1349/1682)\n",
      "False negative rate: 19.798% (333/1682)\n",
      "True negative rate: 99.335% (21971/22118)\n",
      "False positive rate: 0.665% (147/22118)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 18/67: Loss: 0.0527 | Train Acc: 97.964% (24687/25200) | Strict Acc: 78.722% (1417/1800)\n",
      "True positive rate: 79.933% (1422/1779)\n",
      "False negative rate: 20.067% (357/1779)\n",
      "True negative rate: 99.334% (23265/23421)\n",
      "False positive rate: 0.666% (156/23421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 19/67: Loss: 0.0522 | Train Acc: 97.985% (26064/26600) | Strict Acc: 78.947% (1500/1900)\n",
      "True positive rate: 80.128% (1504/1877)\n",
      "False negative rate: 19.872% (373/1877)\n",
      "True negative rate: 99.341% (24560/24723)\n",
      "False positive rate: 0.659% (163/24723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 20/67: Loss: 0.0526 | Train Acc: 97.950% (27426/28000) | Strict Acc: 78.500% (1570/2000)\n",
      "True positive rate: 80.193% (1583/1974)\n",
      "False negative rate: 19.807% (391/1974)\n",
      "True negative rate: 99.297% (25843/26026)\n",
      "False positive rate: 0.703% (183/26026)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 21/67: Loss: 0.0528 | Train Acc: 97.946% (28796/29400) | Strict Acc: 78.381% (1646/2100)\n",
      "True positive rate: 80.588% (1673/2076)\n",
      "False negative rate: 19.412% (403/2076)\n",
      "True negative rate: 99.264% (27123/27324)\n",
      "False positive rate: 0.736% (201/27324)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 22/67: Loss: 0.0525 | Train Acc: 97.964% (30173/30800) | Strict Acc: 78.500% (1727/2200)\n",
      "True positive rate: 81.020% (1763/2176)\n",
      "False negative rate: 18.980% (413/2176)\n",
      "True negative rate: 99.252% (28410/28624)\n",
      "False positive rate: 0.748% (214/28624)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 23/67: Loss: 0.0521 | Train Acc: 97.972% (31547/32200) | Strict Acc: 78.565% (1807/2300)\n",
      "True positive rate: 81.447% (1857/2280)\n",
      "False negative rate: 18.553% (423/2280)\n",
      "True negative rate: 99.231% (29690/29920)\n",
      "False positive rate: 0.769% (230/29920)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 9 - Batch 24/67: Loss: 0.0519 | Train Acc: 97.964% (32916/33600) | Strict Acc: 78.458% (1883/2400)\n",
      "True positive rate: 81.526% (1955/2398)\n",
      "False negative rate: 18.474% (443/2398)\n",
      "True negative rate: 99.228% (30961/31202)\n",
      "False positive rate: 0.772% (241/31202)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 25/67: Loss: 0.0514 | Train Acc: 97.994% (34298/35000) | Strict Acc: 78.840% (1971/2500)\n",
      "True positive rate: 81.624% (2021/2476)\n",
      "False negative rate: 18.376% (455/2476)\n",
      "True negative rate: 99.241% (32277/32524)\n",
      "False positive rate: 0.759% (247/32524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 26/67: Loss: 0.0514 | Train Acc: 97.981% (35665/36400) | Strict Acc: 78.692% (2046/2600)\n",
      "True positive rate: 81.403% (2101/2581)\n",
      "False negative rate: 18.597% (480/2581)\n",
      "True negative rate: 99.246% (33564/33819)\n",
      "False positive rate: 0.754% (255/33819)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 27/67: Loss: 0.0521 | Train Acc: 97.960% (37029/37800) | Strict Acc: 78.481% (2119/2700)\n",
      "True positive rate: 81.009% (2167/2675)\n",
      "False negative rate: 18.991% (508/2675)\n",
      "True negative rate: 99.251% (34862/35125)\n",
      "False positive rate: 0.749% (263/35125)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 28/67: Loss: 0.0522 | Train Acc: 97.952% (38397/39200) | Strict Acc: 78.357% (2194/2800)\n",
      "True positive rate: 81.016% (2249/2776)\n",
      "False negative rate: 18.984% (527/2776)\n",
      "True negative rate: 99.242% (36148/36424)\n",
      "False positive rate: 0.758% (276/36424)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 29/67: Loss: 0.0526 | Train Acc: 97.938% (39763/40600) | Strict Acc: 78.241% (2269/2900)\n",
      "True positive rate: 80.991% (2322/2867)\n",
      "False negative rate: 19.009% (545/2867)\n",
      "True negative rate: 99.226% (37441/37733)\n",
      "False positive rate: 0.774% (292/37733)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 30/67: Loss: 0.0529 | Train Acc: 97.936% (41133/42000) | Strict Acc: 78.067% (2342/3000)\n",
      "True positive rate: 81.098% (2407/2968)\n",
      "False negative rate: 18.902% (561/2968)\n",
      "True negative rate: 99.216% (38726/39032)\n",
      "False positive rate: 0.784% (306/39032)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 31/67: Loss: 0.0528 | Train Acc: 97.940% (42506/43400) | Strict Acc: 78.000% (2418/3100)\n",
      "True positive rate: 81.297% (2495/3069)\n",
      "False negative rate: 18.703% (574/3069)\n",
      "True negative rate: 99.207% (40011/40331)\n",
      "False positive rate: 0.793% (320/40331)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 32/67: Loss: 0.0525 | Train Acc: 97.953% (43883/44800) | Strict Acc: 78.000% (2496/3200)\n",
      "True positive rate: 81.485% (2579/3165)\n",
      "False negative rate: 18.515% (586/3165)\n",
      "True negative rate: 99.205% (41304/41635)\n",
      "False positive rate: 0.795% (331/41635)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 33/67: Loss: 0.0526 | Train Acc: 97.946% (45251/46200) | Strict Acc: 77.909% (2571/3300)\n",
      "True positive rate: 81.451% (2661/3267)\n",
      "False negative rate: 18.549% (606/3267)\n",
      "True negative rate: 99.201% (42590/42933)\n",
      "False positive rate: 0.799% (343/42933)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 34/67: Loss: 0.0525 | Train Acc: 97.943% (46621/47600) | Strict Acc: 77.853% (2647/3400)\n",
      "True positive rate: 81.449% (2731/3353)\n",
      "False negative rate: 18.551% (622/3353)\n",
      "True negative rate: 99.193% (43890/44247)\n",
      "False positive rate: 0.807% (357/44247)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 35/67: Loss: 0.0520 | Train Acc: 97.955% (47998/49000) | Strict Acc: 77.914% (2727/3500)\n",
      "True positive rate: 81.605% (2817/3452)\n",
      "False negative rate: 18.395% (635/3452)\n",
      "True negative rate: 99.194% (45181/45548)\n",
      "False positive rate: 0.806% (367/45548)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 36/67: Loss: 0.0522 | Train Acc: 97.937% (49360/50400) | Strict Acc: 77.833% (2802/3600)\n",
      "True positive rate: 81.424% (2893/3553)\n",
      "False negative rate: 18.576% (660/3553)\n",
      "True negative rate: 99.189% (46467/46847)\n",
      "False positive rate: 0.811% (380/46847)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 37/67: Loss: 0.0522 | Train Acc: 97.940% (50733/51800) | Strict Acc: 77.838% (2880/3700)\n",
      "True positive rate: 81.385% (2973/3653)\n",
      "False negative rate: 18.615% (680/3653)\n",
      "True negative rate: 99.196% (47760/48147)\n",
      "False positive rate: 0.804% (387/48147)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 38/67: Loss: 0.0532 | Train Acc: 97.908% (52087/53200) | Strict Acc: 77.553% (2947/3800)\n",
      "True positive rate: 81.235% (3052/3757)\n",
      "False negative rate: 18.765% (705/3757)\n",
      "True negative rate: 99.175% (49035/49443)\n",
      "False positive rate: 0.825% (408/49443)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 39/67: Loss: 0.0535 | Train Acc: 97.905% (53456/54600) | Strict Acc: 77.462% (3021/3900)\n",
      "True positive rate: 81.271% (3146/3871)\n",
      "False negative rate: 18.729% (725/3871)\n",
      "True negative rate: 99.174% (50310/50729)\n",
      "False positive rate: 0.826% (419/50729)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 40/67: Loss: 0.0538 | Train Acc: 97.895% (54821/56000) | Strict Acc: 77.350% (3094/4000)\n",
      "True positive rate: 81.154% (3234/3985)\n",
      "False negative rate: 18.846% (751/3985)\n",
      "True negative rate: 99.177% (51587/52015)\n",
      "False positive rate: 0.823% (428/52015)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 41/67: Loss: 0.0542 | Train Acc: 97.873% (56179/57400) | Strict Acc: 77.171% (3164/4100)\n",
      "True positive rate: 81.099% (3321/4095)\n",
      "False negative rate: 18.901% (774/4095)\n",
      "True negative rate: 99.161% (52858/53305)\n",
      "False positive rate: 0.839% (447/53305)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 42/67: Loss: 0.0544 | Train Acc: 97.859% (57541/58800) | Strict Acc: 77.000% (3234/4200)\n",
      "True positive rate: 81.118% (3411/4205)\n",
      "False negative rate: 18.882% (794/4205)\n",
      "True negative rate: 99.148% (54130/54595)\n",
      "False positive rate: 0.852% (465/54595)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 43/67: Loss: 0.0543 | Train Acc: 97.867% (58916/60200) | Strict Acc: 77.070% (3314/4300)\n",
      "True positive rate: 81.249% (3488/4293)\n",
      "False negative rate: 18.751% (805/4293)\n",
      "True negative rate: 99.143% (55428/55907)\n",
      "False positive rate: 0.857% (479/55907)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 44/67: Loss: 0.0545 | Train Acc: 97.869% (60287/61600) | Strict Acc: 77.068% (3391/4400)\n",
      "True positive rate: 81.320% (3574/4395)\n",
      "False negative rate: 18.680% (821/4395)\n",
      "True negative rate: 99.140% (56713/57205)\n",
      "False positive rate: 0.860% (492/57205)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 45/67: Loss: 0.0544 | Train Acc: 97.873% (61660/63000) | Strict Acc: 77.200% (3474/4500)\n",
      "True positive rate: 81.371% (3669/4509)\n",
      "False negative rate: 18.629% (840/4509)\n",
      "True negative rate: 99.145% (57991/58491)\n",
      "False positive rate: 0.855% (500/58491)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 46/67: Loss: 0.0542 | Train Acc: 97.890% (63041/64400) | Strict Acc: 77.304% (3556/4600)\n",
      "True positive rate: 81.488% (3746/4597)\n",
      "False negative rate: 18.512% (851/4597)\n",
      "True negative rate: 99.151% (59295/59803)\n",
      "False positive rate: 0.849% (508/59803)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 47/67: Loss: 0.0544 | Train Acc: 97.878% (64404/65800) | Strict Acc: 77.234% (3630/4700)\n",
      "True positive rate: 81.508% (3848/4721)\n",
      "False negative rate: 18.492% (873/4721)\n",
      "True negative rate: 99.144% (60556/61079)\n",
      "False positive rate: 0.856% (523/61079)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 48/67: Loss: 0.0551 | Train Acc: 97.856% (65759/67200) | Strict Acc: 77.125% (3702/4800)\n",
      "True positive rate: 81.334% (3939/4843)\n",
      "False negative rate: 18.666% (904/4843)\n",
      "True negative rate: 99.139% (61820/62357)\n",
      "False positive rate: 0.861% (537/62357)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 49/67: Loss: 0.0551 | Train Acc: 97.862% (67133/68600) | Strict Acc: 77.143% (3780/4900)\n",
      "True positive rate: 81.425% (4024/4942)\n",
      "False negative rate: 18.575% (918/4942)\n",
      "True negative rate: 99.138% (63109/63658)\n",
      "False positive rate: 0.862% (549/63658)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 9 - Batch 50/67: Loss: 0.0551 | Train Acc: 97.854% (68498/70000) | Strict Acc: 77.020% (3851/5000)\n",
      "True positive rate: 81.414% (4100/5036)\n",
      "False negative rate: 18.586% (936/5036)\n",
      "True negative rate: 99.129% (64398/64964)\n",
      "False positive rate: 0.871% (566/64964)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 51/67: Loss: 0.0555 | Train Acc: 97.838% (69856/71400) | Strict Acc: 76.804% (3917/5100)\n",
      "True positive rate: 81.290% (4184/5147)\n",
      "False negative rate: 18.710% (963/5147)\n",
      "True negative rate: 99.123% (65672/66253)\n",
      "False positive rate: 0.877% (581/66253)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 52/67: Loss: 0.0558 | Train Acc: 97.819% (71212/72800) | Strict Acc: 76.673% (3987/5200)\n",
      "True positive rate: 81.347% (4287/5270)\n",
      "False negative rate: 18.653% (983/5270)\n",
      "True negative rate: 99.104% (66925/67530)\n",
      "False positive rate: 0.896% (605/67530)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 53/67: Loss: 0.0558 | Train Acc: 97.825% (72586/74200) | Strict Acc: 76.698% (4065/5300)\n",
      "True positive rate: 81.363% (4370/5371)\n",
      "False negative rate: 18.637% (1001/5371)\n",
      "True negative rate: 99.109% (68216/68829)\n",
      "False positive rate: 0.891% (613/68829)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 54/67: Loss: 0.0558 | Train Acc: 97.827% (73957/75600) | Strict Acc: 76.722% (4143/5400)\n",
      "True positive rate: 81.449% (4452/5466)\n",
      "False negative rate: 18.551% (1014/5466)\n",
      "True negative rate: 99.103% (69505/70134)\n",
      "False positive rate: 0.897% (629/70134)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 55/67: Loss: 0.0558 | Train Acc: 97.835% (75333/77000) | Strict Acc: 76.764% (4222/5500)\n",
      "True positive rate: 81.403% (4526/5560)\n",
      "False negative rate: 18.597% (1034/5560)\n",
      "True negative rate: 99.114% (70807/71440)\n",
      "False positive rate: 0.886% (633/71440)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 56/67: Loss: 0.0561 | Train Acc: 97.819% (76690/78400) | Strict Acc: 76.661% (4293/5600)\n",
      "True positive rate: 81.185% (4604/5671)\n",
      "False negative rate: 18.815% (1067/5671)\n",
      "True negative rate: 99.116% (72086/72729)\n",
      "False positive rate: 0.884% (643/72729)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 57/67: Loss: 0.0558 | Train Acc: 97.833% (78071/79800) | Strict Acc: 76.825% (4379/5700)\n",
      "True positive rate: 81.235% (4671/5750)\n",
      "False negative rate: 18.765% (1079/5750)\n",
      "True negative rate: 99.122% (73400/74050)\n",
      "False positive rate: 0.878% (650/74050)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 58/67: Loss: 0.0559 | Train Acc: 97.831% (79439/81200) | Strict Acc: 76.810% (4455/5800)\n",
      "True positive rate: 81.065% (4735/5841)\n",
      "False negative rate: 18.935% (1106/5841)\n",
      "True negative rate: 99.131% (74704/75359)\n",
      "False positive rate: 0.869% (655/75359)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 59/67: Loss: 0.0560 | Train Acc: 97.834% (80811/82600) | Strict Acc: 76.780% (4530/5900)\n",
      "True positive rate: 81.011% (4808/5935)\n",
      "False negative rate: 18.989% (1127/5935)\n",
      "True negative rate: 99.137% (76003/76665)\n",
      "False positive rate: 0.863% (662/76665)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 60/67: Loss: 0.0561 | Train Acc: 97.833% (82180/84000) | Strict Acc: 76.817% (4609/6000)\n",
      "True positive rate: 81.030% (4895/6041)\n",
      "False negative rate: 18.970% (1146/6041)\n",
      "True negative rate: 99.135% (77285/77959)\n",
      "False positive rate: 0.865% (674/77959)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 61/67: Loss: 0.0561 | Train Acc: 97.831% (83548/85400) | Strict Acc: 76.787% (4684/6100)\n",
      "True positive rate: 81.003% (4976/6143)\n",
      "False negative rate: 18.997% (1167/6143)\n",
      "True negative rate: 99.136% (78572/79257)\n",
      "False positive rate: 0.864% (685/79257)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 62/67: Loss: 0.0562 | Train Acc: 97.826% (84913/86800) | Strict Acc: 76.742% (4758/6200)\n",
      "True positive rate: 81.014% (5065/6252)\n",
      "False negative rate: 18.986% (1187/6252)\n",
      "True negative rate: 99.131% (79848/80548)\n",
      "False positive rate: 0.869% (700/80548)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 63/67: Loss: 0.0565 | Train Acc: 97.805% (86264/88200) | Strict Acc: 76.635% (4828/6300)\n",
      "True positive rate: 80.880% (5131/6344)\n",
      "False negative rate: 19.120% (1213/6344)\n",
      "True negative rate: 99.117% (81133/81856)\n",
      "False positive rate: 0.883% (723/81856)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 64/67: Loss: 0.0567 | Train Acc: 97.792% (87622/89600) | Strict Acc: 76.547% (4899/6400)\n",
      "True positive rate: 80.794% (5212/6451)\n",
      "False negative rate: 19.206% (1239/6451)\n",
      "True negative rate: 99.111% (82410/83149)\n",
      "False positive rate: 0.889% (739/83149)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 65/67: Loss: 0.0568 | Train Acc: 97.785% (88984/91000) | Strict Acc: 76.415% (4967/6500)\n",
      "True positive rate: 80.790% (5299/6559)\n",
      "False negative rate: 19.210% (1260/6559)\n",
      "True negative rate: 99.105% (83685/84441)\n",
      "False positive rate: 0.895% (756/84441)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 66/67: Loss: 0.0569 | Train Acc: 97.786% (90354/92400) | Strict Acc: 76.424% (5044/6600)\n",
      "True positive rate: 80.849% (5370/6642)\n",
      "False negative rate: 19.151% (1272/6642)\n",
      "True negative rate: 99.097% (84984/85758)\n",
      "False positive rate: 0.903% (774/85758)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 67/67: Loss: 0.0570 | Train Acc: 97.779% (91676/93758) | Strict Acc: 76.363% (5114/6697)\n",
      "True positive rate: 80.785% (5453/6750)\n",
      "False negative rate: 19.215% (1297/6750)\n",
      "True negative rate: 99.098% (86223/87008)\n",
      "False positive rate: 0.902% (785/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1731 | Dev Acc: 93.605% (85403/91238) | Strict Acc: 49.256% (3210/6517)\n",
      "True positive rate: 18.939% (1246/6579)\n",
      "False negative rate: 81.061% (5333/6579)\n",
      "True negative rate: 99.407% (84157/84659)\n",
      "False positive rate: 0.593% (502/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 1/67: Loss: 0.0470 | Train Acc: 98.357% (1377/1400) | Strict Acc: 83.000% (83/100)\n",
      "True positive rate: 83.193% (99/119)\n",
      "False negative rate: 16.807% (20/119)\n",
      "True negative rate: 99.766% (1278/1281)\n",
      "False positive rate: 0.234% (3/1281)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 2/67: Loss: 0.0475 | Train Acc: 97.857% (2740/2800) | Strict Acc: 78.000% (156/200)\n",
      "True positive rate: 78.302% (166/212)\n",
      "False negative rate: 21.698% (46/212)\n",
      "True negative rate: 99.459% (2574/2588)\n",
      "False positive rate: 0.541% (14/2588)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 3/67: Loss: 0.0483 | Train Acc: 97.905% (4112/4200) | Strict Acc: 78.667% (236/300)\n",
      "True positive rate: 79.167% (247/312)\n",
      "False negative rate: 20.833% (65/312)\n",
      "True negative rate: 99.408% (3865/3888)\n",
      "False positive rate: 0.592% (23/3888)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 4/67: Loss: 0.0482 | Train Acc: 97.982% (5487/5600) | Strict Acc: 79.250% (317/400)\n",
      "True positive rate: 79.231% (309/390)\n",
      "False negative rate: 20.769% (81/390)\n",
      "True negative rate: 99.386% (5178/5210)\n",
      "False positive rate: 0.614% (32/5210)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 5/67: Loss: 0.0476 | Train Acc: 98.000% (6860/7000) | Strict Acc: 78.600% (393/500)\n",
      "True positive rate: 79.920% (398/498)\n",
      "False negative rate: 20.080% (100/498)\n",
      "True negative rate: 99.385% (6462/6502)\n",
      "False positive rate: 0.615% (40/6502)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 6/67: Loss: 0.0457 | Train Acc: 98.095% (8240/8400) | Strict Acc: 79.333% (476/600)\n",
      "True positive rate: 81.481% (484/594)\n",
      "False negative rate: 18.519% (110/594)\n",
      "True negative rate: 99.359% (7756/7806)\n",
      "False positive rate: 0.641% (50/7806)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 7/67: Loss: 0.0451 | Train Acc: 98.143% (9618/9800) | Strict Acc: 79.857% (559/700)\n",
      "True positive rate: 82.092% (573/698)\n",
      "False negative rate: 17.908% (125/698)\n",
      "True negative rate: 99.374% (9045/9102)\n",
      "False positive rate: 0.626% (57/9102)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 10 - Batch 8/67: Loss: 0.0450 | Train Acc: 98.152% (10993/11200) | Strict Acc: 79.875% (639/800)\n",
      "True positive rate: 81.900% (638/779)\n",
      "False negative rate: 18.100% (141/779)\n",
      "True negative rate: 99.367% (10355/10421)\n",
      "False positive rate: 0.633% (66/10421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 9/67: Loss: 0.0463 | Train Acc: 98.063% (12356/12600) | Strict Acc: 78.556% (707/900)\n",
      "True positive rate: 81.747% (730/893)\n",
      "False negative rate: 18.253% (163/893)\n",
      "True negative rate: 99.308% (11626/11707)\n",
      "False positive rate: 0.692% (81/11707)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 10/67: Loss: 0.0461 | Train Acc: 98.057% (13728/14000) | Strict Acc: 78.500% (785/1000)\n",
      "True positive rate: 81.737% (819/1002)\n",
      "False negative rate: 18.263% (183/1002)\n",
      "True negative rate: 99.315% (12909/12998)\n",
      "False positive rate: 0.685% (89/12998)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 11/67: Loss: 0.0461 | Train Acc: 98.071% (15103/15400) | Strict Acc: 78.818% (867/1100)\n",
      "True positive rate: 81.605% (905/1109)\n",
      "False negative rate: 18.395% (204/1109)\n",
      "True negative rate: 99.349% (14198/14291)\n",
      "False positive rate: 0.651% (93/14291)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 12/67: Loss: 0.0459 | Train Acc: 98.089% (16479/16800) | Strict Acc: 79.000% (948/1200)\n",
      "True positive rate: 82.079% (1003/1222)\n",
      "False negative rate: 17.921% (219/1222)\n",
      "True negative rate: 99.345% (15476/15578)\n",
      "False positive rate: 0.655% (102/15578)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 13/67: Loss: 0.0460 | Train Acc: 98.115% (17857/18200) | Strict Acc: 79.154% (1029/1300)\n",
      "True positive rate: 82.321% (1071/1301)\n",
      "False negative rate: 17.679% (230/1301)\n",
      "True negative rate: 99.331% (16786/16899)\n",
      "False positive rate: 0.669% (113/16899)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 14/67: Loss: 0.0455 | Train Acc: 98.153% (19238/19600) | Strict Acc: 79.357% (1111/1400)\n",
      "True positive rate: 82.761% (1157/1398)\n",
      "False negative rate: 17.239% (241/1398)\n",
      "True negative rate: 99.335% (18081/18202)\n",
      "False positive rate: 0.665% (121/18202)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 15/67: Loss: 0.0449 | Train Acc: 98.200% (20622/21000) | Strict Acc: 79.800% (1197/1500)\n",
      "True positive rate: 83.266% (1239/1488)\n",
      "False negative rate: 16.734% (249/1488)\n",
      "True negative rate: 99.339% (19383/19512)\n",
      "False positive rate: 0.661% (129/19512)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 16/67: Loss: 0.0447 | Train Acc: 98.183% (21993/22400) | Strict Acc: 79.625% (1274/1600)\n",
      "True positive rate: 83.354% (1337/1604)\n",
      "False negative rate: 16.646% (267/1604)\n",
      "True negative rate: 99.327% (20656/20796)\n",
      "False positive rate: 0.673% (140/20796)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 17/67: Loss: 0.0445 | Train Acc: 98.189% (23369/23800) | Strict Acc: 79.529% (1352/1700)\n",
      "True positive rate: 83.713% (1434/1713)\n",
      "False negative rate: 16.287% (279/1713)\n",
      "True negative rate: 99.312% (21935/22087)\n",
      "False positive rate: 0.688% (152/22087)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 18/67: Loss: 0.0441 | Train Acc: 98.194% (24745/25200) | Strict Acc: 79.611% (1433/1800)\n",
      "True positive rate: 83.756% (1521/1816)\n",
      "False negative rate: 16.244% (295/1816)\n",
      "True negative rate: 99.316% (23224/23384)\n",
      "False positive rate: 0.684% (160/23384)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 19/67: Loss: 0.0444 | Train Acc: 98.180% (26116/26600) | Strict Acc: 79.526% (1511/1900)\n",
      "True positive rate: 83.594% (1605/1920)\n",
      "False negative rate: 16.406% (315/1920)\n",
      "True negative rate: 99.315% (24511/24680)\n",
      "False positive rate: 0.685% (169/24680)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 20/67: Loss: 0.0439 | Train Acc: 98.196% (27495/28000) | Strict Acc: 79.650% (1593/2000)\n",
      "True positive rate: 83.567% (1668/1996)\n",
      "False negative rate: 16.433% (328/1996)\n",
      "True negative rate: 99.319% (25827/26004)\n",
      "False positive rate: 0.681% (177/26004)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 21/67: Loss: 0.0446 | Train Acc: 98.170% (28862/29400) | Strict Acc: 79.381% (1667/2100)\n",
      "True positive rate: 83.404% (1769/2121)\n",
      "False negative rate: 16.596% (352/2121)\n",
      "True negative rate: 99.318% (27093/27279)\n",
      "False positive rate: 0.682% (186/27279)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 22/67: Loss: 0.0442 | Train Acc: 98.179% (30239/30800) | Strict Acc: 79.409% (1747/2200)\n",
      "True positive rate: 83.634% (1855/2218)\n",
      "False negative rate: 16.366% (363/2218)\n",
      "True negative rate: 99.307% (28384/28582)\n",
      "False positive rate: 0.693% (198/28582)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 23/67: Loss: 0.0445 | Train Acc: 98.168% (31610/32200) | Strict Acc: 79.304% (1824/2300)\n",
      "True positive rate: 83.608% (1928/2306)\n",
      "False negative rate: 16.392% (378/2306)\n",
      "True negative rate: 99.291% (29682/29894)\n",
      "False positive rate: 0.709% (212/29894)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 24/67: Loss: 0.0447 | Train Acc: 98.173% (32986/33600) | Strict Acc: 79.417% (1906/2400)\n",
      "True positive rate: 83.832% (2017/2406)\n",
      "False negative rate: 16.168% (389/2406)\n",
      "True negative rate: 99.279% (30969/31194)\n",
      "False positive rate: 0.721% (225/31194)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 25/67: Loss: 0.0446 | Train Acc: 98.171% (34360/35000) | Strict Acc: 79.280% (1982/2500)\n",
      "True positive rate: 83.777% (2107/2515)\n",
      "False negative rate: 16.223% (408/2515)\n",
      "True negative rate: 99.286% (32253/32485)\n",
      "False positive rate: 0.714% (232/32485)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 26/67: Loss: 0.0461 | Train Acc: 98.110% (35712/36400) | Strict Acc: 78.808% (2049/2600)\n",
      "True positive rate: 83.276% (2186/2625)\n",
      "False negative rate: 16.724% (439/2625)\n",
      "True negative rate: 99.263% (33526/33775)\n",
      "False positive rate: 0.737% (249/33775)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 27/67: Loss: 0.0461 | Train Acc: 98.119% (37089/37800) | Strict Acc: 78.889% (2130/2700)\n",
      "True positive rate: 83.462% (2276/2727)\n",
      "False negative rate: 16.538% (451/2727)\n",
      "True negative rate: 99.259% (34813/35073)\n",
      "False positive rate: 0.741% (260/35073)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 28/67: Loss: 0.0463 | Train Acc: 98.117% (38462/39200) | Strict Acc: 78.929% (2210/2800)\n",
      "True positive rate: 83.475% (2364/2832)\n",
      "False negative rate: 16.525% (468/2832)\n",
      "True negative rate: 99.258% (36098/36368)\n",
      "False positive rate: 0.742% (270/36368)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 29/67: Loss: 0.0463 | Train Acc: 98.108% (39832/40600) | Strict Acc: 78.793% (2285/2900)\n",
      "True positive rate: 83.642% (2439/2916)\n",
      "False negative rate: 16.358% (477/2916)\n",
      "True negative rate: 99.228% (37393/37684)\n",
      "False positive rate: 0.772% (291/37684)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 30/67: Loss: 0.0471 | Train Acc: 98.081% (41194/42000) | Strict Acc: 78.533% (2356/3000)\n",
      "True positive rate: 83.520% (2539/3040)\n",
      "False negative rate: 16.480% (501/3040)\n",
      "True negative rate: 99.217% (38655/38960)\n",
      "False positive rate: 0.783% (305/38960)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 31/67: Loss: 0.0473 | Train Acc: 98.071% (42563/43400) | Strict Acc: 78.516% (2434/3100)\n",
      "True positive rate: 83.544% (2640/3160)\n",
      "False negative rate: 16.456% (520/3160)\n",
      "True negative rate: 99.212% (39923/40240)\n",
      "False positive rate: 0.788% (317/40240)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 32/67: Loss: 0.0474 | Train Acc: 98.071% (43936/44800) | Strict Acc: 78.469% (2511/3200)\n",
      "True positive rate: 83.655% (2733/3267)\n",
      "False negative rate: 16.345% (534/3267)\n",
      "True negative rate: 99.205% (41203/41533)\n",
      "False positive rate: 0.795% (330/41533)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 33/67: Loss: 0.0469 | Train Acc: 98.095% (45320/46200) | Strict Acc: 78.697% (2597/3300)\n",
      "True positive rate: 83.775% (2814/3359)\n",
      "False negative rate: 16.225% (545/3359)\n",
      "True negative rate: 99.218% (42506/42841)\n",
      "False positive rate: 0.782% (335/42841)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 10 - Batch 34/67: Loss: 0.0473 | Train Acc: 98.082% (46687/47600) | Strict Acc: 78.559% (2671/3400)\n",
      "True positive rate: 83.483% (2876/3445)\n",
      "False negative rate: 16.517% (569/3445)\n",
      "True negative rate: 99.221% (43811/44155)\n",
      "False positive rate: 0.779% (344/44155)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 35/67: Loss: 0.0473 | Train Acc: 98.078% (48058/49000) | Strict Acc: 78.543% (2749/3500)\n",
      "True positive rate: 83.475% (2950/3534)\n",
      "False negative rate: 16.525% (584/3534)\n",
      "True negative rate: 99.213% (45108/45466)\n",
      "False positive rate: 0.787% (358/45466)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 36/67: Loss: 0.0475 | Train Acc: 98.065% (49425/50400) | Strict Acc: 78.444% (2824/3600)\n",
      "True positive rate: 83.209% (3023/3633)\n",
      "False negative rate: 16.791% (610/3633)\n",
      "True negative rate: 99.220% (46402/46767)\n",
      "False positive rate: 0.780% (365/46767)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 37/67: Loss: 0.0474 | Train Acc: 98.064% (50797/51800) | Strict Acc: 78.432% (2902/3700)\n",
      "True positive rate: 83.137% (3101/3730)\n",
      "False negative rate: 16.863% (629/3730)\n",
      "True negative rate: 99.222% (47696/48070)\n",
      "False positive rate: 0.778% (374/48070)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 38/67: Loss: 0.0474 | Train Acc: 98.060% (52168/53200) | Strict Acc: 78.395% (2979/3800)\n",
      "True positive rate: 83.086% (3193/3843)\n",
      "False negative rate: 16.914% (650/3843)\n",
      "True negative rate: 99.226% (48975/49357)\n",
      "False positive rate: 0.774% (382/49357)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 39/67: Loss: 0.0474 | Train Acc: 98.053% (53537/54600) | Strict Acc: 78.385% (3057/3900)\n",
      "True positive rate: 83.049% (3263/3929)\n",
      "False negative rate: 16.951% (666/3929)\n",
      "True negative rate: 99.217% (50274/50671)\n",
      "False positive rate: 0.783% (397/50671)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 40/67: Loss: 0.0477 | Train Acc: 98.034% (54899/56000) | Strict Acc: 78.225% (3129/4000)\n",
      "True positive rate: 83.056% (3343/4025)\n",
      "False negative rate: 16.944% (682/4025)\n",
      "True negative rate: 99.194% (51556/51975)\n",
      "False positive rate: 0.806% (419/51975)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 41/67: Loss: 0.0478 | Train Acc: 98.037% (56273/57400) | Strict Acc: 78.195% (3206/4100)\n",
      "True positive rate: 83.127% (3419/4113)\n",
      "False negative rate: 16.873% (694/4113)\n",
      "True negative rate: 99.187% (52854/53287)\n",
      "False positive rate: 0.813% (433/53287)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 42/67: Loss: 0.0481 | Train Acc: 98.015% (57633/58800) | Strict Acc: 78.071% (3279/4200)\n",
      "True positive rate: 83.067% (3488/4199)\n",
      "False negative rate: 16.933% (711/4199)\n",
      "True negative rate: 99.165% (54145/54601)\n",
      "False positive rate: 0.835% (456/54601)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 43/67: Loss: 0.0480 | Train Acc: 98.023% (59010/60200) | Strict Acc: 78.116% (3359/4300)\n",
      "True positive rate: 83.030% (3562/4290)\n",
      "False negative rate: 16.970% (728/4290)\n",
      "True negative rate: 99.174% (55448/55910)\n",
      "False positive rate: 0.826% (462/55910)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 44/67: Loss: 0.0486 | Train Acc: 98.000% (60368/61600) | Strict Acc: 78.023% (3433/4400)\n",
      "True positive rate: 82.752% (3656/4418)\n",
      "False negative rate: 17.248% (762/4418)\n",
      "True negative rate: 99.178% (56712/57182)\n",
      "False positive rate: 0.822% (470/57182)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 45/67: Loss: 0.0486 | Train Acc: 97.998% (61739/63000) | Strict Acc: 78.044% (3512/4500)\n",
      "True positive rate: 82.749% (3732/4510)\n",
      "False negative rate: 17.251% (778/4510)\n",
      "True negative rate: 99.174% (58007/58490)\n",
      "False positive rate: 0.826% (483/58490)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 46/67: Loss: 0.0489 | Train Acc: 97.988% (63104/64400) | Strict Acc: 77.913% (3584/4600)\n",
      "True positive rate: 82.683% (3815/4614)\n",
      "False negative rate: 17.317% (799/4614)\n",
      "True negative rate: 99.169% (59289/59786)\n",
      "False positive rate: 0.831% (497/59786)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 47/67: Loss: 0.0490 | Train Acc: 97.980% (64471/65800) | Strict Acc: 77.915% (3662/4700)\n",
      "True positive rate: 82.675% (3913/4733)\n",
      "False negative rate: 17.325% (820/4733)\n",
      "True negative rate: 99.166% (60558/61067)\n",
      "False positive rate: 0.834% (509/61067)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 48/67: Loss: 0.0493 | Train Acc: 97.978% (65841/67200) | Strict Acc: 77.812% (3735/4800)\n",
      "True positive rate: 82.707% (4008/4846)\n",
      "False negative rate: 17.293% (838/4846)\n",
      "True negative rate: 99.164% (61833/62354)\n",
      "False positive rate: 0.836% (521/62354)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 49/67: Loss: 0.0494 | Train Acc: 97.983% (67216/68600) | Strict Acc: 77.816% (3813/4900)\n",
      "True positive rate: 82.713% (4086/4940)\n",
      "False negative rate: 17.287% (854/4940)\n",
      "True negative rate: 99.167% (63130/63660)\n",
      "False positive rate: 0.833% (530/63660)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 50/67: Loss: 0.0496 | Train Acc: 97.983% (68588/70000) | Strict Acc: 77.780% (3889/5000)\n",
      "True positive rate: 82.666% (4168/5042)\n",
      "False negative rate: 17.334% (874/5042)\n",
      "True negative rate: 99.172% (64420/64958)\n",
      "False positive rate: 0.828% (538/64958)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 51/67: Loss: 0.0495 | Train Acc: 97.990% (69965/71400) | Strict Acc: 77.784% (3967/5100)\n",
      "True positive rate: 82.688% (4251/5141)\n",
      "False negative rate: 17.312% (890/5141)\n",
      "True negative rate: 99.177% (65714/66259)\n",
      "False positive rate: 0.823% (545/66259)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 52/67: Loss: 0.0498 | Train Acc: 97.977% (71327/72800) | Strict Acc: 77.615% (4036/5200)\n",
      "True positive rate: 82.687% (4351/5262)\n",
      "False negative rate: 17.313% (911/5262)\n",
      "True negative rate: 99.168% (66976/67538)\n",
      "False positive rate: 0.832% (562/67538)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 53/67: Loss: 0.0500 | Train Acc: 97.972% (72695/74200) | Strict Acc: 77.660% (4116/5300)\n",
      "True positive rate: 82.779% (4451/5377)\n",
      "False negative rate: 17.221% (926/5377)\n",
      "True negative rate: 99.159% (68244/68823)\n",
      "False positive rate: 0.841% (579/68823)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 54/67: Loss: 0.0503 | Train Acc: 97.963% (74060/75600) | Strict Acc: 77.574% (4189/5400)\n",
      "True positive rate: 82.778% (4523/5464)\n",
      "False negative rate: 17.222% (941/5464)\n",
      "True negative rate: 99.146% (69537/70136)\n",
      "False positive rate: 0.854% (599/70136)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 55/67: Loss: 0.0506 | Train Acc: 97.951% (75422/77000) | Strict Acc: 77.491% (4262/5500)\n",
      "True positive rate: 82.674% (4619/5587)\n",
      "False negative rate: 17.326% (968/5587)\n",
      "True negative rate: 99.146% (70803/71413)\n",
      "False positive rate: 0.854% (610/71413)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 56/67: Loss: 0.0506 | Train Acc: 97.953% (76795/78400) | Strict Acc: 77.482% (4339/5600)\n",
      "True positive rate: 82.770% (4698/5676)\n",
      "False negative rate: 17.230% (978/5676)\n",
      "True negative rate: 99.138% (72097/72724)\n",
      "False positive rate: 0.862% (627/72724)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 57/67: Loss: 0.0507 | Train Acc: 97.947% (78162/79800) | Strict Acc: 77.439% (4414/5700)\n",
      "True positive rate: 82.786% (4790/5786)\n",
      "False negative rate: 17.214% (996/5786)\n",
      "True negative rate: 99.133% (73372/74014)\n",
      "False positive rate: 0.867% (642/74014)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 58/67: Loss: 0.0509 | Train Acc: 97.946% (79532/81200) | Strict Acc: 77.483% (4494/5800)\n",
      "True positive rate: 82.719% (4868/5885)\n",
      "False negative rate: 17.281% (1017/5885)\n",
      "True negative rate: 99.136% (74664/75315)\n",
      "False positive rate: 0.864% (651/75315)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 10 - Batch 59/67: Loss: 0.0508 | Train Acc: 97.955% (80911/82600) | Strict Acc: 77.542% (4575/5900)\n",
      "True positive rate: 82.675% (4939/5974)\n",
      "False negative rate: 17.325% (1035/5974)\n",
      "True negative rate: 99.147% (75972/76626)\n",
      "False positive rate: 0.853% (654/76626)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 60/67: Loss: 0.0508 | Train Acc: 97.957% (82284/84000) | Strict Acc: 77.567% (4654/6000)\n",
      "True positive rate: 82.721% (5022/6071)\n",
      "False negative rate: 17.279% (1049/6071)\n",
      "True negative rate: 99.144% (77262/77929)\n",
      "False positive rate: 0.856% (667/77929)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 61/67: Loss: 0.0509 | Train Acc: 97.954% (83653/85400) | Strict Acc: 77.557% (4731/6100)\n",
      "True positive rate: 82.656% (5104/6175)\n",
      "False negative rate: 17.344% (1071/6175)\n",
      "True negative rate: 99.147% (78549/79225)\n",
      "False positive rate: 0.853% (676/79225)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 62/67: Loss: 0.0512 | Train Acc: 97.942% (85014/86800) | Strict Acc: 77.516% (4806/6200)\n",
      "True positive rate: 82.466% (5164/6262)\n",
      "False negative rate: 17.534% (1098/6262)\n",
      "True negative rate: 99.146% (79850/80538)\n",
      "False positive rate: 0.854% (688/80538)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 63/67: Loss: 0.0509 | Train Acc: 97.956% (86397/88200) | Strict Acc: 77.667% (4893/6300)\n",
      "True positive rate: 82.590% (5256/6364)\n",
      "False negative rate: 17.410% (1108/6364)\n",
      "True negative rate: 99.151% (81141/81836)\n",
      "False positive rate: 0.849% (695/81836)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 64/67: Loss: 0.0510 | Train Acc: 97.954% (87767/89600) | Strict Acc: 77.656% (4970/6400)\n",
      "True positive rate: 82.620% (5329/6450)\n",
      "False negative rate: 17.380% (1121/6450)\n",
      "True negative rate: 99.144% (82438/83150)\n",
      "False positive rate: 0.856% (712/83150)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 65/67: Loss: 0.0514 | Train Acc: 97.946% (89131/91000) | Strict Acc: 77.569% (5042/6500)\n",
      "True positive rate: 82.524% (5407/6552)\n",
      "False negative rate: 17.476% (1145/6552)\n",
      "True negative rate: 99.143% (83724/84448)\n",
      "False positive rate: 0.857% (724/84448)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 66/67: Loss: 0.0515 | Train Acc: 97.939% (90496/92400) | Strict Acc: 77.485% (5114/6600)\n",
      "True positive rate: 82.522% (5491/6654)\n",
      "False negative rate: 17.478% (1163/6654)\n",
      "True negative rate: 99.136% (85005/85746)\n",
      "False positive rate: 0.864% (741/85746)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 67/67: Loss: 0.0517 | Train Acc: 97.931% (91818/93758) | Strict Acc: 77.423% (5185/6697)\n",
      "True positive rate: 82.430% (5564/6750)\n",
      "False negative rate: 17.570% (1186/6750)\n",
      "True negative rate: 99.133% (86254/87008)\n",
      "False positive rate: 0.867% (754/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1909 | Dev Acc: 93.477% (85287/91238) | Strict Acc: 47.568% (3100/6517)\n",
      "True positive rate: 23.499% (1546/6579)\n",
      "False negative rate: 76.501% (5033/6579)\n",
      "True negative rate: 98.916% (83741/84659)\n",
      "False positive rate: 1.084% (918/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 1/67: Loss: 0.0382 | Train Acc: 98.571% (1380/1400) | Strict Acc: 82.000% (82/100)\n",
      "True positive rate: 87.037% (94/108)\n",
      "False negative rate: 12.963% (14/108)\n",
      "True negative rate: 99.536% (1286/1292)\n",
      "False positive rate: 0.464% (6/1292)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 2/67: Loss: 0.0408 | Train Acc: 98.643% (2762/2800) | Strict Acc: 84.000% (168/200)\n",
      "True positive rate: 85.577% (178/208)\n",
      "False negative rate: 14.423% (30/208)\n",
      "True negative rate: 99.691% (2584/2592)\n",
      "False positive rate: 0.309% (8/2592)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 3/67: Loss: 0.0418 | Train Acc: 98.571% (4140/4200) | Strict Acc: 82.667% (248/300)\n",
      "True positive rate: 84.828% (246/290)\n",
      "False negative rate: 15.172% (44/290)\n",
      "True negative rate: 99.591% (3894/3910)\n",
      "False positive rate: 0.409% (16/3910)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 4/67: Loss: 0.0399 | Train Acc: 98.607% (5522/5600) | Strict Acc: 83.250% (333/400)\n",
      "True positive rate: 85.938% (330/384)\n",
      "False negative rate: 14.062% (54/384)\n",
      "True negative rate: 99.540% (5192/5216)\n",
      "False positive rate: 0.460% (24/5216)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 5/67: Loss: 0.0425 | Train Acc: 98.457% (6892/7000) | Strict Acc: 81.400% (407/500)\n",
      "True positive rate: 85.462% (435/509)\n",
      "False negative rate: 14.538% (74/509)\n",
      "True negative rate: 99.476% (6457/6491)\n",
      "False positive rate: 0.524% (34/6491)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 6/67: Loss: 0.0424 | Train Acc: 98.405% (8266/8400) | Strict Acc: 81.500% (489/600)\n",
      "True positive rate: 85.362% (519/608)\n",
      "False negative rate: 14.638% (89/608)\n",
      "True negative rate: 99.422% (7747/7792)\n",
      "False positive rate: 0.578% (45/7792)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 7/67: Loss: 0.0414 | Train Acc: 98.429% (9646/9800) | Strict Acc: 81.714% (572/700)\n",
      "True positive rate: 85.877% (602/701)\n",
      "False negative rate: 14.123% (99/701)\n",
      "True negative rate: 99.396% (9044/9099)\n",
      "False positive rate: 0.604% (55/9099)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 8/67: Loss: 0.0428 | Train Acc: 98.321% (11012/11200) | Strict Acc: 80.375% (643/800)\n",
      "True positive rate: 85.732% (691/806)\n",
      "False negative rate: 14.268% (115/806)\n",
      "True negative rate: 99.298% (10321/10394)\n",
      "False positive rate: 0.702% (73/10394)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 9/67: Loss: 0.0434 | Train Acc: 98.317% (12388/12600) | Strict Acc: 80.222% (722/900)\n",
      "True positive rate: 85.902% (786/915)\n",
      "False negative rate: 14.098% (129/915)\n",
      "True negative rate: 99.290% (11602/11685)\n",
      "False positive rate: 0.710% (83/11685)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 10/67: Loss: 0.0435 | Train Acc: 98.321% (13765/14000) | Strict Acc: 80.500% (805/1000)\n",
      "True positive rate: 85.956% (863/1004)\n",
      "False negative rate: 14.044% (141/1004)\n",
      "True negative rate: 99.277% (12902/12996)\n",
      "False positive rate: 0.723% (94/12996)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 11/67: Loss: 0.0434 | Train Acc: 98.344% (15145/15400) | Strict Acc: 80.909% (890/1100)\n",
      "True positive rate: 86.434% (943/1091)\n",
      "False negative rate: 13.566% (148/1091)\n",
      "True negative rate: 99.252% (14202/14309)\n",
      "False positive rate: 0.748% (107/14309)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 12/67: Loss: 0.0446 | Train Acc: 98.280% (16511/16800) | Strict Acc: 80.583% (967/1200)\n",
      "True positive rate: 85.487% (1019/1192)\n",
      "False negative rate: 14.513% (173/1192)\n",
      "True negative rate: 99.257% (15492/15608)\n",
      "False positive rate: 0.743% (116/15608)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 13/67: Loss: 0.0442 | Train Acc: 98.308% (17892/18200) | Strict Acc: 80.923% (1052/1300)\n",
      "True positive rate: 85.352% (1078/1263)\n",
      "False negative rate: 14.648% (185/1263)\n",
      "True negative rate: 99.274% (16814/16937)\n",
      "False positive rate: 0.726% (123/16937)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 14/67: Loss: 0.0457 | Train Acc: 98.255% (19258/19600) | Strict Acc: 80.429% (1126/1400)\n",
      "True positive rate: 84.835% (1158/1365)\n",
      "False negative rate: 15.165% (207/1365)\n",
      "True negative rate: 99.260% (18100/18235)\n",
      "False positive rate: 0.740% (135/18235)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 15/67: Loss: 0.0460 | Train Acc: 98.248% (20632/21000) | Strict Acc: 80.533% (1208/1500)\n",
      "True positive rate: 84.509% (1222/1446)\n",
      "False negative rate: 15.491% (224/1446)\n",
      "True negative rate: 99.264% (19410/19554)\n",
      "False positive rate: 0.736% (144/19554)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 16/67: Loss: 0.0460 | Train Acc: 98.246% (22007/22400) | Strict Acc: 80.500% (1288/1600)\n",
      "True positive rate: 84.505% (1298/1536)\n",
      "False negative rate: 15.495% (238/1536)\n",
      "True negative rate: 99.257% (20709/20864)\n",
      "False positive rate: 0.743% (155/20864)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 11 - Batch 17/67: Loss: 0.0458 | Train Acc: 98.235% (23380/23800) | Strict Acc: 80.235% (1364/1700)\n",
      "True positive rate: 84.558% (1369/1619)\n",
      "False negative rate: 15.442% (250/1619)\n",
      "True negative rate: 99.234% (22011/22181)\n",
      "False positive rate: 0.766% (170/22181)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 18/67: Loss: 0.0474 | Train Acc: 98.187% (24743/25200) | Strict Acc: 79.944% (1439/1800)\n",
      "True positive rate: 84.095% (1454/1729)\n",
      "False negative rate: 15.905% (275/1729)\n",
      "True negative rate: 99.225% (23289/23471)\n",
      "False positive rate: 0.775% (182/23471)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 19/67: Loss: 0.0481 | Train Acc: 98.147% (26107/26600) | Strict Acc: 79.579% (1512/1900)\n",
      "True positive rate: 83.876% (1545/1842)\n",
      "False negative rate: 16.124% (297/1842)\n",
      "True negative rate: 99.208% (24562/24758)\n",
      "False positive rate: 0.792% (196/24758)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 20/67: Loss: 0.0489 | Train Acc: 98.086% (27464/28000) | Strict Acc: 79.050% (1581/2000)\n",
      "True positive rate: 83.752% (1634/1951)\n",
      "False negative rate: 16.248% (317/1951)\n",
      "True negative rate: 99.159% (25830/26049)\n",
      "False positive rate: 0.841% (219/26049)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 21/67: Loss: 0.0486 | Train Acc: 98.112% (28845/29400) | Strict Acc: 79.190% (1663/2100)\n",
      "True positive rate: 83.942% (1725/2055)\n",
      "False negative rate: 16.058% (330/2055)\n",
      "True negative rate: 99.177% (27120/27345)\n",
      "False positive rate: 0.823% (225/27345)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 22/67: Loss: 0.0494 | Train Acc: 98.075% (30207/30800) | Strict Acc: 78.909% (1736/2200)\n",
      "True positive rate: 83.791% (1830/2184)\n",
      "False negative rate: 16.209% (354/2184)\n",
      "True negative rate: 99.165% (28377/28616)\n",
      "False positive rate: 0.835% (239/28616)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 23/67: Loss: 0.0501 | Train Acc: 98.068% (31578/32200) | Strict Acc: 78.870% (1814/2300)\n",
      "True positive rate: 83.617% (1914/2289)\n",
      "False negative rate: 16.383% (375/2289)\n",
      "True negative rate: 99.174% (29664/29911)\n",
      "False positive rate: 0.826% (247/29911)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 24/67: Loss: 0.0501 | Train Acc: 98.057% (32947/33600) | Strict Acc: 78.708% (1889/2400)\n",
      "True positive rate: 83.536% (1989/2381)\n",
      "False negative rate: 16.464% (392/2381)\n",
      "True negative rate: 99.164% (30958/31219)\n",
      "False positive rate: 0.836% (261/31219)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 25/67: Loss: 0.0502 | Train Acc: 98.046% (34316/35000) | Strict Acc: 78.520% (1963/2500)\n",
      "True positive rate: 83.554% (2083/2493)\n",
      "False negative rate: 16.446% (410/2493)\n",
      "True negative rate: 99.157% (32233/32507)\n",
      "False positive rate: 0.843% (274/32507)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 26/67: Loss: 0.0500 | Train Acc: 98.055% (35692/36400) | Strict Acc: 78.615% (2044/2600)\n",
      "True positive rate: 83.648% (2174/2599)\n",
      "False negative rate: 16.352% (425/2599)\n",
      "True negative rate: 99.163% (33518/33801)\n",
      "False positive rate: 0.837% (283/33801)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 27/67: Loss: 0.0498 | Train Acc: 98.058% (37066/37800) | Strict Acc: 78.741% (2126/2700)\n",
      "True positive rate: 83.604% (2269/2714)\n",
      "False negative rate: 16.396% (445/2714)\n",
      "True negative rate: 99.176% (34797/35086)\n",
      "False positive rate: 0.824% (289/35086)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 28/67: Loss: 0.0499 | Train Acc: 98.046% (38434/39200) | Strict Acc: 78.750% (2205/2800)\n",
      "True positive rate: 83.488% (2346/2810)\n",
      "False negative rate: 16.512% (464/2810)\n",
      "True negative rate: 99.170% (36088/36390)\n",
      "False positive rate: 0.830% (302/36390)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 29/67: Loss: 0.0498 | Train Acc: 98.047% (39807/40600) | Strict Acc: 78.793% (2285/2900)\n",
      "True positive rate: 83.539% (2436/2916)\n",
      "False negative rate: 16.461% (480/2916)\n",
      "True negative rate: 99.169% (37371/37684)\n",
      "False positive rate: 0.831% (313/37684)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 30/67: Loss: 0.0497 | Train Acc: 98.060% (41185/42000) | Strict Acc: 78.900% (2367/3000)\n",
      "True positive rate: 83.691% (2535/3029)\n",
      "False negative rate: 16.309% (494/3029)\n",
      "True negative rate: 99.176% (38650/38971)\n",
      "False positive rate: 0.824% (321/38971)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 31/67: Loss: 0.0497 | Train Acc: 98.051% (42554/43400) | Strict Acc: 78.871% (2445/3100)\n",
      "True positive rate: 83.618% (2598/3107)\n",
      "False negative rate: 16.382% (509/3107)\n",
      "True negative rate: 99.164% (39956/40293)\n",
      "False positive rate: 0.836% (337/40293)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 32/67: Loss: 0.0497 | Train Acc: 98.060% (43931/44800) | Strict Acc: 78.938% (2526/3200)\n",
      "True positive rate: 83.821% (2694/3214)\n",
      "False negative rate: 16.179% (520/3214)\n",
      "True negative rate: 99.161% (41237/41586)\n",
      "False positive rate: 0.839% (349/41586)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 33/67: Loss: 0.0496 | Train Acc: 98.048% (45298/46200) | Strict Acc: 78.909% (2604/3300)\n",
      "True positive rate: 83.708% (2754/3290)\n",
      "False negative rate: 16.292% (536/3290)\n",
      "True negative rate: 99.147% (42544/42910)\n",
      "False positive rate: 0.853% (366/42910)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 34/67: Loss: 0.0492 | Train Acc: 98.061% (46677/47600) | Strict Acc: 79.000% (2686/3400)\n",
      "True positive rate: 83.790% (2843/3393)\n",
      "False negative rate: 16.210% (550/3393)\n",
      "True negative rate: 99.156% (43834/44207)\n",
      "False positive rate: 0.844% (373/44207)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 35/67: Loss: 0.0495 | Train Acc: 98.041% (48040/49000) | Strict Acc: 79.000% (2765/3500)\n",
      "True positive rate: 83.352% (2919/3502)\n",
      "False negative rate: 16.648% (583/3502)\n",
      "True negative rate: 99.171% (45121/45498)\n",
      "False positive rate: 0.829% (377/45498)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 36/67: Loss: 0.0495 | Train Acc: 98.034% (49409/50400) | Strict Acc: 78.917% (2841/3600)\n",
      "True positive rate: 83.054% (2970/3576)\n",
      "False negative rate: 16.946% (606/3576)\n",
      "True negative rate: 99.178% (46439/46824)\n",
      "False positive rate: 0.822% (385/46824)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 37/67: Loss: 0.0492 | Train Acc: 98.041% (50785/51800) | Strict Acc: 79.000% (2923/3700)\n",
      "True positive rate: 83.011% (3044/3667)\n",
      "False negative rate: 16.989% (623/3667)\n",
      "True negative rate: 99.186% (47741/48133)\n",
      "False positive rate: 0.814% (392/48133)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 38/67: Loss: 0.0491 | Train Acc: 98.047% (52161/53200) | Strict Acc: 79.079% (3005/3800)\n",
      "True positive rate: 83.042% (3134/3774)\n",
      "False negative rate: 16.958% (640/3774)\n",
      "True negative rate: 99.193% (49027/49426)\n",
      "False positive rate: 0.807% (399/49426)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 39/67: Loss: 0.0487 | Train Acc: 98.055% (53538/54600) | Strict Acc: 79.179% (3088/3900)\n",
      "True positive rate: 83.260% (3238/3889)\n",
      "False negative rate: 16.740% (651/3889)\n",
      "True negative rate: 99.190% (50300/50711)\n",
      "False positive rate: 0.810% (411/50711)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 40/67: Loss: 0.0489 | Train Acc: 98.043% (54904/56000) | Strict Acc: 79.125% (3165/4000)\n",
      "True positive rate: 83.292% (3320/3986)\n",
      "False negative rate: 16.708% (666/3986)\n",
      "True negative rate: 99.173% (51584/52014)\n",
      "False positive rate: 0.827% (430/52014)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 41/67: Loss: 0.0490 | Train Acc: 98.045% (56278/57400) | Strict Acc: 79.195% (3247/4100)\n",
      "True positive rate: 83.398% (3416/4096)\n",
      "False negative rate: 16.602% (680/4096)\n",
      "True negative rate: 99.171% (52862/53304)\n",
      "False positive rate: 0.829% (442/53304)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 11 - Batch 42/67: Loss: 0.0489 | Train Acc: 98.051% (57654/58800) | Strict Acc: 79.190% (3326/4200)\n",
      "True positive rate: 83.441% (3502/4197)\n",
      "False negative rate: 16.559% (695/4197)\n",
      "True negative rate: 99.174% (54152/54603)\n",
      "False positive rate: 0.826% (451/54603)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 43/67: Loss: 0.0485 | Train Acc: 98.065% (59035/60200) | Strict Acc: 79.326% (3411/4300)\n",
      "True positive rate: 83.501% (3563/4267)\n",
      "False negative rate: 16.499% (704/4267)\n",
      "True negative rate: 99.176% (55472/55933)\n",
      "False positive rate: 0.824% (461/55933)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 44/67: Loss: 0.0484 | Train Acc: 98.067% (60409/61600) | Strict Acc: 79.341% (3491/4400)\n",
      "True positive rate: 83.543% (3650/4369)\n",
      "False negative rate: 16.457% (719/4369)\n",
      "True negative rate: 99.175% (56759/57231)\n",
      "False positive rate: 0.825% (472/57231)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 45/67: Loss: 0.0485 | Train Acc: 98.048% (61770/63000) | Strict Acc: 79.222% (3565/4500)\n",
      "True positive rate: 83.423% (3734/4476)\n",
      "False negative rate: 16.577% (742/4476)\n",
      "True negative rate: 99.166% (58036/58524)\n",
      "False positive rate: 0.834% (488/58524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 46/67: Loss: 0.0484 | Train Acc: 98.048% (63143/64400) | Strict Acc: 79.196% (3643/4600)\n",
      "True positive rate: 83.428% (3811/4568)\n",
      "False negative rate: 16.572% (757/4568)\n",
      "True negative rate: 99.164% (59332/59832)\n",
      "False positive rate: 0.836% (500/59832)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 47/67: Loss: 0.0483 | Train Acc: 98.055% (64520/65800) | Strict Acc: 79.234% (3724/4700)\n",
      "True positive rate: 83.590% (3907/4674)\n",
      "False negative rate: 16.410% (767/4674)\n",
      "True negative rate: 99.161% (60613/61126)\n",
      "False positive rate: 0.839% (513/61126)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 48/67: Loss: 0.0489 | Train Acc: 98.036% (65880/67200) | Strict Acc: 79.062% (3795/4800)\n",
      "True positive rate: 83.337% (3986/4783)\n",
      "False negative rate: 16.663% (797/4783)\n",
      "True negative rate: 99.162% (61894/62417)\n",
      "False positive rate: 0.838% (523/62417)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 49/67: Loss: 0.0488 | Train Acc: 98.045% (67259/68600) | Strict Acc: 79.102% (3876/4900)\n",
      "True positive rate: 83.398% (4069/4879)\n",
      "False negative rate: 16.602% (810/4879)\n",
      "True negative rate: 99.167% (63190/63721)\n",
      "False positive rate: 0.833% (531/63721)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 50/67: Loss: 0.0488 | Train Acc: 98.046% (68632/70000) | Strict Acc: 79.060% (3953/5000)\n",
      "True positive rate: 83.403% (4161/4989)\n",
      "False negative rate: 16.597% (828/4989)\n",
      "True negative rate: 99.169% (64471/65011)\n",
      "False positive rate: 0.831% (540/65011)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 51/67: Loss: 0.0489 | Train Acc: 98.042% (70002/71400) | Strict Acc: 79.000% (4029/5100)\n",
      "True positive rate: 83.422% (4237/5079)\n",
      "False negative rate: 16.578% (842/5079)\n",
      "True negative rate: 99.162% (65765/66321)\n",
      "False positive rate: 0.838% (556/66321)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 52/67: Loss: 0.0488 | Train Acc: 98.044% (71376/72800) | Strict Acc: 79.000% (4108/5200)\n",
      "True positive rate: 83.475% (4324/5180)\n",
      "False negative rate: 16.525% (856/5180)\n",
      "True negative rate: 99.160% (67052/67620)\n",
      "False positive rate: 0.840% (568/67620)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 53/67: Loss: 0.0488 | Train Acc: 98.051% (72754/74200) | Strict Acc: 79.057% (4190/5300)\n",
      "True positive rate: 83.551% (4424/5295)\n",
      "False negative rate: 16.449% (871/5295)\n",
      "True negative rate: 99.166% (68330/68905)\n",
      "False positive rate: 0.834% (575/68905)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 54/67: Loss: 0.0490 | Train Acc: 98.042% (74120/75600) | Strict Acc: 78.944% (4263/5400)\n",
      "True positive rate: 83.552% (4516/5405)\n",
      "False negative rate: 16.448% (889/5405)\n",
      "True negative rate: 99.158% (69604/70195)\n",
      "False positive rate: 0.842% (591/70195)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 55/67: Loss: 0.0492 | Train Acc: 98.040% (75491/77000) | Strict Acc: 78.945% (4342/5500)\n",
      "True positive rate: 83.573% (4589/5491)\n",
      "False negative rate: 16.427% (902/5491)\n",
      "True negative rate: 99.151% (70902/71509)\n",
      "False positive rate: 0.849% (607/71509)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 56/67: Loss: 0.0494 | Train Acc: 98.027% (76853/78400) | Strict Acc: 78.821% (4414/5600)\n",
      "True positive rate: 83.438% (4660/5585)\n",
      "False negative rate: 16.562% (925/5585)\n",
      "True negative rate: 99.146% (72193/72815)\n",
      "False positive rate: 0.854% (622/72815)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 57/67: Loss: 0.0495 | Train Acc: 98.031% (78229/79800) | Strict Acc: 78.895% (4497/5700)\n",
      "True positive rate: 83.366% (4741/5687)\n",
      "False negative rate: 16.634% (946/5687)\n",
      "True negative rate: 99.157% (73488/74113)\n",
      "False positive rate: 0.843% (625/74113)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 58/67: Loss: 0.0496 | Train Acc: 98.016% (79589/81200) | Strict Acc: 78.793% (4570/5800)\n",
      "True positive rate: 83.198% (4813/5785)\n",
      "False negative rate: 16.802% (972/5785)\n",
      "True negative rate: 99.153% (74776/75415)\n",
      "False positive rate: 0.847% (639/75415)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 59/67: Loss: 0.0495 | Train Acc: 98.017% (80962/82600) | Strict Acc: 78.797% (4649/5900)\n",
      "True positive rate: 83.280% (4906/5891)\n",
      "False negative rate: 16.720% (985/5891)\n",
      "True negative rate: 99.149% (76056/76709)\n",
      "False positive rate: 0.851% (653/76709)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 60/67: Loss: 0.0495 | Train Acc: 98.020% (82337/84000) | Strict Acc: 78.833% (4730/6000)\n",
      "True positive rate: 83.314% (5013/6017)\n",
      "False negative rate: 16.686% (1004/6017)\n",
      "True negative rate: 99.155% (77324/77983)\n",
      "False positive rate: 0.845% (659/77983)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 61/67: Loss: 0.0494 | Train Acc: 98.027% (83715/85400) | Strict Acc: 78.902% (4813/6100)\n",
      "True positive rate: 83.418% (5091/6103)\n",
      "False negative rate: 16.582% (1012/6103)\n",
      "True negative rate: 99.151% (78624/79297)\n",
      "False positive rate: 0.849% (673/79297)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 62/67: Loss: 0.0494 | Train Acc: 98.031% (85091/86800) | Strict Acc: 78.952% (4895/6200)\n",
      "True positive rate: 83.489% (5173/6196)\n",
      "False negative rate: 16.511% (1023/6196)\n",
      "True negative rate: 99.149% (79918/80604)\n",
      "False positive rate: 0.851% (686/80604)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 63/67: Loss: 0.0495 | Train Acc: 98.027% (86460/88200) | Strict Acc: 78.921% (4972/6300)\n",
      "True positive rate: 83.518% (5265/6304)\n",
      "False negative rate: 16.482% (1039/6304)\n",
      "True negative rate: 99.144% (81195/81896)\n",
      "False positive rate: 0.856% (701/81896)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 64/67: Loss: 0.0495 | Train Acc: 98.023% (87829/89600) | Strict Acc: 78.875% (5048/6400)\n",
      "True positive rate: 83.601% (5363/6415)\n",
      "False negative rate: 16.399% (1052/6415)\n",
      "True negative rate: 99.136% (82466/83185)\n",
      "False positive rate: 0.864% (719/83185)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 65/67: Loss: 0.0494 | Train Acc: 98.026% (89204/91000) | Strict Acc: 78.938% (5131/6500)\n",
      "True positive rate: 83.660% (5458/6524)\n",
      "False negative rate: 16.340% (1066/6524)\n",
      "True negative rate: 99.136% (83746/84476)\n",
      "False positive rate: 0.864% (730/84476)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 11 - Batch 66/67: Loss: 0.0493 | Train Acc: 98.031% (90581/92400) | Strict Acc: 78.970% (5212/6600)\n",
      "True positive rate: 83.710% (5550/6630)\n",
      "False negative rate: 16.290% (1080/6630)\n",
      "True negative rate: 99.138% (85031/85770)\n",
      "False positive rate: 0.862% (739/85770)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 11 - Batch 67/67: Loss: 0.0494 | Train Acc: 98.026% (91907/93758) | Strict Acc: 78.961% (5288/6697)\n",
      "True positive rate: 83.674% (5648/6750)\n",
      "False negative rate: 16.326% (1102/6750)\n",
      "True negative rate: 99.139% (86259/87008)\n",
      "False positive rate: 0.861% (749/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1891 | Dev Acc: 92.772% (84643/91238) | Strict Acc: 39.635% (2583/6517)\n",
      "True positive rate: 45.660% (3004/6579)\n",
      "False negative rate: 54.340% (3575/6579)\n",
      "True negative rate: 96.433% (81639/84659)\n",
      "False positive rate: 3.567% (3020/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 1/67: Loss: 0.0358 | Train Acc: 98.714% (1382/1400) | Strict Acc: 85.000% (85/100)\n",
      "True positive rate: 93.333% (84/90)\n",
      "False negative rate: 6.667% (6/90)\n",
      "True negative rate: 99.084% (1298/1310)\n",
      "False positive rate: 0.916% (12/1310)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 2/67: Loss: 0.0327 | Train Acc: 98.929% (2770/2800) | Strict Acc: 87.500% (175/200)\n",
      "True positive rate: 92.593% (175/189)\n",
      "False negative rate: 7.407% (14/189)\n",
      "True negative rate: 99.387% (2595/2611)\n",
      "False positive rate: 0.613% (16/2611)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 3/67: Loss: 0.0365 | Train Acc: 98.738% (4147/4200) | Strict Acc: 85.667% (257/300)\n",
      "True positive rate: 90.268% (269/298)\n",
      "False negative rate: 9.732% (29/298)\n",
      "True negative rate: 99.385% (3878/3902)\n",
      "False positive rate: 0.615% (24/3902)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 4/67: Loss: 0.0375 | Train Acc: 98.661% (5525/5600) | Strict Acc: 85.000% (340/400)\n",
      "True positive rate: 89.487% (366/409)\n",
      "False negative rate: 10.513% (43/409)\n",
      "True negative rate: 99.384% (5159/5191)\n",
      "False positive rate: 0.616% (32/5191)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 5/67: Loss: 0.0385 | Train Acc: 98.614% (6903/7000) | Strict Acc: 84.800% (424/500)\n",
      "True positive rate: 88.224% (442/501)\n",
      "False negative rate: 11.776% (59/501)\n",
      "True negative rate: 99.415% (6461/6499)\n",
      "False positive rate: 0.585% (38/6499)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 6/67: Loss: 0.0393 | Train Acc: 98.560% (8279/8400) | Strict Acc: 84.167% (505/600)\n",
      "True positive rate: 87.396% (527/603)\n",
      "False negative rate: 12.604% (76/603)\n",
      "True negative rate: 99.423% (7752/7797)\n",
      "False positive rate: 0.577% (45/7797)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 7/67: Loss: 0.0395 | Train Acc: 98.541% (9657/9800) | Strict Acc: 84.143% (589/700)\n",
      "True positive rate: 87.286% (611/700)\n",
      "False negative rate: 12.714% (89/700)\n",
      "True negative rate: 99.407% (9046/9100)\n",
      "False positive rate: 0.593% (54/9100)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 8/67: Loss: 0.0400 | Train Acc: 98.473% (11029/11200) | Strict Acc: 83.625% (669/800)\n",
      "True positive rate: 87.375% (699/800)\n",
      "False negative rate: 12.625% (101/800)\n",
      "True negative rate: 99.327% (10330/10400)\n",
      "False positive rate: 0.673% (70/10400)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 9/67: Loss: 0.0392 | Train Acc: 98.500% (12411/12600) | Strict Acc: 83.889% (755/900)\n",
      "True positive rate: 88.098% (792/899)\n",
      "False negative rate: 11.902% (107/899)\n",
      "True negative rate: 99.299% (11619/11701)\n",
      "False positive rate: 0.701% (82/11701)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 10/67: Loss: 0.0400 | Train Acc: 98.450% (13783/14000) | Strict Acc: 83.200% (832/1000)\n",
      "True positive rate: 87.700% (877/1000)\n",
      "False negative rate: 12.300% (123/1000)\n",
      "True negative rate: 99.277% (12906/13000)\n",
      "False positive rate: 0.723% (94/13000)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 11/67: Loss: 0.0390 | Train Acc: 98.487% (15167/15400) | Strict Acc: 83.636% (920/1100)\n",
      "True positive rate: 88.176% (962/1091)\n",
      "False negative rate: 11.824% (129/1091)\n",
      "True negative rate: 99.273% (14205/14309)\n",
      "False positive rate: 0.727% (104/14309)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 12/67: Loss: 0.0399 | Train Acc: 98.446% (16539/16800) | Strict Acc: 83.333% (1000/1200)\n",
      "True positive rate: 87.320% (1033/1183)\n",
      "False negative rate: 12.680% (150/1183)\n",
      "True negative rate: 99.289% (15506/15617)\n",
      "False positive rate: 0.711% (111/15617)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 13/67: Loss: 0.0409 | Train Acc: 98.423% (17913/18200) | Strict Acc: 83.077% (1080/1300)\n",
      "True positive rate: 86.745% (1106/1275)\n",
      "False negative rate: 13.255% (169/1275)\n",
      "True negative rate: 99.303% (16807/16925)\n",
      "False positive rate: 0.697% (118/16925)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 14/67: Loss: 0.0413 | Train Acc: 98.393% (19285/19600) | Strict Acc: 82.571% (1156/1400)\n",
      "True positive rate: 86.038% (1177/1368)\n",
      "False negative rate: 13.962% (191/1368)\n",
      "True negative rate: 99.320% (18108/18232)\n",
      "False positive rate: 0.680% (124/18232)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 15/67: Loss: 0.0409 | Train Acc: 98.390% (20662/21000) | Strict Acc: 82.733% (1241/1500)\n",
      "True positive rate: 85.931% (1246/1450)\n",
      "False negative rate: 14.069% (204/1450)\n",
      "True negative rate: 99.315% (19416/19550)\n",
      "False positive rate: 0.685% (134/19550)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 16/67: Loss: 0.0405 | Train Acc: 98.411% (22044/22400) | Strict Acc: 82.750% (1324/1600)\n",
      "True positive rate: 86.343% (1353/1567)\n",
      "False negative rate: 13.657% (214/1567)\n",
      "True negative rate: 99.318% (20691/20833)\n",
      "False positive rate: 0.682% (142/20833)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 17/67: Loss: 0.0414 | Train Acc: 98.382% (23415/23800) | Strict Acc: 82.471% (1402/1700)\n",
      "True positive rate: 86.383% (1440/1667)\n",
      "False negative rate: 13.617% (227/1667)\n",
      "True negative rate: 99.286% (21975/22133)\n",
      "False positive rate: 0.714% (158/22133)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 18/67: Loss: 0.0424 | Train Acc: 98.306% (24773/25200) | Strict Acc: 81.667% (1470/1800)\n",
      "True positive rate: 86.133% (1528/1774)\n",
      "False negative rate: 13.867% (246/1774)\n",
      "True negative rate: 99.227% (23245/23426)\n",
      "False positive rate: 0.773% (181/23426)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 19/67: Loss: 0.0425 | Train Acc: 98.289% (26145/26600) | Strict Acc: 81.316% (1545/1900)\n",
      "True positive rate: 86.352% (1626/1883)\n",
      "False negative rate: 13.648% (257/1883)\n",
      "True negative rate: 99.199% (24519/24717)\n",
      "False positive rate: 0.801% (198/24717)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 20/67: Loss: 0.0425 | Train Acc: 98.296% (27523/28000) | Strict Acc: 81.400% (1628/2000)\n",
      "True positive rate: 86.324% (1698/1967)\n",
      "False negative rate: 13.676% (269/1967)\n",
      "True negative rate: 99.201% (25825/26033)\n",
      "False positive rate: 0.799% (208/26033)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 21/67: Loss: 0.0421 | Train Acc: 98.316% (28905/29400) | Strict Acc: 81.619% (1714/2100)\n",
      "True positive rate: 86.574% (1799/2078)\n",
      "False negative rate: 13.426% (279/2078)\n",
      "True negative rate: 99.209% (27106/27322)\n",
      "False positive rate: 0.791% (216/27322)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 22/67: Loss: 0.0420 | Train Acc: 98.308% (30279/30800) | Strict Acc: 81.364% (1790/2200)\n",
      "True positive rate: 86.664% (1878/2167)\n",
      "False negative rate: 13.336% (289/2167)\n",
      "True negative rate: 99.190% (28401/28633)\n",
      "False positive rate: 0.810% (232/28633)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 23/67: Loss: 0.0416 | Train Acc: 98.320% (31659/32200) | Strict Acc: 81.522% (1875/2300)\n",
      "True positive rate: 86.805% (1967/2266)\n",
      "False negative rate: 13.195% (299/2266)\n",
      "True negative rate: 99.192% (29692/29934)\n",
      "False positive rate: 0.808% (242/29934)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 24/67: Loss: 0.0416 | Train Acc: 98.330% (33039/33600) | Strict Acc: 81.625% (1959/2400)\n",
      "True positive rate: 86.714% (2056/2371)\n",
      "False negative rate: 13.286% (315/2371)\n",
      "True negative rate: 99.212% (30983/31229)\n",
      "False positive rate: 0.788% (246/31229)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 12 - Batch 25/67: Loss: 0.0416 | Train Acc: 98.329% (34415/35000) | Strict Acc: 81.720% (2043/2500)\n",
      "True positive rate: 86.511% (2142/2476)\n",
      "False negative rate: 13.489% (334/2476)\n",
      "True negative rate: 99.228% (32273/32524)\n",
      "False positive rate: 0.772% (251/32524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 26/67: Loss: 0.0412 | Train Acc: 98.335% (35794/36400) | Strict Acc: 81.731% (2125/2600)\n",
      "True positive rate: 86.592% (2241/2588)\n",
      "False negative rate: 13.408% (347/2588)\n",
      "True negative rate: 99.234% (33553/33812)\n",
      "False positive rate: 0.766% (259/33812)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 27/67: Loss: 0.0415 | Train Acc: 98.310% (37161/37800) | Strict Acc: 81.481% (2200/2700)\n",
      "True positive rate: 86.355% (2329/2697)\n",
      "False negative rate: 13.645% (368/2697)\n",
      "True negative rate: 99.228% (34832/35103)\n",
      "False positive rate: 0.772% (271/35103)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 28/67: Loss: 0.0417 | Train Acc: 98.311% (38538/39200) | Strict Acc: 81.464% (2281/2800)\n",
      "True positive rate: 86.369% (2414/2795)\n",
      "False negative rate: 13.631% (381/2795)\n",
      "True negative rate: 99.228% (36124/36405)\n",
      "False positive rate: 0.772% (281/36405)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 29/67: Loss: 0.0419 | Train Acc: 98.296% (39908/40600) | Strict Acc: 81.345% (2359/2900)\n",
      "True positive rate: 86.426% (2515/2910)\n",
      "False negative rate: 13.574% (395/2910)\n",
      "True negative rate: 99.212% (37393/37690)\n",
      "False positive rate: 0.788% (297/37690)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 30/67: Loss: 0.0417 | Train Acc: 98.305% (41288/42000) | Strict Acc: 81.400% (2442/3000)\n",
      "True positive rate: 86.305% (2590/3001)\n",
      "False negative rate: 13.695% (411/3001)\n",
      "True negative rate: 99.228% (38698/38999)\n",
      "False positive rate: 0.772% (301/38999)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 31/67: Loss: 0.0418 | Train Acc: 98.304% (42664/43400) | Strict Acc: 81.419% (2524/3100)\n",
      "True positive rate: 86.302% (2665/3088)\n",
      "False negative rate: 13.698% (423/3088)\n",
      "True negative rate: 99.224% (39999/40312)\n",
      "False positive rate: 0.776% (313/40312)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 32/67: Loss: 0.0418 | Train Acc: 98.304% (44040/44800) | Strict Acc: 81.344% (2603/3200)\n",
      "True positive rate: 86.341% (2756/3192)\n",
      "False negative rate: 13.659% (436/3192)\n",
      "True negative rate: 99.221% (41284/41608)\n",
      "False positive rate: 0.779% (324/41608)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 33/67: Loss: 0.0415 | Train Acc: 98.318% (45423/46200) | Strict Acc: 81.424% (2687/3300)\n",
      "True positive rate: 86.466% (2843/3288)\n",
      "False negative rate: 13.534% (445/3288)\n",
      "True negative rate: 99.226% (42580/42912)\n",
      "False positive rate: 0.774% (332/42912)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 34/67: Loss: 0.0414 | Train Acc: 98.319% (46800/47600) | Strict Acc: 81.441% (2769/3400)\n",
      "True positive rate: 86.549% (2947/3405)\n",
      "False negative rate: 13.451% (458/3405)\n",
      "True negative rate: 99.226% (43853/44195)\n",
      "False positive rate: 0.774% (342/44195)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 35/67: Loss: 0.0416 | Train Acc: 98.306% (48170/49000) | Strict Acc: 81.314% (2846/3500)\n",
      "True positive rate: 86.572% (3056/3530)\n",
      "False negative rate: 13.428% (474/3530)\n",
      "True negative rate: 99.217% (45114/45470)\n",
      "False positive rate: 0.783% (356/45470)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 36/67: Loss: 0.0416 | Train Acc: 98.308% (49547/50400) | Strict Acc: 81.222% (2924/3600)\n",
      "True positive rate: 86.606% (3123/3606)\n",
      "False negative rate: 13.394% (483/3606)\n",
      "True negative rate: 99.209% (46424/46794)\n",
      "False positive rate: 0.791% (370/46794)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 37/67: Loss: 0.0417 | Train Acc: 98.305% (50922/51800) | Strict Acc: 81.162% (3003/3700)\n",
      "True positive rate: 86.523% (3223/3725)\n",
      "False negative rate: 13.477% (502/3725)\n",
      "True negative rate: 99.218% (47699/48075)\n",
      "False positive rate: 0.782% (376/48075)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 38/67: Loss: 0.0420 | Train Acc: 98.301% (52296/53200) | Strict Acc: 81.026% (3079/3800)\n",
      "True positive rate: 86.393% (3308/3829)\n",
      "False negative rate: 13.607% (521/3829)\n",
      "True negative rate: 99.224% (48988/49371)\n",
      "False positive rate: 0.776% (383/49371)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 39/67: Loss: 0.0420 | Train Acc: 98.304% (53674/54600) | Strict Acc: 81.128% (3164/3900)\n",
      "True positive rate: 86.372% (3378/3911)\n",
      "False negative rate: 13.628% (533/3911)\n",
      "True negative rate: 99.225% (50296/50689)\n",
      "False positive rate: 0.775% (393/50689)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 40/67: Loss: 0.0421 | Train Acc: 98.298% (55047/56000) | Strict Acc: 81.150% (3246/4000)\n",
      "True positive rate: 86.216% (3459/4012)\n",
      "False negative rate: 13.784% (553/4012)\n",
      "True negative rate: 99.231% (51588/51988)\n",
      "False positive rate: 0.769% (400/51988)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 41/67: Loss: 0.0424 | Train Acc: 98.293% (56420/57400) | Strict Acc: 81.098% (3325/4100)\n",
      "True positive rate: 86.255% (3533/4096)\n",
      "False negative rate: 13.745% (563/4096)\n",
      "True negative rate: 99.218% (52887/53304)\n",
      "False positive rate: 0.782% (417/53304)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 42/67: Loss: 0.0423 | Train Acc: 98.299% (57800/58800) | Strict Acc: 81.190% (3410/4200)\n",
      "True positive rate: 86.337% (3627/4201)\n",
      "False negative rate: 13.663% (574/4201)\n",
      "True negative rate: 99.220% (54173/54599)\n",
      "False positive rate: 0.780% (426/54599)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 43/67: Loss: 0.0423 | Train Acc: 98.302% (59178/60200) | Strict Acc: 81.233% (3493/4300)\n",
      "True positive rate: 86.411% (3720/4305)\n",
      "False negative rate: 13.589% (585/4305)\n",
      "True negative rate: 99.218% (55458/55895)\n",
      "False positive rate: 0.782% (437/55895)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 44/67: Loss: 0.0422 | Train Acc: 98.307% (60557/61600) | Strict Acc: 81.295% (3577/4400)\n",
      "True positive rate: 86.448% (3821/4420)\n",
      "False negative rate: 13.552% (599/4420)\n",
      "True negative rate: 99.224% (56736/57180)\n",
      "False positive rate: 0.776% (444/57180)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 45/67: Loss: 0.0423 | Train Acc: 98.302% (61930/63000) | Strict Acc: 81.200% (3654/4500)\n",
      "True positive rate: 86.491% (3912/4523)\n",
      "False negative rate: 13.509% (611/4523)\n",
      "True negative rate: 99.215% (58018/58477)\n",
      "False positive rate: 0.785% (459/58477)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 46/67: Loss: 0.0425 | Train Acc: 98.300% (63305/64400) | Strict Acc: 81.152% (3733/4600)\n",
      "True positive rate: 86.613% (4018/4639)\n",
      "False negative rate: 13.387% (621/4639)\n",
      "True negative rate: 99.207% (59287/59761)\n",
      "False positive rate: 0.793% (474/59761)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 47/67: Loss: 0.0426 | Train Acc: 98.298% (64680/65800) | Strict Acc: 81.170% (3815/4700)\n",
      "True positive rate: 86.477% (4099/4740)\n",
      "False negative rate: 13.523% (641/4740)\n",
      "True negative rate: 99.216% (60581/61060)\n",
      "False positive rate: 0.784% (479/61060)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 48/67: Loss: 0.0427 | Train Acc: 98.289% (66050/67200) | Strict Acc: 81.062% (3891/4800)\n",
      "True positive rate: 86.425% (4170/4825)\n",
      "False negative rate: 13.575% (655/4825)\n",
      "True negative rate: 99.206% (61880/62375)\n",
      "False positive rate: 0.794% (495/62375)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 49/67: Loss: 0.0428 | Train Acc: 98.283% (67422/68600) | Strict Acc: 81.020% (3970/4900)\n",
      "True positive rate: 86.317% (4252/4926)\n",
      "False negative rate: 13.683% (674/4926)\n",
      "True negative rate: 99.208% (63170/63674)\n",
      "False positive rate: 0.792% (504/63674)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 12 - Batch 50/67: Loss: 0.0427 | Train Acc: 98.284% (68799/70000) | Strict Acc: 81.020% (4051/5000)\n",
      "True positive rate: 86.310% (4325/5011)\n",
      "False negative rate: 13.690% (686/5011)\n",
      "True negative rate: 99.208% (64474/64989)\n",
      "False positive rate: 0.792% (515/64989)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 51/67: Loss: 0.0430 | Train Acc: 98.279% (70171/71400) | Strict Acc: 80.980% (4130/5100)\n",
      "True positive rate: 86.191% (4413/5120)\n",
      "False negative rate: 13.809% (707/5120)\n",
      "True negative rate: 99.212% (65758/66280)\n",
      "False positive rate: 0.788% (522/66280)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 52/67: Loss: 0.0430 | Train Acc: 98.284% (71551/72800) | Strict Acc: 81.077% (4216/5200)\n",
      "True positive rate: 86.225% (4513/5234)\n",
      "False negative rate: 13.775% (721/5234)\n",
      "True negative rate: 99.219% (67038/67566)\n",
      "False positive rate: 0.781% (528/67566)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 53/67: Loss: 0.0430 | Train Acc: 98.286% (72928/74200) | Strict Acc: 81.094% (4298/5300)\n",
      "True positive rate: 86.235% (4592/5325)\n",
      "False negative rate: 13.765% (733/5325)\n",
      "True negative rate: 99.217% (68336/68875)\n",
      "False positive rate: 0.783% (539/68875)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 54/67: Loss: 0.0429 | Train Acc: 98.291% (74308/75600) | Strict Acc: 81.111% (4380/5400)\n",
      "True positive rate: 86.267% (4680/5425)\n",
      "False negative rate: 13.733% (745/5425)\n",
      "True negative rate: 99.221% (69628/70175)\n",
      "False positive rate: 0.779% (547/70175)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 55/67: Loss: 0.0430 | Train Acc: 98.287% (75681/77000) | Strict Acc: 81.055% (4458/5500)\n",
      "True positive rate: 86.221% (4762/5523)\n",
      "False negative rate: 13.779% (761/5523)\n",
      "True negative rate: 99.219% (70919/71477)\n",
      "False positive rate: 0.781% (558/71477)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 56/67: Loss: 0.0428 | Train Acc: 98.297% (77065/78400) | Strict Acc: 81.143% (4544/5600)\n",
      "True positive rate: 86.240% (4851/5625)\n",
      "False negative rate: 13.760% (774/5625)\n",
      "True negative rate: 99.229% (72214/72775)\n",
      "False positive rate: 0.771% (561/72775)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 57/67: Loss: 0.0432 | Train Acc: 98.271% (78420/79800) | Strict Acc: 80.895% (4611/5700)\n",
      "True positive rate: 85.975% (4941/5747)\n",
      "False negative rate: 14.025% (806/5747)\n",
      "True negative rate: 99.225% (73479/74053)\n",
      "False positive rate: 0.775% (574/74053)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 58/67: Loss: 0.0433 | Train Acc: 98.267% (79793/81200) | Strict Acc: 80.879% (4691/5800)\n",
      "True positive rate: 85.947% (5015/5835)\n",
      "False negative rate: 14.053% (820/5835)\n",
      "True negative rate: 99.221% (74778/75365)\n",
      "False positive rate: 0.779% (587/75365)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 59/67: Loss: 0.0434 | Train Acc: 98.265% (81167/82600) | Strict Acc: 80.864% (4771/5900)\n",
      "True positive rate: 85.977% (5101/5933)\n",
      "False negative rate: 14.023% (832/5933)\n",
      "True negative rate: 99.216% (76066/76667)\n",
      "False positive rate: 0.784% (601/76667)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 60/67: Loss: 0.0434 | Train Acc: 98.261% (82539/84000) | Strict Acc: 80.783% (4847/6000)\n",
      "True positive rate: 85.897% (5177/6027)\n",
      "False negative rate: 14.103% (850/6027)\n",
      "True negative rate: 99.216% (77362/77973)\n",
      "False positive rate: 0.784% (611/77973)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 61/67: Loss: 0.0433 | Train Acc: 98.267% (83920/85400) | Strict Acc: 80.869% (4933/6100)\n",
      "True positive rate: 85.975% (5284/6146)\n",
      "False negative rate: 14.025% (862/6146)\n",
      "True negative rate: 99.220% (78636/79254)\n",
      "False positive rate: 0.780% (618/79254)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 62/67: Loss: 0.0436 | Train Acc: 98.256% (85286/86800) | Strict Acc: 80.839% (5012/6200)\n",
      "True positive rate: 85.890% (5369/6251)\n",
      "False negative rate: 14.110% (882/6251)\n",
      "True negative rate: 99.215% (79917/80549)\n",
      "False positive rate: 0.785% (632/80549)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 63/67: Loss: 0.0436 | Train Acc: 98.253% (86659/88200) | Strict Acc: 80.825% (5092/6300)\n",
      "True positive rate: 86.024% (5478/6368)\n",
      "False negative rate: 13.976% (890/6368)\n",
      "True negative rate: 99.204% (81181/81832)\n",
      "False positive rate: 0.796% (651/81832)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 64/67: Loss: 0.0439 | Train Acc: 98.233% (88017/89600) | Strict Acc: 80.734% (5167/6400)\n",
      "True positive rate: 85.871% (5555/6469)\n",
      "False negative rate: 14.129% (914/6469)\n",
      "True negative rate: 99.195% (82462/83131)\n",
      "False positive rate: 0.805% (669/83131)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 65/67: Loss: 0.0439 | Train Acc: 98.232% (89391/91000) | Strict Acc: 80.692% (5245/6500)\n",
      "True positive rate: 85.858% (5646/6576)\n",
      "False negative rate: 14.142% (930/6576)\n",
      "True negative rate: 99.196% (83745/84424)\n",
      "False positive rate: 0.804% (679/84424)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 66/67: Loss: 0.0438 | Train Acc: 98.234% (90768/92400) | Strict Acc: 80.712% (5327/6600)\n",
      "True positive rate: 85.899% (5714/6652)\n",
      "False negative rate: 14.101% (938/6652)\n",
      "True negative rate: 99.191% (85054/85748)\n",
      "False positive rate: 0.809% (694/85748)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 12 - Batch 67/67: Loss: 0.0438 | Train Acc: 98.233% (92101/93758) | Strict Acc: 80.708% (5405/6697)\n",
      "True positive rate: 85.896% (5798/6750)\n",
      "False negative rate: 14.104% (952/6750)\n",
      "True negative rate: 99.190% (86303/87008)\n",
      "False positive rate: 0.810% (705/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1936 | Dev Acc: 93.579% (85380/91238) | Strict Acc: 48.565% (3165/6517)\n",
      "True positive rate: 29.275% (1926/6579)\n",
      "False negative rate: 70.725% (4653/6579)\n",
      "True negative rate: 98.577% (83454/84659)\n",
      "False positive rate: 1.423% (1205/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 1/67: Loss: 0.0338 | Train Acc: 98.643% (1381/1400) | Strict Acc: 86.000% (86/100)\n",
      "True positive rate: 85.577% (89/104)\n",
      "False negative rate: 14.423% (15/104)\n",
      "True negative rate: 99.691% (1292/1296)\n",
      "False positive rate: 0.309% (4/1296)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 2/67: Loss: 0.0400 | Train Acc: 98.393% (2755/2800) | Strict Acc: 81.500% (163/200)\n",
      "True positive rate: 83.333% (185/222)\n",
      "False negative rate: 16.667% (37/222)\n",
      "True negative rate: 99.690% (2570/2578)\n",
      "False positive rate: 0.310% (8/2578)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 3/67: Loss: 0.0378 | Train Acc: 98.571% (4140/4200) | Strict Acc: 83.000% (249/300)\n",
      "True positive rate: 84.783% (273/322)\n",
      "False negative rate: 15.217% (49/322)\n",
      "True negative rate: 99.716% (3867/3878)\n",
      "False positive rate: 0.284% (11/3878)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 4/67: Loss: 0.0359 | Train Acc: 98.696% (5527/5600) | Strict Acc: 84.750% (339/400)\n",
      "True positive rate: 85.952% (361/420)\n",
      "False negative rate: 14.048% (59/420)\n",
      "True negative rate: 99.730% (5166/5180)\n",
      "False positive rate: 0.270% (14/5180)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 5/67: Loss: 0.0343 | Train Acc: 98.786% (6915/7000) | Strict Acc: 85.600% (428/500)\n",
      "True positive rate: 87.524% (449/513)\n",
      "False negative rate: 12.476% (64/513)\n",
      "True negative rate: 99.676% (6466/6487)\n",
      "False positive rate: 0.324% (21/6487)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 6/67: Loss: 0.0351 | Train Acc: 98.702% (8291/8400) | Strict Acc: 84.667% (508/600)\n",
      "True positive rate: 87.705% (535/610)\n",
      "False negative rate: 12.295% (75/610)\n",
      "True negative rate: 99.564% (7756/7790)\n",
      "False positive rate: 0.436% (34/7790)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 7/67: Loss: 0.0351 | Train Acc: 98.684% (9671/9800) | Strict Acc: 84.571% (592/700)\n",
      "True positive rate: 88.075% (613/696)\n",
      "False negative rate: 11.925% (83/696)\n",
      "True negative rate: 99.495% (9058/9104)\n",
      "False positive rate: 0.505% (46/9104)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 13 - Batch 8/67: Loss: 0.0368 | Train Acc: 98.634% (11047/11200) | Strict Acc: 84.125% (673/800)\n",
      "True positive rate: 88.062% (686/779)\n",
      "False negative rate: 11.938% (93/779)\n",
      "True negative rate: 99.424% (10361/10421)\n",
      "False positive rate: 0.576% (60/10421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 9/67: Loss: 0.0365 | Train Acc: 98.659% (12431/12600) | Strict Acc: 84.556% (761/900)\n",
      "True positive rate: 87.910% (778/885)\n",
      "False negative rate: 12.090% (107/885)\n",
      "True negative rate: 99.471% (11653/11715)\n",
      "False positive rate: 0.529% (62/11715)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 10/67: Loss: 0.0362 | Train Acc: 98.643% (13810/14000) | Strict Acc: 84.500% (845/1000)\n",
      "True positive rate: 87.411% (861/985)\n",
      "False negative rate: 12.589% (124/985)\n",
      "True negative rate: 99.493% (12949/13015)\n",
      "False positive rate: 0.507% (66/13015)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 11/67: Loss: 0.0357 | Train Acc: 98.656% (15193/15400) | Strict Acc: 84.818% (933/1100)\n",
      "True positive rate: 87.279% (940/1077)\n",
      "False negative rate: 12.721% (137/1077)\n",
      "True negative rate: 99.511% (14253/14323)\n",
      "False positive rate: 0.489% (70/14323)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 12/67: Loss: 0.0359 | Train Acc: 98.595% (16564/16800) | Strict Acc: 84.167% (1010/1200)\n",
      "True positive rate: 86.847% (1030/1186)\n",
      "False negative rate: 13.153% (156/1186)\n",
      "True negative rate: 99.488% (15534/15614)\n",
      "False positive rate: 0.512% (80/15614)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 13/67: Loss: 0.0362 | Train Acc: 98.560% (17938/18200) | Strict Acc: 83.923% (1091/1300)\n",
      "True positive rate: 86.950% (1106/1272)\n",
      "False negative rate: 13.050% (166/1272)\n",
      "True negative rate: 99.433% (16832/16928)\n",
      "False positive rate: 0.567% (96/16928)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 14/67: Loss: 0.0360 | Train Acc: 98.561% (19318/19600) | Strict Acc: 83.929% (1175/1400)\n",
      "True positive rate: 87.254% (1198/1373)\n",
      "False negative rate: 12.746% (175/1373)\n",
      "True negative rate: 99.413% (18120/18227)\n",
      "False positive rate: 0.587% (107/18227)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 15/67: Loss: 0.0368 | Train Acc: 98.524% (20690/21000) | Strict Acc: 83.600% (1254/1500)\n",
      "True positive rate: 87.077% (1287/1478)\n",
      "False negative rate: 12.923% (191/1478)\n",
      "True negative rate: 99.390% (19403/19522)\n",
      "False positive rate: 0.610% (119/19522)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 16/67: Loss: 0.0374 | Train Acc: 98.518% (22068/22400) | Strict Acc: 83.438% (1335/1600)\n",
      "True positive rate: 87.103% (1371/1574)\n",
      "False negative rate: 12.897% (203/1574)\n",
      "True negative rate: 99.381% (20697/20826)\n",
      "False positive rate: 0.619% (129/20826)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 17/67: Loss: 0.0373 | Train Acc: 98.525% (23449/23800) | Strict Acc: 83.471% (1419/1700)\n",
      "True positive rate: 87.306% (1465/1678)\n",
      "False negative rate: 12.694% (213/1678)\n",
      "True negative rate: 99.376% (21984/22122)\n",
      "False positive rate: 0.624% (138/22122)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 18/67: Loss: 0.0364 | Train Acc: 98.552% (24835/25200) | Strict Acc: 83.722% (1507/1800)\n",
      "True positive rate: 87.584% (1559/1780)\n",
      "False negative rate: 12.416% (221/1780)\n",
      "True negative rate: 99.385% (23276/23420)\n",
      "False positive rate: 0.615% (144/23420)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 19/67: Loss: 0.0369 | Train Acc: 98.534% (26210/26600) | Strict Acc: 83.474% (1586/1900)\n",
      "True positive rate: 87.474% (1669/1908)\n",
      "False negative rate: 12.526% (239/1908)\n",
      "True negative rate: 99.388% (24541/24692)\n",
      "False positive rate: 0.612% (151/24692)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 20/67: Loss: 0.0370 | Train Acc: 98.550% (27594/28000) | Strict Acc: 83.550% (1671/2000)\n",
      "True positive rate: 87.438% (1754/2006)\n",
      "False negative rate: 12.562% (252/2006)\n",
      "True negative rate: 99.408% (25840/25994)\n",
      "False positive rate: 0.592% (154/25994)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 21/67: Loss: 0.0370 | Train Acc: 98.558% (28976/29400) | Strict Acc: 83.714% (1758/2100)\n",
      "True positive rate: 87.762% (1843/2100)\n",
      "False negative rate: 12.238% (257/2100)\n",
      "True negative rate: 99.388% (27133/27300)\n",
      "False positive rate: 0.612% (167/27300)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 22/67: Loss: 0.0369 | Train Acc: 98.568% (30359/30800) | Strict Acc: 83.727% (1842/2200)\n",
      "True positive rate: 87.946% (1948/2215)\n",
      "False negative rate: 12.054% (267/2215)\n",
      "True negative rate: 99.391% (28411/28585)\n",
      "False positive rate: 0.609% (174/28585)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 23/67: Loss: 0.0369 | Train Acc: 98.584% (31744/32200) | Strict Acc: 83.826% (1928/2300)\n",
      "True positive rate: 87.990% (2044/2323)\n",
      "False negative rate: 12.010% (279/2323)\n",
      "True negative rate: 99.408% (29700/29877)\n",
      "False positive rate: 0.592% (177/29877)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 24/67: Loss: 0.0372 | Train Acc: 98.580% (33123/33600) | Strict Acc: 83.708% (2009/2400)\n",
      "True positive rate: 87.923% (2133/2426)\n",
      "False negative rate: 12.077% (293/2426)\n",
      "True negative rate: 99.410% (30990/31174)\n",
      "False positive rate: 0.590% (184/31174)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 25/67: Loss: 0.0370 | Train Acc: 98.577% (34502/35000) | Strict Acc: 83.720% (2093/2500)\n",
      "True positive rate: 87.837% (2217/2524)\n",
      "False negative rate: 12.163% (307/2524)\n",
      "True negative rate: 99.412% (32285/32476)\n",
      "False positive rate: 0.588% (191/32476)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 26/67: Loss: 0.0365 | Train Acc: 98.593% (35888/36400) | Strict Acc: 83.808% (2179/2600)\n",
      "True positive rate: 87.948% (2306/2622)\n",
      "False negative rate: 12.052% (316/2622)\n",
      "True negative rate: 99.420% (33582/33778)\n",
      "False positive rate: 0.580% (196/33778)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 27/67: Loss: 0.0364 | Train Acc: 98.585% (37265/37800) | Strict Acc: 83.741% (2261/2700)\n",
      "True positive rate: 88.034% (2391/2716)\n",
      "False negative rate: 11.966% (325/2716)\n",
      "True negative rate: 99.401% (34874/35084)\n",
      "False positive rate: 0.599% (210/35084)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 28/67: Loss: 0.0362 | Train Acc: 98.584% (38645/39200) | Strict Acc: 83.750% (2345/2800)\n",
      "True positive rate: 88.258% (2473/2802)\n",
      "False negative rate: 11.742% (329/2802)\n",
      "True negative rate: 99.379% (36172/36398)\n",
      "False positive rate: 0.621% (226/36398)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 29/67: Loss: 0.0361 | Train Acc: 98.589% (40027/40600) | Strict Acc: 83.862% (2432/2900)\n",
      "True positive rate: 88.231% (2549/2889)\n",
      "False negative rate: 11.769% (340/2889)\n",
      "True negative rate: 99.382% (37478/37711)\n",
      "False positive rate: 0.618% (233/37711)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 30/67: Loss: 0.0359 | Train Acc: 98.602% (41413/42000) | Strict Acc: 83.967% (2519/3000)\n",
      "True positive rate: 88.235% (2625/2975)\n",
      "False negative rate: 11.765% (350/2975)\n",
      "True negative rate: 99.393% (38788/39025)\n",
      "False positive rate: 0.607% (237/39025)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 31/67: Loss: 0.0361 | Train Acc: 98.590% (42788/43400) | Strict Acc: 83.839% (2599/3100)\n",
      "True positive rate: 87.982% (2694/3062)\n",
      "False negative rate: 12.018% (368/3062)\n",
      "True negative rate: 99.395% (40094/40338)\n",
      "False positive rate: 0.605% (244/40338)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 32/67: Loss: 0.0364 | Train Acc: 98.578% (44163/44800) | Strict Acc: 83.719% (2679/3200)\n",
      "True positive rate: 87.741% (2777/3165)\n",
      "False negative rate: 12.259% (388/3165)\n",
      "True negative rate: 99.402% (41386/41635)\n",
      "False positive rate: 0.598% (249/41635)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 33/67: Loss: 0.0365 | Train Acc: 98.582% (45545/46200) | Strict Acc: 83.788% (2765/3300)\n",
      "True positive rate: 87.764% (2862/3261)\n",
      "False negative rate: 12.236% (399/3261)\n",
      "True negative rate: 99.404% (42683/42939)\n",
      "False positive rate: 0.596% (256/42939)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 13 - Batch 34/67: Loss: 0.0364 | Train Acc: 98.586% (46927/47600) | Strict Acc: 83.853% (2851/3400)\n",
      "True positive rate: 87.960% (2966/3372)\n",
      "False negative rate: 12.040% (406/3372)\n",
      "True negative rate: 99.396% (43961/44228)\n",
      "False positive rate: 0.604% (267/44228)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 35/67: Loss: 0.0365 | Train Acc: 98.573% (48301/49000) | Strict Acc: 83.771% (2932/3500)\n",
      "True positive rate: 87.971% (3057/3475)\n",
      "False negative rate: 12.029% (418/3475)\n",
      "True negative rate: 99.383% (45244/45525)\n",
      "False positive rate: 0.617% (281/45525)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 36/67: Loss: 0.0364 | Train Acc: 98.587% (49688/50400) | Strict Acc: 83.861% (3019/3600)\n",
      "True positive rate: 88.056% (3148/3575)\n",
      "False negative rate: 11.944% (427/3575)\n",
      "True negative rate: 99.391% (46540/46825)\n",
      "False positive rate: 0.609% (285/46825)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 37/67: Loss: 0.0363 | Train Acc: 98.591% (51070/51800) | Strict Acc: 83.892% (3104/3700)\n",
      "True positive rate: 88.100% (3250/3689)\n",
      "False negative rate: 11.900% (439/3689)\n",
      "True negative rate: 99.395% (47820/48111)\n",
      "False positive rate: 0.605% (291/48111)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 38/67: Loss: 0.0361 | Train Acc: 98.605% (52458/53200) | Strict Acc: 84.079% (3195/3800)\n",
      "True positive rate: 88.195% (3332/3778)\n",
      "False negative rate: 11.805% (446/3778)\n",
      "True negative rate: 99.401% (49126/49422)\n",
      "False positive rate: 0.599% (296/49422)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 39/67: Loss: 0.0361 | Train Acc: 98.606% (53839/54600) | Strict Acc: 84.051% (3278/3900)\n",
      "True positive rate: 88.238% (3406/3860)\n",
      "False negative rate: 11.762% (454/3860)\n",
      "True negative rate: 99.395% (50433/50740)\n",
      "False positive rate: 0.605% (307/50740)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 40/67: Loss: 0.0362 | Train Acc: 98.598% (55215/56000) | Strict Acc: 84.000% (3360/4000)\n",
      "True positive rate: 88.160% (3492/3961)\n",
      "False negative rate: 11.840% (469/3961)\n",
      "True negative rate: 99.393% (51723/52039)\n",
      "False positive rate: 0.607% (316/52039)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 41/67: Loss: 0.0359 | Train Acc: 98.610% (56602/57400) | Strict Acc: 84.146% (3450/4100)\n",
      "True positive rate: 88.216% (3571/4048)\n",
      "False negative rate: 11.784% (477/4048)\n",
      "True negative rate: 99.398% (53031/53352)\n",
      "False positive rate: 0.602% (321/53352)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 42/67: Loss: 0.0362 | Train Acc: 98.590% (57971/58800) | Strict Acc: 83.952% (3526/4200)\n",
      "True positive rate: 88.079% (3650/4144)\n",
      "False negative rate: 11.921% (494/4144)\n",
      "True negative rate: 99.387% (54321/54656)\n",
      "False positive rate: 0.613% (335/54656)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 43/67: Loss: 0.0361 | Train Acc: 98.586% (59349/60200) | Strict Acc: 83.907% (3608/4300)\n",
      "True positive rate: 88.083% (3740/4246)\n",
      "False negative rate: 11.917% (506/4246)\n",
      "True negative rate: 99.383% (55609/55954)\n",
      "False positive rate: 0.617% (345/55954)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 44/67: Loss: 0.0362 | Train Acc: 98.580% (60725/61600) | Strict Acc: 83.864% (3690/4400)\n",
      "True positive rate: 88.023% (3829/4350)\n",
      "False negative rate: 11.977% (521/4350)\n",
      "True negative rate: 99.382% (56896/57250)\n",
      "False positive rate: 0.618% (354/57250)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 45/67: Loss: 0.0364 | Train Acc: 98.573% (62101/63000) | Strict Acc: 83.867% (3774/4500)\n",
      "True positive rate: 87.960% (3916/4452)\n",
      "False negative rate: 12.040% (536/4452)\n",
      "True negative rate: 99.380% (58185/58548)\n",
      "False positive rate: 0.620% (363/58548)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 46/67: Loss: 0.0365 | Train Acc: 98.573% (63481/64400) | Strict Acc: 83.848% (3857/4600)\n",
      "True positive rate: 87.943% (4019/4570)\n",
      "False negative rate: 12.057% (551/4570)\n",
      "True negative rate: 99.385% (59462/59830)\n",
      "False positive rate: 0.615% (368/59830)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 47/67: Loss: 0.0365 | Train Acc: 98.565% (64856/65800) | Strict Acc: 83.681% (3933/4700)\n",
      "True positive rate: 87.962% (4121/4685)\n",
      "False negative rate: 12.038% (564/4685)\n",
      "True negative rate: 99.378% (60735/61115)\n",
      "False positive rate: 0.622% (380/61115)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 48/67: Loss: 0.0367 | Train Acc: 98.558% (66231/67200) | Strict Acc: 83.583% (4012/4800)\n",
      "True positive rate: 88.054% (4209/4780)\n",
      "False negative rate: 11.946% (571/4780)\n",
      "True negative rate: 99.362% (62022/62420)\n",
      "False positive rate: 0.638% (398/62420)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 49/67: Loss: 0.0370 | Train Acc: 98.545% (67602/68600) | Strict Acc: 83.469% (4090/4900)\n",
      "True positive rate: 88.173% (4309/4887)\n",
      "False negative rate: 11.827% (578/4887)\n",
      "True negative rate: 99.341% (63293/63713)\n",
      "False positive rate: 0.659% (420/63713)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 50/67: Loss: 0.0372 | Train Acc: 98.527% (68969/70000) | Strict Acc: 83.340% (4167/5000)\n",
      "True positive rate: 88.147% (4395/4986)\n",
      "False negative rate: 11.853% (591/4986)\n",
      "True negative rate: 99.323% (64574/65014)\n",
      "False positive rate: 0.677% (440/65014)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 51/67: Loss: 0.0371 | Train Acc: 98.528% (70349/71400) | Strict Acc: 83.392% (4253/5100)\n",
      "True positive rate: 88.172% (4480/5081)\n",
      "False negative rate: 11.828% (601/5081)\n",
      "True negative rate: 99.321% (65869/66319)\n",
      "False positive rate: 0.679% (450/66319)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 52/67: Loss: 0.0370 | Train Acc: 98.530% (71730/72800) | Strict Acc: 83.385% (4336/5200)\n",
      "True positive rate: 88.043% (4543/5160)\n",
      "False negative rate: 11.957% (617/5160)\n",
      "True negative rate: 99.330% (67187/67640)\n",
      "False positive rate: 0.670% (453/67640)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 53/67: Loss: 0.0374 | Train Acc: 98.513% (73097/74200) | Strict Acc: 83.245% (4412/5300)\n",
      "True positive rate: 87.832% (4634/5276)\n",
      "False negative rate: 12.168% (642/5276)\n",
      "True negative rate: 99.331% (68463/68924)\n",
      "False positive rate: 0.669% (461/68924)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 54/67: Loss: 0.0372 | Train Acc: 98.521% (74482/75600) | Strict Acc: 83.315% (4499/5400)\n",
      "True positive rate: 87.838% (4709/5361)\n",
      "False negative rate: 12.162% (652/5361)\n",
      "True negative rate: 99.337% (69773/70239)\n",
      "False positive rate: 0.663% (466/70239)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 55/67: Loss: 0.0375 | Train Acc: 98.509% (75852/77000) | Strict Acc: 83.200% (4576/5500)\n",
      "True positive rate: 87.605% (4785/5462)\n",
      "False negative rate: 12.395% (677/5462)\n",
      "True negative rate: 99.342% (71067/71538)\n",
      "False positive rate: 0.658% (471/71538)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 56/67: Loss: 0.0372 | Train Acc: 98.519% (77239/78400) | Strict Acc: 83.286% (4664/5600)\n",
      "True positive rate: 87.657% (4879/5566)\n",
      "False negative rate: 12.343% (687/5566)\n",
      "True negative rate: 99.349% (72360/72834)\n",
      "False positive rate: 0.651% (474/72834)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 57/67: Loss: 0.0378 | Train Acc: 98.489% (78594/79800) | Strict Acc: 83.000% (4731/5700)\n",
      "True positive rate: 87.339% (4953/5671)\n",
      "False negative rate: 12.661% (718/5671)\n",
      "True negative rate: 99.342% (73641/74129)\n",
      "False positive rate: 0.658% (488/74129)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 58/67: Loss: 0.0378 | Train Acc: 98.490% (79974/81200) | Strict Acc: 83.000% (4814/5800)\n",
      "True positive rate: 87.405% (5052/5780)\n",
      "False negative rate: 12.595% (728/5780)\n",
      "True negative rate: 99.340% (74922/75420)\n",
      "False positive rate: 0.660% (498/75420)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 13 - Batch 59/67: Loss: 0.0381 | Train Acc: 98.475% (81340/82600) | Strict Acc: 82.864% (4889/5900)\n",
      "True positive rate: 87.415% (5154/5896)\n",
      "False negative rate: 12.585% (742/5896)\n",
      "True negative rate: 99.325% (76186/76704)\n",
      "False positive rate: 0.675% (518/76704)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 60/67: Loss: 0.0382 | Train Acc: 98.473% (82717/84000) | Strict Acc: 82.817% (4969/6000)\n",
      "True positive rate: 87.538% (5247/5994)\n",
      "False negative rate: 12.462% (747/5994)\n",
      "True negative rate: 99.313% (77470/78006)\n",
      "False positive rate: 0.687% (536/78006)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 61/67: Loss: 0.0382 | Train Acc: 98.473% (84096/85400) | Strict Acc: 82.820% (5052/6100)\n",
      "True positive rate: 87.664% (5358/6112)\n",
      "False negative rate: 12.336% (754/6112)\n",
      "True negative rate: 99.306% (78738/79288)\n",
      "False positive rate: 0.694% (550/79288)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 62/67: Loss: 0.0385 | Train Acc: 98.468% (85470/86800) | Strict Acc: 82.823% (5135/6200)\n",
      "True positive rate: 87.725% (5460/6224)\n",
      "False negative rate: 12.275% (764/6224)\n",
      "True negative rate: 99.298% (80010/80576)\n",
      "False positive rate: 0.702% (566/80576)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 63/67: Loss: 0.0385 | Train Acc: 98.466% (86847/88200) | Strict Acc: 82.825% (5218/6300)\n",
      "True positive rate: 87.688% (5548/6327)\n",
      "False negative rate: 12.312% (779/6327)\n",
      "True negative rate: 99.299% (81299/81873)\n",
      "False positive rate: 0.701% (574/81873)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 64/67: Loss: 0.0387 | Train Acc: 98.461% (88221/89600) | Strict Acc: 82.781% (5298/6400)\n",
      "True positive rate: 87.578% (5619/6416)\n",
      "False negative rate: 12.422% (797/6416)\n",
      "True negative rate: 99.300% (82602/83184)\n",
      "False positive rate: 0.700% (582/83184)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 65/67: Loss: 0.0391 | Train Acc: 98.446% (89586/91000) | Strict Acc: 82.677% (5374/6500)\n",
      "True positive rate: 87.343% (5693/6518)\n",
      "False negative rate: 12.657% (825/6518)\n",
      "True negative rate: 99.303% (83893/84482)\n",
      "False positive rate: 0.697% (589/84482)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 66/67: Loss: 0.0395 | Train Acc: 98.429% (90948/92400) | Strict Acc: 82.530% (5447/6600)\n",
      "True positive rate: 87.122% (5791/6647)\n",
      "False negative rate: 12.878% (856/6647)\n",
      "True negative rate: 99.305% (85157/85753)\n",
      "False positive rate: 0.695% (596/85753)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 13 - Batch 67/67: Loss: 0.0395 | Train Acc: 98.431% (92287/93758) | Strict Acc: 82.559% (5529/6697)\n",
      "True positive rate: 87.096% (5879/6750)\n",
      "False negative rate: 12.904% (871/6750)\n",
      "True negative rate: 99.310% (86408/87008)\n",
      "False positive rate: 0.690% (600/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.2081 | Dev Acc: 92.331% (84241/91238) | Strict Acc: 38.177% (2488/6517)\n",
      "True positive rate: 42.408% (2790/6579)\n",
      "False negative rate: 57.592% (3789/6579)\n",
      "True negative rate: 96.211% (81451/84659)\n",
      "False positive rate: 3.789% (3208/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 1/67: Loss: 0.0476 | Train Acc: 98.357% (1377/1400) | Strict Acc: 81.000% (81/100)\n",
      "True positive rate: 92.523% (99/107)\n",
      "False negative rate: 7.477% (8/107)\n",
      "True negative rate: 98.840% (1278/1293)\n",
      "False positive rate: 1.160% (15/1293)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 2/67: Loss: 0.0401 | Train Acc: 98.607% (2761/2800) | Strict Acc: 83.500% (167/200)\n",
      "True positive rate: 93.750% (195/208)\n",
      "False negative rate: 6.250% (13/208)\n",
      "True negative rate: 98.997% (2566/2592)\n",
      "False positive rate: 1.003% (26/2592)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 3/67: Loss: 0.0396 | Train Acc: 98.524% (4138/4200) | Strict Acc: 82.667% (248/300)\n",
      "True positive rate: 93.069% (282/303)\n",
      "False negative rate: 6.931% (21/303)\n",
      "True negative rate: 98.948% (3856/3897)\n",
      "False positive rate: 1.052% (41/3897)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 4/67: Loss: 0.0366 | Train Acc: 98.661% (5525/5600) | Strict Acc: 84.250% (337/400)\n",
      "True positive rate: 93.634% (353/377)\n",
      "False negative rate: 6.366% (24/377)\n",
      "True negative rate: 99.024% (5172/5223)\n",
      "False positive rate: 0.976% (51/5223)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 5/67: Loss: 0.0351 | Train Acc: 98.714% (6910/7000) | Strict Acc: 85.200% (426/500)\n",
      "True positive rate: 93.277% (444/476)\n",
      "False negative rate: 6.723% (32/476)\n",
      "True negative rate: 99.111% (6466/6524)\n",
      "False positive rate: 0.889% (58/6524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 6/67: Loss: 0.0344 | Train Acc: 98.667% (8288/8400) | Strict Acc: 84.833% (509/600)\n",
      "True positive rate: 91.740% (522/569)\n",
      "False negative rate: 8.260% (47/569)\n",
      "True negative rate: 99.170% (7766/7831)\n",
      "False positive rate: 0.830% (65/7831)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 7/67: Loss: 0.0386 | Train Acc: 98.541% (9657/9800) | Strict Acc: 84.286% (590/700)\n",
      "True positive rate: 90.071% (635/705)\n",
      "False negative rate: 9.929% (70/705)\n",
      "True negative rate: 99.197% (9022/9095)\n",
      "False positive rate: 0.803% (73/9095)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 8/67: Loss: 0.0388 | Train Acc: 98.509% (11033/11200) | Strict Acc: 84.125% (673/800)\n",
      "True positive rate: 89.000% (712/800)\n",
      "False negative rate: 11.000% (88/800)\n",
      "True negative rate: 99.240% (10321/10400)\n",
      "False positive rate: 0.760% (79/10400)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 9/67: Loss: 0.0386 | Train Acc: 98.524% (12414/12600) | Strict Acc: 84.222% (758/900)\n",
      "True positive rate: 89.210% (802/899)\n",
      "False negative rate: 10.790% (97/899)\n",
      "True negative rate: 99.239% (11612/11701)\n",
      "False positive rate: 0.761% (89/11701)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 10/67: Loss: 0.0377 | Train Acc: 98.564% (13799/14000) | Strict Acc: 84.700% (847/1000)\n",
      "True positive rate: 89.336% (888/994)\n",
      "False negative rate: 10.664% (106/994)\n",
      "True negative rate: 99.270% (12911/13006)\n",
      "False positive rate: 0.730% (95/13006)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 11/67: Loss: 0.0369 | Train Acc: 98.604% (15185/15400) | Strict Acc: 85.000% (935/1100)\n",
      "True positive rate: 89.764% (991/1104)\n",
      "False negative rate: 10.236% (113/1104)\n",
      "True negative rate: 99.287% (14194/14296)\n",
      "False positive rate: 0.713% (102/14296)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 12/67: Loss: 0.0367 | Train Acc: 98.631% (16570/16800) | Strict Acc: 85.167% (1022/1200)\n",
      "True positive rate: 90.133% (1087/1206)\n",
      "False negative rate: 9.867% (119/1206)\n",
      "True negative rate: 99.288% (15483/15594)\n",
      "False positive rate: 0.712% (111/15594)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 13/67: Loss: 0.0371 | Train Acc: 98.604% (17946/18200) | Strict Acc: 84.923% (1104/1300)\n",
      "True positive rate: 90.183% (1185/1314)\n",
      "False negative rate: 9.817% (129/1314)\n",
      "True negative rate: 99.260% (16761/16886)\n",
      "False positive rate: 0.740% (125/16886)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 14/67: Loss: 0.0370 | Train Acc: 98.592% (19324/19600) | Strict Acc: 84.571% (1184/1400)\n",
      "True positive rate: 90.192% (1269/1407)\n",
      "False negative rate: 9.808% (138/1407)\n",
      "True negative rate: 99.241% (18055/18193)\n",
      "False positive rate: 0.759% (138/18193)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 15/67: Loss: 0.0369 | Train Acc: 98.605% (20707/21000) | Strict Acc: 84.600% (1269/1500)\n",
      "True positive rate: 90.271% (1364/1511)\n",
      "False negative rate: 9.729% (147/1511)\n",
      "True negative rate: 99.251% (19343/19489)\n",
      "False positive rate: 0.749% (146/19489)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 16/67: Loss: 0.0369 | Train Acc: 98.589% (22084/22400) | Strict Acc: 84.375% (1350/1600)\n",
      "True positive rate: 89.758% (1446/1611)\n",
      "False negative rate: 10.242% (165/1611)\n",
      "True negative rate: 99.274% (20638/20789)\n",
      "False positive rate: 0.726% (151/20789)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 14 - Batch 17/67: Loss: 0.0382 | Train Acc: 98.525% (23449/23800) | Strict Acc: 84.000% (1428/1700)\n",
      "True positive rate: 89.005% (1530/1719)\n",
      "False negative rate: 10.995% (189/1719)\n",
      "True negative rate: 99.266% (21919/22081)\n",
      "False positive rate: 0.734% (162/22081)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 18/67: Loss: 0.0377 | Train Acc: 98.536% (24831/25200) | Strict Acc: 84.167% (1515/1800)\n",
      "True positive rate: 89.030% (1615/1814)\n",
      "False negative rate: 10.970% (199/1814)\n",
      "True negative rate: 99.273% (23216/23386)\n",
      "False positive rate: 0.727% (170/23386)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 19/67: Loss: 0.0379 | Train Acc: 98.523% (26207/26600) | Strict Acc: 83.895% (1594/1900)\n",
      "True positive rate: 88.825% (1693/1906)\n",
      "False negative rate: 11.175% (213/1906)\n",
      "True negative rate: 99.271% (24514/24694)\n",
      "False positive rate: 0.729% (180/24694)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 20/67: Loss: 0.0387 | Train Acc: 98.496% (27579/28000) | Strict Acc: 83.750% (1675/2000)\n",
      "True positive rate: 88.625% (1792/2022)\n",
      "False negative rate: 11.375% (230/2022)\n",
      "True negative rate: 99.265% (25787/25978)\n",
      "False positive rate: 0.735% (191/25978)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 21/67: Loss: 0.0387 | Train Acc: 98.466% (28949/29400) | Strict Acc: 83.476% (1753/2100)\n",
      "True positive rate: 88.514% (1888/2133)\n",
      "False negative rate: 11.486% (245/2133)\n",
      "True negative rate: 99.245% (27061/27267)\n",
      "False positive rate: 0.755% (206/27267)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 22/67: Loss: 0.0396 | Train Acc: 98.422% (30314/30800) | Strict Acc: 83.000% (1826/2200)\n",
      "True positive rate: 88.332% (1991/2254)\n",
      "False negative rate: 11.668% (263/2254)\n",
      "True negative rate: 99.219% (28323/28546)\n",
      "False positive rate: 0.781% (223/28546)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 23/67: Loss: 0.0393 | Train Acc: 98.429% (31694/32200) | Strict Acc: 83.130% (1912/2300)\n",
      "True positive rate: 88.413% (2083/2356)\n",
      "False negative rate: 11.587% (273/2356)\n",
      "True negative rate: 99.219% (29611/29844)\n",
      "False positive rate: 0.781% (233/29844)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 24/67: Loss: 0.0395 | Train Acc: 98.420% (33069/33600) | Strict Acc: 82.958% (1991/2400)\n",
      "True positive rate: 88.573% (2178/2459)\n",
      "False negative rate: 11.427% (281/2459)\n",
      "True negative rate: 99.197% (30891/31141)\n",
      "False positive rate: 0.803% (250/31141)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 25/67: Loss: 0.0397 | Train Acc: 98.429% (34450/35000) | Strict Acc: 82.960% (2074/2500)\n",
      "True positive rate: 88.707% (2278/2568)\n",
      "False negative rate: 11.293% (290/2568)\n",
      "True negative rate: 99.198% (32172/32432)\n",
      "False positive rate: 0.802% (260/32432)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 26/67: Loss: 0.0393 | Train Acc: 98.448% (35835/36400) | Strict Acc: 83.077% (2160/2600)\n",
      "True positive rate: 88.726% (2361/2661)\n",
      "False negative rate: 11.274% (300/2661)\n",
      "True negative rate: 99.215% (33474/33739)\n",
      "False positive rate: 0.785% (265/33739)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 27/67: Loss: 0.0392 | Train Acc: 98.434% (37208/37800) | Strict Acc: 83.037% (2242/2700)\n",
      "True positive rate: 88.361% (2437/2758)\n",
      "False negative rate: 11.639% (321/2758)\n",
      "True negative rate: 99.227% (34771/35042)\n",
      "False positive rate: 0.773% (271/35042)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 28/67: Loss: 0.0392 | Train Acc: 98.418% (38580/39200) | Strict Acc: 82.929% (2322/2800)\n",
      "True positive rate: 88.157% (2516/2854)\n",
      "False negative rate: 11.843% (338/2854)\n",
      "True negative rate: 99.224% (36064/36346)\n",
      "False positive rate: 0.776% (282/36346)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 29/67: Loss: 0.0391 | Train Acc: 98.421% (39959/40600) | Strict Acc: 82.931% (2405/2900)\n",
      "True positive rate: 88.113% (2587/2936)\n",
      "False negative rate: 11.887% (349/2936)\n",
      "True negative rate: 99.225% (37372/37664)\n",
      "False positive rate: 0.775% (292/37664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 30/67: Loss: 0.0388 | Train Acc: 98.436% (41343/42000) | Strict Acc: 83.000% (2490/3000)\n",
      "True positive rate: 88.146% (2662/3020)\n",
      "False negative rate: 11.854% (358/3020)\n",
      "True negative rate: 99.233% (38681/38980)\n",
      "False positive rate: 0.767% (299/38980)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 31/67: Loss: 0.0387 | Train Acc: 98.435% (42721/43400) | Strict Acc: 83.000% (2573/3100)\n",
      "True positive rate: 88.194% (2749/3117)\n",
      "False negative rate: 11.806% (368/3117)\n",
      "True negative rate: 99.228% (39972/40283)\n",
      "False positive rate: 0.772% (311/40283)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 32/67: Loss: 0.0389 | Train Acc: 98.420% (44092/44800) | Strict Acc: 82.812% (2650/3200)\n",
      "True positive rate: 88.200% (2833/3212)\n",
      "False negative rate: 11.800% (379/3212)\n",
      "True negative rate: 99.209% (41259/41588)\n",
      "False positive rate: 0.791% (329/41588)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 33/67: Loss: 0.0394 | Train Acc: 98.409% (45465/46200) | Strict Acc: 82.727% (2730/3300)\n",
      "True positive rate: 88.008% (2921/3319)\n",
      "False negative rate: 11.992% (398/3319)\n",
      "True negative rate: 99.214% (42544/42881)\n",
      "False positive rate: 0.786% (337/42881)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 34/67: Loss: 0.0392 | Train Acc: 98.426% (46851/47600) | Strict Acc: 82.853% (2817/3400)\n",
      "True positive rate: 88.009% (3002/3411)\n",
      "False negative rate: 11.991% (409/3411)\n",
      "True negative rate: 99.231% (43849/44189)\n",
      "False positive rate: 0.769% (340/44189)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 35/67: Loss: 0.0388 | Train Acc: 98.443% (48237/49000) | Strict Acc: 83.086% (2908/3500)\n",
      "True positive rate: 88.100% (3102/3521)\n",
      "False negative rate: 11.900% (419/3521)\n",
      "True negative rate: 99.244% (45135/45479)\n",
      "False positive rate: 0.756% (344/45479)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 36/67: Loss: 0.0388 | Train Acc: 98.450% (49619/50400) | Strict Acc: 83.139% (2993/3600)\n",
      "True positive rate: 88.187% (3195/3623)\n",
      "False negative rate: 11.813% (428/3623)\n",
      "True negative rate: 99.245% (46424/46777)\n",
      "False positive rate: 0.755% (353/46777)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 37/67: Loss: 0.0383 | Train Acc: 98.473% (51009/51800) | Strict Acc: 83.351% (3084/3700)\n",
      "True positive rate: 88.275% (3275/3710)\n",
      "False negative rate: 11.725% (435/3710)\n",
      "True negative rate: 99.260% (47734/48090)\n",
      "False positive rate: 0.740% (356/48090)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 38/67: Loss: 0.0382 | Train Acc: 98.485% (52394/53200) | Strict Acc: 83.474% (3172/3800)\n",
      "True positive rate: 88.369% (3381/3826)\n",
      "False negative rate: 11.631% (445/3826)\n",
      "True negative rate: 99.269% (49013/49374)\n",
      "False positive rate: 0.731% (361/49374)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 39/67: Loss: 0.0382 | Train Acc: 98.489% (53775/54600) | Strict Acc: 83.538% (3258/3900)\n",
      "True positive rate: 88.447% (3468/3921)\n",
      "False negative rate: 11.553% (453/3921)\n",
      "True negative rate: 99.266% (50307/50679)\n",
      "False positive rate: 0.734% (372/50679)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 40/67: Loss: 0.0379 | Train Acc: 98.489% (55154/56000) | Strict Acc: 83.550% (3342/4000)\n",
      "True positive rate: 88.422% (3559/4025)\n",
      "False negative rate: 11.578% (466/4025)\n",
      "True negative rate: 99.269% (51595/51975)\n",
      "False positive rate: 0.731% (380/51975)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 41/67: Loss: 0.0381 | Train Acc: 98.486% (56531/57400) | Strict Acc: 83.488% (3423/4100)\n",
      "True positive rate: 88.429% (3653/4131)\n",
      "False negative rate: 11.571% (478/4131)\n",
      "True negative rate: 99.266% (52878/53269)\n",
      "False positive rate: 0.734% (391/53269)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 14 - Batch 42/67: Loss: 0.0378 | Train Acc: 98.493% (57914/58800) | Strict Acc: 83.524% (3508/4200)\n",
      "True positive rate: 88.511% (3752/4239)\n",
      "False negative rate: 11.489% (487/4239)\n",
      "True negative rate: 99.269% (54162/54561)\n",
      "False positive rate: 0.731% (399/54561)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 43/67: Loss: 0.0376 | Train Acc: 98.502% (59298/60200) | Strict Acc: 83.628% (3596/4300)\n",
      "True positive rate: 88.564% (3841/4337)\n",
      "False negative rate: 11.436% (496/4337)\n",
      "True negative rate: 99.273% (55457/55863)\n",
      "False positive rate: 0.727% (406/55863)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 44/67: Loss: 0.0376 | Train Acc: 98.500% (60676/61600) | Strict Acc: 83.523% (3675/4400)\n",
      "True positive rate: 88.573% (3930/4437)\n",
      "False negative rate: 11.427% (507/4437)\n",
      "True negative rate: 99.271% (56746/57163)\n",
      "False positive rate: 0.729% (417/57163)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 45/67: Loss: 0.0378 | Train Acc: 98.502% (62056/63000) | Strict Acc: 83.578% (3761/4500)\n",
      "True positive rate: 88.620% (4026/4543)\n",
      "False negative rate: 11.380% (517/4543)\n",
      "True negative rate: 99.270% (58030/58457)\n",
      "False positive rate: 0.730% (427/58457)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 46/67: Loss: 0.0379 | Train Acc: 98.495% (63431/64400) | Strict Acc: 83.543% (3843/4600)\n",
      "True positive rate: 88.575% (4109/4639)\n",
      "False negative rate: 11.425% (530/4639)\n",
      "True negative rate: 99.265% (59322/59761)\n",
      "False positive rate: 0.735% (439/59761)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 47/67: Loss: 0.0384 | Train Acc: 98.476% (64797/65800) | Strict Acc: 83.426% (3921/4700)\n",
      "True positive rate: 88.449% (4204/4753)\n",
      "False negative rate: 11.551% (549/4753)\n",
      "True negative rate: 99.256% (60593/61047)\n",
      "False positive rate: 0.744% (454/61047)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 48/67: Loss: 0.0383 | Train Acc: 98.476% (66176/67200) | Strict Acc: 83.417% (4004/4800)\n",
      "True positive rate: 88.443% (4293/4854)\n",
      "False negative rate: 11.557% (561/4854)\n",
      "True negative rate: 99.257% (61883/62346)\n",
      "False positive rate: 0.743% (463/62346)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 49/67: Loss: 0.0384 | Train Acc: 98.475% (67554/68600) | Strict Acc: 83.408% (4087/4900)\n",
      "True positive rate: 88.436% (4382/4955)\n",
      "False negative rate: 11.564% (573/4955)\n",
      "True negative rate: 99.257% (63172/63645)\n",
      "False positive rate: 0.743% (473/63645)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 50/67: Loss: 0.0384 | Train Acc: 98.479% (68935/70000) | Strict Acc: 83.420% (4171/5000)\n",
      "True positive rate: 88.452% (4450/5031)\n",
      "False negative rate: 11.548% (581/5031)\n",
      "True negative rate: 99.255% (64485/64969)\n",
      "False positive rate: 0.745% (484/64969)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 51/67: Loss: 0.0387 | Train Acc: 98.475% (70311/71400) | Strict Acc: 83.392% (4253/5100)\n",
      "True positive rate: 88.357% (4538/5136)\n",
      "False negative rate: 11.643% (598/5136)\n",
      "True negative rate: 99.259% (65773/66264)\n",
      "False positive rate: 0.741% (491/66264)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 52/67: Loss: 0.0386 | Train Acc: 98.482% (71695/72800) | Strict Acc: 83.462% (4340/5200)\n",
      "True positive rate: 88.451% (4641/5247)\n",
      "False negative rate: 11.549% (606/5247)\n",
      "True negative rate: 99.261% (67054/67553)\n",
      "False positive rate: 0.739% (499/67553)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 53/67: Loss: 0.0388 | Train Acc: 98.478% (73071/74200) | Strict Acc: 83.434% (4422/5300)\n",
      "True positive rate: 88.368% (4733/5356)\n",
      "False negative rate: 11.632% (623/5356)\n",
      "True negative rate: 99.265% (68338/68844)\n",
      "False positive rate: 0.735% (506/68844)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 54/67: Loss: 0.0386 | Train Acc: 98.483% (74453/75600) | Strict Acc: 83.463% (4507/5400)\n",
      "True positive rate: 88.434% (4817/5447)\n",
      "False negative rate: 11.566% (630/5447)\n",
      "True negative rate: 99.263% (69636/70153)\n",
      "False positive rate: 0.737% (517/70153)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 55/67: Loss: 0.0388 | Train Acc: 98.474% (75825/77000) | Strict Acc: 83.327% (4583/5500)\n",
      "True positive rate: 88.360% (4904/5550)\n",
      "False negative rate: 11.640% (646/5550)\n",
      "True negative rate: 99.260% (70921/71450)\n",
      "False positive rate: 0.740% (529/71450)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 56/67: Loss: 0.0389 | Train Acc: 98.476% (77205/78400) | Strict Acc: 83.286% (4664/5600)\n",
      "True positive rate: 88.301% (4989/5650)\n",
      "False negative rate: 11.699% (661/5650)\n",
      "True negative rate: 99.266% (72216/72750)\n",
      "False positive rate: 0.734% (534/72750)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 57/67: Loss: 0.0390 | Train Acc: 98.475% (78583/79800) | Strict Acc: 83.263% (4746/5700)\n",
      "True positive rate: 88.314% (5071/5742)\n",
      "False negative rate: 11.686% (671/5742)\n",
      "True negative rate: 99.263% (73512/74058)\n",
      "False positive rate: 0.737% (546/74058)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 58/67: Loss: 0.0391 | Train Acc: 98.466% (79954/81200) | Strict Acc: 83.190% (4825/5800)\n",
      "True positive rate: 88.236% (5153/5840)\n",
      "False negative rate: 11.764% (687/5840)\n",
      "True negative rate: 99.258% (74801/75360)\n",
      "False positive rate: 0.742% (559/75360)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 59/67: Loss: 0.0390 | Train Acc: 98.462% (81330/82600) | Strict Acc: 83.136% (4905/5900)\n",
      "True positive rate: 88.123% (5231/5936)\n",
      "False negative rate: 11.877% (705/5936)\n",
      "True negative rate: 99.263% (76099/76664)\n",
      "False positive rate: 0.737% (565/76664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 60/67: Loss: 0.0391 | Train Acc: 98.460% (82706/84000) | Strict Acc: 83.100% (4986/6000)\n",
      "True positive rate: 88.040% (5315/6037)\n",
      "False negative rate: 11.960% (722/6037)\n",
      "True negative rate: 99.266% (77391/77963)\n",
      "False positive rate: 0.734% (572/77963)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 61/67: Loss: 0.0390 | Train Acc: 98.466% (84090/85400) | Strict Acc: 83.164% (5073/6100)\n",
      "True positive rate: 88.042% (5397/6130)\n",
      "False negative rate: 11.958% (733/6130)\n",
      "True negative rate: 99.272% (78693/79270)\n",
      "False positive rate: 0.728% (577/79270)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 62/67: Loss: 0.0390 | Train Acc: 98.463% (85466/86800) | Strict Acc: 83.129% (5154/6200)\n",
      "True positive rate: 88.071% (5478/6220)\n",
      "False negative rate: 11.929% (742/6220)\n",
      "True negative rate: 99.265% (79988/80580)\n",
      "False positive rate: 0.735% (592/80580)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 63/67: Loss: 0.0390 | Train Acc: 98.459% (86841/88200) | Strict Acc: 83.079% (5234/6300)\n",
      "True positive rate: 88.115% (5568/6319)\n",
      "False negative rate: 11.885% (751/6319)\n",
      "True negative rate: 99.257% (81273/81881)\n",
      "False positive rate: 0.743% (608/81881)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 64/67: Loss: 0.0392 | Train Acc: 98.452% (88213/89600) | Strict Acc: 83.000% (5312/6400)\n",
      "True positive rate: 88.045% (5671/6441)\n",
      "False negative rate: 11.955% (770/6441)\n",
      "True negative rate: 99.258% (82542/83159)\n",
      "False positive rate: 0.742% (617/83159)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 65/67: Loss: 0.0392 | Train Acc: 98.447% (89587/91000) | Strict Acc: 82.923% (5390/6500)\n",
      "True positive rate: 88.071% (5766/6547)\n",
      "False negative rate: 11.929% (781/6547)\n",
      "True negative rate: 99.252% (83821/84453)\n",
      "False positive rate: 0.748% (632/84453)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 14 - Batch 66/67: Loss: 0.0391 | Train Acc: 98.453% (90971/92400) | Strict Acc: 82.985% (5477/6600)\n",
      "True positive rate: 88.167% (5864/6651)\n",
      "False negative rate: 11.833% (787/6651)\n",
      "True negative rate: 99.251% (85107/85749)\n",
      "False positive rate: 0.749% (642/85749)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 14 - Batch 67/67: Loss: 0.0391 | Train Acc: 98.460% (92314/93758) | Strict Acc: 83.052% (5562/6697)\n",
      "True positive rate: 88.267% (5958/6750)\n",
      "False negative rate: 11.733% (792/6750)\n",
      "True negative rate: 99.251% (86356/87008)\n",
      "False positive rate: 0.749% (652/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1908 | Dev Acc: 93.030% (84879/91238) | Strict Acc: 41.737% (2720/6517)\n",
      "True positive rate: 45.600% (3000/6579)\n",
      "False negative rate: 54.400% (3579/6579)\n",
      "True negative rate: 96.716% (81879/84659)\n",
      "False positive rate: 3.284% (2780/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 1/67: Loss: 0.0438 | Train Acc: 98.071% (1373/1400) | Strict Acc: 82.000% (82/100)\n",
      "True positive rate: 85.417% (82/96)\n",
      "False negative rate: 14.583% (14/96)\n",
      "True negative rate: 99.003% (1291/1304)\n",
      "False positive rate: 0.997% (13/1304)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 2/67: Loss: 0.0365 | Train Acc: 98.571% (2760/2800) | Strict Acc: 85.000% (170/200)\n",
      "True positive rate: 87.755% (172/196)\n",
      "False negative rate: 12.245% (24/196)\n",
      "True negative rate: 99.386% (2588/2604)\n",
      "False positive rate: 0.614% (16/2604)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 3/67: Loss: 0.0314 | Train Acc: 98.810% (4150/4200) | Strict Acc: 86.667% (260/300)\n",
      "True positive rate: 89.667% (269/300)\n",
      "False negative rate: 10.333% (31/300)\n",
      "True negative rate: 99.513% (3881/3900)\n",
      "False positive rate: 0.487% (19/3900)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 4/67: Loss: 0.0315 | Train Acc: 98.804% (5533/5600) | Strict Acc: 86.500% (346/400)\n",
      "True positive rate: 90.263% (343/380)\n",
      "False negative rate: 9.737% (37/380)\n",
      "True negative rate: 99.425% (5190/5220)\n",
      "False positive rate: 0.575% (30/5220)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 5/67: Loss: 0.0302 | Train Acc: 98.886% (6922/7000) | Strict Acc: 87.000% (435/500)\n",
      "True positive rate: 90.289% (437/484)\n",
      "False negative rate: 9.711% (47/484)\n",
      "True negative rate: 99.524% (6485/6516)\n",
      "False positive rate: 0.476% (31/6516)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 6/67: Loss: 0.0314 | Train Acc: 98.833% (8302/8400) | Strict Acc: 86.500% (519/600)\n",
      "True positive rate: 89.212% (521/584)\n",
      "False negative rate: 10.788% (63/584)\n",
      "True negative rate: 99.552% (7781/7816)\n",
      "False positive rate: 0.448% (35/7816)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 7/67: Loss: 0.0305 | Train Acc: 98.827% (9685/9800) | Strict Acc: 86.286% (604/700)\n",
      "True positive rate: 88.791% (602/678)\n",
      "False negative rate: 11.209% (76/678)\n",
      "True negative rate: 99.572% (9083/9122)\n",
      "False positive rate: 0.428% (39/9122)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 8/67: Loss: 0.0307 | Train Acc: 98.821% (11068/11200) | Strict Acc: 86.250% (690/800)\n",
      "True positive rate: 88.491% (692/782)\n",
      "False negative rate: 11.509% (90/782)\n",
      "True negative rate: 99.597% (10376/10418)\n",
      "False positive rate: 0.403% (42/10418)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 9/67: Loss: 0.0308 | Train Acc: 98.786% (12447/12600) | Strict Acc: 86.000% (774/900)\n",
      "True positive rate: 88.222% (779/883)\n",
      "False negative rate: 11.778% (104/883)\n",
      "True negative rate: 99.582% (11668/11717)\n",
      "False positive rate: 0.418% (49/11717)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 10/67: Loss: 0.0325 | Train Acc: 98.736% (13823/14000) | Strict Acc: 85.700% (857/1000)\n",
      "True positive rate: 88.043% (891/1012)\n",
      "False negative rate: 11.957% (121/1012)\n",
      "True negative rate: 99.569% (12932/12988)\n",
      "False positive rate: 0.431% (56/12988)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 11/67: Loss: 0.0333 | Train Acc: 98.688% (15198/15400) | Strict Acc: 85.091% (936/1100)\n",
      "True positive rate: 88.378% (981/1110)\n",
      "False negative rate: 11.622% (129/1110)\n",
      "True negative rate: 99.489% (14217/14290)\n",
      "False positive rate: 0.511% (73/14290)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 12/67: Loss: 0.0338 | Train Acc: 98.679% (16578/16800) | Strict Acc: 85.167% (1022/1200)\n",
      "True positive rate: 88.499% (1085/1226)\n",
      "False negative rate: 11.501% (141/1226)\n",
      "True negative rate: 99.480% (15493/15574)\n",
      "False positive rate: 0.520% (81/15574)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 13/67: Loss: 0.0336 | Train Acc: 98.681% (17960/18200) | Strict Acc: 85.154% (1107/1300)\n",
      "True positive rate: 89.096% (1193/1339)\n",
      "False negative rate: 10.904% (146/1339)\n",
      "True negative rate: 99.443% (16767/16861)\n",
      "False positive rate: 0.557% (94/16861)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 14/67: Loss: 0.0332 | Train Acc: 98.709% (19347/19600) | Strict Acc: 85.286% (1194/1400)\n",
      "True positive rate: 89.686% (1287/1435)\n",
      "False negative rate: 10.314% (148/1435)\n",
      "True negative rate: 99.422% (18060/18165)\n",
      "False positive rate: 0.578% (105/18165)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 15/67: Loss: 0.0333 | Train Acc: 98.676% (20722/21000) | Strict Acc: 85.000% (1275/1500)\n",
      "True positive rate: 89.660% (1370/1528)\n",
      "False negative rate: 10.340% (158/1528)\n",
      "True negative rate: 99.384% (19352/19472)\n",
      "False positive rate: 0.616% (120/19472)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 16/67: Loss: 0.0333 | Train Acc: 98.692% (22107/22400) | Strict Acc: 85.062% (1361/1600)\n",
      "True positive rate: 89.551% (1457/1627)\n",
      "False negative rate: 10.449% (170/1627)\n",
      "True negative rate: 99.408% (20650/20773)\n",
      "False positive rate: 0.592% (123/20773)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 17/67: Loss: 0.0334 | Train Acc: 98.710% (23493/23800) | Strict Acc: 85.235% (1449/1700)\n",
      "True positive rate: 89.486% (1549/1731)\n",
      "False negative rate: 10.514% (182/1731)\n",
      "True negative rate: 99.434% (21944/22069)\n",
      "False positive rate: 0.566% (125/22069)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 18/67: Loss: 0.0331 | Train Acc: 98.718% (24877/25200) | Strict Acc: 85.389% (1537/1800)\n",
      "True positive rate: 89.410% (1638/1832)\n",
      "False negative rate: 10.590% (194/1832)\n",
      "True negative rate: 99.448% (23239/23368)\n",
      "False positive rate: 0.552% (129/23368)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 19/67: Loss: 0.0332 | Train Acc: 98.707% (26256/26600) | Strict Acc: 85.263% (1620/1900)\n",
      "True positive rate: 89.343% (1727/1933)\n",
      "False negative rate: 10.657% (206/1933)\n",
      "True negative rate: 99.441% (24529/24667)\n",
      "False positive rate: 0.559% (138/24667)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 20/67: Loss: 0.0328 | Train Acc: 98.721% (27642/28000) | Strict Acc: 85.300% (1706/2000)\n",
      "True positive rate: 89.419% (1817/2032)\n",
      "False negative rate: 10.581% (215/2032)\n",
      "True negative rate: 99.449% (25825/25968)\n",
      "False positive rate: 0.551% (143/25968)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 21/67: Loss: 0.0333 | Train Acc: 98.687% (29014/29400) | Strict Acc: 85.095% (1787/2100)\n",
      "True positive rate: 89.274% (1906/2135)\n",
      "False negative rate: 10.726% (229/2135)\n",
      "True negative rate: 99.424% (27108/27265)\n",
      "False positive rate: 0.576% (157/27265)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 22/67: Loss: 0.0332 | Train Acc: 98.692% (30397/30800) | Strict Acc: 85.182% (1874/2200)\n",
      "True positive rate: 89.464% (1987/2221)\n",
      "False negative rate: 10.536% (234/2221)\n",
      "True negative rate: 99.409% (28410/28579)\n",
      "False positive rate: 0.591% (169/28579)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 23/67: Loss: 0.0334 | Train Acc: 98.686% (31777/32200) | Strict Acc: 85.043% (1956/2300)\n",
      "True positive rate: 89.494% (2087/2332)\n",
      "False negative rate: 10.506% (245/2332)\n",
      "True negative rate: 99.404% (29690/29868)\n",
      "False positive rate: 0.596% (178/29868)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 24/67: Loss: 0.0335 | Train Acc: 98.685% (33158/33600) | Strict Acc: 84.875% (2037/2400)\n",
      "True positive rate: 89.474% (2159/2413)\n",
      "False negative rate: 10.526% (254/2413)\n",
      "True negative rate: 99.397% (30999/31187)\n",
      "False positive rate: 0.603% (188/31187)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 15 - Batch 25/67: Loss: 0.0335 | Train Acc: 98.677% (34537/35000) | Strict Acc: 84.840% (2121/2500)\n",
      "True positive rate: 89.384% (2248/2515)\n",
      "False negative rate: 10.616% (267/2515)\n",
      "True negative rate: 99.397% (32289/32485)\n",
      "False positive rate: 0.603% (196/32485)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 26/67: Loss: 0.0336 | Train Acc: 98.657% (35911/36400) | Strict Acc: 84.654% (2201/2600)\n",
      "True positive rate: 89.003% (2347/2637)\n",
      "False negative rate: 10.997% (290/2637)\n",
      "True negative rate: 99.411% (33564/33763)\n",
      "False positive rate: 0.589% (199/33763)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 27/67: Loss: 0.0335 | Train Acc: 98.656% (37292/37800) | Strict Acc: 84.556% (2283/2700)\n",
      "True positive rate: 88.974% (2429/2730)\n",
      "False negative rate: 11.026% (301/2730)\n",
      "True negative rate: 99.410% (34863/35070)\n",
      "False positive rate: 0.590% (207/35070)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 28/67: Loss: 0.0331 | Train Acc: 98.684% (38684/39200) | Strict Acc: 84.857% (2376/2800)\n",
      "True positive rate: 89.161% (2509/2814)\n",
      "False negative rate: 10.839% (305/2814)\n",
      "True negative rate: 99.420% (36175/36386)\n",
      "False positive rate: 0.580% (211/36386)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 29/67: Loss: 0.0331 | Train Acc: 98.672% (40061/40600) | Strict Acc: 84.655% (2455/2900)\n",
      "True positive rate: 89.071% (2608/2928)\n",
      "False negative rate: 10.929% (320/2928)\n",
      "True negative rate: 99.419% (37453/37672)\n",
      "False positive rate: 0.581% (219/37672)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 30/67: Loss: 0.0327 | Train Acc: 98.693% (41451/42000) | Strict Acc: 84.900% (2547/3000)\n",
      "True positive rate: 89.269% (2687/3010)\n",
      "False negative rate: 10.731% (323/3010)\n",
      "True negative rate: 99.420% (38764/38990)\n",
      "False positive rate: 0.580% (226/38990)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 31/67: Loss: 0.0326 | Train Acc: 98.700% (42836/43400) | Strict Acc: 84.968% (2634/3100)\n",
      "True positive rate: 89.340% (2774/3105)\n",
      "False negative rate: 10.660% (331/3105)\n",
      "True negative rate: 99.422% (40062/40295)\n",
      "False positive rate: 0.578% (233/40295)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 32/67: Loss: 0.0327 | Train Acc: 98.701% (44218/44800) | Strict Acc: 84.969% (2719/3200)\n",
      "True positive rate: 89.393% (2874/3215)\n",
      "False negative rate: 10.607% (341/3215)\n",
      "True negative rate: 99.420% (41344/41585)\n",
      "False positive rate: 0.580% (241/41585)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 33/67: Loss: 0.0328 | Train Acc: 98.706% (45602/46200) | Strict Acc: 85.061% (2807/3300)\n",
      "True positive rate: 89.477% (2976/3326)\n",
      "False negative rate: 10.523% (350/3326)\n",
      "True negative rate: 99.422% (42626/42874)\n",
      "False positive rate: 0.578% (248/42874)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 34/67: Loss: 0.0328 | Train Acc: 98.714% (46988/47600) | Strict Acc: 85.088% (2893/3400)\n",
      "True positive rate: 89.655% (3068/3422)\n",
      "False negative rate: 10.345% (354/3422)\n",
      "True negative rate: 99.416% (43920/44178)\n",
      "False positive rate: 0.584% (258/44178)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 35/67: Loss: 0.0326 | Train Acc: 98.731% (48378/49000) | Strict Acc: 85.229% (2983/3500)\n",
      "True positive rate: 89.730% (3154/3515)\n",
      "False negative rate: 10.270% (361/3515)\n",
      "True negative rate: 99.426% (45224/45485)\n",
      "False positive rate: 0.574% (261/45485)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 36/67: Loss: 0.0325 | Train Acc: 98.740% (49765/50400) | Strict Acc: 85.333% (3072/3600)\n",
      "True positive rate: 89.794% (3264/3635)\n",
      "False negative rate: 10.206% (371/3635)\n",
      "True negative rate: 99.435% (46501/46765)\n",
      "False positive rate: 0.565% (264/46765)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 37/67: Loss: 0.0327 | Train Acc: 98.726% (51140/51800) | Strict Acc: 85.189% (3152/3700)\n",
      "True positive rate: 89.674% (3361/3748)\n",
      "False negative rate: 10.326% (387/3748)\n",
      "True negative rate: 99.432% (47779/48052)\n",
      "False positive rate: 0.568% (273/48052)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 38/67: Loss: 0.0328 | Train Acc: 98.716% (52517/53200) | Strict Acc: 85.132% (3235/3800)\n",
      "True positive rate: 89.618% (3453/3853)\n",
      "False negative rate: 10.382% (400/3853)\n",
      "True negative rate: 99.427% (49064/49347)\n",
      "False positive rate: 0.573% (283/49347)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 39/67: Loss: 0.0327 | Train Acc: 98.718% (53900/54600) | Strict Acc: 85.179% (3322/3900)\n",
      "True positive rate: 89.679% (3545/3953)\n",
      "False negative rate: 10.321% (408/3953)\n",
      "True negative rate: 99.423% (50355/50647)\n",
      "False positive rate: 0.577% (292/50647)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 40/67: Loss: 0.0327 | Train Acc: 98.718% (55282/56000) | Strict Acc: 85.225% (3409/4000)\n",
      "True positive rate: 89.744% (3614/4027)\n",
      "False negative rate: 10.256% (413/4027)\n",
      "True negative rate: 99.413% (51668/51973)\n",
      "False positive rate: 0.587% (305/51973)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 41/67: Loss: 0.0327 | Train Acc: 98.718% (56664/57400) | Strict Acc: 85.171% (3492/4100)\n",
      "True positive rate: 89.808% (3701/4121)\n",
      "False negative rate: 10.192% (420/4121)\n",
      "True negative rate: 99.407% (52963/53279)\n",
      "False positive rate: 0.593% (316/53279)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 42/67: Loss: 0.0324 | Train Acc: 98.731% (58054/58800) | Strict Acc: 85.310% (3583/4200)\n",
      "True positive rate: 89.866% (3769/4194)\n",
      "False negative rate: 10.134% (425/4194)\n",
      "True negative rate: 99.412% (54285/54606)\n",
      "False positive rate: 0.588% (321/54606)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 43/67: Loss: 0.0327 | Train Acc: 98.726% (59433/60200) | Strict Acc: 85.302% (3668/4300)\n",
      "True positive rate: 89.719% (3857/4299)\n",
      "False negative rate: 10.281% (442/4299)\n",
      "True negative rate: 99.419% (55576/55901)\n",
      "False positive rate: 0.581% (325/55901)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 44/67: Loss: 0.0333 | Train Acc: 98.705% (60802/61600) | Strict Acc: 85.114% (3745/4400)\n",
      "True positive rate: 89.347% (3942/4412)\n",
      "False negative rate: 10.653% (470/4412)\n",
      "True negative rate: 99.426% (56860/57188)\n",
      "False positive rate: 0.574% (328/57188)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 45/67: Loss: 0.0334 | Train Acc: 98.700% (62181/63000) | Strict Acc: 85.044% (3827/4500)\n",
      "True positive rate: 89.153% (4011/4499)\n",
      "False negative rate: 10.847% (488/4499)\n",
      "True negative rate: 99.434% (58170/58501)\n",
      "False positive rate: 0.566% (331/58501)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 46/67: Loss: 0.0334 | Train Acc: 98.702% (63564/64400) | Strict Acc: 85.087% (3914/4600)\n",
      "True positive rate: 89.202% (4114/4612)\n",
      "False negative rate: 10.798% (498/4612)\n",
      "True negative rate: 99.435% (59450/59788)\n",
      "False positive rate: 0.565% (338/59788)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 47/67: Loss: 0.0336 | Train Acc: 98.696% (64942/65800) | Strict Acc: 85.043% (3997/4700)\n",
      "True positive rate: 89.362% (4200/4700)\n",
      "False negative rate: 10.638% (500/4700)\n",
      "True negative rate: 99.414% (60742/61100)\n",
      "False positive rate: 0.586% (358/61100)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 48/67: Loss: 0.0335 | Train Acc: 98.699% (66326/67200) | Strict Acc: 85.042% (4082/4800)\n",
      "True positive rate: 89.584% (4309/4810)\n",
      "False negative rate: 10.416% (501/4810)\n",
      "True negative rate: 99.402% (62017/62390)\n",
      "False positive rate: 0.598% (373/62390)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 49/67: Loss: 0.0336 | Train Acc: 98.691% (67702/68600) | Strict Acc: 84.980% (4164/4900)\n",
      "True positive rate: 89.749% (4395/4897)\n",
      "False negative rate: 10.251% (502/4897)\n",
      "True negative rate: 99.378% (63307/63703)\n",
      "False positive rate: 0.622% (396/63703)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 15 - Batch 50/67: Loss: 0.0337 | Train Acc: 98.694% (69086/70000) | Strict Acc: 85.000% (4250/5000)\n",
      "True positive rate: 89.782% (4490/5001)\n",
      "False negative rate: 10.218% (511/5001)\n",
      "True negative rate: 99.380% (64596/64999)\n",
      "False positive rate: 0.620% (403/64999)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 51/67: Loss: 0.0335 | Train Acc: 98.695% (70468/71400) | Strict Acc: 84.980% (4334/5100)\n",
      "True positive rate: 89.766% (4561/5081)\n",
      "False negative rate: 10.234% (520/5081)\n",
      "True negative rate: 99.379% (65907/66319)\n",
      "False positive rate: 0.621% (412/66319)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 52/67: Loss: 0.0335 | Train Acc: 98.698% (71852/72800) | Strict Acc: 85.058% (4423/5200)\n",
      "True positive rate: 89.701% (4651/5185)\n",
      "False negative rate: 10.299% (534/5185)\n",
      "True negative rate: 99.388% (67201/67615)\n",
      "False positive rate: 0.612% (414/67615)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 53/67: Loss: 0.0336 | Train Acc: 98.690% (73228/74200) | Strict Acc: 84.981% (4504/5300)\n",
      "True positive rate: 89.537% (4741/5295)\n",
      "False negative rate: 10.463% (554/5295)\n",
      "True negative rate: 99.393% (68487/68905)\n",
      "False positive rate: 0.607% (418/68905)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 54/67: Loss: 0.0336 | Train Acc: 98.693% (74612/75600) | Strict Acc: 85.019% (4591/5400)\n",
      "True positive rate: 89.457% (4828/5397)\n",
      "False negative rate: 10.543% (569/5397)\n",
      "True negative rate: 99.403% (69784/70203)\n",
      "False positive rate: 0.597% (419/70203)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 55/67: Loss: 0.0337 | Train Acc: 98.687% (75989/77000) | Strict Acc: 84.945% (4672/5500)\n",
      "True positive rate: 89.299% (4907/5495)\n",
      "False negative rate: 10.701% (588/5495)\n",
      "True negative rate: 99.408% (71082/71505)\n",
      "False positive rate: 0.592% (423/71505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 56/67: Loss: 0.0336 | Train Acc: 98.691% (77374/78400) | Strict Acc: 85.000% (4760/5600)\n",
      "True positive rate: 89.284% (4999/5599)\n",
      "False negative rate: 10.716% (600/5599)\n",
      "True negative rate: 99.415% (72375/72801)\n",
      "False positive rate: 0.585% (426/72801)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 57/67: Loss: 0.0336 | Train Acc: 98.693% (78757/79800) | Strict Acc: 85.018% (4846/5700)\n",
      "True positive rate: 89.280% (5097/5709)\n",
      "False negative rate: 10.720% (612/5709)\n",
      "True negative rate: 99.418% (73660/74091)\n",
      "False positive rate: 0.582% (431/74091)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 58/67: Loss: 0.0335 | Train Acc: 98.696% (80141/81200) | Strict Acc: 85.069% (4934/5800)\n",
      "True positive rate: 89.386% (5196/5813)\n",
      "False negative rate: 10.614% (617/5813)\n",
      "True negative rate: 99.414% (74945/75387)\n",
      "False positive rate: 0.586% (442/75387)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 59/67: Loss: 0.0336 | Train Acc: 98.685% (81514/82600) | Strict Acc: 84.949% (5012/5900)\n",
      "True positive rate: 89.436% (5300/5926)\n",
      "False negative rate: 10.564% (626/5926)\n",
      "True negative rate: 99.400% (76214/76674)\n",
      "False positive rate: 0.600% (460/76674)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 60/67: Loss: 0.0338 | Train Acc: 98.681% (82892/84000) | Strict Acc: 84.883% (5093/6000)\n",
      "True positive rate: 89.513% (5403/6036)\n",
      "False negative rate: 10.487% (633/6036)\n",
      "True negative rate: 99.391% (77489/77964)\n",
      "False positive rate: 0.609% (475/77964)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 61/67: Loss: 0.0339 | Train Acc: 98.671% (84265/85400) | Strict Acc: 84.721% (5168/6100)\n",
      "True positive rate: 89.582% (5512/6153)\n",
      "False negative rate: 10.418% (641/6153)\n",
      "True negative rate: 99.377% (78753/79247)\n",
      "False positive rate: 0.623% (494/79247)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 62/67: Loss: 0.0339 | Train Acc: 98.673% (85648/86800) | Strict Acc: 84.758% (5255/6200)\n",
      "True positive rate: 89.655% (5607/6254)\n",
      "False negative rate: 10.345% (647/6254)\n",
      "True negative rate: 99.373% (80041/80546)\n",
      "False positive rate: 0.627% (505/80546)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 63/67: Loss: 0.0341 | Train Acc: 98.670% (87027/88200) | Strict Acc: 84.730% (5338/6300)\n",
      "True positive rate: 89.653% (5710/6369)\n",
      "False negative rate: 10.347% (659/6369)\n",
      "True negative rate: 99.372% (81317/81831)\n",
      "False positive rate: 0.628% (514/81831)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 64/67: Loss: 0.0340 | Train Acc: 98.674% (88412/89600) | Strict Acc: 84.812% (5428/6400)\n",
      "True positive rate: 89.686% (5800/6467)\n",
      "False negative rate: 10.314% (667/6467)\n",
      "True negative rate: 99.373% (82612/83133)\n",
      "False positive rate: 0.627% (521/83133)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 65/67: Loss: 0.0340 | Train Acc: 98.673% (89792/91000) | Strict Acc: 84.800% (5512/6500)\n",
      "True positive rate: 89.675% (5871/6547)\n",
      "False negative rate: 10.325% (676/6547)\n",
      "True negative rate: 99.370% (83921/84453)\n",
      "False positive rate: 0.630% (532/84453)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 66/67: Loss: 0.0341 | Train Acc: 98.663% (91165/92400) | Strict Acc: 84.773% (5595/6600)\n",
      "True positive rate: 89.520% (5962/6660)\n",
      "False negative rate: 10.480% (698/6660)\n",
      "True negative rate: 99.374% (85203/85740)\n",
      "False positive rate: 0.626% (537/85740)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 15 - Batch 67/67: Loss: 0.0339 | Train Acc: 98.672% (92513/93758) | Strict Acc: 84.859% (5683/6697)\n",
      "True positive rate: 89.570% (6046/6750)\n",
      "False negative rate: 10.430% (704/6750)\n",
      "True negative rate: 99.378% (86467/87008)\n",
      "False positive rate: 0.622% (541/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.1989 | Dev Acc: 93.616% (85413/91238) | Strict Acc: 48.780% (3179/6517)\n",
      "True positive rate: 26.600% (1750/6579)\n",
      "False negative rate: 73.400% (4829/6579)\n",
      "True negative rate: 98.824% (83663/84659)\n",
      "False positive rate: 1.176% (996/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 1/67: Loss: 0.0420 | Train Acc: 98.571% (1380/1400) | Strict Acc: 82.000% (82/100)\n",
      "True positive rate: 84.259% (91/108)\n",
      "False negative rate: 15.741% (17/108)\n",
      "True negative rate: 99.768% (1289/1292)\n",
      "False positive rate: 0.232% (3/1292)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 2/67: Loss: 0.0487 | Train Acc: 98.179% (2749/2800) | Strict Acc: 79.000% (158/200)\n",
      "True positive rate: 82.063% (183/223)\n",
      "False negative rate: 17.937% (40/223)\n",
      "True negative rate: 99.573% (2566/2577)\n",
      "False positive rate: 0.427% (11/2577)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 3/67: Loss: 0.0443 | Train Acc: 98.357% (4131/4200) | Strict Acc: 81.333% (244/300)\n",
      "True positive rate: 84.345% (264/313)\n",
      "False negative rate: 15.655% (49/313)\n",
      "True negative rate: 99.485% (3867/3887)\n",
      "False positive rate: 0.515% (20/3887)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 4/67: Loss: 0.0437 | Train Acc: 98.268% (5503/5600) | Strict Acc: 81.000% (324/400)\n",
      "True positive rate: 86.765% (354/408)\n",
      "False negative rate: 13.235% (54/408)\n",
      "True negative rate: 99.172% (5149/5192)\n",
      "False positive rate: 0.828% (43/5192)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 5/67: Loss: 0.0413 | Train Acc: 98.400% (6888/7000) | Strict Acc: 82.000% (410/500)\n",
      "True positive rate: 88.008% (455/517)\n",
      "False negative rate: 11.992% (62/517)\n",
      "True negative rate: 99.229% (6433/6483)\n",
      "False positive rate: 0.771% (50/6483)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 6/67: Loss: 0.0397 | Train Acc: 98.429% (8268/8400) | Strict Acc: 82.667% (496/600)\n",
      "True positive rate: 88.689% (541/610)\n",
      "False negative rate: 11.311% (69/610)\n",
      "True negative rate: 99.191% (7727/7790)\n",
      "False positive rate: 0.809% (63/7790)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 7/67: Loss: 0.0371 | Train Acc: 98.541% (9657/9800) | Strict Acc: 83.714% (586/700)\n",
      "True positive rate: 89.143% (624/700)\n",
      "False negative rate: 10.857% (76/700)\n",
      "True negative rate: 99.264% (9033/9100)\n",
      "False positive rate: 0.736% (67/9100)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 16 - Batch 8/67: Loss: 0.0365 | Train Acc: 98.571% (11040/11200) | Strict Acc: 84.125% (673/800)\n",
      "True positive rate: 88.889% (712/801)\n",
      "False negative rate: 11.111% (89/801)\n",
      "True negative rate: 99.317% (10328/10399)\n",
      "False positive rate: 0.683% (71/10399)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 9/67: Loss: 0.0344 | Train Acc: 98.643% (12429/12600) | Strict Acc: 84.889% (764/900)\n",
      "True positive rate: 89.266% (790/885)\n",
      "False negative rate: 10.734% (95/885)\n",
      "True negative rate: 99.351% (11639/11715)\n",
      "False positive rate: 0.649% (76/11715)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 10/67: Loss: 0.0339 | Train Acc: 98.664% (13813/14000) | Strict Acc: 85.100% (851/1000)\n",
      "True positive rate: 89.242% (871/976)\n",
      "False negative rate: 10.758% (105/976)\n",
      "True negative rate: 99.370% (12942/13024)\n",
      "False positive rate: 0.630% (82/13024)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 11/67: Loss: 0.0339 | Train Acc: 98.682% (15197/15400) | Strict Acc: 85.273% (938/1100)\n",
      "True positive rate: 88.776% (957/1078)\n",
      "False negative rate: 11.224% (121/1078)\n",
      "True negative rate: 99.427% (14240/14322)\n",
      "False positive rate: 0.573% (82/14322)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 12/67: Loss: 0.0336 | Train Acc: 98.679% (16578/16800) | Strict Acc: 85.167% (1022/1200)\n",
      "True positive rate: 88.917% (1051/1182)\n",
      "False negative rate: 11.083% (131/1182)\n",
      "True negative rate: 99.417% (15527/15618)\n",
      "False positive rate: 0.583% (91/15618)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 13/67: Loss: 0.0335 | Train Acc: 98.681% (17960/18200) | Strict Acc: 85.077% (1106/1300)\n",
      "True positive rate: 89.102% (1161/1303)\n",
      "False negative rate: 10.898% (142/1303)\n",
      "True negative rate: 99.420% (16799/16897)\n",
      "False positive rate: 0.580% (98/16897)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 14/67: Loss: 0.0333 | Train Acc: 98.684% (19342/19600) | Strict Acc: 85.143% (1192/1400)\n",
      "True positive rate: 89.474% (1258/1406)\n",
      "False negative rate: 10.526% (148/1406)\n",
      "True negative rate: 99.395% (18084/18194)\n",
      "False positive rate: 0.605% (110/18194)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 15/67: Loss: 0.0333 | Train Acc: 98.667% (20720/21000) | Strict Acc: 84.933% (1274/1500)\n",
      "True positive rate: 89.432% (1354/1514)\n",
      "False negative rate: 10.568% (160/1514)\n",
      "True negative rate: 99.384% (19366/19486)\n",
      "False positive rate: 0.616% (120/19486)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 16/67: Loss: 0.0330 | Train Acc: 98.705% (22110/22400) | Strict Acc: 85.312% (1365/1600)\n",
      "True positive rate: 89.851% (1452/1616)\n",
      "False negative rate: 10.149% (164/1616)\n",
      "True negative rate: 99.394% (20658/20784)\n",
      "False positive rate: 0.606% (126/20784)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 17/67: Loss: 0.0330 | Train Acc: 98.706% (23492/23800) | Strict Acc: 85.294% (1450/1700)\n",
      "True positive rate: 89.884% (1546/1720)\n",
      "False negative rate: 10.116% (174/1720)\n",
      "True negative rate: 99.393% (21946/22080)\n",
      "False positive rate: 0.607% (134/22080)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 18/67: Loss: 0.0330 | Train Acc: 98.706% (24874/25200) | Strict Acc: 85.278% (1535/1800)\n",
      "True positive rate: 89.761% (1613/1797)\n",
      "False negative rate: 10.239% (184/1797)\n",
      "True negative rate: 99.393% (23261/23403)\n",
      "False positive rate: 0.607% (142/23403)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 19/67: Loss: 0.0322 | Train Acc: 98.744% (26266/26600) | Strict Acc: 85.737% (1629/1900)\n",
      "True positive rate: 90.058% (1703/1891)\n",
      "False negative rate: 9.942% (188/1891)\n",
      "True negative rate: 99.409% (24563/24709)\n",
      "False positive rate: 0.591% (146/24709)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 20/67: Loss: 0.0324 | Train Acc: 98.736% (27646/28000) | Strict Acc: 85.650% (1713/2000)\n",
      "True positive rate: 90.035% (1807/2007)\n",
      "False negative rate: 9.965% (200/2007)\n",
      "True negative rate: 99.408% (25839/25993)\n",
      "False positive rate: 0.592% (154/25993)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 21/67: Loss: 0.0320 | Train Acc: 98.752% (29033/29400) | Strict Acc: 85.714% (1800/2100)\n",
      "True positive rate: 90.110% (1886/2093)\n",
      "False negative rate: 9.890% (207/2093)\n",
      "True negative rate: 99.414% (27147/27307)\n",
      "False positive rate: 0.586% (160/27307)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 22/67: Loss: 0.0315 | Train Acc: 98.766% (30420/30800) | Strict Acc: 86.000% (1892/2200)\n",
      "True positive rate: 90.078% (1952/2167)\n",
      "False negative rate: 9.922% (215/2167)\n",
      "True negative rate: 99.424% (28468/28633)\n",
      "False positive rate: 0.576% (165/28633)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 23/67: Loss: 0.0316 | Train Acc: 98.764% (31802/32200) | Strict Acc: 86.043% (1979/2300)\n",
      "True positive rate: 89.903% (2048/2278)\n",
      "False negative rate: 10.097% (230/2278)\n",
      "True negative rate: 99.439% (29754/29922)\n",
      "False positive rate: 0.561% (168/29922)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 24/67: Loss: 0.0318 | Train Acc: 98.756% (33182/33600) | Strict Acc: 86.000% (2064/2400)\n",
      "True positive rate: 89.500% (2131/2381)\n",
      "False negative rate: 10.500% (250/2381)\n",
      "True negative rate: 99.462% (31051/31219)\n",
      "False positive rate: 0.538% (168/31219)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 25/67: Loss: 0.0320 | Train Acc: 98.743% (34560/35000) | Strict Acc: 85.800% (2145/2500)\n",
      "True positive rate: 89.412% (2221/2484)\n",
      "False negative rate: 10.588% (263/2484)\n",
      "True negative rate: 99.456% (32339/32516)\n",
      "False positive rate: 0.544% (177/32516)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 26/67: Loss: 0.0315 | Train Acc: 98.766% (35951/36400) | Strict Acc: 86.038% (2237/2600)\n",
      "True positive rate: 89.531% (2309/2579)\n",
      "False negative rate: 10.469% (270/2579)\n",
      "True negative rate: 99.471% (33642/33821)\n",
      "False positive rate: 0.529% (179/33821)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 27/67: Loss: 0.0316 | Train Acc: 98.770% (37335/37800) | Strict Acc: 86.074% (2324/2700)\n",
      "True positive rate: 89.662% (2411/2689)\n",
      "False negative rate: 10.338% (278/2689)\n",
      "True negative rate: 99.467% (34924/35111)\n",
      "False positive rate: 0.533% (187/35111)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 28/67: Loss: 0.0313 | Train Acc: 98.786% (38724/39200) | Strict Acc: 86.214% (2414/2800)\n",
      "True positive rate: 90.021% (2535/2816)\n",
      "False negative rate: 9.979% (281/2816)\n",
      "True negative rate: 99.464% (36189/36384)\n",
      "False positive rate: 0.536% (195/36384)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 29/67: Loss: 0.0316 | Train Acc: 98.781% (40105/40600) | Strict Acc: 86.172% (2499/2900)\n",
      "True positive rate: 90.266% (2643/2928)\n",
      "False negative rate: 9.734% (285/2928)\n",
      "True negative rate: 99.443% (37462/37672)\n",
      "False positive rate: 0.557% (210/37672)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 30/67: Loss: 0.0312 | Train Acc: 98.798% (41495/42000) | Strict Acc: 86.300% (2589/3000)\n",
      "True positive rate: 90.511% (2728/3014)\n",
      "False negative rate: 9.489% (286/3014)\n",
      "True negative rate: 99.438% (38767/38986)\n",
      "False positive rate: 0.562% (219/38986)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 31/67: Loss: 0.0310 | Train Acc: 98.806% (42882/43400) | Strict Acc: 86.387% (2678/3100)\n",
      "True positive rate: 90.661% (2825/3116)\n",
      "False negative rate: 9.339% (291/3116)\n",
      "True negative rate: 99.437% (40057/40284)\n",
      "False positive rate: 0.563% (227/40284)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 32/67: Loss: 0.0309 | Train Acc: 98.815% (44269/44800) | Strict Acc: 86.469% (2767/3200)\n",
      "True positive rate: 90.821% (2909/3203)\n",
      "False negative rate: 9.179% (294/3203)\n",
      "True negative rate: 99.430% (41360/41597)\n",
      "False positive rate: 0.570% (237/41597)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 33/67: Loss: 0.0307 | Train Acc: 98.827% (45658/46200) | Strict Acc: 86.545% (2856/3300)\n",
      "True positive rate: 90.868% (3015/3318)\n",
      "False negative rate: 9.132% (303/3318)\n",
      "True negative rate: 99.443% (42643/42882)\n",
      "False positive rate: 0.557% (239/42882)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 16 - Batch 34/67: Loss: 0.0305 | Train Acc: 98.838% (47047/47600) | Strict Acc: 86.676% (2947/3400)\n",
      "True positive rate: 90.954% (3107/3416)\n",
      "False negative rate: 9.046% (309/3416)\n",
      "True negative rate: 99.448% (43940/44184)\n",
      "False positive rate: 0.552% (244/44184)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 35/67: Loss: 0.0305 | Train Acc: 98.839% (48431/49000) | Strict Acc: 86.629% (3032/3500)\n",
      "True positive rate: 90.945% (3224/3545)\n",
      "False negative rate: 9.055% (321/3545)\n",
      "True negative rate: 99.454% (45207/45455)\n",
      "False positive rate: 0.546% (248/45455)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 36/67: Loss: 0.0302 | Train Acc: 98.847% (49819/50400) | Strict Acc: 86.722% (3122/3600)\n",
      "True positive rate: 90.929% (3298/3627)\n",
      "False negative rate: 9.071% (329/3627)\n",
      "True negative rate: 99.461% (46521/46773)\n",
      "False positive rate: 0.539% (252/46773)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 37/67: Loss: 0.0304 | Train Acc: 98.846% (51202/51800) | Strict Acc: 86.649% (3206/3700)\n",
      "True positive rate: 90.853% (3407/3750)\n",
      "False negative rate: 9.147% (343/3750)\n",
      "True negative rate: 99.469% (47795/48050)\n",
      "False positive rate: 0.531% (255/48050)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 38/67: Loss: 0.0301 | Train Acc: 98.861% (52594/53200) | Strict Acc: 86.816% (3299/3800)\n",
      "True positive rate: 90.963% (3503/3851)\n",
      "False negative rate: 9.037% (348/3851)\n",
      "True negative rate: 99.477% (49091/49349)\n",
      "False positive rate: 0.523% (258/49349)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 39/67: Loss: 0.0300 | Train Acc: 98.857% (53976/54600) | Strict Acc: 86.872% (3388/3900)\n",
      "True positive rate: 90.898% (3575/3933)\n",
      "False negative rate: 9.102% (358/3933)\n",
      "True negative rate: 99.475% (50401/50667)\n",
      "False positive rate: 0.525% (266/50667)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 40/67: Loss: 0.0299 | Train Acc: 98.862% (55363/56000) | Strict Acc: 86.900% (3476/4000)\n",
      "True positive rate: 90.927% (3678/4045)\n",
      "False negative rate: 9.073% (367/4045)\n",
      "True negative rate: 99.480% (51685/51955)\n",
      "False positive rate: 0.520% (270/51955)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 41/67: Loss: 0.0298 | Train Acc: 98.868% (56750/57400) | Strict Acc: 86.951% (3565/4100)\n",
      "True positive rate: 90.913% (3772/4149)\n",
      "False negative rate: 9.087% (377/4149)\n",
      "True negative rate: 99.487% (52978/53251)\n",
      "False positive rate: 0.513% (273/53251)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 42/67: Loss: 0.0302 | Train Acc: 98.861% (58130/58800) | Strict Acc: 86.881% (3649/4200)\n",
      "True positive rate: 90.945% (3877/4263)\n",
      "False negative rate: 9.055% (386/4263)\n",
      "True negative rate: 99.479% (54253/54537)\n",
      "False positive rate: 0.521% (284/54537)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 43/67: Loss: 0.0301 | Train Acc: 98.865% (59517/60200) | Strict Acc: 86.884% (3736/4300)\n",
      "True positive rate: 91.009% (3968/4360)\n",
      "False negative rate: 8.991% (392/4360)\n",
      "True negative rate: 99.479% (55549/55840)\n",
      "False positive rate: 0.521% (291/55840)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 44/67: Loss: 0.0301 | Train Acc: 98.869% (60903/61600) | Strict Acc: 86.932% (3825/4400)\n",
      "True positive rate: 91.033% (4061/4461)\n",
      "False negative rate: 8.967% (400/4461)\n",
      "True negative rate: 99.480% (56842/57139)\n",
      "False positive rate: 0.520% (297/57139)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 45/67: Loss: 0.0301 | Train Acc: 98.862% (62283/63000) | Strict Acc: 86.956% (3913/4500)\n",
      "True positive rate: 91.017% (4134/4542)\n",
      "False negative rate: 8.983% (408/4542)\n",
      "True negative rate: 99.471% (58149/58458)\n",
      "False positive rate: 0.529% (309/58458)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 46/67: Loss: 0.0300 | Train Acc: 98.865% (63669/64400) | Strict Acc: 87.000% (4002/4600)\n",
      "True positive rate: 91.035% (4214/4629)\n",
      "False negative rate: 8.965% (415/4629)\n",
      "True negative rate: 99.471% (59455/59771)\n",
      "False positive rate: 0.529% (316/59771)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 47/67: Loss: 0.0300 | Train Acc: 98.868% (65055/65800) | Strict Acc: 87.021% (4090/4700)\n",
      "True positive rate: 90.942% (4277/4703)\n",
      "False negative rate: 9.058% (426/4703)\n",
      "True negative rate: 99.478% (60778/61097)\n",
      "False positive rate: 0.522% (319/61097)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 48/67: Loss: 0.0301 | Train Acc: 98.856% (66431/67200) | Strict Acc: 86.875% (4170/4800)\n",
      "True positive rate: 90.757% (4350/4793)\n",
      "False negative rate: 9.243% (443/4793)\n",
      "True negative rate: 99.478% (62081/62407)\n",
      "False positive rate: 0.522% (326/62407)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 49/67: Loss: 0.0301 | Train Acc: 98.860% (67818/68600) | Strict Acc: 86.898% (4258/4900)\n",
      "True positive rate: 90.764% (4442/4894)\n",
      "False negative rate: 9.236% (452/4894)\n",
      "True negative rate: 99.482% (63376/63706)\n",
      "False positive rate: 0.518% (330/63706)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 50/67: Loss: 0.0300 | Train Acc: 98.864% (69205/70000) | Strict Acc: 86.920% (4346/5000)\n",
      "True positive rate: 90.783% (4521/4980)\n",
      "False negative rate: 9.217% (459/4980)\n",
      "True negative rate: 99.483% (64684/65020)\n",
      "False positive rate: 0.517% (336/65020)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 51/67: Loss: 0.0302 | Train Acc: 98.856% (70583/71400) | Strict Acc: 86.784% (4426/5100)\n",
      "True positive rate: 90.704% (4615/5088)\n",
      "False negative rate: 9.296% (473/5088)\n",
      "True negative rate: 99.481% (65968/66312)\n",
      "False positive rate: 0.519% (344/66312)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 52/67: Loss: 0.0303 | Train Acc: 98.845% (71959/72800) | Strict Acc: 86.692% (4508/5200)\n",
      "True positive rate: 90.722% (4713/5195)\n",
      "False negative rate: 9.278% (482/5195)\n",
      "True negative rate: 99.469% (67246/67605)\n",
      "False positive rate: 0.531% (359/67605)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 53/67: Loss: 0.0303 | Train Acc: 98.842% (73341/74200) | Strict Acc: 86.642% (4592/5300)\n",
      "True positive rate: 90.810% (4812/5299)\n",
      "False negative rate: 9.190% (487/5299)\n",
      "True negative rate: 99.460% (68529/68901)\n",
      "False positive rate: 0.540% (372/68901)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 54/67: Loss: 0.0302 | Train Acc: 98.847% (74728/75600) | Strict Acc: 86.648% (4679/5400)\n",
      "True positive rate: 90.956% (4928/5418)\n",
      "False negative rate: 9.044% (490/5418)\n",
      "True negative rate: 99.456% (69800/70182)\n",
      "False positive rate: 0.544% (382/70182)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 55/67: Loss: 0.0302 | Train Acc: 98.845% (76111/77000) | Strict Acc: 86.618% (4764/5500)\n",
      "True positive rate: 91.021% (5028/5524)\n",
      "False negative rate: 8.979% (496/5524)\n",
      "True negative rate: 99.450% (71083/71476)\n",
      "False positive rate: 0.550% (393/71476)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 56/67: Loss: 0.0301 | Train Acc: 98.847% (77496/78400) | Strict Acc: 86.625% (4851/5600)\n",
      "True positive rate: 91.060% (5103/5604)\n",
      "False negative rate: 8.940% (501/5604)\n",
      "True negative rate: 99.446% (72393/72796)\n",
      "False positive rate: 0.554% (403/72796)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 57/67: Loss: 0.0302 | Train Acc: 98.842% (78876/79800) | Strict Acc: 86.561% (4934/5700)\n",
      "True positive rate: 91.024% (5192/5704)\n",
      "False negative rate: 8.976% (512/5704)\n",
      "True negative rate: 99.444% (73684/74096)\n",
      "False positive rate: 0.556% (412/74096)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 58/67: Loss: 0.0302 | Train Acc: 98.844% (80261/81200) | Strict Acc: 86.586% (5022/5800)\n",
      "True positive rate: 91.030% (5287/5808)\n",
      "False negative rate: 8.970% (521/5808)\n",
      "True negative rate: 99.446% (74974/75392)\n",
      "False positive rate: 0.554% (418/75392)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 59/67: Loss: 0.0301 | Train Acc: 98.851% (81651/82600) | Strict Acc: 86.661% (5113/5900)\n",
      "True positive rate: 91.083% (5393/5921)\n",
      "False negative rate: 8.917% (528/5921)\n",
      "True negative rate: 99.451% (76258/76679)\n",
      "False positive rate: 0.549% (421/76679)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 16 - Batch 60/67: Loss: 0.0300 | Train Acc: 98.860% (83042/84000) | Strict Acc: 86.750% (5205/6000)\n",
      "True positive rate: 91.122% (5481/6015)\n",
      "False negative rate: 8.878% (534/6015)\n",
      "True negative rate: 99.456% (77561/77985)\n",
      "False positive rate: 0.544% (424/77985)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 61/67: Loss: 0.0300 | Train Acc: 98.858% (84425/85400) | Strict Acc: 86.689% (5288/6100)\n",
      "True positive rate: 91.102% (5580/6125)\n",
      "False negative rate: 8.898% (545/6125)\n",
      "True negative rate: 99.458% (78845/79275)\n",
      "False positive rate: 0.542% (430/79275)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 62/67: Loss: 0.0300 | Train Acc: 98.853% (85804/86800) | Strict Acc: 86.613% (5370/6200)\n",
      "True positive rate: 90.988% (5654/6214)\n",
      "False negative rate: 9.012% (560/6214)\n",
      "True negative rate: 99.459% (80150/80586)\n",
      "False positive rate: 0.541% (436/80586)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 63/67: Loss: 0.0302 | Train Acc: 98.844% (87180/88200) | Strict Acc: 86.492% (5449/6300)\n",
      "True positive rate: 90.860% (5726/6302)\n",
      "False negative rate: 9.140% (576/6302)\n",
      "True negative rate: 99.458% (81454/81898)\n",
      "False positive rate: 0.542% (444/81898)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 64/67: Loss: 0.0302 | Train Acc: 98.844% (88564/89600) | Strict Acc: 86.453% (5533/6400)\n",
      "True positive rate: 90.804% (5816/6405)\n",
      "False negative rate: 9.196% (589/6405)\n",
      "True negative rate: 99.463% (82748/83195)\n",
      "False positive rate: 0.537% (447/83195)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 65/67: Loss: 0.0302 | Train Acc: 98.843% (89947/91000) | Strict Acc: 86.462% (5620/6500)\n",
      "True positive rate: 90.788% (5913/6513)\n",
      "False negative rate: 9.212% (600/6513)\n",
      "True negative rate: 99.464% (84034/84487)\n",
      "False positive rate: 0.536% (453/84487)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 66/67: Loss: 0.0304 | Train Acc: 98.837% (91325/92400) | Strict Acc: 86.394% (5702/6600)\n",
      "True positive rate: 90.668% (6014/6633)\n",
      "False negative rate: 9.332% (619/6633)\n",
      "True negative rate: 99.468% (85311/85767)\n",
      "False positive rate: 0.532% (456/85767)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 16 - Batch 67/67: Loss: 0.0304 | Train Acc: 98.838% (92669/93758) | Strict Acc: 86.382% (5785/6697)\n",
      "True positive rate: 90.681% (6121/6750)\n",
      "False negative rate: 9.319% (629/6750)\n",
      "True negative rate: 99.471% (86548/87008)\n",
      "False positive rate: 0.529% (460/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.2438 | Dev Acc: 90.723% (82774/91238) | Strict Acc: 28.265% (1842/6517)\n",
      "True positive rate: 40.492% (2664/6579)\n",
      "False negative rate: 59.508% (3915/6579)\n",
      "True negative rate: 94.627% (80110/84659)\n",
      "False positive rate: 5.373% (4549/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 1/67: Loss: 0.0264 | Train Acc: 98.857% (1384/1400) | Strict Acc: 87.000% (87/100)\n",
      "True positive rate: 94.845% (92/97)\n",
      "False negative rate: 5.155% (5/97)\n",
      "True negative rate: 99.156% (1292/1303)\n",
      "False positive rate: 0.844% (11/1303)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 2/67: Loss: 0.0299 | Train Acc: 98.893% (2769/2800) | Strict Acc: 88.000% (176/200)\n",
      "True positive rate: 95.673% (199/208)\n",
      "False negative rate: 4.327% (9/208)\n",
      "True negative rate: 99.151% (2570/2592)\n",
      "False positive rate: 0.849% (22/2592)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 3/67: Loss: 0.0287 | Train Acc: 98.905% (4154/4200) | Strict Acc: 88.333% (265/300)\n",
      "True positive rate: 95.161% (295/310)\n",
      "False negative rate: 4.839% (15/310)\n",
      "True negative rate: 99.203% (3859/3890)\n",
      "False positive rate: 0.797% (31/3890)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 4/67: Loss: 0.0271 | Train Acc: 98.929% (5540/5600) | Strict Acc: 88.250% (353/400)\n",
      "True positive rate: 94.891% (390/411)\n",
      "False negative rate: 5.109% (21/411)\n",
      "True negative rate: 99.248% (5150/5189)\n",
      "False positive rate: 0.752% (39/5189)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 5/67: Loss: 0.0297 | Train Acc: 98.829% (6918/7000) | Strict Acc: 87.400% (437/500)\n",
      "True positive rate: 95.019% (496/522)\n",
      "False negative rate: 4.981% (26/522)\n",
      "True negative rate: 99.136% (6422/6478)\n",
      "False positive rate: 0.864% (56/6478)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 6/67: Loss: 0.0288 | Train Acc: 98.857% (8304/8400) | Strict Acc: 87.500% (525/600)\n",
      "True positive rate: 94.737% (594/627)\n",
      "False negative rate: 5.263% (33/627)\n",
      "True negative rate: 99.190% (7710/7773)\n",
      "False positive rate: 0.810% (63/7773)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 7/67: Loss: 0.0281 | Train Acc: 98.847% (9687/9800) | Strict Acc: 87.286% (611/700)\n",
      "True positive rate: 94.278% (692/734)\n",
      "False negative rate: 5.722% (42/734)\n",
      "True negative rate: 99.217% (8995/9066)\n",
      "False positive rate: 0.783% (71/9066)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 8/67: Loss: 0.0289 | Train Acc: 98.812% (11067/11200) | Strict Acc: 86.750% (694/800)\n",
      "True positive rate: 93.476% (788/843)\n",
      "False negative rate: 6.524% (55/843)\n",
      "True negative rate: 99.247% (10279/10357)\n",
      "False positive rate: 0.753% (78/10357)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 9/67: Loss: 0.0286 | Train Acc: 98.817% (12451/12600) | Strict Acc: 86.778% (781/900)\n",
      "True positive rate: 93.126% (867/931)\n",
      "False negative rate: 6.874% (64/931)\n",
      "True negative rate: 99.272% (11584/11669)\n",
      "False positive rate: 0.728% (85/11669)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 10/67: Loss: 0.0278 | Train Acc: 98.886% (13844/14000) | Strict Acc: 87.500% (875/1000)\n",
      "True positive rate: 93.455% (971/1039)\n",
      "False negative rate: 6.545% (68/1039)\n",
      "True negative rate: 99.321% (12873/12961)\n",
      "False positive rate: 0.679% (88/12961)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 11/67: Loss: 0.0269 | Train Acc: 98.929% (15235/15400) | Strict Acc: 87.909% (967/1100)\n",
      "True positive rate: 93.673% (1066/1138)\n",
      "False negative rate: 6.327% (72/1138)\n",
      "True negative rate: 99.348% (14169/14262)\n",
      "False positive rate: 0.652% (93/14262)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 12/67: Loss: 0.0291 | Train Acc: 98.810% (16600/16800) | Strict Acc: 86.917% (1043/1200)\n",
      "True positive rate: 92.535% (1190/1286)\n",
      "False negative rate: 7.465% (96/1286)\n",
      "True negative rate: 99.330% (15410/15514)\n",
      "False positive rate: 0.670% (104/15514)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 13/67: Loss: 0.0290 | Train Acc: 98.813% (17984/18200) | Strict Acc: 86.923% (1130/1300)\n",
      "True positive rate: 92.451% (1286/1391)\n",
      "False negative rate: 7.549% (105/1391)\n",
      "True negative rate: 99.340% (16698/16809)\n",
      "False positive rate: 0.660% (111/16809)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 14/67: Loss: 0.0281 | Train Acc: 98.852% (19375/19600) | Strict Acc: 87.286% (1222/1400)\n",
      "True positive rate: 92.814% (1382/1489)\n",
      "False negative rate: 7.186% (107/1489)\n",
      "True negative rate: 99.348% (17993/18111)\n",
      "False positive rate: 0.652% (118/18111)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 15/67: Loss: 0.0281 | Train Acc: 98.857% (20760/21000) | Strict Acc: 87.267% (1309/1500)\n",
      "True positive rate: 92.695% (1472/1588)\n",
      "False negative rate: 7.305% (116/1588)\n",
      "True negative rate: 99.361% (19288/19412)\n",
      "False positive rate: 0.639% (124/19412)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 16/67: Loss: 0.0286 | Train Acc: 98.830% (22138/22400) | Strict Acc: 87.188% (1395/1600)\n",
      "True positive rate: 92.612% (1567/1692)\n",
      "False negative rate: 7.388% (125/1692)\n",
      "True negative rate: 99.338% (20571/20708)\n",
      "False positive rate: 0.662% (137/20708)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 17/67: Loss: 0.0289 | Train Acc: 98.819% (23519/23800) | Strict Acc: 86.941% (1478/1700)\n",
      "True positive rate: 92.766% (1667/1797)\n",
      "False negative rate: 7.234% (130/1797)\n",
      "True negative rate: 99.314% (21852/22003)\n",
      "False positive rate: 0.686% (151/22003)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 17 - Batch 18/67: Loss: 0.0297 | Train Acc: 98.782% (24893/25200) | Strict Acc: 86.667% (1560/1800)\n",
      "True positive rate: 92.646% (1751/1890)\n",
      "False negative rate: 7.354% (139/1890)\n",
      "True negative rate: 99.279% (23142/23310)\n",
      "False positive rate: 0.721% (168/23310)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 19/67: Loss: 0.0295 | Train Acc: 98.797% (26280/26600) | Strict Acc: 86.737% (1648/1900)\n",
      "True positive rate: 92.768% (1860/2005)\n",
      "False negative rate: 7.232% (145/2005)\n",
      "True negative rate: 99.288% (24420/24595)\n",
      "False positive rate: 0.712% (175/24595)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 20/67: Loss: 0.0294 | Train Acc: 98.793% (27662/28000) | Strict Acc: 86.600% (1732/2000)\n",
      "True positive rate: 92.600% (1952/2108)\n",
      "False negative rate: 7.400% (156/2108)\n",
      "True negative rate: 99.297% (25710/25892)\n",
      "False positive rate: 0.703% (182/25892)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 21/67: Loss: 0.0294 | Train Acc: 98.796% (29046/29400) | Strict Acc: 86.667% (1820/2100)\n",
      "True positive rate: 92.283% (2033/2203)\n",
      "False negative rate: 7.717% (170/2203)\n",
      "True negative rate: 99.323% (27013/27197)\n",
      "False positive rate: 0.677% (184/27197)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 22/67: Loss: 0.0296 | Train Acc: 98.786% (30426/30800) | Strict Acc: 86.455% (1902/2200)\n",
      "True positive rate: 92.050% (2119/2302)\n",
      "False negative rate: 7.950% (183/2302)\n",
      "True negative rate: 99.330% (28307/28498)\n",
      "False positive rate: 0.670% (191/28498)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 23/67: Loss: 0.0294 | Train Acc: 98.792% (31811/32200) | Strict Acc: 86.522% (1990/2300)\n",
      "True positive rate: 91.950% (2216/2410)\n",
      "False negative rate: 8.050% (194/2410)\n",
      "True negative rate: 99.345% (29595/29790)\n",
      "False positive rate: 0.655% (195/29790)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 24/67: Loss: 0.0299 | Train Acc: 98.765% (33185/33600) | Strict Acc: 86.250% (2070/2400)\n",
      "True positive rate: 91.723% (2305/2513)\n",
      "False negative rate: 8.277% (208/2513)\n",
      "True negative rate: 99.334% (30880/31087)\n",
      "False positive rate: 0.666% (207/31087)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 25/67: Loss: 0.0298 | Train Acc: 98.771% (34570/35000) | Strict Acc: 86.240% (2156/2500)\n",
      "True positive rate: 91.632% (2398/2617)\n",
      "False negative rate: 8.368% (219/2617)\n",
      "True negative rate: 99.348% (32172/32383)\n",
      "False positive rate: 0.652% (211/32383)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 26/67: Loss: 0.0293 | Train Acc: 98.802% (35964/36400) | Strict Acc: 86.538% (2250/2600)\n",
      "True positive rate: 91.830% (2484/2705)\n",
      "False negative rate: 8.170% (221/2705)\n",
      "True negative rate: 99.362% (33480/33695)\n",
      "False positive rate: 0.638% (215/33695)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 27/67: Loss: 0.0296 | Train Acc: 98.794% (37344/37800) | Strict Acc: 86.444% (2334/2700)\n",
      "True positive rate: 91.770% (2587/2819)\n",
      "False negative rate: 8.230% (232/2819)\n",
      "True negative rate: 99.360% (34757/34981)\n",
      "False positive rate: 0.640% (224/34981)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 28/67: Loss: 0.0296 | Train Acc: 98.796% (38728/39200) | Strict Acc: 86.429% (2420/2800)\n",
      "True positive rate: 91.868% (2666/2902)\n",
      "False negative rate: 8.132% (236/2902)\n",
      "True negative rate: 99.350% (36062/36298)\n",
      "False positive rate: 0.650% (236/36298)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 29/67: Loss: 0.0297 | Train Acc: 98.800% (40113/40600) | Strict Acc: 86.379% (2505/2900)\n",
      "True positive rate: 91.858% (2764/3009)\n",
      "False negative rate: 8.142% (245/3009)\n",
      "True negative rate: 99.356% (37349/37591)\n",
      "False positive rate: 0.644% (242/37591)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 30/67: Loss: 0.0299 | Train Acc: 98.795% (41494/42000) | Strict Acc: 86.333% (2590/3000)\n",
      "True positive rate: 91.932% (2860/3111)\n",
      "False negative rate: 8.068% (251/3111)\n",
      "True negative rate: 99.344% (38634/38889)\n",
      "False positive rate: 0.656% (255/38889)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 31/67: Loss: 0.0299 | Train Acc: 98.806% (42882/43400) | Strict Acc: 86.419% (2679/3100)\n",
      "True positive rate: 92.002% (2968/3226)\n",
      "False negative rate: 7.998% (258/3226)\n",
      "True negative rate: 99.353% (39914/40174)\n",
      "False positive rate: 0.647% (260/40174)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 32/67: Loss: 0.0300 | Train Acc: 98.801% (44263/44800) | Strict Acc: 86.438% (2766/3200)\n",
      "True positive rate: 91.824% (3055/3327)\n",
      "False negative rate: 8.176% (272/3327)\n",
      "True negative rate: 99.361% (41208/41473)\n",
      "False positive rate: 0.639% (265/41473)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 33/67: Loss: 0.0300 | Train Acc: 98.799% (45645/46200) | Strict Acc: 86.333% (2849/3300)\n",
      "True positive rate: 91.836% (3161/3442)\n",
      "False negative rate: 8.164% (281/3442)\n",
      "True negative rate: 99.359% (42484/42758)\n",
      "False positive rate: 0.641% (274/42758)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 34/67: Loss: 0.0298 | Train Acc: 98.798% (47028/47600) | Strict Acc: 86.412% (2938/3400)\n",
      "True positive rate: 91.822% (3245/3534)\n",
      "False negative rate: 8.178% (289/3534)\n",
      "True negative rate: 99.358% (43783/44066)\n",
      "False positive rate: 0.642% (283/44066)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 35/67: Loss: 0.0299 | Train Acc: 98.794% (48409/49000) | Strict Acc: 86.343% (3022/3500)\n",
      "True positive rate: 91.878% (3337/3632)\n",
      "False negative rate: 8.122% (295/3632)\n",
      "True negative rate: 99.348% (45072/45368)\n",
      "False positive rate: 0.652% (296/45368)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 36/67: Loss: 0.0299 | Train Acc: 98.796% (49793/50400) | Strict Acc: 86.333% (3108/3600)\n",
      "True positive rate: 91.861% (3431/3735)\n",
      "False negative rate: 8.139% (304/3735)\n",
      "True negative rate: 99.351% (46362/46665)\n",
      "False positive rate: 0.649% (303/46665)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 37/67: Loss: 0.0297 | Train Acc: 98.795% (51176/51800) | Strict Acc: 86.324% (3194/3700)\n",
      "True positive rate: 91.857% (3497/3807)\n",
      "False negative rate: 8.143% (310/3807)\n",
      "True negative rate: 99.346% (47679/47993)\n",
      "False positive rate: 0.654% (314/47993)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 38/67: Loss: 0.0298 | Train Acc: 98.793% (52558/53200) | Strict Acc: 86.342% (3281/3800)\n",
      "True positive rate: 91.741% (3588/3911)\n",
      "False negative rate: 8.259% (323/3911)\n",
      "True negative rate: 99.353% (48970/49289)\n",
      "False positive rate: 0.647% (319/49289)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 39/67: Loss: 0.0295 | Train Acc: 98.806% (53948/54600) | Strict Acc: 86.462% (3372/3900)\n",
      "True positive rate: 91.762% (3676/4006)\n",
      "False negative rate: 8.238% (330/4006)\n",
      "True negative rate: 99.364% (50272/50594)\n",
      "False positive rate: 0.636% (322/50594)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 40/67: Loss: 0.0295 | Train Acc: 98.805% (55331/56000) | Strict Acc: 86.525% (3461/4000)\n",
      "True positive rate: 91.640% (3749/4091)\n",
      "False negative rate: 8.360% (342/4091)\n",
      "True negative rate: 99.370% (51582/51909)\n",
      "False positive rate: 0.630% (327/51909)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 41/67: Loss: 0.0294 | Train Acc: 98.815% (56720/57400) | Strict Acc: 86.659% (3553/4100)\n",
      "True positive rate: 91.621% (3838/4189)\n",
      "False negative rate: 8.379% (351/4189)\n",
      "True negative rate: 99.382% (52882/53211)\n",
      "False positive rate: 0.618% (329/53211)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 42/67: Loss: 0.0294 | Train Acc: 98.818% (58105/58800) | Strict Acc: 86.690% (3641/4200)\n",
      "True positive rate: 91.593% (3922/4282)\n",
      "False negative rate: 8.407% (360/4282)\n",
      "True negative rate: 99.386% (54183/54518)\n",
      "False positive rate: 0.614% (335/54518)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 43/67: Loss: 0.0292 | Train Acc: 98.829% (59495/60200) | Strict Acc: 86.791% (3732/4300)\n",
      "True positive rate: 91.684% (4024/4389)\n",
      "False negative rate: 8.316% (365/4389)\n",
      "True negative rate: 99.391% (55471/55811)\n",
      "False positive rate: 0.609% (340/55811)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 17 - Batch 44/67: Loss: 0.0292 | Train Acc: 98.825% (60876/61600) | Strict Acc: 86.773% (3818/4400)\n",
      "True positive rate: 91.628% (4115/4491)\n",
      "False negative rate: 8.372% (376/4491)\n",
      "True negative rate: 99.391% (56761/57109)\n",
      "False positive rate: 0.609% (348/57109)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 45/67: Loss: 0.0293 | Train Acc: 98.821% (62257/63000) | Strict Acc: 86.711% (3902/4500)\n",
      "True positive rate: 91.547% (4202/4590)\n",
      "False negative rate: 8.453% (388/4590)\n",
      "True negative rate: 99.392% (58055/58410)\n",
      "False positive rate: 0.608% (355/58410)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 46/67: Loss: 0.0293 | Train Acc: 98.818% (63639/64400) | Strict Acc: 86.717% (3989/4600)\n",
      "True positive rate: 91.526% (4277/4673)\n",
      "False negative rate: 8.474% (396/4673)\n",
      "True negative rate: 99.389% (59362/59727)\n",
      "False positive rate: 0.611% (365/59727)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 47/67: Loss: 0.0291 | Train Acc: 98.824% (65026/65800) | Strict Acc: 86.787% (4079/4700)\n",
      "True positive rate: 91.560% (4350/4751)\n",
      "False negative rate: 8.440% (401/4751)\n",
      "True negative rate: 99.389% (60676/61049)\n",
      "False positive rate: 0.611% (373/61049)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 48/67: Loss: 0.0292 | Train Acc: 98.821% (66408/67200) | Strict Acc: 86.771% (4165/4800)\n",
      "True positive rate: 91.541% (4448/4859)\n",
      "False negative rate: 8.459% (411/4859)\n",
      "True negative rate: 99.389% (61960/62341)\n",
      "False positive rate: 0.611% (381/62341)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 49/67: Loss: 0.0290 | Train Acc: 98.832% (67799/68600) | Strict Acc: 86.857% (4256/4900)\n",
      "True positive rate: 91.628% (4542/4957)\n",
      "False negative rate: 8.372% (415/4957)\n",
      "True negative rate: 99.393% (63257/63643)\n",
      "False positive rate: 0.607% (386/63643)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 50/67: Loss: 0.0288 | Train Acc: 98.844% (69191/70000) | Strict Acc: 87.000% (4350/5000)\n",
      "True positive rate: 91.700% (4629/5048)\n",
      "False negative rate: 8.300% (419/5048)\n",
      "True negative rate: 99.400% (64562/64952)\n",
      "False positive rate: 0.600% (390/64952)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 51/67: Loss: 0.0285 | Train Acc: 98.857% (70584/71400) | Strict Acc: 87.137% (4444/5100)\n",
      "True positive rate: 91.710% (4713/5139)\n",
      "False negative rate: 8.290% (426/5139)\n",
      "True negative rate: 99.411% (65871/66261)\n",
      "False positive rate: 0.589% (390/66261)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 52/67: Loss: 0.0283 | Train Acc: 98.861% (71971/72800) | Strict Acc: 87.154% (4532/5200)\n",
      "True positive rate: 91.691% (4800/5235)\n",
      "False negative rate: 8.309% (435/5235)\n",
      "True negative rate: 99.417% (67171/67565)\n",
      "False positive rate: 0.583% (394/67565)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 53/67: Loss: 0.0283 | Train Acc: 98.861% (73355/74200) | Strict Acc: 87.151% (4619/5300)\n",
      "True positive rate: 91.637% (4887/5333)\n",
      "False negative rate: 8.363% (446/5333)\n",
      "True negative rate: 99.421% (68468/68867)\n",
      "False positive rate: 0.579% (399/68867)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 54/67: Loss: 0.0282 | Train Acc: 98.866% (74743/75600) | Strict Acc: 87.167% (4707/5400)\n",
      "True positive rate: 91.653% (4996/5451)\n",
      "False negative rate: 8.347% (455/5451)\n",
      "True negative rate: 99.427% (69747/70149)\n",
      "False positive rate: 0.573% (402/70149)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 55/67: Loss: 0.0279 | Train Acc: 98.881% (76138/77000) | Strict Acc: 87.327% (4803/5500)\n",
      "True positive rate: 91.742% (5088/5546)\n",
      "False negative rate: 8.258% (458/5546)\n",
      "True negative rate: 99.435% (71050/71454)\n",
      "False positive rate: 0.565% (404/71454)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 56/67: Loss: 0.0277 | Train Acc: 98.886% (77527/78400) | Strict Acc: 87.429% (4896/5600)\n",
      "True positive rate: 91.797% (5170/5632)\n",
      "False negative rate: 8.203% (462/5632)\n",
      "True negative rate: 99.435% (72357/72768)\n",
      "False positive rate: 0.565% (411/72768)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 57/67: Loss: 0.0279 | Train Acc: 98.882% (78908/79800) | Strict Acc: 87.368% (4980/5700)\n",
      "True positive rate: 91.746% (5269/5743)\n",
      "False negative rate: 8.254% (474/5743)\n",
      "True negative rate: 99.436% (73639/74057)\n",
      "False positive rate: 0.564% (418/74057)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 58/67: Loss: 0.0278 | Train Acc: 98.888% (80297/81200) | Strict Acc: 87.431% (5071/5800)\n",
      "True positive rate: 91.808% (5357/5835)\n",
      "False negative rate: 8.192% (478/5835)\n",
      "True negative rate: 99.436% (74940/75365)\n",
      "False positive rate: 0.564% (425/75365)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 59/67: Loss: 0.0278 | Train Acc: 98.883% (81677/82600) | Strict Acc: 87.373% (5155/5900)\n",
      "True positive rate: 91.783% (5451/5939)\n",
      "False negative rate: 8.217% (488/5939)\n",
      "True negative rate: 99.433% (76226/76661)\n",
      "False positive rate: 0.567% (435/76661)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 60/67: Loss: 0.0279 | Train Acc: 98.881% (83060/84000) | Strict Acc: 87.333% (5240/6000)\n",
      "True positive rate: 91.781% (5539/6035)\n",
      "False negative rate: 8.219% (496/6035)\n",
      "True negative rate: 99.431% (77521/77965)\n",
      "False positive rate: 0.569% (444/77965)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 61/67: Loss: 0.0278 | Train Acc: 98.883% (84446/85400) | Strict Acc: 87.328% (5327/6100)\n",
      "True positive rate: 91.827% (5618/6118)\n",
      "False negative rate: 8.173% (500/6118)\n",
      "True negative rate: 99.427% (78828/79282)\n",
      "False positive rate: 0.573% (454/79282)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 62/67: Loss: 0.0278 | Train Acc: 98.874% (85823/86800) | Strict Acc: 87.226% (5408/6200)\n",
      "True positive rate: 91.754% (5708/6221)\n",
      "False negative rate: 8.246% (513/6221)\n",
      "True negative rate: 99.424% (80115/80579)\n",
      "False positive rate: 0.576% (464/80579)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 63/67: Loss: 0.0280 | Train Acc: 98.868% (87202/88200) | Strict Acc: 87.159% (5491/6300)\n",
      "True positive rate: 91.635% (5784/6312)\n",
      "False negative rate: 8.365% (528/6312)\n",
      "True negative rate: 99.426% (81418/81888)\n",
      "False positive rate: 0.574% (470/81888)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 64/67: Loss: 0.0282 | Train Acc: 98.862% (88580/89600) | Strict Acc: 87.078% (5573/6400)\n",
      "True positive rate: 91.524% (5885/6430)\n",
      "False negative rate: 8.476% (545/6430)\n",
      "True negative rate: 99.429% (82695/83170)\n",
      "False positive rate: 0.571% (475/83170)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 65/67: Loss: 0.0283 | Train Acc: 98.858% (89961/91000) | Strict Acc: 87.031% (5657/6500)\n",
      "True positive rate: 91.466% (5991/6550)\n",
      "False negative rate: 8.534% (559/6550)\n",
      "True negative rate: 99.432% (83970/84450)\n",
      "False positive rate: 0.568% (480/84450)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 66/67: Loss: 0.0283 | Train Acc: 98.858% (91345/92400) | Strict Acc: 87.015% (5743/6600)\n",
      "True positive rate: 91.454% (6089/6658)\n",
      "False negative rate: 8.546% (569/6658)\n",
      "True negative rate: 99.433% (85256/85742)\n",
      "False positive rate: 0.567% (486/85742)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 17 - Batch 67/67: Loss: 0.0285 | Train Acc: 98.858% (92687/93758) | Strict Acc: 87.039% (5829/6697)\n",
      "True positive rate: 91.467% (6174/6750)\n",
      "False negative rate: 8.533% (576/6750)\n",
      "True negative rate: 99.431% (86513/87008)\n",
      "False positive rate: 0.569% (495/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.2394 | Dev Acc: 90.790% (82835/91238) | Strict Acc: 27.697% (1805/6517)\n",
      "True positive rate: 46.740% (3075/6579)\n",
      "False negative rate: 53.260% (3504/6579)\n",
      "True negative rate: 94.213% (79760/84659)\n",
      "False positive rate: 5.787% (4899/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 1/67: Loss: 0.0209 | Train Acc: 99.286% (1390/1400) | Strict Acc: 91.000% (91/100)\n",
      "True positive rate: 95.181% (79/83)\n",
      "False negative rate: 4.819% (4/83)\n",
      "True negative rate: 99.544% (1311/1317)\n",
      "False positive rate: 0.456% (6/1317)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 18 - Batch 2/67: Loss: 0.0227 | Train Acc: 99.286% (2780/2800) | Strict Acc: 91.500% (183/200)\n",
      "True positive rate: 96.410% (188/195)\n",
      "False negative rate: 3.590% (7/195)\n",
      "True negative rate: 99.501% (2592/2605)\n",
      "False positive rate: 0.499% (13/2605)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 3/67: Loss: 0.0229 | Train Acc: 99.167% (4165/4200) | Strict Acc: 90.333% (271/300)\n",
      "True positive rate: 96.479% (274/284)\n",
      "False negative rate: 3.521% (10/284)\n",
      "True negative rate: 99.362% (3891/3916)\n",
      "False positive rate: 0.638% (25/3916)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 4/67: Loss: 0.0232 | Train Acc: 99.179% (5554/5600) | Strict Acc: 90.500% (362/400)\n",
      "True positive rate: 96.354% (370/384)\n",
      "False negative rate: 3.646% (14/384)\n",
      "True negative rate: 99.387% (5184/5216)\n",
      "False positive rate: 0.613% (32/5216)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 5/67: Loss: 0.0215 | Train Acc: 99.214% (6945/7000) | Strict Acc: 90.800% (454/500)\n",
      "True positive rate: 95.652% (462/483)\n",
      "False negative rate: 4.348% (21/483)\n",
      "True negative rate: 99.478% (6483/6517)\n",
      "False positive rate: 0.522% (34/6517)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 6/67: Loss: 0.0212 | Train Acc: 99.190% (8332/8400) | Strict Acc: 90.667% (544/600)\n",
      "True positive rate: 94.737% (558/589)\n",
      "False negative rate: 5.263% (31/589)\n",
      "True negative rate: 99.526% (7774/7811)\n",
      "False positive rate: 0.474% (37/7811)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 7/67: Loss: 0.0222 | Train Acc: 99.173% (9719/9800) | Strict Acc: 90.857% (636/700)\n",
      "True positive rate: 94.388% (656/695)\n",
      "False negative rate: 5.612% (39/695)\n",
      "True negative rate: 99.539% (9063/9105)\n",
      "False positive rate: 0.461% (42/9105)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 8/67: Loss: 0.0223 | Train Acc: 99.161% (11106/11200) | Strict Acc: 91.000% (728/800)\n",
      "True positive rate: 94.020% (739/786)\n",
      "False negative rate: 5.980% (47/786)\n",
      "True negative rate: 99.549% (10367/10414)\n",
      "False positive rate: 0.451% (47/10414)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 9/67: Loss: 0.0219 | Train Acc: 99.143% (12492/12600) | Strict Acc: 90.778% (817/900)\n",
      "True positive rate: 93.588% (832/889)\n",
      "False negative rate: 6.412% (57/889)\n",
      "True negative rate: 99.565% (11660/11711)\n",
      "False positive rate: 0.435% (51/11711)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 10/67: Loss: 0.0210 | Train Acc: 99.186% (13886/14000) | Strict Acc: 91.100% (911/1000)\n",
      "True positive rate: 93.927% (928/988)\n",
      "False negative rate: 6.073% (60/988)\n",
      "True negative rate: 99.585% (12958/13012)\n",
      "False positive rate: 0.415% (54/13012)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 11/67: Loss: 0.0214 | Train Acc: 99.195% (15276/15400) | Strict Acc: 91.000% (1001/1100)\n",
      "True positive rate: 93.965% (1012/1077)\n",
      "False negative rate: 6.035% (65/1077)\n",
      "True negative rate: 99.588% (14264/14323)\n",
      "False positive rate: 0.412% (59/14323)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 12/67: Loss: 0.0217 | Train Acc: 99.190% (16664/16800) | Strict Acc: 90.917% (1091/1200)\n",
      "True positive rate: 93.952% (1103/1174)\n",
      "False negative rate: 6.048% (71/1174)\n",
      "True negative rate: 99.584% (15561/15626)\n",
      "False positive rate: 0.416% (65/15626)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 13/67: Loss: 0.0220 | Train Acc: 99.203% (18055/18200) | Strict Acc: 91.000% (1183/1300)\n",
      "True positive rate: 94.026% (1212/1289)\n",
      "False negative rate: 5.974% (77/1289)\n",
      "True negative rate: 99.598% (16843/16911)\n",
      "False positive rate: 0.402% (68/16911)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 14/67: Loss: 0.0225 | Train Acc: 99.179% (19439/19600) | Strict Acc: 90.571% (1268/1400)\n",
      "True positive rate: 93.935% (1332/1418)\n",
      "False negative rate: 6.065% (86/1418)\n",
      "True negative rate: 99.588% (18107/18182)\n",
      "False positive rate: 0.412% (75/18182)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 15/67: Loss: 0.0225 | Train Acc: 99.176% (20827/21000) | Strict Acc: 90.400% (1356/1500)\n",
      "True positive rate: 93.902% (1432/1525)\n",
      "False negative rate: 6.098% (93/1525)\n",
      "True negative rate: 99.589% (19395/19475)\n",
      "False positive rate: 0.411% (80/19475)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 16/67: Loss: 0.0224 | Train Acc: 99.170% (22214/22400) | Strict Acc: 90.312% (1445/1600)\n",
      "True positive rate: 93.861% (1529/1629)\n",
      "False negative rate: 6.139% (100/1629)\n",
      "True negative rate: 99.586% (20685/20771)\n",
      "False positive rate: 0.414% (86/20771)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 17/67: Loss: 0.0227 | Train Acc: 99.164% (23601/23800) | Strict Acc: 90.235% (1534/1700)\n",
      "True positive rate: 93.797% (1633/1741)\n",
      "False negative rate: 6.203% (108/1741)\n",
      "True negative rate: 99.587% (21968/22059)\n",
      "False positive rate: 0.413% (91/22059)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 18/67: Loss: 0.0224 | Train Acc: 99.175% (24992/25200) | Strict Acc: 90.278% (1625/1800)\n",
      "True positive rate: 93.814% (1729/1843)\n",
      "False negative rate: 6.186% (114/1843)\n",
      "True negative rate: 99.598% (23263/23357)\n",
      "False positive rate: 0.402% (94/23357)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 19/67: Loss: 0.0221 | Train Acc: 99.188% (26384/26600) | Strict Acc: 90.421% (1718/1900)\n",
      "True positive rate: 93.987% (1860/1979)\n",
      "False negative rate: 6.013% (119/1979)\n",
      "True negative rate: 99.606% (24524/24621)\n",
      "False positive rate: 0.394% (97/24621)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 20/67: Loss: 0.0221 | Train Acc: 99.193% (27774/28000) | Strict Acc: 90.450% (1809/2000)\n",
      "True positive rate: 93.905% (1972/2100)\n",
      "False negative rate: 6.095% (128/2100)\n",
      "True negative rate: 99.622% (25802/25900)\n",
      "False positive rate: 0.378% (98/25900)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 21/67: Loss: 0.0221 | Train Acc: 99.190% (29162/29400) | Strict Acc: 90.381% (1898/2100)\n",
      "True positive rate: 93.905% (2049/2182)\n",
      "False negative rate: 6.095% (133/2182)\n",
      "True negative rate: 99.614% (27113/27218)\n",
      "False positive rate: 0.386% (105/27218)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 22/67: Loss: 0.0220 | Train Acc: 99.205% (30555/30800) | Strict Acc: 90.500% (1991/2200)\n",
      "True positive rate: 94.074% (2159/2295)\n",
      "False negative rate: 5.926% (136/2295)\n",
      "True negative rate: 99.618% (28396/28505)\n",
      "False positive rate: 0.382% (109/28505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 23/67: Loss: 0.0221 | Train Acc: 99.189% (31939/32200) | Strict Acc: 90.304% (2077/2300)\n",
      "True positive rate: 94.027% (2251/2394)\n",
      "False negative rate: 5.973% (143/2394)\n",
      "True negative rate: 99.604% (29688/29806)\n",
      "False positive rate: 0.396% (118/29806)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 24/67: Loss: 0.0218 | Train Acc: 99.196% (33330/33600) | Strict Acc: 90.375% (2169/2400)\n",
      "True positive rate: 94.057% (2358/2507)\n",
      "False negative rate: 5.943% (149/2507)\n",
      "True negative rate: 99.611% (30972/31093)\n",
      "False positive rate: 0.389% (121/31093)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 25/67: Loss: 0.0218 | Train Acc: 99.200% (34720/35000) | Strict Acc: 90.480% (2262/2500)\n",
      "True positive rate: 94.012% (2449/2605)\n",
      "False negative rate: 5.988% (156/2605)\n",
      "True negative rate: 99.617% (32271/32395)\n",
      "False positive rate: 0.383% (124/32395)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 26/67: Loss: 0.0222 | Train Acc: 99.176% (36100/36400) | Strict Acc: 90.308% (2348/2600)\n",
      "True positive rate: 93.938% (2557/2722)\n",
      "False negative rate: 6.062% (165/2722)\n",
      "True negative rate: 99.599% (33543/33678)\n",
      "False positive rate: 0.401% (135/33678)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 27/67: Loss: 0.0222 | Train Acc: 99.172% (37487/37800) | Strict Acc: 90.222% (2436/2700)\n",
      "True positive rate: 93.975% (2667/2838)\n",
      "False negative rate: 6.025% (171/2838)\n",
      "True negative rate: 99.594% (34820/34962)\n",
      "False positive rate: 0.406% (142/34962)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 18 - Batch 28/67: Loss: 0.0222 | Train Acc: 99.166% (38873/39200) | Strict Acc: 90.143% (2524/2800)\n",
      "True positive rate: 93.933% (2787/2967)\n",
      "False negative rate: 6.067% (180/2967)\n",
      "True negative rate: 99.594% (36086/36233)\n",
      "False positive rate: 0.406% (147/36233)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 29/67: Loss: 0.0223 | Train Acc: 99.163% (40260/40600) | Strict Acc: 90.103% (2613/2900)\n",
      "True positive rate: 93.991% (2878/3062)\n",
      "False negative rate: 6.009% (184/3062)\n",
      "True negative rate: 99.584% (37382/37538)\n",
      "False positive rate: 0.416% (156/37538)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 30/67: Loss: 0.0223 | Train Acc: 99.160% (41647/42000) | Strict Acc: 90.033% (2701/3000)\n",
      "True positive rate: 94.015% (2969/3158)\n",
      "False negative rate: 5.985% (189/3158)\n",
      "True negative rate: 99.578% (38678/38842)\n",
      "False positive rate: 0.422% (164/38842)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 31/67: Loss: 0.0225 | Train Acc: 99.157% (43034/43400) | Strict Acc: 90.000% (2790/3100)\n",
      "True positive rate: 94.054% (3053/3246)\n",
      "False negative rate: 5.946% (193/3246)\n",
      "True negative rate: 99.569% (39981/40154)\n",
      "False positive rate: 0.431% (173/40154)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 32/67: Loss: 0.0227 | Train Acc: 99.152% (44420/44800) | Strict Acc: 89.969% (2879/3200)\n",
      "True positive rate: 94.060% (3151/3350)\n",
      "False negative rate: 5.940% (199/3350)\n",
      "True negative rate: 99.563% (41269/41450)\n",
      "False positive rate: 0.437% (181/41450)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 33/67: Loss: 0.0227 | Train Acc: 99.152% (45808/46200) | Strict Acc: 89.970% (2969/3300)\n",
      "True positive rate: 94.017% (3237/3443)\n",
      "False negative rate: 5.983% (206/3443)\n",
      "True negative rate: 99.565% (42571/42757)\n",
      "False positive rate: 0.435% (186/42757)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 34/67: Loss: 0.0226 | Train Acc: 99.155% (47198/47600) | Strict Acc: 90.029% (3061/3400)\n",
      "True positive rate: 93.972% (3336/3550)\n",
      "False negative rate: 6.028% (214/3550)\n",
      "True negative rate: 99.573% (43862/44050)\n",
      "False positive rate: 0.427% (188/44050)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 35/67: Loss: 0.0231 | Train Acc: 99.137% (48577/49000) | Strict Acc: 89.829% (3144/3500)\n",
      "True positive rate: 93.728% (3437/3667)\n",
      "False negative rate: 6.272% (230/3667)\n",
      "True negative rate: 99.574% (45140/45333)\n",
      "False positive rate: 0.426% (193/45333)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 36/67: Loss: 0.0232 | Train Acc: 99.135% (49964/50400) | Strict Acc: 89.833% (3234/3600)\n",
      "True positive rate: 93.690% (3534/3772)\n",
      "False negative rate: 6.310% (238/3772)\n",
      "True negative rate: 99.575% (46430/46628)\n",
      "False positive rate: 0.425% (198/46628)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 37/67: Loss: 0.0234 | Train Acc: 99.122% (51345/51800) | Strict Acc: 89.703% (3319/3700)\n",
      "True positive rate: 93.582% (3631/3880)\n",
      "False negative rate: 6.418% (249/3880)\n",
      "True negative rate: 99.570% (47714/47920)\n",
      "False positive rate: 0.430% (206/47920)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 38/67: Loss: 0.0236 | Train Acc: 99.107% (52725/53200) | Strict Acc: 89.658% (3407/3800)\n",
      "True positive rate: 93.587% (3707/3961)\n",
      "False negative rate: 6.413% (254/3961)\n",
      "True negative rate: 99.551% (49018/49239)\n",
      "False positive rate: 0.449% (221/49239)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 39/67: Loss: 0.0236 | Train Acc: 99.106% (54112/54600) | Strict Acc: 89.615% (3495/3900)\n",
      "True positive rate: 93.555% (3803/4065)\n",
      "False negative rate: 6.445% (262/4065)\n",
      "True negative rate: 99.553% (50309/50535)\n",
      "False positive rate: 0.447% (226/50535)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 40/67: Loss: 0.0235 | Train Acc: 99.104% (55498/56000) | Strict Acc: 89.550% (3582/4000)\n",
      "True positive rate: 93.527% (3887/4156)\n",
      "False negative rate: 6.473% (269/4156)\n",
      "True negative rate: 99.551% (51611/51844)\n",
      "False positive rate: 0.449% (233/51844)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 41/67: Loss: 0.0235 | Train Acc: 99.099% (56883/57400) | Strict Acc: 89.463% (3668/4100)\n",
      "True positive rate: 93.545% (3971/4245)\n",
      "False negative rate: 6.455% (274/4245)\n",
      "True negative rate: 99.543% (52912/53155)\n",
      "False positive rate: 0.457% (243/53155)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 42/67: Loss: 0.0238 | Train Acc: 99.090% (58265/58800) | Strict Acc: 89.429% (3756/4200)\n",
      "True positive rate: 93.456% (4056/4340)\n",
      "False negative rate: 6.544% (284/4340)\n",
      "True negative rate: 99.539% (54209/54460)\n",
      "False positive rate: 0.461% (251/54460)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 43/67: Loss: 0.0238 | Train Acc: 99.088% (59651/60200) | Strict Acc: 89.395% (3844/4300)\n",
      "True positive rate: 93.431% (4153/4445)\n",
      "False negative rate: 6.569% (292/4445)\n",
      "True negative rate: 99.539% (55498/55755)\n",
      "False positive rate: 0.461% (257/55755)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 44/67: Loss: 0.0238 | Train Acc: 99.088% (61038/61600) | Strict Acc: 89.409% (3934/4400)\n",
      "True positive rate: 93.388% (4251/4552)\n",
      "False negative rate: 6.612% (301/4552)\n",
      "True negative rate: 99.542% (56787/57048)\n",
      "False positive rate: 0.458% (261/57048)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 45/67: Loss: 0.0238 | Train Acc: 99.087% (62425/63000) | Strict Acc: 89.400% (4023/4500)\n",
      "True positive rate: 93.333% (4340/4650)\n",
      "False negative rate: 6.667% (310/4650)\n",
      "True negative rate: 99.546% (58085/58350)\n",
      "False positive rate: 0.454% (265/58350)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 46/67: Loss: 0.0236 | Train Acc: 99.092% (63815/64400) | Strict Acc: 89.435% (4114/4600)\n",
      "True positive rate: 93.336% (4440/4757)\n",
      "False negative rate: 6.664% (317/4757)\n",
      "True negative rate: 99.551% (59375/59643)\n",
      "False positive rate: 0.449% (268/59643)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 47/67: Loss: 0.0235 | Train Acc: 99.097% (65206/65800) | Strict Acc: 89.511% (4207/4700)\n",
      "True positive rate: 93.344% (4516/4838)\n",
      "False negative rate: 6.656% (322/4838)\n",
      "True negative rate: 99.554% (60690/60962)\n",
      "False positive rate: 0.446% (272/60962)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 48/67: Loss: 0.0234 | Train Acc: 99.098% (66594/67200) | Strict Acc: 89.542% (4298/4800)\n",
      "True positive rate: 93.299% (4581/4910)\n",
      "False negative rate: 6.701% (329/4910)\n",
      "True negative rate: 99.555% (62013/62290)\n",
      "False positive rate: 0.445% (277/62290)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 49/67: Loss: 0.0233 | Train Acc: 99.106% (67987/68600) | Strict Acc: 89.633% (4392/4900)\n",
      "True positive rate: 93.341% (4668/5001)\n",
      "False negative rate: 6.659% (333/5001)\n",
      "True negative rate: 99.560% (63319/63599)\n",
      "False positive rate: 0.440% (280/63599)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 50/67: Loss: 0.0234 | Train Acc: 99.099% (69369/70000) | Strict Acc: 89.560% (4478/5000)\n",
      "True positive rate: 93.256% (4757/5101)\n",
      "False negative rate: 6.744% (344/5101)\n",
      "True negative rate: 99.558% (64612/64899)\n",
      "False positive rate: 0.442% (287/64899)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 51/67: Loss: 0.0233 | Train Acc: 99.099% (70757/71400) | Strict Acc: 89.588% (4569/5100)\n",
      "True positive rate: 93.256% (4854/5205)\n",
      "False negative rate: 6.744% (351/5205)\n",
      "True negative rate: 99.559% (65903/66195)\n",
      "False positive rate: 0.441% (292/66195)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 52/67: Loss: 0.0236 | Train Acc: 99.093% (72140/72800) | Strict Acc: 89.538% (4656/5200)\n",
      "True positive rate: 93.311% (4924/5277)\n",
      "False negative rate: 6.689% (353/5277)\n",
      "True negative rate: 99.545% (67216/67523)\n",
      "False positive rate: 0.455% (307/67523)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 53/67: Loss: 0.0235 | Train Acc: 99.102% (73534/74200) | Strict Acc: 89.623% (4750/5300)\n",
      "True positive rate: 93.372% (5001/5356)\n",
      "False negative rate: 6.628% (355/5356)\n",
      "True negative rate: 99.548% (68533/68844)\n",
      "False positive rate: 0.452% (311/68844)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 18 - Batch 54/67: Loss: 0.0235 | Train Acc: 99.101% (74920/75600) | Strict Acc: 89.593% (4838/5400)\n",
      "True positive rate: 93.365% (5094/5456)\n",
      "False negative rate: 6.635% (362/5456)\n",
      "True negative rate: 99.547% (69826/70144)\n",
      "False positive rate: 0.453% (318/70144)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 55/67: Loss: 0.0236 | Train Acc: 99.096% (76304/77000) | Strict Acc: 89.564% (4926/5500)\n",
      "True positive rate: 93.349% (5193/5563)\n",
      "False negative rate: 6.651% (370/5563)\n",
      "True negative rate: 99.544% (71111/71437)\n",
      "False positive rate: 0.456% (326/71437)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 56/67: Loss: 0.0238 | Train Acc: 99.084% (77682/78400) | Strict Acc: 89.429% (5008/5600)\n",
      "True positive rate: 93.215% (5289/5674)\n",
      "False negative rate: 6.785% (385/5674)\n",
      "True negative rate: 99.542% (72393/72726)\n",
      "False positive rate: 0.458% (333/72726)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 57/67: Loss: 0.0237 | Train Acc: 99.086% (79071/79800) | Strict Acc: 89.439% (5098/5700)\n",
      "True positive rate: 93.192% (5366/5758)\n",
      "False negative rate: 6.808% (392/5758)\n",
      "True negative rate: 99.545% (73705/74042)\n",
      "False positive rate: 0.455% (337/74042)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 58/67: Loss: 0.0236 | Train Acc: 99.089% (80460/81200) | Strict Acc: 89.448% (5188/5800)\n",
      "True positive rate: 93.175% (5461/5861)\n",
      "False negative rate: 6.825% (400/5861)\n",
      "True negative rate: 99.549% (74999/75339)\n",
      "False positive rate: 0.451% (340/75339)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 59/67: Loss: 0.0236 | Train Acc: 99.088% (81847/82600) | Strict Acc: 89.475% (5279/5900)\n",
      "True positive rate: 93.148% (5560/5969)\n",
      "False negative rate: 6.852% (409/5969)\n",
      "True negative rate: 99.551% (76287/76631)\n",
      "False positive rate: 0.449% (344/76631)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 60/67: Loss: 0.0234 | Train Acc: 99.101% (83245/84000) | Strict Acc: 89.617% (5377/6000)\n",
      "True positive rate: 93.255% (5669/6079)\n",
      "False negative rate: 6.745% (410/6079)\n",
      "True negative rate: 99.557% (77576/77921)\n",
      "False positive rate: 0.443% (345/77921)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 61/67: Loss: 0.0236 | Train Acc: 99.096% (84628/85400) | Strict Acc: 89.508% (5460/6100)\n",
      "True positive rate: 93.263% (5759/6175)\n",
      "False negative rate: 6.737% (416/6175)\n",
      "True negative rate: 99.551% (78869/79225)\n",
      "False positive rate: 0.449% (356/79225)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 62/67: Loss: 0.0238 | Train Acc: 99.085% (86006/86800) | Strict Acc: 89.403% (5543/6200)\n",
      "True positive rate: 93.197% (5850/6277)\n",
      "False negative rate: 6.803% (427/6277)\n",
      "True negative rate: 99.544% (80156/80523)\n",
      "False positive rate: 0.456% (367/80523)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 63/67: Loss: 0.0239 | Train Acc: 99.078% (87387/88200) | Strict Acc: 89.317% (5627/6300)\n",
      "True positive rate: 93.132% (5939/6377)\n",
      "False negative rate: 6.868% (438/6377)\n",
      "True negative rate: 99.542% (81448/81823)\n",
      "False positive rate: 0.458% (375/81823)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 64/67: Loss: 0.0238 | Train Acc: 99.083% (88778/89600) | Strict Acc: 89.406% (5722/6400)\n",
      "True positive rate: 93.190% (6035/6476)\n",
      "False negative rate: 6.810% (441/6476)\n",
      "True negative rate: 99.542% (82743/83124)\n",
      "False positive rate: 0.458% (381/83124)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 65/67: Loss: 0.0239 | Train Acc: 99.081% (90164/91000) | Strict Acc: 89.400% (5811/6500)\n",
      "True positive rate: 93.100% (6112/6565)\n",
      "False negative rate: 6.900% (453/6565)\n",
      "True negative rate: 99.546% (84052/84435)\n",
      "False positive rate: 0.454% (383/84435)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 66/67: Loss: 0.0238 | Train Acc: 99.084% (91554/92400) | Strict Acc: 89.455% (5904/6600)\n",
      "True positive rate: 93.092% (6199/6659)\n",
      "False negative rate: 6.908% (460/6659)\n",
      "True negative rate: 99.550% (85355/85741)\n",
      "False positive rate: 0.450% (386/85741)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 18 - Batch 67/67: Loss: 0.0238 | Train Acc: 99.083% (92898/93758) | Strict Acc: 89.413% (5988/6697)\n",
      "True positive rate: 93.067% (6282/6750)\n",
      "False negative rate: 6.933% (468/6750)\n",
      "True negative rate: 99.549% (86616/87008)\n",
      "False positive rate: 0.451% (392/87008)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 6517/6517: Loss: 0.2214 | Dev Acc: 93.174% (85010/91238) | Strict Acc: 43.195% (2815/6517)\n",
      "True positive rate: 32.969% (2169/6579)\n",
      "False negative rate: 67.031% (4410/6579)\n",
      "True negative rate: 97.853% (82841/84659)\n",
      "False positive rate: 2.147% (1818/84659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 1/67: Loss: 0.0152 | Train Acc: 99.357% (1391/1400) | Strict Acc: 93.000% (93/100)\n",
      "True positive rate: 95.238% (100/105)\n",
      "False negative rate: 4.762% (5/105)\n",
      "True negative rate: 99.691% (1291/1295)\n",
      "False positive rate: 0.309% (4/1295)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 2/67: Loss: 0.0193 | Train Acc: 99.214% (2778/2800) | Strict Acc: 90.500% (181/200)\n",
      "True positive rate: 94.527% (190/201)\n",
      "False negative rate: 5.473% (11/201)\n",
      "True negative rate: 99.577% (2588/2599)\n",
      "False positive rate: 0.423% (11/2599)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 3/67: Loss: 0.0168 | Train Acc: 99.381% (4174/4200) | Strict Acc: 92.667% (278/300)\n",
      "True positive rate: 95.862% (278/290)\n",
      "False negative rate: 4.138% (12/290)\n",
      "True negative rate: 99.642% (3896/3910)\n",
      "False positive rate: 0.358% (14/3910)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 4/67: Loss: 0.0174 | Train Acc: 99.393% (5566/5600) | Strict Acc: 92.500% (370/400)\n",
      "True positive rate: 95.631% (394/412)\n",
      "False negative rate: 4.369% (18/412)\n",
      "True negative rate: 99.692% (5172/5188)\n",
      "False positive rate: 0.308% (16/5188)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 5/67: Loss: 0.0160 | Train Acc: 99.443% (6961/7000) | Strict Acc: 93.000% (465/500)\n",
      "True positive rate: 95.775% (476/497)\n",
      "False negative rate: 4.225% (21/497)\n",
      "True negative rate: 99.723% (6485/6503)\n",
      "False positive rate: 0.277% (18/6503)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 6/67: Loss: 0.0159 | Train Acc: 99.452% (8354/8400) | Strict Acc: 93.333% (560/600)\n",
      "True positive rate: 95.545% (579/606)\n",
      "False negative rate: 4.455% (27/606)\n",
      "True negative rate: 99.756% (7775/7794)\n",
      "False positive rate: 0.244% (19/7794)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 7/67: Loss: 0.0167 | Train Acc: 99.398% (9741/9800) | Strict Acc: 92.571% (648/700)\n",
      "True positive rate: 95.775% (680/710)\n",
      "False negative rate: 4.225% (30/710)\n",
      "True negative rate: 99.681% (9061/9090)\n",
      "False positive rate: 0.319% (29/9090)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 8/67: Loss: 0.0177 | Train Acc: 99.357% (11128/11200) | Strict Acc: 92.375% (739/800)\n",
      "True positive rate: 95.404% (768/805)\n",
      "False negative rate: 4.596% (37/805)\n",
      "True negative rate: 99.663% (10360/10395)\n",
      "False positive rate: 0.337% (35/10395)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 9/67: Loss: 0.0172 | Train Acc: 99.373% (12521/12600) | Strict Acc: 92.556% (833/900)\n",
      "True positive rate: 95.761% (881/920)\n",
      "False negative rate: 4.239% (39/920)\n",
      "True negative rate: 99.658% (11640/11680)\n",
      "False positive rate: 0.342% (40/11680)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 10/67: Loss: 0.0185 | Train Acc: 99.343% (13908/14000) | Strict Acc: 92.400% (924/1000)\n",
      "True positive rate: 95.821% (986/1029)\n",
      "False negative rate: 4.179% (43/1029)\n",
      "True negative rate: 99.622% (12922/12971)\n",
      "False positive rate: 0.378% (49/12971)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 11/67: Loss: 0.0191 | Train Acc: 99.312% (15294/15400) | Strict Acc: 92.000% (1012/1100)\n",
      "True positive rate: 95.584% (1104/1155)\n",
      "False negative rate: 4.416% (51/1155)\n",
      "True negative rate: 99.614% (14190/14245)\n",
      "False positive rate: 0.386% (55/14245)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 19 - Batch 12/67: Loss: 0.0197 | Train Acc: 99.292% (16681/16800) | Strict Acc: 91.750% (1101/1200)\n",
      "True positive rate: 95.532% (1176/1231)\n",
      "False negative rate: 4.468% (55/1231)\n",
      "True negative rate: 99.589% (15505/15569)\n",
      "False positive rate: 0.411% (64/15569)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 13/67: Loss: 0.0199 | Train Acc: 99.280% (18069/18200) | Strict Acc: 91.692% (1192/1300)\n",
      "True positive rate: 95.347% (1250/1311)\n",
      "False negative rate: 4.653% (61/1311)\n",
      "True negative rate: 99.586% (16819/16889)\n",
      "False positive rate: 0.414% (70/16889)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 14/67: Loss: 0.0198 | Train Acc: 99.276% (19458/19600) | Strict Acc: 91.571% (1282/1400)\n",
      "True positive rate: 95.061% (1328/1397)\n",
      "False negative rate: 4.939% (69/1397)\n",
      "True negative rate: 99.599% (18130/18203)\n",
      "False positive rate: 0.401% (73/18203)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 15/67: Loss: 0.0197 | Train Acc: 99.248% (20842/21000) | Strict Acc: 91.200% (1368/1500)\n",
      "True positive rate: 94.983% (1420/1495)\n",
      "False negative rate: 5.017% (75/1495)\n",
      "True negative rate: 99.574% (19422/19505)\n",
      "False positive rate: 0.426% (83/19505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 16/67: Loss: 0.0201 | Train Acc: 99.214% (22224/22400) | Strict Acc: 91.000% (1456/1600)\n",
      "True positive rate: 94.750% (1498/1581)\n",
      "False negative rate: 5.250% (83/1581)\n",
      "True negative rate: 99.553% (20726/20819)\n",
      "False positive rate: 0.447% (93/20819)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 17/67: Loss: 0.0202 | Train Acc: 99.235% (23618/23800) | Strict Acc: 91.176% (1550/1700)\n",
      "True positive rate: 94.762% (1592/1680)\n",
      "False negative rate: 5.238% (88/1680)\n",
      "True negative rate: 99.575% (22026/22120)\n",
      "False positive rate: 0.425% (94/22120)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 18/67: Loss: 0.0204 | Train Acc: 99.238% (25008/25200) | Strict Acc: 91.222% (1642/1800)\n",
      "True positive rate: 94.639% (1677/1772)\n",
      "False negative rate: 5.361% (95/1772)\n",
      "True negative rate: 99.586% (23331/23428)\n",
      "False positive rate: 0.414% (97/23428)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 19/67: Loss: 0.0207 | Train Acc: 99.229% (26395/26600) | Strict Acc: 91.158% (1732/1900)\n",
      "True positive rate: 94.566% (1775/1877)\n",
      "False negative rate: 5.434% (102/1877)\n",
      "True negative rate: 99.583% (24620/24723)\n",
      "False positive rate: 0.417% (103/24723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 20/67: Loss: 0.0202 | Train Acc: 99.257% (27792/28000) | Strict Acc: 91.450% (1829/2000)\n",
      "True positive rate: 94.742% (1856/1959)\n",
      "False negative rate: 5.258% (103/1959)\n",
      "True negative rate: 99.597% (25936/26041)\n",
      "False positive rate: 0.403% (105/26041)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 21/67: Loss: 0.0202 | Train Acc: 99.255% (29181/29400) | Strict Acc: 91.333% (1918/2100)\n",
      "True positive rate: 94.767% (1956/2064)\n",
      "False negative rate: 5.233% (108/2064)\n",
      "True negative rate: 99.594% (27225/27336)\n",
      "False positive rate: 0.406% (111/27336)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 22/67: Loss: 0.0206 | Train Acc: 99.237% (30565/30800) | Strict Acc: 91.136% (2005/2200)\n",
      "True positive rate: 94.691% (2069/2185)\n",
      "False negative rate: 5.309% (116/2185)\n",
      "True negative rate: 99.584% (28496/28615)\n",
      "False positive rate: 0.416% (119/28615)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 23/67: Loss: 0.0206 | Train Acc: 99.239% (31955/32200) | Strict Acc: 91.174% (2097/2300)\n",
      "True positive rate: 94.656% (2161/2283)\n",
      "False negative rate: 5.344% (122/2283)\n",
      "True negative rate: 99.589% (29794/29917)\n",
      "False positive rate: 0.411% (123/29917)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 24/67: Loss: 0.0206 | Train Acc: 99.226% (33340/33600) | Strict Acc: 91.042% (2185/2400)\n",
      "True positive rate: 94.584% (2253/2382)\n",
      "False negative rate: 5.416% (129/2382)\n",
      "True negative rate: 99.580% (31087/31218)\n",
      "False positive rate: 0.420% (131/31218)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 25/67: Loss: 0.0202 | Train Acc: 99.243% (34735/35000) | Strict Acc: 91.240% (2281/2500)\n",
      "True positive rate: 94.709% (2345/2476)\n",
      "False negative rate: 5.291% (131/2476)\n",
      "True negative rate: 99.588% (32390/32524)\n",
      "False positive rate: 0.412% (134/32524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 26/67: Loss: 0.0203 | Train Acc: 99.250% (36127/36400) | Strict Acc: 91.269% (2373/2600)\n",
      "True positive rate: 94.644% (2421/2558)\n",
      "False negative rate: 5.356% (137/2558)\n",
      "True negative rate: 99.598% (33706/33842)\n",
      "False positive rate: 0.402% (136/33842)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 27/67: Loss: 0.0206 | Train Acc: 99.246% (37515/37800) | Strict Acc: 91.185% (2462/2700)\n",
      "True positive rate: 94.559% (2520/2665)\n",
      "False negative rate: 5.441% (145/2665)\n",
      "True negative rate: 99.602% (34995/35135)\n",
      "False positive rate: 0.398% (140/35135)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 28/67: Loss: 0.0208 | Train Acc: 99.242% (38903/39200) | Strict Acc: 91.143% (2552/2800)\n",
      "True positive rate: 94.613% (2617/2766)\n",
      "False negative rate: 5.387% (149/2766)\n",
      "True negative rate: 99.594% (36286/36434)\n",
      "False positive rate: 0.406% (148/36434)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 29/67: Loss: 0.0207 | Train Acc: 99.244% (40293/40600) | Strict Acc: 91.103% (2642/2900)\n",
      "True positive rate: 94.474% (2701/2859)\n",
      "False negative rate: 5.526% (158/2859)\n",
      "True negative rate: 99.605% (37592/37741)\n",
      "False positive rate: 0.395% (149/37741)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 30/67: Loss: 0.0207 | Train Acc: 99.238% (41680/42000) | Strict Acc: 90.967% (2729/3000)\n",
      "True positive rate: 94.512% (2807/2970)\n",
      "False negative rate: 5.488% (163/2970)\n",
      "True negative rate: 99.598% (38873/39030)\n",
      "False positive rate: 0.402% (157/39030)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 31/67: Loss: 0.0208 | Train Acc: 99.237% (43069/43400) | Strict Acc: 90.935% (2819/3100)\n",
      "True positive rate: 94.580% (2914/3081)\n",
      "False negative rate: 5.420% (167/3081)\n",
      "True negative rate: 99.593% (40155/40319)\n",
      "False positive rate: 0.407% (164/40319)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 32/67: Loss: 0.0210 | Train Acc: 99.228% (44454/44800) | Strict Acc: 90.906% (2909/3200)\n",
      "True positive rate: 94.518% (3000/3174)\n",
      "False negative rate: 5.482% (174/3174)\n",
      "True negative rate: 99.587% (41454/41626)\n",
      "False positive rate: 0.413% (172/41626)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 33/67: Loss: 0.0212 | Train Acc: 99.212% (45836/46200) | Strict Acc: 90.727% (2994/3300)\n",
      "True positive rate: 94.426% (3083/3265)\n",
      "False negative rate: 5.574% (182/3265)\n",
      "True negative rate: 99.576% (42753/42935)\n",
      "False positive rate: 0.424% (182/42935)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 34/67: Loss: 0.0213 | Train Acc: 99.214% (47226/47600) | Strict Acc: 90.765% (3086/3400)\n",
      "True positive rate: 94.499% (3161/3345)\n",
      "False negative rate: 5.501% (184/3345)\n",
      "True negative rate: 99.571% (44065/44255)\n",
      "False positive rate: 0.429% (190/44255)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 35/67: Loss: 0.0211 | Train Acc: 99.222% (48619/49000) | Strict Acc: 90.857% (3180/3500)\n",
      "True positive rate: 94.509% (3253/3442)\n",
      "False negative rate: 5.491% (189/3442)\n",
      "True negative rate: 99.579% (45366/45558)\n",
      "False positive rate: 0.421% (192/45558)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 36/67: Loss: 0.0212 | Train Acc: 99.216% (50005/50400) | Strict Acc: 90.750% (3267/3600)\n",
      "True positive rate: 94.330% (3344/3545)\n",
      "False negative rate: 5.670% (201/3545)\n",
      "True negative rate: 99.586% (46661/46855)\n",
      "False positive rate: 0.414% (194/46855)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 37/67: Loss: 0.0215 | Train Acc: 99.203% (51387/51800) | Strict Acc: 90.568% (3351/3700)\n",
      "True positive rate: 94.135% (3435/3649)\n",
      "False negative rate: 5.865% (214/3649)\n",
      "True negative rate: 99.587% (47952/48151)\n",
      "False positive rate: 0.413% (199/48151)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 19 - Batch 38/67: Loss: 0.0213 | Train Acc: 99.205% (52777/53200) | Strict Acc: 90.605% (3443/3800)\n",
      "True positive rate: 94.094% (3537/3759)\n",
      "False negative rate: 5.906% (222/3759)\n",
      "True negative rate: 99.593% (49240/49441)\n",
      "False positive rate: 0.407% (201/49441)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 39/67: Loss: 0.0211 | Train Acc: 99.207% (54167/54600) | Strict Acc: 90.641% (3535/3900)\n",
      "True positive rate: 94.139% (3646/3873)\n",
      "False negative rate: 5.861% (227/3873)\n",
      "True negative rate: 99.594% (50521/50727)\n",
      "False positive rate: 0.406% (206/50727)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 40/67: Loss: 0.0211 | Train Acc: 99.204% (55554/56000) | Strict Acc: 90.575% (3623/4000)\n",
      "True positive rate: 94.095% (3729/3963)\n",
      "False negative rate: 5.905% (234/3963)\n",
      "True negative rate: 99.593% (51825/52037)\n",
      "False positive rate: 0.407% (212/52037)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 41/67: Loss: 0.0208 | Train Acc: 99.218% (56951/57400) | Strict Acc: 90.732% (3720/4100)\n",
      "True positive rate: 94.194% (3829/4065)\n",
      "False negative rate: 5.806% (236/4065)\n",
      "True negative rate: 99.601% (53122/53335)\n",
      "False positive rate: 0.399% (213/53335)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 42/67: Loss: 0.0209 | Train Acc: 99.216% (58339/58800) | Strict Acc: 90.690% (3809/4200)\n",
      "True positive rate: 94.232% (3921/4161)\n",
      "False negative rate: 5.768% (240/4161)\n",
      "True negative rate: 99.596% (54418/54639)\n",
      "False positive rate: 0.404% (221/54639)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 43/67: Loss: 0.0209 | Train Acc: 99.218% (59729/60200) | Strict Acc: 90.698% (3900/4300)\n",
      "True positive rate: 94.333% (4012/4253)\n",
      "False negative rate: 5.667% (241/4253)\n",
      "True negative rate: 99.589% (55717/55947)\n",
      "False positive rate: 0.411% (230/55947)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 44/67: Loss: 0.0208 | Train Acc: 99.222% (61121/61600) | Strict Acc: 90.727% (3992/4400)\n",
      "True positive rate: 94.404% (4099/4342)\n",
      "False negative rate: 5.596% (243/4342)\n",
      "True negative rate: 99.588% (57022/57258)\n",
      "False positive rate: 0.412% (236/57258)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 45/67: Loss: 0.0208 | Train Acc: 99.217% (62507/63000) | Strict Acc: 90.667% (4080/4500)\n",
      "True positive rate: 94.402% (4199/4448)\n",
      "False negative rate: 5.598% (249/4448)\n",
      "True negative rate: 99.583% (58308/58552)\n",
      "False positive rate: 0.417% (244/58552)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 46/67: Loss: 0.0208 | Train Acc: 99.214% (63894/64400) | Strict Acc: 90.674% (4171/4600)\n",
      "True positive rate: 94.288% (4275/4534)\n",
      "False negative rate: 5.712% (259/4534)\n",
      "True negative rate: 99.587% (59619/59866)\n",
      "False positive rate: 0.413% (247/59866)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 47/67: Loss: 0.0212 | Train Acc: 99.202% (65275/65800) | Strict Acc: 90.532% (4255/4700)\n",
      "True positive rate: 94.113% (4364/4637)\n",
      "False negative rate: 5.887% (273/4637)\n",
      "True negative rate: 99.588% (60911/61163)\n",
      "False positive rate: 0.412% (252/61163)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 48/67: Loss: 0.0215 | Train Acc: 99.195% (66659/67200) | Strict Acc: 90.458% (4342/4800)\n",
      "True positive rate: 94.037% (4479/4763)\n",
      "False negative rate: 5.963% (284/4763)\n",
      "True negative rate: 99.588% (62180/62437)\n",
      "False positive rate: 0.412% (257/62437)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 49/67: Loss: 0.0216 | Train Acc: 99.182% (68039/68600) | Strict Acc: 90.367% (4428/4900)\n",
      "True positive rate: 93.872% (4580/4879)\n",
      "False negative rate: 6.128% (299/4879)\n",
      "True negative rate: 99.589% (63459/63721)\n",
      "False positive rate: 0.411% (262/63721)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 50/67: Loss: 0.0216 | Train Acc: 99.181% (69427/70000) | Strict Acc: 90.320% (4516/5000)\n",
      "True positive rate: 93.947% (4672/4973)\n",
      "False negative rate: 6.053% (301/4973)\n",
      "True negative rate: 99.582% (64755/65027)\n",
      "False positive rate: 0.418% (272/65027)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 51/67: Loss: 0.0218 | Train Acc: 99.172% (70809/71400) | Strict Acc: 90.216% (4601/5100)\n",
      "True positive rate: 93.954% (4771/5078)\n",
      "False negative rate: 6.046% (307/5078)\n",
      "True negative rate: 99.572% (66038/66322)\n",
      "False positive rate: 0.428% (284/66322)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 52/67: Loss: 0.0218 | Train Acc: 99.177% (72201/72800) | Strict Acc: 90.269% (4694/5200)\n",
      "True positive rate: 94.033% (4885/5195)\n",
      "False negative rate: 5.967% (310/5195)\n",
      "True negative rate: 99.573% (67316/67605)\n",
      "False positive rate: 0.427% (289/67605)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 53/67: Loss: 0.0218 | Train Acc: 99.179% (73591/74200) | Strict Acc: 90.283% (4785/5300)\n",
      "True positive rate: 94.089% (4982/5295)\n",
      "False negative rate: 5.911% (313/5295)\n",
      "True negative rate: 99.570% (68609/68905)\n",
      "False positive rate: 0.430% (296/68905)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 54/67: Loss: 0.0219 | Train Acc: 99.171% (74973/75600) | Strict Acc: 90.204% (4871/5400)\n",
      "True positive rate: 94.072% (5094/5415)\n",
      "False negative rate: 5.928% (321/5415)\n",
      "True negative rate: 99.564% (69879/70185)\n",
      "False positive rate: 0.436% (306/70185)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 55/67: Loss: 0.0220 | Train Acc: 99.168% (76359/77000) | Strict Acc: 90.182% (4960/5500)\n",
      "True positive rate: 94.007% (5192/5523)\n",
      "False negative rate: 5.993% (331/5523)\n",
      "True negative rate: 99.566% (71167/71477)\n",
      "False positive rate: 0.434% (310/71477)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 56/67: Loss: 0.0219 | Train Acc: 99.171% (77750/78400) | Strict Acc: 90.196% (5051/5600)\n",
      "True positive rate: 94.030% (5292/5628)\n",
      "False negative rate: 5.970% (336/5628)\n",
      "True negative rate: 99.569% (72458/72772)\n",
      "False positive rate: 0.431% (314/72772)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 57/67: Loss: 0.0218 | Train Acc: 99.178% (79144/79800) | Strict Acc: 90.298% (5147/5700)\n",
      "True positive rate: 94.104% (5395/5733)\n",
      "False negative rate: 5.896% (338/5733)\n",
      "True negative rate: 99.571% (73749/74067)\n",
      "False positive rate: 0.429% (318/74067)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 58/67: Loss: 0.0218 | Train Acc: 99.175% (80530/81200) | Strict Acc: 90.259% (5235/5800)\n",
      "True positive rate: 94.028% (5479/5827)\n",
      "False negative rate: 5.972% (348/5827)\n",
      "True negative rate: 99.573% (75051/75373)\n",
      "False positive rate: 0.427% (322/75373)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 59/67: Loss: 0.0221 | Train Acc: 99.166% (81911/82600) | Strict Acc: 90.119% (5317/5900)\n",
      "True positive rate: 93.885% (5589/5953)\n",
      "False negative rate: 6.115% (364/5953)\n",
      "True negative rate: 99.576% (76322/76647)\n",
      "False positive rate: 0.424% (325/76647)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 60/67: Loss: 0.0220 | Train Acc: 99.165% (83299/84000) | Strict Acc: 90.133% (5408/6000)\n",
      "True positive rate: 93.828% (5670/6043)\n",
      "False negative rate: 6.172% (373/6043)\n",
      "True negative rate: 99.579% (77629/77957)\n",
      "False positive rate: 0.421% (328/77957)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 61/67: Loss: 0.0220 | Train Acc: 99.165% (84687/85400) | Strict Acc: 90.148% (5499/6100)\n",
      "True positive rate: 93.834% (5783/6163)\n",
      "False negative rate: 6.166% (380/6163)\n",
      "True negative rate: 99.580% (78904/79237)\n",
      "False positive rate: 0.420% (333/79237)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 62/67: Loss: 0.0221 | Train Acc: 99.167% (86077/86800) | Strict Acc: 90.145% (5589/6200)\n",
      "True positive rate: 93.824% (5864/6250)\n",
      "False negative rate: 6.176% (386/6250)\n",
      "True negative rate: 99.582% (80213/80550)\n",
      "False positive rate: 0.418% (337/80550)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 63/67: Loss: 0.0221 | Train Acc: 99.168% (87466/88200) | Strict Acc: 90.159% (5680/6300)\n",
      "True positive rate: 93.837% (5969/6361)\n",
      "False negative rate: 6.163% (392/6361)\n",
      "True negative rate: 99.582% (81497/81839)\n",
      "False positive rate: 0.418% (342/81839)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 19 - Batch 64/67: Loss: 0.0221 | Train Acc: 99.167% (88854/89600) | Strict Acc: 90.141% (5769/6400)\n",
      "True positive rate: 93.882% (6077/6473)\n",
      "False negative rate: 6.118% (396/6473)\n",
      "True negative rate: 99.579% (82777/83127)\n",
      "False positive rate: 0.421% (350/83127)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 65/67: Loss: 0.0222 | Train Acc: 99.167% (90242/91000) | Strict Acc: 90.138% (5859/6500)\n",
      "True positive rate: 93.883% (6155/6556)\n",
      "False negative rate: 6.117% (401/6556)\n",
      "True negative rate: 99.577% (84087/84444)\n",
      "False positive rate: 0.423% (357/84444)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 66/67: Loss: 0.0223 | Train Acc: 99.165% (91628/92400) | Strict Acc: 90.106% (5947/6600)\n",
      "True positive rate: 93.874% (6268/6677)\n",
      "False negative rate: 6.126% (409/6677)\n",
      "True negative rate: 99.577% (85360/85723)\n",
      "False positive rate: 0.423% (363/85723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 19 - Batch 67/67: Loss: 0.0224 | Train Acc: 99.166% (92976/93758) | Strict Acc: 90.115% (6035/6697)\n",
      "True positive rate: 93.867% (6336/6750)\n",
      "False negative rate: 6.133% (414/6750)\n",
      "True negative rate: 99.577% (86640/87008)\n",
      "False positive rate: 0.423% (368/87008)\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "#--- hyperparameters ---\n",
    "N_EPOCHS = 25\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_TEST = 100\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 0.00\n",
    "MOMENTUM = 0.1\n",
    "\n",
    "\n",
    "#--- fixed constants ---\n",
    "NUM_CLASSES = 14\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "\n",
    "\n",
    "# --- Dataset initialization ---\n",
    "\n",
    "# We transform image files' contents to tensors\n",
    "# Plus, we can add random transformations to the training data if we like\n",
    "# Think on what kind of transformations may be meaningful for this data.\n",
    "# Eg., horizontal-flip is definitely a bad idea for sign language data.\n",
    "# You can use another transformation here if you find a better one.\n",
    "\n",
    "\n",
    "# Create Pytorch data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE_TEST, shuffle=False)\n",
    "dev_loader = torch.utils.data.DataLoader(dataset=dev_set, shuffle=False)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "resnet = models.resnet101(pretrained=True)\n",
    "\n",
    "alexnet.train()\n",
    "resnet.train()\n",
    "\n",
    "#--- model ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.alex = alexnet\n",
    "        for p in self.alex.parameters():\n",
    "            p.requires_grad=False\n",
    "        \n",
    "        self.resnet = resnet\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad=False\n",
    "        \n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(2000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out_alex = self.alex(x)\n",
    "        out_resnet = self.resnet(x)\n",
    "        \n",
    "        combined_pretrained_output = torch.cat((out_alex, out_resnet), dim=1)\n",
    "        \n",
    "        out = self.lin(combined_pretrained_output)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "#--- set up ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "dev_loss = math.inf\n",
    "dev_losses = []\n",
    "dev_accuracies = []\n",
    "stop_early = False\n",
    "\n",
    "#--- training ---\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if stop_early:\n",
    "        break\n",
    "    train_loss = 0\n",
    "    train_correct = {annotation: [0,0] for annotation in annotations}\n",
    "    train_correct['tot'] = [0,0]\n",
    "    train_correct['tot_strict'] = [0,0]\n",
    "    evaluation = {\"true_positive\": 0,\n",
    "                    \"false_positive\": 0,\n",
    "                    \"true_negative\": 0,\n",
    "                    \"false_negative\": 0,\n",
    "                    \"negative\": 0,\n",
    "                    \"positive\": 0}\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += len(data)\n",
    "        train_loss += loss.item()\n",
    "        new_correct = calc_correct(pred, target)\n",
    "        for annotation in annotations:\n",
    "            new = new_correct[annotation]\n",
    "            train_correct[annotation][0] += new[0]\n",
    "            train_correct[annotation][1] += new[1]\n",
    "        train_correct['tot'][0] += new_correct['tot'][0]\n",
    "        train_correct['tot'][1] += new_correct['tot'][1]\n",
    "        train_correct['tot_strict'][0] += new_correct['tot_strict'][0]\n",
    "        train_correct['tot_strict'][1] += new_correct['tot_strict'][1]\n",
    "        \n",
    "        evaluations = class_evaluation(pred, target)\n",
    "        evaluation[\"true_positive\"] += evaluations[\"true_positive\"]\n",
    "        evaluation[\"false_positive\"] += evaluations[\"false_positive\"]\n",
    "        evaluation[\"true_negative\"] += evaluations[\"true_negative\"]\n",
    "        evaluation[\"false_negative\"] += evaluations[\"false_negative\"]\n",
    "        evaluation[\"positive\"] += evaluations[\"positive\"]\n",
    "        evaluation[\"negative\"] += evaluations[\"negative\"]\n",
    "\n",
    "        print(\"------------------------\")\n",
    "        print('Training: Epoch %d - Batch %d/%d: Loss: %.4f | Train Acc: %.3f%% (%d/%d) | Strict Acc: %.3f%% (%d/%d)' % \n",
    "              (epoch+1, batch_num+1, len(train_loader), train_loss / (batch_num + 1), \n",
    "               100. * train_correct['tot'][0] / train_correct['tot'][1], train_correct['tot'][0], train_correct['tot'][1],\n",
    "               100. * train_correct['tot_strict'][0] / train_correct['tot_strict'][1], train_correct['tot_strict'][0], train_correct['tot_strict'][1]))\n",
    "        print('True positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_positive\"] / evaluation[\"positive\"], evaluation[\"true_positive\"], evaluation[\"positive\"]) )\n",
    "        print('False negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_negative\"] / evaluation[\"positive\"], evaluation[\"false_negative\"], evaluation[\"positive\"]) )\n",
    "        print('True negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_negative\"] / evaluation[\"negative\"], evaluation[\"true_negative\"], evaluation[\"negative\"]) )\n",
    "        print('False positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_positive\"] / evaluation[\"negative\"], evaluation[\"false_positive\"], evaluation[\"negative\"]) )\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    cur_dev_loss = 0\n",
    "    dev_correct = {annotation: [0,0] for annotation in annotations}\n",
    "    dev_correct['tot'] = [0,0]\n",
    "    dev_correct['tot_strict'] = [0,0]\n",
    "    evaluation = {\"true_positive\": 0,\n",
    "                    \"false_positive\": 0,\n",
    "                    \"true_negative\": 0,\n",
    "                    \"false_negative\": 0,\n",
    "                    \"negative\": 0,\n",
    "                    \"positive\": 0}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (data, target) in enumerate(dev_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            pred = model(data)\n",
    "            loss = loss_function(pred, target)\n",
    "\n",
    "            cur_dev_loss += loss.item()\n",
    "            new_dev_correct = calc_correct(pred, target)\n",
    "            for annotation in annotations:\n",
    "                new = new_dev_correct[annotation]\n",
    "                dev_correct[annotation][0] += new[0]\n",
    "                dev_correct[annotation][1] += new[1]\n",
    "            dev_correct['tot'][0] += new_dev_correct['tot'][0]\n",
    "            dev_correct['tot'][1] += new_dev_correct['tot'][1]\n",
    "            dev_correct['tot_strict'][0] += new_dev_correct['tot_strict'][0]\n",
    "            dev_correct['tot_strict'][1] += new_dev_correct['tot_strict'][1]\n",
    "            \n",
    "            evaluations = class_evaluation(pred, target)\n",
    "            evaluation[\"true_positive\"] += evaluations[\"true_positive\"]\n",
    "            evaluation[\"false_positive\"] += evaluations[\"false_positive\"]\n",
    "            evaluation[\"true_negative\"] += evaluations[\"true_negative\"]\n",
    "            evaluation[\"false_negative\"] += evaluations[\"false_negative\"]\n",
    "            evaluation[\"positive\"] += evaluations[\"positive\"]\n",
    "            evaluation[\"negative\"] += evaluations[\"negative\"]\n",
    "\n",
    "        current_loss = cur_dev_loss / (len(dev_loader) + 1)\n",
    "        dev_losses.append(current_loss)\n",
    "        current_accuracy = {annotation: 100. * dev_correct[annotation][0] / dev_correct[annotation][1]  for annotation in annotations}  # Accuracies for all classes \n",
    "        current_accuracy['tot'] = 100. * dev_correct['tot'][0] / dev_correct['tot'][1]\n",
    "        current_accuracy['tot_strict'] = 100. * dev_correct['tot_strict'][0] / dev_correct['tot_strict'][1]\n",
    "        dev_accuracies.append(current_accuracy)\n",
    "\n",
    "        if current_loss <= dev_loss:\n",
    "            dev_loss = current_loss\n",
    "        # else:\n",
    "        #     stop_early = True\n",
    "\n",
    "        print(\"------------------------\")\n",
    "        print('Evaluating: Batch %d/%d: Loss: %.4f | Dev Acc: %.3f%% (%d/%d) | Strict Acc: %.3f%% (%d/%d)' % \n",
    "            (batch_num+1, len(dev_loader), cur_dev_loss / (len(dev_loader) + 1), \n",
    "            100. * dev_correct['tot'][0] / dev_correct['tot'][1], dev_correct['tot'][0], dev_correct['tot'][1],\n",
    "            100. * dev_correct['tot_strict'][0] / dev_correct['tot_strict'][1], dev_correct['tot_strict'][0], dev_correct['tot_strict'][1]))\n",
    "        print('True positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_positive\"] / evaluation[\"positive\"], evaluation[\"true_positive\"], evaluation[\"positive\"]) )\n",
    "        print('False negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_negative\"] / evaluation[\"positive\"], evaluation[\"false_negative\"], evaluation[\"positive\"]) )\n",
    "        print('True negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_negative\"] / evaluation[\"negative\"], evaluation[\"true_negative\"], evaluation[\"negative\"]) )\n",
    "        print('False positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_positive\"] / evaluation[\"negative\"], evaluation[\"false_positive\"], evaluation[\"negative\"]) )\n",
    "        print(\"------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- test ---\n",
    "\n",
    "alexnet.eval()\n",
    "resnet.eval()\n",
    "\n",
    "test_loss = 0\n",
    "test_correct = {annotation: [0,0] for annotation in annotations}\n",
    "test_correct['tot'] = [0,0]\n",
    "test_correct['tot_strict'] = [0,0]\n",
    "evaluation = {\"true_positive\": 0,\n",
    "                    \"false_positive\": 0,\n",
    "                    \"true_negative\": 0,\n",
    "                    \"false_negative\": 0,\n",
    "                    \"negative\": 0,\n",
    "                    \"positive\": 0}\n",
    "\n",
    "evaluation_by_annotation = {}\n",
    "for a in range(len(annotations)):\n",
    "    evaluation_by_annotation[annotations[a]] = {\"true_positive\": 0,\n",
    "                                                \"false_positive\": 0,\n",
    "                                                \"true_negative\": 0,\n",
    "                                                \"false_negative\": 0,\n",
    "                                                \"negative\": 0,\n",
    "                                                \"positive\": 0}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_num, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        new_test_correct = calc_correct(pred, target)\n",
    "        for annotation in annotations:\n",
    "            new = new_test_correct[annotation]\n",
    "            test_correct[annotation][0] += new[0]\n",
    "            test_correct[annotation][1] += new[1]\n",
    "        test_correct['tot'][0] += new_test_correct['tot'][0]\n",
    "        test_correct['tot'][1] += new_test_correct['tot'][1]\n",
    "        test_correct['tot_strict'][0] += new_test_correct['tot_strict'][0]\n",
    "        test_correct['tot_strict'][1] += new_test_correct['tot_strict'][1]\n",
    "        \n",
    "        evaluations = class_evaluation(pred, target)\n",
    "        evaluation[\"true_positive\"] += evaluations[\"true_positive\"]\n",
    "        evaluation[\"false_positive\"] += evaluations[\"false_positive\"]\n",
    "        evaluation[\"true_negative\"] += evaluations[\"true_negative\"]\n",
    "        evaluation[\"false_negative\"] += evaluations[\"false_negative\"]\n",
    "        evaluation[\"positive\"] += evaluations[\"positive\"]\n",
    "        evaluation[\"negative\"] += evaluations[\"negative\"]\n",
    "        \n",
    "        evaluations_by_annotation = class_evaluation_by_annotation(pred, target)\n",
    "        print(evaluation_by_annotation)\n",
    "        \n",
    "        for a in range(len(annotations)):\n",
    "            evaluation_by_annotation[annotations[a]][\"true_positive\"] += evaluations_by_annotation[annotations[a]][\"true_positive\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"false_positive\"] += evaluations_by_annotation[annotations[a]][\"false_positive\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"true_negative\"] += evaluations_by_annotation[annotations[a]][\"true_negative\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"false_negative\"] += evaluations_by_annotation[annotations[a]][\"false_negative\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"positive\"] += evaluations_by_annotation[annotations[a]][\"positive\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"negative\"] += evaluations_by_annotation[annotations[a]][\"negative\"]\n",
    "        \n",
    "        print(\"------------------------\")\n",
    "        print('Evaluating: Batch %d/%d: Loss: %.4f | Test Acc: %.3f%% (%d/%d) | Strict Acc: %.3f%% (%d/%d)' % \n",
    "              (batch_num+1, len(test_loader), test_loss / (batch_num + 1), \n",
    "               100. * test_correct['tot'][0] / test_correct['tot'][1], test_correct['tot'][0], test_correct['tot'][1],\n",
    "               100. * test_correct['tot_strict'][0] / test_correct['tot_strict'][1], test_correct['tot_strict'][0], test_correct['tot_strict'][1]))\n",
    "        print('True positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_positive\"] / evaluation[\"positive\"], evaluation[\"true_positive\"], evaluation[\"positive\"]) )\n",
    "        print('False negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_negative\"] / evaluation[\"positive\"], evaluation[\"false_negative\"], evaluation[\"positive\"]) )\n",
    "        print('True negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_negative\"] / evaluation[\"negative\"], evaluation[\"true_negative\"], evaluation[\"negative\"]) )\n",
    "        print('False positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_positive\"] / evaluation[\"negative\"], evaluation[\"false_positive\"], evaluation[\"negative\"]) )\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "print(dev_losses)\n",
    "print(dev_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91378623",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in evaluation_by_annotation:\n",
    "    print(\"------------------------\")\n",
    "    print(i + \":\")\n",
    "    print(\"\")\n",
    "    print(\"positive: \" + str(evaluation_by_annotation[i][\"positive\"]))\n",
    "    print(\"true_positive: \" + str(evaluation_by_annotation[i][\"true_positive\"]))\n",
    "    print(\"false_negative: \" + str(evaluation_by_annotation[i][\"false_negative\"]))\n",
    "    print(\"\")\n",
    "    print(\"negative: \" + str(evaluation_by_annotation[i][\"negative\"]))\n",
    "    print(\"true_negative: \" + str(evaluation_by_annotation[i][\"true_negative\"]))\n",
    "    print(\"false_positive: \" + str(evaluation_by_annotation[i][\"false_positive\"]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ec63d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
