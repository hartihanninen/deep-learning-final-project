{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4547e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data for pytorch DataLoader\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "\n",
    "DATA_DIR = '../../dl2021-image-corpus-proj/'\n",
    "# DATA_DIR = '/Users/hartih/Documents/School/Deep learning/Final_project/dl2021-image-corpus-proj/'\n",
    "ANNOTATIONS_DIR = DATA_DIR + 'annotations/'\n",
    "IMAGES_DIR = DATA_DIR + 'images/'\n",
    "\n",
    "# New fodlers for train, test, and dev sets\n",
    "TRAIN_DIR = DATA_DIR + 'train/'\n",
    "DEV_DIR = DATA_DIR + 'dev/'\n",
    "TEST_DIR = DATA_DIR + 'test/'\n",
    "\n",
    "annotations = [\"baby\",\n",
    "               \"bird\",\n",
    "               \"car\",\n",
    "               \"clouds\",\n",
    "               \"dog\",\n",
    "               \"female\",\n",
    "               \"flower\",\n",
    "               \"male\",\n",
    "               \"night\",\n",
    "               \"people\",\n",
    "               \"portrait\",\n",
    "               \"river\",\n",
    "               \"sea\",\n",
    "               \"tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0729b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for images\n",
    "image_file_names = os.listdir(IMAGES_DIR)\n",
    "dict_labels = {}\n",
    "for image_file_name in image_file_names:  # Initiate label tensors\n",
    "    if os.path.isfile(IMAGES_DIR + image_file_name):\n",
    "        dict_labels[image_file_name] = torch.zeros(14)\n",
    "for i in range(len(annotations)):  # Fill label tensors with 1's if found in one of the annotations text files\n",
    "    with open(ANNOTATIONS_DIR + annotations[i] + \".txt\") as f:\n",
    "        for row in f:\n",
    "            row = \"im\" + row.strip() + \".jpg\"\n",
    "            dict_labels[row][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fe60c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'im1976.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12710.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17668.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10107.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11219.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19645.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16576.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19123.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16210.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10661.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3807.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8952.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im14407.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9494.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13368.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12076.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15719.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14413.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8946.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9480.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12062.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19137.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16204.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10675.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3813.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18229.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10113.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19889.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19651.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16562.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1962.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12704.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14375.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17654.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4832.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18567.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11225.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3185.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19679.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15043.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13432.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im1792.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13354.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7485.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im598.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6943.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15725.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10885.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11543.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im5292.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17132.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18201.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16238.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10891.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11557.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4198.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10649.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5286.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17126.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im18215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13340.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7491.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6957.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15731.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15057.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12738.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13426.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14349.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1786.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17640.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18573.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4826.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17898.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11231.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3191.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4615.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 'im17873.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19686.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18598.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2264.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9331.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6002.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im201.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im567.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8749.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8991.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im9457.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15902.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6764.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2502.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4173.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5279.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2516.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3608.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4167.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im573.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8985.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im15916.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9443.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6770.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9325.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6016.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1779.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7308.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4601.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17867.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19692.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im2270.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12937.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1751.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15080.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7320.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1989.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8013.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4629.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " 'im16589.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3146.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17697.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im2258.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5537.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19862.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5251.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im3620.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10846.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11580.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im12089.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7446.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8775.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6980.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1037.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13397.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6758.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7452.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8761.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6994.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1023.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im13383.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5245.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im3634.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10852.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11594.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3152.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17683.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19876.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5523.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9319.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12923.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1745.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im15094.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7334.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8007.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im229.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12274.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8588.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9696.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7863.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10463.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16012.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19321.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16774.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5912.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19447.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18981.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10305.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18759.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14163.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12512.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14177.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13618.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12506.jpg': tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15269.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16760.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19453.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5906.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18995.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im10311.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17318.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10477.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11769.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16006.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19335.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12260.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9682.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7877.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18003.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11999.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17330.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5090.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11741.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2927.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9872.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15527.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12248.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7687.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13156.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6599.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14639.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im942.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1590.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13630.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15241.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16748.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3387.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11027.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10339.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16990.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18765.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17456.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2099.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3393.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11033.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im16984.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18771.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17442.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1584.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13624.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15255.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15533.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9866.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 'im7693.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13142.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im956.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18017.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17324.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5084.jpg': tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11755.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2933.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im19309.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4371.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2700.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11966.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6566.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9655.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1209.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7678.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im765.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13817.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6200.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9133.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5709.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2066.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3378.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19484.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4417.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18942.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2072.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19490.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18956.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4403.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8239.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im13803.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6214.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9127.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6572.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9641.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9899.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im771.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4365.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2714.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11972.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9669.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13195.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1235.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im981.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8577.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im759.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14822.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7644.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11782.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3422.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5053.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5735.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16953.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17495.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3344.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8211.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7122.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15282.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1553.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8205.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7136.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im15296.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14188.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1547.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6228.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5721.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16947.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17481.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3350.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11796.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4359.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3436.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2728.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10488.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5047.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13181.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im995.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1221.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7888.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8563.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7650.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7917.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im14771.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12300.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16166.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19255.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11609.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10517.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17278.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10271.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im16600.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19533.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5866.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15309.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12466.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13778.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9084.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im14017.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12472.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9090.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14003.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18639.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10265.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im16614.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5872.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19527.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16172.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19241.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10503.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7903.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14765.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12314.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19269.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3595.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11635.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2853.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18177.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17244.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1382.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13022.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14995.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15453.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9906.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15335.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im188.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7095.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13744.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17522.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5682.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im11153.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17536.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10259.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im5696.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11147.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4588.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16628.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15321.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13988.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7081.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13750.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1396.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14759.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im822.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13036.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14981.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im12328.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9912.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15447.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3581.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11621.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2847.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18163.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17250.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2674.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18188.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11812.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19296.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4205.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6412.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9721.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6374.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9047.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13963.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im177.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8359.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4563.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2112.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4577.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18822.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3218.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2106.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5669.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6360.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9053.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13977.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im163.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7718.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1369.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6406.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9735.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2660.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11806.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19282.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4211.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14956.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8403.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7730.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15490.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1341.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5127.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17287.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2648.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16199.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3556.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4239.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2890.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11190.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5899.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3230.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5641.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16827.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13787.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6348.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1427.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8365.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12499.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7056.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13793.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1433.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8371.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im7042.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11184.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3224.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im5655.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16833.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5133.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17293.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3542.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2884.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8417.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im639.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14942.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7724.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15484.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1355.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " 'im9709.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9286.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1802.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8198.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im12664.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19731.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16402.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10073.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im50.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18349.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10715.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3973.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19057.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16364.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12102.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14573.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8826.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15679.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12116.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13208.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8832.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14567.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10701.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3967.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19043.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16370.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.]),\n",
       " 'im19725.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16416.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11379.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10067.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im44.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17708.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14201.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9292.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1816.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12670.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11351.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5480.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17720.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18413.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4946.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12880.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14229.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13546.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6189.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12658.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7297.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15137.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6837.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15651.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13220.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15889.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1180.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17046.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2489.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18375.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10729.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11437.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16358.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3797.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17052.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11423.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]),\n",
       " 'im3783.jpg': tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6823.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15645.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13234.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1194.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12894.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13552.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7283.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15123.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19719.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11345.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5494.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17734.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4952.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im78.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18407.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im93.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2310.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4761.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17907.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im375.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7268.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1619.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9245.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6176.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im15876.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9523.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6610.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im413.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4007.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19094.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3768.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2476.jpg': tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5319.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4013.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im19080.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2462.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9537.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15862.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6604.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im407.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8629.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9251.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6162.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im87.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2304.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4775.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17913.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7254.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8167.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im349.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12843.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1625.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13585.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9279.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im19916.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5443.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4985.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3032.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11392.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im3754.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10932.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17085.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5325.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1143.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im15692.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im7532.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8601.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6638.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1157.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.]),\n",
       " 'im14598.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15686.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7526.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8615.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im3740.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10926.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17091.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3998.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5331.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10098.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5457.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19902.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2338.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4991.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3026.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11386.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4749.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7240.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8173.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12857.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1631.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13591.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5330.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3999.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im17090.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10927.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3741.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8614.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7527.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15687.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1156.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14599.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6639.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13590.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1630.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12856.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8172.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7241.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11387.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4748.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3027.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4990.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2339.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10099.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5456.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19903.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11393.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3033.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4984.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19917.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5442.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9278.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]),\n",
       " 'im13584.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1624.jpg': tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12842.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8166.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im348.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7255.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8600.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7533.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15693.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1142.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5324.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17084.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10933.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3755.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im406.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8628.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6605.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9536.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15863.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2463.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19081.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4012.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17912.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4774.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2305.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im86.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6163.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im9250.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im360.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6177.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9244.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1618.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7269.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im374.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17906.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4760.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2311.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im92.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im5318.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2477.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3769.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19095.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4006.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im412.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6611.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15877.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9522.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im1195.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13235.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15644.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im6822.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3782.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11422.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18360.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17053.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im79.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im4953.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18406.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17735.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5495.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11344.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19718.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15122.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7282.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13553.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12895.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15136.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12659.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7296.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13547.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6188.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14228.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12881.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18412.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4947.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17721.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5481.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11350.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16359.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3796.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11436.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10728.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18374.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.]),\n",
       " 'im17047.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2488.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1181.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im15888.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13221.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15650.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6836.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16371.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19042.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3966.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10700.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8833.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14566.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13209.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12117.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15678.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12671.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1817.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9293.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14200.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]),\n",
       " 'im17709.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im45.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10066.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11378.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16417.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19724.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im51.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im10072.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16403.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im19730.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12665.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1803.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im8199.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9287.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im14214.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im14572.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im8827.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12103.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16365.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19056.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3972.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10714.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18348.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.]),\n",
       " 'im16832.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5654.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3225.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11185.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7043.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8370.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im1432.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13792.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im9708.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1354.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15485.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7725.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8416.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14943.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im638.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2885.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3543.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17292.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5132.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2891.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'im4238.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16198.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3557.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17286.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2649.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5126.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1340.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15491.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7731.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14957.jpg': tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8402.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12498.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7057.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8364.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im1426.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13786.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6349.jpg': tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im16826.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5640.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3231.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5898.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11191.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im162.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13976.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9052.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6361.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5668.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2107.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3219.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4576.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18823.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4210.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19283.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11807.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2661.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9734.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6407.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1368.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im604.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7719.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9720.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im6413.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im610.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4204.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19297.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18189.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11813.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2675.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im2113.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18837.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4562.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im176.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im8358.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13962.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9046.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6375.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13751.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im7080.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13989.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15320.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16629.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.]),\n",
       " 'im11146.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4589.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10258.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im5697.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17537.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18604.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17251.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18162.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2846.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11620.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im3580.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9913.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15446.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12329.jpg': tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14980.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im13037.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im823.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1397.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14758.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im15452.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9907.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14994.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13023.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1383.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im837.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17245.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18176.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2852.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11634.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im3594.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19268.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11152.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5683.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17523.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18610.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13745.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7094.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im189.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15334.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5873.jpg': tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im19526.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16615.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im10264.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im18638.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14002.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9091.jpg': tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im12473.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im12315.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14764.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7902.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10502.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19240.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16173.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17279.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10516.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11608.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19254.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16167.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12301.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im14770.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7916.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14016.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9085.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13779.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im12467.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15308.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19532.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5867.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im16601.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im10270.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3351.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im17480.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im16946.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5720.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im6229.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im14189.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1546.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15297.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im7137.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8204.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7651.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im14837.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8562.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im7889.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1220.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im994.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im13180.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im10489.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im5046.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im2729.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3437.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im11797.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4358.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5052.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3423.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im11783.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7645.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8576.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im14823.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im758.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im980.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im1234.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im13194.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9668.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1552.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15283.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7123.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im8210.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3345.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im17494.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16952.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im5734.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " 'im9126.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6215.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13802.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im8238.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18957.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4402.jpg': tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im19491.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im2073.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im11973.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2715.jpg': tensor([0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im4364.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im770.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9898.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9640.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im6573.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im764.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im7679.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im1208.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9654.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im6567.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im11967.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'im2701.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im4370.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im4416.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.]),\n",
       " 'im18943.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im19485.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im3379.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im2067.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im5708.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im9132.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im6201.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13816.jpg': tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im15254.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im13625.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im1585.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im17443.jpg': tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'im18770.jpg': tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'im16985.jpg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021ccf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train, test, and dev\n",
    "os.makedirs(TRAIN_DIR)\n",
    "os.makedirs(TEST_DIR)\n",
    "os.makedirs(DEV_DIR)\n",
    "for image_file_name in image_file_names:\n",
    "    if os.path.isfile(IMAGES_DIR + image_file_name):\n",
    "        division = random.randint(1, 4)\n",
    "        if division == 1 or division == 2:\n",
    "            shutil.copyfile(IMAGES_DIR + image_file_name, TRAIN_DIR + image_file_name)\n",
    "        if division == 3:\n",
    "            shutil.copyfile(IMAGES_DIR + image_file_name, DEV_DIR + image_file_name)\n",
    "        if division == 4:\n",
    "            shutil.copyfile(IMAGES_DIR + image_file_name, TEST_DIR + image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b380180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "5020\n",
      "9910\n",
      "5070\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print( len(os.listdir(TEST_DIR)) + len(os.listdir(TRAIN_DIR)) + len( os.listdir(DEV_DIR)) == len(os.listdir(IMAGES_DIR)) )\n",
    "print(len(os.listdir(TEST_DIR)))\n",
    "print(len(os.listdir(TRAIN_DIR)))\n",
    "print(len(os.listdir(DEV_DIR)))\n",
    "print(len(os.listdir(IMAGES_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db46e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "\n",
    "# Enable creating train, test, and dev test datasets for PyTorch\n",
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir=IMAGES_DIR, transform=None):\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.images = [root_dir + img for img in os.listdir(root_dir)]                \n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.images)       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img = img = Image.open(img_path)     \n",
    "       \n",
    "        if self.transform:\n",
    "            img = self.transform(img)     \n",
    "\n",
    "        return img, dict_labels[img_path.split(\"/\")[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f19ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.42986962, 0.42986962, 0.42986962]\n",
      "std: [0.2697042, 0.2697042, 0.2697042]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "#Calculate mean and std with whole dataset\n",
    "imageNet = False  # If imageNet is True, then we use the values from imagenet, else we calculate them from the dataset\n",
    "\n",
    "if imageNet:\n",
    "  mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]  # Imagenet mean and std\n",
    "else:\n",
    "  def mean_std(loader):\n",
    "    mean, std = 0, 0 \n",
    "    for batch_num, (images, labels) in enumerate(loader):\n",
    "    # images, labels = next(iter(loader))\n",
    "    # shape of images = [b,c,w,h]\n",
    "      mean += images.mean([0,2,3])\n",
    "      std += images.std([0,2,3]) \n",
    "      # mean, std = images.mean([0,2,3]), images.std([0,2,3]) \n",
    "    return mean/(batch_num+1), std/(batch_num+1)\n",
    "\n",
    "  mean_transform = transforms.Compose([\n",
    "                                          transforms.Grayscale(num_output_channels=3),\n",
    "                                          transforms.Resize(256),                    \n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "  #Splitting these was the easiest due to memory allocation problem, you could only used IMAGES_DIR if this is not a problem, note the equal divide\n",
    "  train_mean_set = myDataset(TRAIN_DIR, transform=mean_transform)\n",
    "  train_data_loader = torch.utils.data.DataLoader(dataset=train_mean_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "  dev_mean_set = myDataset(DEV_DIR, transform=mean_transform)\n",
    "  dev_data_loader = torch.utils.data.DataLoader(dataset=dev_mean_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "  test_mean_set = myDataset(TEST_DIR, transform=mean_transform)\n",
    "  test_data_loader = torch.utils.data.DataLoader(dataset=test_mean_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "  mean_train, std_train = mean_std(train_data_loader)\n",
    "  mean_dev, std_dev = mean_std(dev_data_loader)\n",
    "  mean_test, std_test = mean_std(test_data_loader)\n",
    "  mean = list((np.array(mean_train)+np.array(mean_dev)+np.array(mean_test))/3)\n",
    "  std = list((np.array(std_train)+np.array(std_dev)+np.array(std_test))/3)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"std:\", std)\n",
    "\n",
    "#Imagenet mean and std\n",
    "# mean = [0.485, 0.456, 0.406]\n",
    "# std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98e04313",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([            \n",
    "                                        transforms.Grayscale(num_output_channels=3),\n",
    "                                        transforms.Resize(256),                    \n",
    "                                        transforms.CenterCrop(224),                \n",
    "                                        transforms.ToTensor(),                     \n",
    "                                        transforms.Normalize(                      \n",
    "                                        mean=mean,                \n",
    "                                        std=std\n",
    "                                        )])\n",
    "\n",
    "test_transform = transforms.Compose([            \n",
    "                                        transforms.Grayscale(num_output_channels=3),\n",
    "                                        transforms.Resize(256),                    \n",
    "                                        transforms.CenterCrop(224),                \n",
    "                                        transforms.ToTensor(),                     \n",
    "                                        transforms.Normalize(                      \n",
    "                                        mean=mean,                \n",
    "                                        std=std\n",
    "                                        )])\n",
    "\n",
    "# Create datasets for CNN\n",
    "train_set = myDataset(TRAIN_DIR, transform=train_transform)\n",
    "test_set = myDataset(TEST_DIR, transform=train_transform)\n",
    "dev_set = myDataset(DEV_DIR, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa5543a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# Calculate the amount of correctly predicted as well as total predictions done\n",
    "def calc_correct(pred: torch.Tensor, target: torch.Tensor):\n",
    "    pred = torch.sigmoid(pred)  # Since our neural network does not apply sigmoid\n",
    "    correct_dict = {'tot': [0,0]}  # First number in value is correct ones, the second one is total amount\n",
    "    correct_dict['tot_strict'] = [0,0] # All correct\n",
    "    for i in range(len(pred)): # [100,14]\n",
    "        all_correct = 0\n",
    "        total = 0\n",
    "        # estim_pred_array = []\n",
    "        for j in range(len(pred[i])):\n",
    "            estim_pred = 0 if float(pred[i][j]) < 0.5 else 1\n",
    "            # estim_pred_array.append(estim_pred)\n",
    "            if annotations[j] not in correct_dict.keys():\n",
    "                correct_dict[annotations[j]] = [0,0]\n",
    "            correct_dict['tot'][1] += 1\n",
    "            correct_dict[annotations[j]][1] += 1\n",
    "            correct_dict['tot'][0] += int(estim_pred == target[i][j])\n",
    "            correct_dict[annotations[j]][0] += int(estim_pred == target[i][j])\n",
    "            all_correct += int(estim_pred == target[i][j])\n",
    "            total += 1\n",
    "        correct_dict['tot_strict'][1] += 1\n",
    "        correct_dict['tot_strict'][0] += int(total==all_correct)\n",
    "    # To-do how many pictures were entirely correct (accuracy)\n",
    "    return correct_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04e7e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_evaluation(pred: torch.Tensor, target: torch.Tensor):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    \n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    negative = 0\n",
    "    positive = 0\n",
    "    \n",
    "    for i in range(len(pred)): # [100,14]\n",
    "        for j in range(len(pred[i])):\n",
    "            estim_pred = 0 if float(pred[i][j]) < 0.5 else 1\n",
    "            \n",
    "            # Negative target values\n",
    "            if target[i][j] == 0:\n",
    "                negative += 1\n",
    "                if estim_pred == 1:\n",
    "                    false_positive += 1\n",
    "                if estim_pred == 0:\n",
    "                    true_negative += 1\n",
    "            \n",
    "            # Positive target values\n",
    "            if target[i][j] == 1:\n",
    "                positive += 1\n",
    "                if estim_pred == 1:\n",
    "                    true_positive += 1\n",
    "                if estim_pred == 0:\n",
    "                    false_negative += 1\n",
    "    \n",
    "    result = {\"true_positive\": true_positive,\n",
    "            \"false_positive\": false_positive,\n",
    "            \"true_negative\": true_negative,\n",
    "            \"false_negative\": false_negative,\n",
    "            \"negative\": negative,\n",
    "            \"positive\": positive}\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9035bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_evaluation_by_annotation(pred: torch.Tensor, target: torch.Tensor):\n",
    "    \n",
    "    pred = torch.sigmoid(pred)\n",
    "    \n",
    "    # Initiate vslues for every annotation\n",
    "    eval_dict = {}\n",
    "    for a in range(len(annotations)):\n",
    "        eval_dict[annotations[a]] = {\"true_positive\": 0,\n",
    "                                        \"false_positive\": 0,\n",
    "                                        \"true_negative\": 0,\n",
    "                                        \"false_negative\": 0,\n",
    "                                        \"negative\": 0,\n",
    "                                        \"positive\": 0}\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        for j in range(len(pred[i])):\n",
    "            estim_pred = 0 if float(pred[i][j]) < 0.5 else 1\n",
    "            \n",
    "            # Negative target values\n",
    "            if target[i][j] == 0:\n",
    "                eval_dict[annotations[j]][\"negative\"] += 1\n",
    "                if estim_pred == 1:\n",
    "                    eval_dict[annotations[j]][\"false_positive\"] += 1\n",
    "                if estim_pred == 0:\n",
    "                    eval_dict[annotations[j]][\"true_negative\"] += 1\n",
    "            \n",
    "            # Positive target values\n",
    "            if target[i][j] == 1:\n",
    "                eval_dict[annotations[j]][\"positive\"] += 1\n",
    "                if estim_pred == 1:\n",
    "                    eval_dict[annotations[j]][\"true_positive\"] += 1\n",
    "                if estim_pred == 0:\n",
    "                    eval_dict[annotations[j]][\"false_negative\"] += 1\n",
    "                    \n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ccd4ed4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juhan\\anaconda3\\envs\\pytorch3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\juhan\\anaconda3\\envs\\pytorch3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\juhan\\anaconda3\\envs\\pytorch3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Training: Epoch 1 - Batch 1/100: Loss: 0.7077 | Train Acc: 40.571% (568/1400) | Strict Acc: 0.000% (0/100)\n",
      "True positive rate: 58.929% (66/112)\n",
      "False negative rate: 41.071% (46/112)\n",
      "True negative rate: 38.975% (502/1288)\n",
      "False positive rate: 61.025% (786/1288)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 2/100: Loss: 0.5342 | Train Acc: 66.679% (1867/2800) | Strict Acc: 25.000% (50/200)\n",
      "True positive rate: 30.986% (66/213)\n",
      "False negative rate: 69.014% (147/213)\n",
      "True negative rate: 69.617% (1801/2587)\n",
      "False positive rate: 30.383% (786/2587)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 3/100: Loss: 0.6187 | Train Acc: 75.452% (3169/4200) | Strict Acc: 33.000% (99/300)\n",
      "True positive rate: 21.222% (66/311)\n",
      "False negative rate: 78.778% (245/311)\n",
      "True negative rate: 79.789% (3103/3889)\n",
      "False positive rate: 20.211% (786/3889)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 4/100: Loss: 0.5795 | Train Acc: 78.964% (4422/5600) | Strict Acc: 25.500% (102/400)\n",
      "True positive rate: 24.318% (107/440)\n",
      "False negative rate: 75.682% (333/440)\n",
      "True negative rate: 83.624% (4315/5160)\n",
      "False positive rate: 16.376% (845/5160)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 5/100: Loss: 0.5300 | Train Acc: 80.586% (5641/7000) | Strict Acc: 22.800% (114/500)\n",
      "True positive rate: 31.041% (167/538)\n",
      "False negative rate: 68.959% (371/538)\n",
      "True negative rate: 84.711% (5474/6462)\n",
      "False positive rate: 15.289% (988/6462)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 6/100: Loss: 0.4904 | Train Acc: 81.214% (6822/8400) | Strict Acc: 20.667% (124/600)\n",
      "True positive rate: 37.147% (237/638)\n",
      "False negative rate: 62.853% (401/638)\n",
      "True negative rate: 84.836% (6585/7762)\n",
      "False positive rate: 15.164% (1177/7762)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 7/100: Loss: 0.4593 | Train Acc: 82.408% (8076/9800) | Strict Acc: 20.286% (142/700)\n",
      "True positive rate: 35.553% (267/751)\n",
      "False negative rate: 64.447% (484/751)\n",
      "True negative rate: 86.297% (7809/9049)\n",
      "False positive rate: 13.703% (1240/9049)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 8/100: Loss: 0.4287 | Train Acc: 83.786% (9384/11200) | Strict Acc: 23.625% (189/800)\n",
      "True positive rate: 32.779% (276/842)\n",
      "False negative rate: 67.221% (566/842)\n",
      "True negative rate: 87.932% (9108/10358)\n",
      "False positive rate: 12.068% (1250/10358)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 9/100: Loss: 0.4062 | Train Acc: 84.683% (10670/12600) | Strict Acc: 25.889% (233/900)\n",
      "True positive rate: 28.870% (276/956)\n",
      "False negative rate: 71.130% (680/956)\n",
      "True negative rate: 89.265% (10394/11644)\n",
      "False positive rate: 10.735% (1250/11644)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 10/100: Loss: 0.3863 | Train Acc: 85.500% (11970/14000) | Strict Acc: 28.500% (285/1000)\n",
      "True positive rate: 26.136% (276/1056)\n",
      "False negative rate: 73.864% (780/1056)\n",
      "True negative rate: 90.343% (11694/12944)\n",
      "False positive rate: 9.657% (1250/12944)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 11/100: Loss: 0.3696 | Train Acc: 86.182% (13272/15400) | Strict Acc: 30.273% (333/1100)\n",
      "True positive rate: 24.180% (280/1158)\n",
      "False negative rate: 75.820% (878/1158)\n",
      "True negative rate: 91.223% (12992/14242)\n",
      "False positive rate: 8.777% (1250/14242)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 12/100: Loss: 0.3527 | Train Acc: 86.917% (14602/16800) | Strict Acc: 32.333% (388/1200)\n",
      "True positive rate: 23.697% (291/1228)\n",
      "False negative rate: 76.303% (937/1228)\n",
      "True negative rate: 91.902% (14311/15572)\n",
      "False positive rate: 8.098% (1261/15572)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 13/100: Loss: 0.3384 | Train Acc: 87.462% (15918/18200) | Strict Acc: 32.769% (426/1300)\n",
      "True positive rate: 23.708% (312/1316)\n",
      "False negative rate: 76.292% (1004/1316)\n",
      "True negative rate: 92.431% (15606/16884)\n",
      "False positive rate: 7.569% (1278/16884)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 14/100: Loss: 0.3261 | Train Acc: 87.954% (17239/19600) | Strict Acc: 33.500% (469/1400)\n",
      "True positive rate: 24.062% (340/1413)\n",
      "False negative rate: 75.938% (1073/1413)\n",
      "True negative rate: 92.918% (16899/18187)\n",
      "False positive rate: 7.082% (1288/18187)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 15/100: Loss: 0.3135 | Train Acc: 88.410% (18566/21000) | Strict Acc: 34.733% (521/1500)\n",
      "True positive rate: 25.215% (381/1511)\n",
      "False negative rate: 74.785% (1130/1511)\n",
      "True negative rate: 93.309% (18185/19489)\n",
      "False positive rate: 6.691% (1304/19489)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 16/100: Loss: 0.3032 | Train Acc: 88.804% (19892/22400) | Strict Acc: 35.938% (575/1600)\n",
      "True positive rate: 26.349% (420/1594)\n",
      "False negative rate: 73.651% (1174/1594)\n",
      "True negative rate: 93.588% (19472/20806)\n",
      "False positive rate: 6.412% (1334/20806)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 17/100: Loss: 0.2948 | Train Acc: 89.101% (21206/23800) | Strict Acc: 36.882% (627/1700)\n",
      "True positive rate: 27.592% (471/1707)\n",
      "False negative rate: 72.408% (1236/1707)\n",
      "True negative rate: 93.853% (20735/22093)\n",
      "False positive rate: 6.147% (1358/22093)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 18/100: Loss: 0.2864 | Train Acc: 89.373% (22522/25200) | Strict Acc: 37.667% (678/1800)\n",
      "True positive rate: 28.540% (518/1815)\n",
      "False negative rate: 71.460% (1297/1815)\n",
      "True negative rate: 94.095% (22004/23385)\n",
      "False positive rate: 5.905% (1381/23385)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 19/100: Loss: 0.2804 | Train Acc: 89.605% (23835/26600) | Strict Acc: 38.053% (723/1900)\n",
      "True positive rate: 29.195% (562/1925)\n",
      "False negative rate: 70.805% (1363/1925)\n",
      "True negative rate: 94.318% (23273/24675)\n",
      "False positive rate: 5.682% (1402/24675)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 20/100: Loss: 0.2735 | Train Acc: 89.832% (25153/28000) | Strict Acc: 38.700% (774/2000)\n",
      "True positive rate: 29.754% (604/2030)\n",
      "False negative rate: 70.246% (1426/2030)\n",
      "True negative rate: 94.528% (24549/25970)\n",
      "False positive rate: 5.472% (1421/25970)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 21/100: Loss: 0.2672 | Train Acc: 90.075% (26482/29400) | Strict Acc: 39.286% (825/2100)\n",
      "True positive rate: 30.336% (641/2113)\n",
      "False negative rate: 69.664% (1472/2113)\n",
      "True negative rate: 94.701% (25841/27287)\n",
      "False positive rate: 5.299% (1446/27287)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 22/100: Loss: 0.2614 | Train Acc: 90.250% (27797/30800) | Strict Acc: 39.455% (868/2200)\n",
      "True positive rate: 31.971% (712/2227)\n",
      "False negative rate: 68.029% (1515/2227)\n",
      "True negative rate: 94.792% (27085/28573)\n",
      "False positive rate: 5.208% (1488/28573)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 23/100: Loss: 0.2568 | Train Acc: 90.413% (29113/32200) | Strict Acc: 39.478% (908/2300)\n",
      "True positive rate: 32.845% (762/2320)\n",
      "False negative rate: 67.155% (1558/2320)\n",
      "True negative rate: 94.883% (28351/29880)\n",
      "False positive rate: 5.117% (1529/29880)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 24/100: Loss: 0.2521 | Train Acc: 90.586% (30437/33600) | Strict Acc: 39.875% (957/2400)\n",
      "True positive rate: 33.909% (825/2433)\n",
      "False negative rate: 66.091% (1608/2433)\n",
      "True negative rate: 95.011% (29612/31167)\n",
      "False positive rate: 4.989% (1555/31167)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 25/100: Loss: 0.2486 | Train Acc: 90.731% (31756/35000) | Strict Acc: 40.200% (1005/2500)\n",
      "True positive rate: 34.300% (875/2551)\n",
      "False negative rate: 65.700% (1676/2551)\n",
      "True negative rate: 95.168% (30881/32449)\n",
      "False positive rate: 4.832% (1568/32449)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 26/100: Loss: 0.2453 | Train Acc: 90.860% (33073/36400) | Strict Acc: 40.423% (1051/2600)\n",
      "True positive rate: 34.835% (928/2664)\n",
      "False negative rate: 65.165% (1736/2664)\n",
      "True negative rate: 95.284% (32145/33736)\n",
      "False positive rate: 4.716% (1591/33736)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 27/100: Loss: 0.2419 | Train Acc: 90.989% (34394/37800) | Strict Acc: 40.704% (1099/2700)\n",
      "True positive rate: 35.217% (972/2760)\n",
      "False negative rate: 64.783% (1788/2760)\n",
      "True negative rate: 95.382% (33422/35040)\n",
      "False positive rate: 4.618% (1618/35040)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 28/100: Loss: 0.2381 | Train Acc: 91.130% (35723/39200) | Strict Acc: 41.036% (1149/2800)\n",
      "True positive rate: 35.819% (1028/2870)\n",
      "False negative rate: 64.181% (1842/2870)\n",
      "True negative rate: 95.500% (34695/36330)\n",
      "False positive rate: 4.500% (1635/36330)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 29/100: Loss: 0.2337 | Train Acc: 91.315% (37074/40600) | Strict Acc: 41.724% (1210/2900)\n",
      "True positive rate: 36.563% (1083/2962)\n",
      "False negative rate: 63.437% (1879/2962)\n",
      "True negative rate: 95.624% (35991/37638)\n",
      "False positive rate: 4.376% (1647/37638)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 30/100: Loss: 0.2311 | Train Acc: 91.414% (38394/42000) | Strict Acc: 42.000% (1260/3000)\n",
      "True positive rate: 36.919% (1136/3077)\n",
      "False negative rate: 63.081% (1941/3077)\n",
      "True negative rate: 95.722% (37258/38923)\n",
      "False positive rate: 4.278% (1665/38923)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 31/100: Loss: 0.2280 | Train Acc: 91.532% (39725/43400) | Strict Acc: 42.323% (1312/3100)\n",
      "True positive rate: 37.744% (1201/3182)\n",
      "False negative rate: 62.256% (1981/3182)\n",
      "True negative rate: 95.788% (38524/40218)\n",
      "False positive rate: 4.212% (1694/40218)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 32/100: Loss: 0.2251 | Train Acc: 91.629% (41050/44800) | Strict Acc: 42.625% (1364/3200)\n",
      "True positive rate: 37.927% (1244/3280)\n",
      "False negative rate: 62.073% (2036/3280)\n",
      "True negative rate: 95.872% (39806/41520)\n",
      "False positive rate: 4.128% (1714/41520)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 33/100: Loss: 0.2226 | Train Acc: 91.714% (42372/46200) | Strict Acc: 42.758% (1411/3300)\n",
      "True positive rate: 38.455% (1304/3391)\n",
      "False negative rate: 61.545% (2087/3391)\n",
      "True negative rate: 95.933% (41068/42809)\n",
      "False positive rate: 4.067% (1741/42809)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 34/100: Loss: 0.2203 | Train Acc: 91.779% (43687/47600) | Strict Acc: 42.941% (1460/3400)\n",
      "True positive rate: 39.055% (1372/3513)\n",
      "False negative rate: 60.945% (2141/3513)\n",
      "True negative rate: 95.981% (42315/44087)\n",
      "False positive rate: 4.019% (1772/44087)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 35/100: Loss: 0.2176 | Train Acc: 91.882% (45022/49000) | Strict Acc: 43.286% (1515/3500)\n",
      "True positive rate: 39.502% (1428/3615)\n",
      "False negative rate: 60.498% (2187/3615)\n",
      "True negative rate: 96.054% (43594/45385)\n",
      "False positive rate: 3.946% (1791/45385)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 36/100: Loss: 0.2153 | Train Acc: 91.966% (46351/50400) | Strict Acc: 43.611% (1570/3600)\n",
      "True positive rate: 39.644% (1472/3713)\n",
      "False negative rate: 60.356% (2241/3713)\n",
      "True negative rate: 96.127% (44879/46687)\n",
      "False positive rate: 3.873% (1808/46687)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 37/100: Loss: 0.2134 | Train Acc: 92.014% (47663/51800) | Strict Acc: 43.622% (1614/3700)\n",
      "True positive rate: 39.624% (1518/3831)\n",
      "False negative rate: 60.376% (2313/3831)\n",
      "True negative rate: 96.198% (46145/47969)\n",
      "False positive rate: 3.802% (1824/47969)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 38/100: Loss: 0.2115 | Train Acc: 92.085% (48989/53200) | Strict Acc: 43.763% (1663/3800)\n",
      "True positive rate: 40.056% (1585/3957)\n",
      "False negative rate: 59.944% (2372/3957)\n",
      "True negative rate: 96.265% (47404/49243)\n",
      "False positive rate: 3.735% (1839/49243)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 39/100: Loss: 0.2097 | Train Acc: 92.141% (50309/54600) | Strict Acc: 43.821% (1709/3900)\n",
      "True positive rate: 40.339% (1643/4073)\n",
      "False negative rate: 59.661% (2430/4073)\n",
      "True negative rate: 96.317% (48666/50527)\n",
      "False positive rate: 3.683% (1861/50527)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 40/100: Loss: 0.2078 | Train Acc: 92.205% (51635/56000) | Strict Acc: 43.900% (1756/4000)\n",
      "True positive rate: 40.634% (1692/4164)\n",
      "False negative rate: 59.366% (2472/4164)\n",
      "True negative rate: 96.348% (49943/51836)\n",
      "False positive rate: 3.652% (1893/51836)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 41/100: Loss: 0.2057 | Train Acc: 92.282% (52970/57400) | Strict Acc: 44.122% (1809/4100)\n",
      "True positive rate: 40.977% (1744/4256)\n",
      "False negative rate: 59.023% (2512/4256)\n",
      "True negative rate: 96.391% (51226/53144)\n",
      "False positive rate: 3.609% (1918/53144)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 42/100: Loss: 0.2042 | Train Acc: 92.325% (54287/58800) | Strict Acc: 44.143% (1854/4200)\n",
      "True positive rate: 41.144% (1798/4370)\n",
      "False negative rate: 58.856% (2572/4370)\n",
      "True negative rate: 96.434% (52489/54430)\n",
      "False positive rate: 3.566% (1941/54430)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 43/100: Loss: 0.2029 | Train Acc: 92.352% (55596/60200) | Strict Acc: 44.140% (1898/4300)\n",
      "True positive rate: 41.071% (1840/4480)\n",
      "False negative rate: 58.929% (2640/4480)\n",
      "True negative rate: 96.475% (53756/55720)\n",
      "False positive rate: 3.525% (1964/55720)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 44/100: Loss: 0.2012 | Train Acc: 92.399% (56918/61600) | Strict Acc: 44.341% (1951/4400)\n",
      "True positive rate: 41.156% (1887/4585)\n",
      "False negative rate: 58.844% (2698/4585)\n",
      "True negative rate: 96.520% (55031/57015)\n",
      "False positive rate: 3.480% (1984/57015)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 45/100: Loss: 0.1996 | Train Acc: 92.451% (58244/63000) | Strict Acc: 44.578% (2006/4500)\n",
      "True positive rate: 41.271% (1936/4691)\n",
      "False negative rate: 58.729% (2755/4691)\n",
      "True negative rate: 96.568% (56308/58309)\n",
      "False positive rate: 3.432% (2001/58309)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 46/100: Loss: 0.1980 | Train Acc: 92.514% (59579/64400) | Strict Acc: 44.717% (2057/4600)\n",
      "True positive rate: 41.381% (1983/4792)\n",
      "False negative rate: 58.619% (2809/4792)\n",
      "True negative rate: 96.625% (57596/59608)\n",
      "False positive rate: 3.375% (2012/59608)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 47/100: Loss: 0.1961 | Train Acc: 92.574% (60914/65800) | Strict Acc: 44.979% (2114/4700)\n",
      "True positive rate: 41.639% (2037/4892)\n",
      "False negative rate: 58.361% (2855/4892)\n",
      "True negative rate: 96.665% (58877/60908)\n",
      "False positive rate: 3.335% (2031/60908)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 48/100: Loss: 0.1943 | Train Acc: 92.653% (62263/67200) | Strict Acc: 45.292% (2174/4800)\n",
      "True positive rate: 41.946% (2091/4985)\n",
      "False negative rate: 58.054% (2894/4985)\n",
      "True negative rate: 96.716% (60172/62215)\n",
      "False positive rate: 3.284% (2043/62215)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 49/100: Loss: 0.1934 | Train Acc: 92.682% (63580/68600) | Strict Acc: 45.286% (2219/4900)\n",
      "True positive rate: 42.287% (2160/5108)\n",
      "False negative rate: 57.713% (2948/5108)\n",
      "True negative rate: 96.737% (61420/63492)\n",
      "False positive rate: 3.263% (2072/63492)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 50/100: Loss: 0.1924 | Train Acc: 92.709% (64896/70000) | Strict Acc: 45.320% (2266/5000)\n",
      "True positive rate: 42.404% (2208/5207)\n",
      "False negative rate: 57.596% (2999/5207)\n",
      "True negative rate: 96.751% (62688/64793)\n",
      "False positive rate: 3.249% (2105/64793)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 51/100: Loss: 0.1914 | Train Acc: 92.742% (66218/71400) | Strict Acc: 45.333% (2312/5100)\n",
      "True positive rate: 42.567% (2265/5321)\n",
      "False negative rate: 57.433% (3056/5321)\n",
      "True negative rate: 96.783% (63953/66079)\n",
      "False positive rate: 3.217% (2126/66079)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 52/100: Loss: 0.1903 | Train Acc: 92.786% (67548/72800) | Strict Acc: 45.519% (2367/5200)\n",
      "True positive rate: 42.759% (2312/5407)\n",
      "False negative rate: 57.241% (3095/5407)\n",
      "True negative rate: 96.799% (65236/67393)\n",
      "False positive rate: 3.201% (2157/67393)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 53/100: Loss: 0.1892 | Train Acc: 92.830% (68880/74200) | Strict Acc: 45.642% (2419/5300)\n",
      "True positive rate: 42.805% (2353/5497)\n",
      "False negative rate: 57.195% (3144/5497)\n",
      "True negative rate: 96.833% (66527/68703)\n",
      "False positive rate: 3.167% (2176/68703)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 54/100: Loss: 0.1875 | Train Acc: 92.902% (70234/75600) | Strict Acc: 46.111% (2490/5400)\n",
      "True positive rate: 43.003% (2400/5581)\n",
      "False negative rate: 56.997% (3181/5581)\n",
      "True negative rate: 96.879% (67834/70019)\n",
      "False positive rate: 3.121% (2185/70019)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 55/100: Loss: 0.1864 | Train Acc: 92.940% (71564/77000) | Strict Acc: 46.255% (2544/5500)\n",
      "True positive rate: 43.054% (2442/5672)\n",
      "False negative rate: 56.946% (3230/5672)\n",
      "True negative rate: 96.907% (69122/71328)\n",
      "False positive rate: 3.093% (2206/71328)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 56/100: Loss: 0.1854 | Train Acc: 92.972% (72890/78400) | Strict Acc: 46.464% (2602/5600)\n",
      "True positive rate: 42.946% (2475/5763)\n",
      "False negative rate: 57.054% (3288/5763)\n",
      "True negative rate: 96.941% (70415/72637)\n",
      "False positive rate: 3.059% (2222/72637)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 57/100: Loss: 0.1844 | Train Acc: 93.003% (74216/79800) | Strict Acc: 46.544% (2653/5700)\n",
      "True positive rate: 43.022% (2531/5883)\n",
      "False negative rate: 56.978% (3352/5883)\n",
      "True negative rate: 96.980% (71685/73917)\n",
      "False positive rate: 3.020% (2232/73917)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 58/100: Loss: 0.1836 | Train Acc: 93.026% (75537/81200) | Strict Acc: 46.586% (2702/5800)\n",
      "True positive rate: 42.919% (2573/5995)\n",
      "False negative rate: 57.081% (3422/5995)\n",
      "True negative rate: 97.020% (72964/75205)\n",
      "False positive rate: 2.980% (2241/75205)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 59/100: Loss: 0.1829 | Train Acc: 93.047% (76857/82600) | Strict Acc: 46.644% (2752/5900)\n",
      "True positive rate: 43.083% (2638/6123)\n",
      "False negative rate: 56.917% (3485/6123)\n",
      "True negative rate: 97.047% (74219/76477)\n",
      "False positive rate: 2.953% (2258/76477)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 60/100: Loss: 0.1820 | Train Acc: 93.075% (78183/84000) | Strict Acc: 46.717% (2803/6000)\n",
      "True positive rate: 43.191% (2683/6212)\n",
      "False negative rate: 56.809% (3529/6212)\n",
      "True negative rate: 97.059% (75500/77788)\n",
      "False positive rate: 2.941% (2288/77788)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 61/100: Loss: 0.1814 | Train Acc: 93.103% (79510/85400) | Strict Acc: 46.820% (2856/6100)\n",
      "True positive rate: 43.528% (2751/6320)\n",
      "False negative rate: 56.472% (3569/6320)\n",
      "True negative rate: 97.065% (76759/79080)\n",
      "False positive rate: 2.935% (2321/79080)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 62/100: Loss: 0.1805 | Train Acc: 93.132% (80839/86800) | Strict Acc: 46.855% (2905/6200)\n",
      "True positive rate: 43.761% (2802/6403)\n",
      "False negative rate: 56.239% (3601/6403)\n",
      "True negative rate: 97.065% (78037/80397)\n",
      "False positive rate: 2.935% (2360/80397)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 63/100: Loss: 0.1794 | Train Acc: 93.169% (82175/88200) | Strict Acc: 46.984% (2960/6300)\n",
      "True positive rate: 44.119% (2873/6512)\n",
      "False negative rate: 55.881% (3639/6512)\n",
      "True negative rate: 97.079% (79302/81688)\n",
      "False positive rate: 2.921% (2386/81688)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 64/100: Loss: 0.1785 | Train Acc: 93.199% (83506/89600) | Strict Acc: 47.078% (3013/6400)\n",
      "True positive rate: 44.366% (2937/6620)\n",
      "False negative rate: 55.634% (3683/6620)\n",
      "True negative rate: 97.094% (80569/82980)\n",
      "False positive rate: 2.906% (2411/82980)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 65/100: Loss: 0.1779 | Train Acc: 93.229% (84838/91000) | Strict Acc: 47.215% (3069/6500)\n",
      "True positive rate: 44.522% (2995/6727)\n",
      "False negative rate: 55.478% (3732/6727)\n",
      "True negative rate: 97.117% (81843/84273)\n",
      "False positive rate: 2.883% (2430/84273)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 66/100: Loss: 0.1773 | Train Acc: 93.244% (86157/92400) | Strict Acc: 47.227% (3117/6600)\n",
      "True positive rate: 44.561% (3048/6840)\n",
      "False negative rate: 55.439% (3792/6840)\n",
      "True negative rate: 97.135% (83109/85560)\n",
      "False positive rate: 2.865% (2451/85560)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 67/100: Loss: 0.1762 | Train Acc: 93.287% (87503/93800) | Strict Acc: 47.493% (3182/6700)\n",
      "True positive rate: 44.630% (3092/6928)\n",
      "False negative rate: 55.370% (3836/6928)\n",
      "True negative rate: 97.167% (84411/86872)\n",
      "False positive rate: 2.833% (2461/86872)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 68/100: Loss: 0.1752 | Train Acc: 93.327% (88847/95200) | Strict Acc: 47.676% (3242/6800)\n",
      "True positive rate: 44.717% (3136/7013)\n",
      "False negative rate: 55.283% (3877/7013)\n",
      "True negative rate: 97.192% (85711/88187)\n",
      "False positive rate: 2.808% (2476/88187)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 69/100: Loss: 0.1745 | Train Acc: 93.359% (90185/96600) | Strict Acc: 47.841% (3301/6900)\n",
      "True positive rate: 44.745% (3180/7107)\n",
      "False negative rate: 55.255% (3927/7107)\n",
      "True negative rate: 97.220% (87005/89493)\n",
      "False positive rate: 2.780% (2488/89493)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 70/100: Loss: 0.1736 | Train Acc: 93.393% (91525/98000) | Strict Acc: 47.971% (3358/7000)\n",
      "True positive rate: 44.773% (3225/7203)\n",
      "False negative rate: 55.227% (3978/7203)\n",
      "True negative rate: 97.250% (88300/90797)\n",
      "False positive rate: 2.750% (2497/90797)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 71/100: Loss: 0.1727 | Train Acc: 93.427% (92866/99400) | Strict Acc: 48.141% (3418/7100)\n",
      "True positive rate: 44.812% (3269/7295)\n",
      "False negative rate: 55.188% (4026/7295)\n",
      "True negative rate: 97.277% (89597/92105)\n",
      "False positive rate: 2.723% (2508/92105)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 72/100: Loss: 0.1719 | Train Acc: 93.461% (94209/100800) | Strict Acc: 48.250% (3474/7200)\n",
      "True positive rate: 44.881% (3314/7384)\n",
      "False negative rate: 55.119% (4070/7384)\n",
      "True negative rate: 97.301% (90895/93416)\n",
      "False positive rate: 2.699% (2521/93416)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 73/100: Loss: 0.1712 | Train Acc: 93.489% (95546/102200) | Strict Acc: 48.370% (3531/7300)\n",
      "True positive rate: 44.981% (3361/7472)\n",
      "False negative rate: 55.019% (4111/7472)\n",
      "True negative rate: 97.315% (92185/94728)\n",
      "False positive rate: 2.685% (2543/94728)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 74/100: Loss: 0.1708 | Train Acc: 93.513% (96879/103600) | Strict Acc: 48.459% (3586/7400)\n",
      "True positive rate: 45.000% (3411/7580)\n",
      "False negative rate: 55.000% (4169/7580)\n",
      "True negative rate: 97.342% (93468/96020)\n",
      "False positive rate: 2.658% (2552/96020)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 75/100: Loss: 0.1705 | Train Acc: 93.523% (98199/105000) | Strict Acc: 48.507% (3638/7500)\n",
      "True positive rate: 45.073% (3472/7703)\n",
      "False negative rate: 54.927% (4231/7703)\n",
      "True negative rate: 97.359% (94727/97297)\n",
      "False positive rate: 2.641% (2570/97297)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 76/100: Loss: 0.1702 | Train Acc: 93.537% (99523/106400) | Strict Acc: 48.553% (3690/7600)\n",
      "True positive rate: 45.085% (3518/7803)\n",
      "False negative rate: 54.915% (4285/7803)\n",
      "True negative rate: 97.371% (96005/98597)\n",
      "False positive rate: 2.629% (2592/98597)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 77/100: Loss: 0.1695 | Train Acc: 93.567% (100865/107800) | Strict Acc: 48.714% (3751/7700)\n",
      "True positive rate: 45.371% (3587/7906)\n",
      "False negative rate: 54.629% (4319/7906)\n",
      "True negative rate: 97.381% (97278/99894)\n",
      "False positive rate: 2.619% (2616/99894)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 78/100: Loss: 0.1688 | Train Acc: 93.589% (102199/109200) | Strict Acc: 48.833% (3809/7800)\n",
      "True positive rate: 45.538% (3633/7978)\n",
      "False negative rate: 54.462% (4345/7978)\n",
      "True negative rate: 97.376% (98566/101222)\n",
      "False positive rate: 2.624% (2656/101222)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 79/100: Loss: 0.1682 | Train Acc: 93.609% (103532/110600) | Strict Acc: 48.949% (3867/7900)\n",
      "True positive rate: 45.682% (3692/8082)\n",
      "False negative rate: 54.318% (4390/8082)\n",
      "True negative rate: 97.388% (99840/102518)\n",
      "False positive rate: 2.612% (2678/102518)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 80/100: Loss: 0.1675 | Train Acc: 93.633% (104869/112000) | Strict Acc: 49.087% (3927/8000)\n",
      "True positive rate: 45.804% (3750/8187)\n",
      "False negative rate: 54.196% (4437/8187)\n",
      "True negative rate: 97.405% (101119/103813)\n",
      "False positive rate: 2.595% (2694/103813)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 81/100: Loss: 0.1666 | Train Acc: 93.666% (106217/113400) | Strict Acc: 49.247% (3989/8100)\n",
      "True positive rate: 46.009% (3816/8294)\n",
      "False negative rate: 53.991% (4478/8294)\n",
      "True negative rate: 97.426% (102401/105106)\n",
      "False positive rate: 2.574% (2705/105106)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 82/100: Loss: 0.1659 | Train Acc: 93.688% (107554/114800) | Strict Acc: 49.402% (4051/8200)\n",
      "True positive rate: 46.125% (3874/8399)\n",
      "False negative rate: 53.875% (4525/8399)\n",
      "True negative rate: 97.443% (103680/106401)\n",
      "False positive rate: 2.557% (2721/106401)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 83/100: Loss: 0.1652 | Train Acc: 93.711% (108892/116200) | Strict Acc: 49.590% (4116/8300)\n",
      "True positive rate: 46.208% (3930/8505)\n",
      "False negative rate: 53.792% (4575/8505)\n",
      "True negative rate: 97.462% (104962/107695)\n",
      "False positive rate: 2.538% (2733/107695)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 84/100: Loss: 0.1648 | Train Acc: 93.737% (110235/117600) | Strict Acc: 49.738% (4178/8400)\n",
      "True positive rate: 46.386% (3998/8619)\n",
      "False negative rate: 53.614% (4621/8619)\n",
      "True negative rate: 97.482% (106237/108981)\n",
      "False positive rate: 2.518% (2744/108981)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 85/100: Loss: 0.1644 | Train Acc: 93.755% (111569/119000) | Strict Acc: 49.800% (4233/8500)\n",
      "True positive rate: 46.490% (4053/8718)\n",
      "False negative rate: 53.510% (4665/8718)\n",
      "True negative rate: 97.492% (107516/110282)\n",
      "False positive rate: 2.508% (2766/110282)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 86/100: Loss: 0.1637 | Train Acc: 93.787% (112920/120400) | Strict Acc: 50.000% (4300/8600)\n",
      "True positive rate: 46.785% (4125/8817)\n",
      "False negative rate: 53.215% (4692/8817)\n",
      "True negative rate: 97.501% (108795/111583)\n",
      "False positive rate: 2.499% (2788/111583)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 87/100: Loss: 0.1631 | Train Acc: 93.805% (114255/121800) | Strict Acc: 50.034% (4353/8700)\n",
      "True positive rate: 47.061% (4204/8933)\n",
      "False negative rate: 52.939% (4729/8933)\n",
      "True negative rate: 97.505% (110051/112867)\n",
      "False positive rate: 2.495% (2816/112867)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 88/100: Loss: 0.1623 | Train Acc: 93.833% (115602/123200) | Strict Acc: 50.193% (4417/8800)\n",
      "True positive rate: 47.287% (4271/9032)\n",
      "False negative rate: 52.713% (4761/9032)\n",
      "True negative rate: 97.515% (111331/114168)\n",
      "False positive rate: 2.485% (2837/114168)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 89/100: Loss: 0.1619 | Train Acc: 93.851% (116938/124600) | Strict Acc: 50.281% (4475/8900)\n",
      "True positive rate: 47.398% (4326/9127)\n",
      "False negative rate: 52.602% (4801/9127)\n",
      "True negative rate: 97.522% (112612/115473)\n",
      "False positive rate: 2.478% (2861/115473)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 90/100: Loss: 0.1612 | Train Acc: 93.875% (118283/126000) | Strict Acc: 50.378% (4534/9000)\n",
      "True positive rate: 47.554% (4385/9221)\n",
      "False negative rate: 52.446% (4836/9221)\n",
      "True negative rate: 97.533% (113898/116779)\n",
      "False positive rate: 2.467% (2881/116779)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 91/100: Loss: 0.1605 | Train Acc: 93.900% (119629/127400) | Strict Acc: 50.516% (4597/9100)\n",
      "True positive rate: 47.692% (4443/9316)\n",
      "False negative rate: 52.308% (4873/9316)\n",
      "True negative rate: 97.546% (115186/118084)\n",
      "False positive rate: 2.454% (2898/118084)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 92/100: Loss: 0.1600 | Train Acc: 93.914% (120961/128800) | Strict Acc: 50.587% (4654/9200)\n",
      "True positive rate: 47.784% (4507/9432)\n",
      "False negative rate: 52.216% (4925/9432)\n",
      "True negative rate: 97.559% (116454/119368)\n",
      "False positive rate: 2.441% (2914/119368)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 93/100: Loss: 0.1595 | Train Acc: 93.932% (122299/130200) | Strict Acc: 50.667% (4712/9300)\n",
      "True positive rate: 47.834% (4560/9533)\n",
      "False negative rate: 52.166% (4973/9533)\n",
      "True negative rate: 97.573% (117739/120667)\n",
      "False positive rate: 2.427% (2928/120667)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 94/100: Loss: 0.1588 | Train Acc: 93.964% (123656/131600) | Strict Acc: 50.862% (4781/9400)\n",
      "True positive rate: 47.967% (4612/9615)\n",
      "False negative rate: 52.033% (5003/9615)\n",
      "True negative rate: 97.589% (119044/121985)\n",
      "False positive rate: 2.411% (2941/121985)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 95/100: Loss: 0.1582 | Train Acc: 93.987% (125003/133000) | Strict Acc: 50.958% (4841/9500)\n",
      "True positive rate: 48.012% (4662/9710)\n",
      "False negative rate: 51.988% (5048/9710)\n",
      "True negative rate: 97.608% (120341/123290)\n",
      "False positive rate: 2.392% (2949/123290)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 96/100: Loss: 0.1576 | Train Acc: 94.017% (126359/134400) | Strict Acc: 51.146% (4910/9600)\n",
      "True positive rate: 48.169% (4721/9801)\n",
      "False negative rate: 51.831% (5080/9801)\n",
      "True negative rate: 97.624% (121638/124599)\n",
      "False positive rate: 2.376% (2961/124599)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 97/100: Loss: 0.1569 | Train Acc: 94.047% (127716/135800) | Strict Acc: 51.351% (4981/9700)\n",
      "True positive rate: 48.207% (4760/9874)\n",
      "False negative rate: 51.793% (5114/9874)\n",
      "True negative rate: 97.641% (122956/125926)\n",
      "False positive rate: 2.359% (2970/125926)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 98/100: Loss: 0.1565 | Train Acc: 94.061% (129052/137200) | Strict Acc: 51.398% (5037/9800)\n",
      "True positive rate: 48.285% (4814/9970)\n",
      "False negative rate: 51.715% (5156/9970)\n",
      "True negative rate: 97.648% (124238/127230)\n",
      "False positive rate: 2.352% (2992/127230)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 99/100: Loss: 0.1561 | Train Acc: 94.073% (130385/138600) | Strict Acc: 51.434% (5092/9900)\n",
      "True positive rate: 48.345% (4863/10059)\n",
      "False negative rate: 51.655% (5196/10059)\n",
      "True negative rate: 97.651% (125522/128541)\n",
      "False positive rate: 2.349% (3019/128541)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 1 - Batch 100/100: Loss: 0.1557 | Train Acc: 94.075% (130519/138740) | Strict Acc: 51.453% (5099/9910)\n",
      "True positive rate: 48.335% (4864/10063)\n",
      "False negative rate: 51.665% (5199/10063)\n",
      "True negative rate: 97.651% (125655/128677)\n",
      "False positive rate: 2.349% (3022/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1180 | Dev Acc: 95.466% (67762/70980) | Strict Acc: 58.323% (2957/5070)\n",
      "True positive rate: 52.435% (2702/5153)\n",
      "False negative rate: 47.565% (2451/5153)\n",
      "True negative rate: 98.835% (65060/65827)\n",
      "False positive rate: 1.165% (767/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 1/100: Loss: 0.1100 | Train Acc: 95.571% (1338/1400) | Strict Acc: 58.000% (58/100)\n",
      "True positive rate: 56.075% (60/107)\n",
      "False negative rate: 43.925% (47/107)\n",
      "True negative rate: 98.840% (1278/1293)\n",
      "False positive rate: 1.160% (15/1293)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 2/100: Loss: 0.1223 | Train Acc: 95.429% (2672/2800) | Strict Acc: 59.000% (118/200)\n",
      "True positive rate: 52.074% (113/217)\n",
      "False negative rate: 47.926% (104/217)\n",
      "True negative rate: 99.071% (2559/2583)\n",
      "False positive rate: 0.929% (24/2583)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 3/100: Loss: 0.1243 | Train Acc: 95.429% (4008/4200) | Strict Acc: 59.333% (178/300)\n",
      "True positive rate: 50.938% (163/320)\n",
      "False negative rate: 49.062% (157/320)\n",
      "True negative rate: 99.098% (3845/3880)\n",
      "False positive rate: 0.902% (35/3880)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 4/100: Loss: 0.1237 | Train Acc: 95.357% (5340/5600) | Strict Acc: 58.500% (234/400)\n",
      "True positive rate: 49.535% (213/430)\n",
      "False negative rate: 50.465% (217/430)\n",
      "True negative rate: 99.168% (5127/5170)\n",
      "False positive rate: 0.832% (43/5170)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 5/100: Loss: 0.1190 | Train Acc: 95.500% (6685/7000) | Strict Acc: 58.400% (292/500)\n",
      "True positive rate: 50.752% (270/532)\n",
      "False negative rate: 49.248% (262/532)\n",
      "True negative rate: 99.181% (6415/6468)\n",
      "False positive rate: 0.819% (53/6468)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 6/100: Loss: 0.1185 | Train Acc: 95.440% (8017/8400) | Strict Acc: 58.000% (348/600)\n",
      "True positive rate: 50.478% (317/628)\n",
      "False negative rate: 49.522% (311/628)\n",
      "True negative rate: 99.074% (7700/7772)\n",
      "False positive rate: 0.926% (72/7772)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 7/100: Loss: 0.1138 | Train Acc: 95.684% (9377/9800) | Strict Acc: 60.143% (421/700)\n",
      "True positive rate: 53.605% (394/735)\n",
      "False negative rate: 46.395% (341/735)\n",
      "True negative rate: 99.095% (8983/9065)\n",
      "False positive rate: 0.905% (82/9065)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 8/100: Loss: 0.1140 | Train Acc: 95.705% (10719/11200) | Strict Acc: 60.000% (480/800)\n",
      "True positive rate: 54.719% (458/837)\n",
      "False negative rate: 45.281% (379/837)\n",
      "True negative rate: 99.016% (10261/10363)\n",
      "False positive rate: 0.984% (102/10363)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 9/100: Loss: 0.1134 | Train Acc: 95.762% (12066/12600) | Strict Acc: 60.778% (547/900)\n",
      "True positive rate: 56.046% (533/951)\n",
      "False negative rate: 43.954% (418/951)\n",
      "True negative rate: 99.004% (11533/11649)\n",
      "False positive rate: 0.996% (116/11649)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 10/100: Loss: 0.1114 | Train Acc: 95.871% (13422/14000) | Strict Acc: 61.600% (616/1000)\n",
      "True positive rate: 56.989% (583/1023)\n",
      "False negative rate: 43.011% (440/1023)\n",
      "True negative rate: 98.937% (12839/12977)\n",
      "False positive rate: 1.063% (138/12977)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 11/100: Loss: 0.1110 | Train Acc: 95.896% (14768/15400) | Strict Acc: 61.909% (681/1100)\n",
      "True positive rate: 58.016% (655/1129)\n",
      "False negative rate: 41.984% (474/1129)\n",
      "True negative rate: 98.893% (14113/14271)\n",
      "False positive rate: 1.107% (158/14271)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 12/100: Loss: 0.1103 | Train Acc: 95.905% (16112/16800) | Strict Acc: 62.000% (744/1200)\n",
      "True positive rate: 57.899% (700/1209)\n",
      "False negative rate: 42.101% (509/1209)\n",
      "True negative rate: 98.852% (15412/15591)\n",
      "False positive rate: 1.148% (179/15591)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 13/100: Loss: 0.1128 | Train Acc: 95.841% (17443/18200) | Strict Acc: 61.538% (800/1300)\n",
      "True positive rate: 57.262% (757/1322)\n",
      "False negative rate: 42.738% (565/1322)\n",
      "True negative rate: 98.862% (16686/16878)\n",
      "False positive rate: 1.138% (192/16878)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 14/100: Loss: 0.1131 | Train Acc: 95.832% (18783/19600) | Strict Acc: 61.571% (862/1400)\n",
      "True positive rate: 56.740% (804/1417)\n",
      "False negative rate: 43.260% (613/1417)\n",
      "True negative rate: 98.878% (17979/18183)\n",
      "False positive rate: 1.122% (204/18183)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 15/100: Loss: 0.1118 | Train Acc: 95.867% (20132/21000) | Strict Acc: 61.733% (926/1500)\n",
      "True positive rate: 56.530% (844/1493)\n",
      "False negative rate: 43.470% (649/1493)\n",
      "True negative rate: 98.877% (19288/19507)\n",
      "False positive rate: 1.123% (219/19507)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 16/100: Loss: 0.1124 | Train Acc: 95.835% (21467/22400) | Strict Acc: 61.438% (983/1600)\n",
      "True positive rate: 56.438% (903/1600)\n",
      "False negative rate: 43.562% (697/1600)\n",
      "True negative rate: 98.865% (20564/20800)\n",
      "False positive rate: 1.135% (236/20800)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 17/100: Loss: 0.1124 | Train Acc: 95.857% (22814/23800) | Strict Acc: 61.529% (1046/1700)\n",
      "True positive rate: 56.750% (971/1711)\n",
      "False negative rate: 43.250% (740/1711)\n",
      "True negative rate: 98.886% (21843/22089)\n",
      "False positive rate: 1.114% (246/22089)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 18/100: Loss: 0.1132 | Train Acc: 95.837% (24151/25200) | Strict Acc: 61.167% (1101/1800)\n",
      "True positive rate: 56.591% (1026/1813)\n",
      "False negative rate: 43.409% (787/1813)\n",
      "True negative rate: 98.880% (23125/23387)\n",
      "False positive rate: 1.120% (262/23387)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 19/100: Loss: 0.1137 | Train Acc: 95.812% (25486/26600) | Strict Acc: 60.789% (1155/1900)\n",
      "True positive rate: 56.385% (1073/1903)\n",
      "False negative rate: 43.615% (830/1903)\n",
      "True negative rate: 98.850% (24413/24697)\n",
      "False positive rate: 1.150% (284/24697)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 20/100: Loss: 0.1140 | Train Acc: 95.804% (26825/28000) | Strict Acc: 60.500% (1210/2000)\n",
      "True positive rate: 56.902% (1146/2014)\n",
      "False negative rate: 43.098% (868/2014)\n",
      "True negative rate: 98.819% (25679/25986)\n",
      "False positive rate: 1.181% (307/25986)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 21/100: Loss: 0.1141 | Train Acc: 95.772% (28157/29400) | Strict Acc: 60.048% (1261/2100)\n",
      "True positive rate: 56.927% (1208/2122)\n",
      "False negative rate: 43.073% (914/2122)\n",
      "True negative rate: 98.794% (26949/27278)\n",
      "False positive rate: 1.206% (329/27278)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 22/100: Loss: 0.1146 | Train Acc: 95.789% (29503/30800) | Strict Acc: 60.227% (1325/2200)\n",
      "True positive rate: 57.340% (1285/2241)\n",
      "False negative rate: 42.660% (956/2241)\n",
      "True negative rate: 98.806% (28218/28559)\n",
      "False positive rate: 1.194% (341/28559)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 23/100: Loss: 0.1143 | Train Acc: 95.789% (30844/32200) | Strict Acc: 60.087% (1382/2300)\n",
      "True positive rate: 57.728% (1352/2342)\n",
      "False negative rate: 42.272% (990/2342)\n",
      "True negative rate: 98.774% (29492/29858)\n",
      "False positive rate: 1.226% (366/29858)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 24/100: Loss: 0.1140 | Train Acc: 95.780% (32182/33600) | Strict Acc: 60.167% (1444/2400)\n",
      "True positive rate: 57.959% (1420/2450)\n",
      "False negative rate: 42.041% (1030/2450)\n",
      "True negative rate: 98.754% (30762/31150)\n",
      "False positive rate: 1.246% (388/31150)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 25/100: Loss: 0.1137 | Train Acc: 95.811% (33534/35000) | Strict Acc: 60.440% (1511/2500)\n",
      "True positive rate: 58.185% (1475/2535)\n",
      "False negative rate: 41.815% (1060/2535)\n",
      "True negative rate: 98.749% (32059/32465)\n",
      "False positive rate: 1.251% (406/32465)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 26/100: Loss: 0.1129 | Train Acc: 95.841% (34886/36400) | Strict Acc: 60.808% (1581/2600)\n",
      "True positive rate: 58.343% (1535/2631)\n",
      "False negative rate: 41.657% (1096/2631)\n",
      "True negative rate: 98.762% (33351/33769)\n",
      "False positive rate: 1.238% (418/33769)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 27/100: Loss: 0.1129 | Train Acc: 95.849% (36231/37800) | Strict Acc: 60.852% (1643/2700)\n",
      "True positive rate: 58.278% (1591/2730)\n",
      "False negative rate: 41.722% (1139/2730)\n",
      "True negative rate: 98.774% (34640/35070)\n",
      "False positive rate: 1.226% (430/35070)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 28/100: Loss: 0.1133 | Train Acc: 95.834% (37567/39200) | Strict Acc: 60.679% (1699/2800)\n",
      "True positive rate: 58.042% (1642/2829)\n",
      "False negative rate: 41.958% (1187/2829)\n",
      "True negative rate: 98.774% (35925/36371)\n",
      "False positive rate: 1.226% (446/36371)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 29/100: Loss: 0.1127 | Train Acc: 95.833% (38908/40600) | Strict Acc: 60.655% (1759/2900)\n",
      "True positive rate: 58.018% (1704/2937)\n",
      "False negative rate: 41.982% (1233/2937)\n",
      "True negative rate: 98.781% (37204/37663)\n",
      "False positive rate: 1.219% (459/37663)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 30/100: Loss: 0.1127 | Train Acc: 95.829% (40248/42000) | Strict Acc: 60.833% (1825/3000)\n",
      "True positive rate: 57.876% (1760/3041)\n",
      "False negative rate: 42.124% (1281/3041)\n",
      "True negative rate: 98.791% (38488/38959)\n",
      "False positive rate: 1.209% (471/38959)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 31/100: Loss: 0.1124 | Train Acc: 95.832% (41591/43400) | Strict Acc: 60.968% (1890/3100)\n",
      "True positive rate: 58.009% (1818/3134)\n",
      "False negative rate: 41.991% (1316/3134)\n",
      "True negative rate: 98.776% (39773/40266)\n",
      "False positive rate: 1.224% (493/40266)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 32/100: Loss: 0.1119 | Train Acc: 95.862% (42946/44800) | Strict Acc: 61.219% (1959/3200)\n",
      "True positive rate: 58.256% (1884/3234)\n",
      "False negative rate: 41.744% (1350/3234)\n",
      "True negative rate: 98.787% (41062/41566)\n",
      "False positive rate: 1.213% (504/41566)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 33/100: Loss: 0.1118 | Train Acc: 95.851% (44283/46200) | Strict Acc: 61.121% (2017/3300)\n",
      "True positive rate: 58.306% (1941/3329)\n",
      "False negative rate: 41.694% (1388/3329)\n",
      "True negative rate: 98.766% (42342/42871)\n",
      "False positive rate: 1.234% (529/42871)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 34/100: Loss: 0.1125 | Train Acc: 95.811% (45606/47600) | Strict Acc: 60.971% (2073/3400)\n",
      "True positive rate: 58.237% (2008/3448)\n",
      "False negative rate: 41.763% (1440/3448)\n",
      "True negative rate: 98.745% (43598/44152)\n",
      "False positive rate: 1.255% (554/44152)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 35/100: Loss: 0.1119 | Train Acc: 95.818% (46951/49000) | Strict Acc: 60.971% (2134/3500)\n",
      "True positive rate: 58.685% (2088/3558)\n",
      "False negative rate: 41.315% (1470/3558)\n",
      "True negative rate: 98.726% (44863/45442)\n",
      "False positive rate: 1.274% (579/45442)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 36/100: Loss: 0.1115 | Train Acc: 95.845% (48306/50400) | Strict Acc: 61.167% (2202/3600)\n",
      "True positive rate: 58.946% (2148/3644)\n",
      "False negative rate: 41.054% (1496/3644)\n",
      "True negative rate: 98.721% (46158/46756)\n",
      "False positive rate: 1.279% (598/46756)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 37/100: Loss: 0.1123 | Train Acc: 95.813% (49631/51800) | Strict Acc: 60.865% (2252/3700)\n",
      "True positive rate: 58.751% (2202/3748)\n",
      "False negative rate: 41.249% (1546/3748)\n",
      "True negative rate: 98.703% (47429/48052)\n",
      "False positive rate: 1.297% (623/48052)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 38/100: Loss: 0.1119 | Train Acc: 95.838% (50986/53200) | Strict Acc: 61.079% (2321/3800)\n",
      "True positive rate: 59.039% (2273/3850)\n",
      "False negative rate: 40.961% (1577/3850)\n",
      "True negative rate: 98.709% (48713/49350)\n",
      "False positive rate: 1.291% (637/49350)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 39/100: Loss: 0.1121 | Train Acc: 95.817% (52316/54600) | Strict Acc: 60.744% (2369/3900)\n",
      "True positive rate: 58.831% (2335/3969)\n",
      "False negative rate: 41.169% (1634/3969)\n",
      "True negative rate: 98.716% (49981/50631)\n",
      "False positive rate: 1.284% (650/50631)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 40/100: Loss: 0.1125 | Train Acc: 95.789% (53642/56000) | Strict Acc: 60.600% (2424/4000)\n",
      "True positive rate: 58.519% (2387/4079)\n",
      "False negative rate: 41.481% (1692/4079)\n",
      "True negative rate: 98.717% (51255/51921)\n",
      "False positive rate: 1.283% (666/51921)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 41/100: Loss: 0.1120 | Train Acc: 95.793% (54985/57400) | Strict Acc: 60.732% (2490/4100)\n",
      "True positive rate: 58.463% (2442/4177)\n",
      "False negative rate: 41.537% (1735/4177)\n",
      "True negative rate: 98.722% (52543/53223)\n",
      "False positive rate: 1.278% (680/53223)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 42/100: Loss: 0.1117 | Train Acc: 95.787% (56323/58800) | Strict Acc: 60.667% (2548/4200)\n",
      "True positive rate: 58.343% (2486/4261)\n",
      "False negative rate: 41.657% (1775/4261)\n",
      "True negative rate: 98.713% (53837/54539)\n",
      "False positive rate: 1.287% (702/54539)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 43/100: Loss: 0.1117 | Train Acc: 95.786% (57663/60200) | Strict Acc: 60.651% (2608/4300)\n",
      "True positive rate: 58.337% (2547/4366)\n",
      "False negative rate: 41.663% (1819/4366)\n",
      "True negative rate: 98.714% (55116/55834)\n",
      "False positive rate: 1.286% (718/55834)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 44/100: Loss: 0.1109 | Train Acc: 95.821% (59026/61600) | Strict Acc: 61.023% (2685/4400)\n",
      "True positive rate: 58.611% (2607/4448)\n",
      "False negative rate: 41.389% (1841/4448)\n",
      "True negative rate: 98.717% (56419/57152)\n",
      "False positive rate: 1.283% (733/57152)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 45/100: Loss: 0.1107 | Train Acc: 95.830% (60373/63000) | Strict Acc: 61.067% (2748/4500)\n",
      "True positive rate: 58.543% (2652/4530)\n",
      "False negative rate: 41.457% (1878/4530)\n",
      "True negative rate: 98.719% (57721/58470)\n",
      "False positive rate: 1.281% (749/58470)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 46/100: Loss: 0.1110 | Train Acc: 95.801% (61696/64400) | Strict Acc: 60.935% (2803/4600)\n",
      "True positive rate: 58.175% (2697/4636)\n",
      "False negative rate: 41.825% (1939/4636)\n",
      "True negative rate: 98.720% (58999/59764)\n",
      "False positive rate: 1.280% (765/59764)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 47/100: Loss: 0.1110 | Train Acc: 95.799% (63036/65800) | Strict Acc: 60.894% (2862/4700)\n",
      "True positive rate: 58.099% (2751/4735)\n",
      "False negative rate: 41.901% (1984/4735)\n",
      "True negative rate: 98.723% (60285/61065)\n",
      "False positive rate: 1.277% (780/61065)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 48/100: Loss: 0.1110 | Train Acc: 95.801% (64378/67200) | Strict Acc: 60.917% (2924/4800)\n",
      "True positive rate: 58.189% (2821/4848)\n",
      "False negative rate: 41.811% (2027/4848)\n",
      "True negative rate: 98.725% (61557/62352)\n",
      "False positive rate: 1.275% (795/62352)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 49/100: Loss: 0.1104 | Train Acc: 95.818% (65731/68600) | Strict Acc: 61.000% (2989/4900)\n",
      "True positive rate: 58.246% (2875/4936)\n",
      "False negative rate: 41.754% (2061/4936)\n",
      "True negative rate: 98.731% (62856/63664)\n",
      "False positive rate: 1.269% (808/63664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 50/100: Loss: 0.1108 | Train Acc: 95.806% (67064/70000) | Strict Acc: 60.880% (3044/5000)\n",
      "True positive rate: 58.201% (2938/5048)\n",
      "False negative rate: 41.799% (2110/5048)\n",
      "True negative rate: 98.728% (64126/64952)\n",
      "False positive rate: 1.272% (826/64952)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 51/100: Loss: 0.1106 | Train Acc: 95.808% (68407/71400) | Strict Acc: 60.922% (3107/5100)\n",
      "True positive rate: 58.306% (3001/5147)\n",
      "False negative rate: 41.694% (2146/5147)\n",
      "True negative rate: 98.722% (65406/66253)\n",
      "False positive rate: 1.278% (847/66253)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 52/100: Loss: 0.1105 | Train Acc: 95.806% (69747/72800) | Strict Acc: 60.942% (3169/5200)\n",
      "True positive rate: 58.390% (3069/5256)\n",
      "False negative rate: 41.610% (2187/5256)\n",
      "True negative rate: 98.718% (66678/67544)\n",
      "False positive rate: 1.282% (866/67544)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 53/100: Loss: 0.1106 | Train Acc: 95.795% (71080/74200) | Strict Acc: 60.849% (3225/5300)\n",
      "True positive rate: 58.556% (3138/5359)\n",
      "False negative rate: 41.444% (2221/5359)\n",
      "True negative rate: 98.694% (67942/68841)\n",
      "False positive rate: 1.306% (899/68841)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 54/100: Loss: 0.1107 | Train Acc: 95.790% (72417/75600) | Strict Acc: 60.815% (3284/5400)\n",
      "True positive rate: 58.546% (3189/5447)\n",
      "False negative rate: 41.454% (2258/5447)\n",
      "True negative rate: 98.681% (69228/70153)\n",
      "False positive rate: 1.319% (925/70153)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 55/100: Loss: 0.1105 | Train Acc: 95.796% (73763/77000) | Strict Acc: 60.855% (3347/5500)\n",
      "True positive rate: 58.614% (3249/5543)\n",
      "False negative rate: 41.386% (2294/5543)\n",
      "True negative rate: 98.680% (70514/71457)\n",
      "False positive rate: 1.320% (943/71457)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 56/100: Loss: 0.1103 | Train Acc: 95.806% (75112/78400) | Strict Acc: 60.893% (3410/5600)\n",
      "True positive rate: 58.779% (3321/5650)\n",
      "False negative rate: 41.221% (2329/5650)\n",
      "True negative rate: 98.682% (71791/72750)\n",
      "False positive rate: 1.318% (959/72750)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 57/100: Loss: 0.1105 | Train Acc: 95.792% (76442/79800) | Strict Acc: 60.789% (3465/5700)\n",
      "True positive rate: 58.566% (3374/5761)\n",
      "False negative rate: 41.434% (2387/5761)\n",
      "True negative rate: 98.689% (73068/74039)\n",
      "False positive rate: 1.311% (971/74039)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 58/100: Loss: 0.1102 | Train Acc: 95.800% (77790/81200) | Strict Acc: 60.931% (3534/5800)\n",
      "True positive rate: 58.702% (3447/5872)\n",
      "False negative rate: 41.298% (2425/5872)\n",
      "True negative rate: 98.692% (74343/75328)\n",
      "False positive rate: 1.308% (985/75328)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 59/100: Loss: 0.1102 | Train Acc: 95.804% (79134/82600) | Strict Acc: 61.000% (3599/5900)\n",
      "True positive rate: 58.747% (3506/5968)\n",
      "False negative rate: 41.253% (2462/5968)\n",
      "True negative rate: 98.690% (75628/76632)\n",
      "False positive rate: 1.310% (1004/76632)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 60/100: Loss: 0.1098 | Train Acc: 95.825% (80493/84000) | Strict Acc: 61.150% (3669/6000)\n",
      "True positive rate: 59.077% (3583/6065)\n",
      "False negative rate: 40.923% (2482/6065)\n",
      "True negative rate: 98.685% (76910/77935)\n",
      "False positive rate: 1.315% (1025/77935)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 61/100: Loss: 0.1095 | Train Acc: 95.836% (81844/85400) | Strict Acc: 61.164% (3731/6100)\n",
      "True positive rate: 59.221% (3648/6160)\n",
      "False negative rate: 40.779% (2512/6160)\n",
      "True negative rate: 98.682% (78196/79240)\n",
      "False positive rate: 1.318% (1044/79240)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 62/100: Loss: 0.1100 | Train Acc: 95.824% (83175/86800) | Strict Acc: 61.065% (3786/6200)\n",
      "True positive rate: 59.253% (3730/6295)\n",
      "False negative rate: 40.747% (2565/6295)\n",
      "True negative rate: 98.683% (79445/80505)\n",
      "False positive rate: 1.317% (1060/80505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 63/100: Loss: 0.1103 | Train Acc: 95.814% (84508/88200) | Strict Acc: 60.968% (3841/6300)\n",
      "True positive rate: 59.163% (3790/6406)\n",
      "False negative rate: 40.837% (2616/6406)\n",
      "True negative rate: 98.685% (80718/81794)\n",
      "False positive rate: 1.315% (1076/81794)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 64/100: Loss: 0.1103 | Train Acc: 95.819% (85854/89600) | Strict Acc: 61.000% (3904/6400)\n",
      "True positive rate: 59.268% (3856/6506)\n",
      "False negative rate: 40.732% (2650/6506)\n",
      "True negative rate: 98.681% (81998/83094)\n",
      "False positive rate: 1.319% (1096/83094)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 65/100: Loss: 0.1102 | Train Acc: 95.821% (87197/91000) | Strict Acc: 60.969% (3963/6500)\n",
      "True positive rate: 59.496% (3941/6624)\n",
      "False negative rate: 40.504% (2683/6624)\n",
      "True negative rate: 98.673% (83256/84376)\n",
      "False positive rate: 1.327% (1120/84376)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 66/100: Loss: 0.1103 | Train Acc: 95.814% (88532/92400) | Strict Acc: 60.939% (4022/6600)\n",
      "True positive rate: 59.562% (4002/6719)\n",
      "False negative rate: 40.438% (2717/6719)\n",
      "True negative rate: 98.657% (84530/85681)\n",
      "False positive rate: 1.343% (1151/85681)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 67/100: Loss: 0.1103 | Train Acc: 95.804% (89864/93800) | Strict Acc: 60.836% (4076/6700)\n",
      "True positive rate: 59.568% (4053/6804)\n",
      "False negative rate: 40.432% (2751/6804)\n",
      "True negative rate: 98.638% (85811/86996)\n",
      "False positive rate: 1.362% (1185/86996)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 68/100: Loss: 0.1102 | Train Acc: 95.810% (91211/95200) | Strict Acc: 60.824% (4136/6800)\n",
      "True positive rate: 59.693% (4123/6907)\n",
      "False negative rate: 40.307% (2784/6907)\n",
      "True negative rate: 98.635% (87088/88293)\n",
      "False positive rate: 1.365% (1205/88293)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 69/100: Loss: 0.1100 | Train Acc: 95.815% (92557/96600) | Strict Acc: 60.870% (4200/6900)\n",
      "True positive rate: 59.632% (4182/7013)\n",
      "False negative rate: 40.368% (2831/7013)\n",
      "True negative rate: 98.647% (88375/89587)\n",
      "False positive rate: 1.353% (1212/89587)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 70/100: Loss: 0.1099 | Train Acc: 95.817% (93901/98000) | Strict Acc: 60.900% (4263/7000)\n",
      "True positive rate: 59.550% (4237/7115)\n",
      "False negative rate: 40.450% (2878/7115)\n",
      "True negative rate: 98.657% (89664/90885)\n",
      "False positive rate: 1.343% (1221/90885)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 71/100: Loss: 0.1096 | Train Acc: 95.836% (95261/99400) | Strict Acc: 61.070% (4336/7100)\n",
      "True positive rate: 59.572% (4285/7193)\n",
      "False negative rate: 40.428% (2908/7193)\n",
      "True negative rate: 98.665% (90976/92207)\n",
      "False positive rate: 1.335% (1231/92207)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 72/100: Loss: 0.1097 | Train Acc: 95.828% (96595/100800) | Strict Acc: 61.014% (4393/7200)\n",
      "True positive rate: 59.311% (4322/7287)\n",
      "False negative rate: 40.689% (2965/7287)\n",
      "True negative rate: 98.674% (92273/93513)\n",
      "False positive rate: 1.326% (1240/93513)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 73/100: Loss: 0.1096 | Train Acc: 95.833% (97941/102200) | Strict Acc: 61.000% (4453/7300)\n",
      "True positive rate: 59.244% (4374/7383)\n",
      "False negative rate: 40.756% (3009/7383)\n",
      "True negative rate: 98.682% (93567/94817)\n",
      "False positive rate: 1.318% (1250/94817)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 74/100: Loss: 0.1097 | Train Acc: 95.823% (99273/103600) | Strict Acc: 60.892% (4506/7400)\n",
      "True positive rate: 59.113% (4427/7489)\n",
      "False negative rate: 40.887% (3062/7489)\n",
      "True negative rate: 98.684% (94846/96111)\n",
      "False positive rate: 1.316% (1265/96111)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 75/100: Loss: 0.1099 | Train Acc: 95.817% (100608/105000) | Strict Acc: 60.840% (4563/7500)\n",
      "True positive rate: 59.082% (4492/7603)\n",
      "False negative rate: 40.918% (3111/7603)\n",
      "True negative rate: 98.685% (96116/97397)\n",
      "False positive rate: 1.315% (1281/97397)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 76/100: Loss: 0.1097 | Train Acc: 95.819% (101951/106400) | Strict Acc: 60.868% (4626/7600)\n",
      "True positive rate: 59.178% (4552/7692)\n",
      "False negative rate: 40.822% (3140/7692)\n",
      "True negative rate: 98.674% (97399/98708)\n",
      "False positive rate: 1.326% (1309/98708)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 77/100: Loss: 0.1099 | Train Acc: 95.817% (103291/107800) | Strict Acc: 60.883% (4688/7700)\n",
      "True positive rate: 59.235% (4615/7791)\n",
      "False negative rate: 40.765% (3176/7791)\n",
      "True negative rate: 98.667% (98676/100009)\n",
      "False positive rate: 1.333% (1333/100009)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 78/100: Loss: 0.1097 | Train Acc: 95.817% (104632/109200) | Strict Acc: 60.885% (4749/7800)\n",
      "True positive rate: 59.318% (4679/7888)\n",
      "False negative rate: 40.682% (3209/7888)\n",
      "True negative rate: 98.659% (99953/101312)\n",
      "False positive rate: 1.341% (1359/101312)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 79/100: Loss: 0.1098 | Train Acc: 95.811% (105967/110600) | Strict Acc: 60.835% (4806/7900)\n",
      "True positive rate: 59.368% (4750/8001)\n",
      "False negative rate: 40.632% (3251/8001)\n",
      "True negative rate: 98.653% (101217/102599)\n",
      "False positive rate: 1.347% (1382/102599)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 80/100: Loss: 0.1097 | Train Acc: 95.812% (107310/112000) | Strict Acc: 60.837% (4867/8000)\n",
      "True positive rate: 59.395% (4811/8100)\n",
      "False negative rate: 40.605% (3289/8100)\n",
      "True negative rate: 98.652% (102499/103900)\n",
      "False positive rate: 1.348% (1401/103900)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 81/100: Loss: 0.1097 | Train Acc: 95.807% (108645/113400) | Strict Acc: 60.802% (4925/8100)\n",
      "True positive rate: 59.393% (4869/8198)\n",
      "False negative rate: 40.607% (3329/8198)\n",
      "True negative rate: 98.645% (103776/105202)\n",
      "False positive rate: 1.355% (1426/105202)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 82/100: Loss: 0.1098 | Train Acc: 95.801% (109979/114800) | Strict Acc: 60.780% (4984/8200)\n",
      "True positive rate: 59.444% (4941/8312)\n",
      "False negative rate: 40.556% (3371/8312)\n",
      "True negative rate: 98.638% (105038/106488)\n",
      "False positive rate: 1.362% (1450/106488)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 83/100: Loss: 0.1096 | Train Acc: 95.806% (111326/116200) | Strict Acc: 60.783% (5045/8300)\n",
      "True positive rate: 59.443% (4995/8403)\n",
      "False negative rate: 40.557% (3408/8403)\n",
      "True negative rate: 98.640% (106331/107797)\n",
      "False positive rate: 1.360% (1466/107797)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 84/100: Loss: 0.1100 | Train Acc: 95.798% (112659/117600) | Strict Acc: 60.762% (5104/8400)\n",
      "True positive rate: 59.402% (5067/8530)\n",
      "False negative rate: 40.598% (3463/8530)\n",
      "True negative rate: 98.645% (107592/109070)\n",
      "False positive rate: 1.355% (1478/109070)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 85/100: Loss: 0.1099 | Train Acc: 95.794% (113995/119000) | Strict Acc: 60.671% (5157/8500)\n",
      "True positive rate: 59.426% (5132/8636)\n",
      "False negative rate: 40.574% (3504/8636)\n",
      "True negative rate: 98.640% (108863/110364)\n",
      "False positive rate: 1.360% (1501/110364)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 86/100: Loss: 0.1099 | Train Acc: 95.786% (115326/120400) | Strict Acc: 60.651% (5216/8600)\n",
      "True positive rate: 59.401% (5197/8749)\n",
      "False negative rate: 40.599% (3552/8749)\n",
      "True negative rate: 98.637% (110129/111651)\n",
      "False positive rate: 1.363% (1522/111651)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 87/100: Loss: 0.1098 | Train Acc: 95.790% (116672/121800) | Strict Acc: 60.667% (5278/8700)\n",
      "True positive rate: 59.514% (5261/8840)\n",
      "False negative rate: 40.486% (3579/8840)\n",
      "True negative rate: 98.629% (111411/112960)\n",
      "False positive rate: 1.371% (1549/112960)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 88/100: Loss: 0.1097 | Train Acc: 95.791% (118015/123200) | Strict Acc: 60.693% (5341/8800)\n",
      "True positive rate: 59.546% (5327/8946)\n",
      "False negative rate: 40.454% (3619/8946)\n",
      "True negative rate: 98.629% (112688/114254)\n",
      "False positive rate: 1.371% (1566/114254)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 89/100: Loss: 0.1096 | Train Acc: 95.789% (119353/124600) | Strict Acc: 60.640% (5397/8900)\n",
      "True positive rate: 59.549% (5391/9053)\n",
      "False negative rate: 40.451% (3662/9053)\n",
      "True negative rate: 98.628% (113962/115547)\n",
      "False positive rate: 1.372% (1585/115547)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 90/100: Loss: 0.1095 | Train Acc: 95.791% (120697/126000) | Strict Acc: 60.667% (5460/9000)\n",
      "True positive rate: 59.653% (5463/9158)\n",
      "False negative rate: 40.347% (3695/9158)\n",
      "True negative rate: 98.624% (115234/116842)\n",
      "False positive rate: 1.376% (1608/116842)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 91/100: Loss: 0.1096 | Train Acc: 95.789% (122035/127400) | Strict Acc: 60.681% (5522/9100)\n",
      "True positive rate: 59.698% (5528/9260)\n",
      "False negative rate: 40.302% (3732/9260)\n",
      "True negative rate: 98.618% (116507/118140)\n",
      "False positive rate: 1.382% (1633/118140)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 92/100: Loss: 0.1095 | Train Acc: 95.788% (123375/128800) | Strict Acc: 60.696% (5584/9200)\n",
      "True positive rate: 59.744% (5595/9365)\n",
      "False negative rate: 40.256% (3770/9365)\n",
      "True negative rate: 98.614% (117780/119435)\n",
      "False positive rate: 1.386% (1655/119435)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 93/100: Loss: 0.1094 | Train Acc: 95.787% (124715/130200) | Strict Acc: 60.731% (5648/9300)\n",
      "True positive rate: 59.744% (5656/9467)\n",
      "False negative rate: 40.256% (3811/9467)\n",
      "True negative rate: 98.613% (119059/120733)\n",
      "False positive rate: 1.387% (1674/120733)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 94/100: Loss: 0.1093 | Train Acc: 95.790% (126059/131600) | Strict Acc: 60.745% (5710/9400)\n",
      "True positive rate: 59.760% (5722/9575)\n",
      "False negative rate: 40.240% (3853/9575)\n",
      "True negative rate: 98.617% (120337/122025)\n",
      "False positive rate: 1.383% (1688/122025)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 95/100: Loss: 0.1092 | Train Acc: 95.796% (127409/133000) | Strict Acc: 60.779% (5774/9500)\n",
      "True positive rate: 59.764% (5781/9673)\n",
      "False negative rate: 40.236% (3892/9673)\n",
      "True negative rate: 98.622% (121628/123327)\n",
      "False positive rate: 1.378% (1699/123327)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 96/100: Loss: 0.1091 | Train Acc: 95.801% (128756/134400) | Strict Acc: 60.792% (5836/9600)\n",
      "True positive rate: 59.722% (5833/9767)\n",
      "False negative rate: 40.278% (3934/9767)\n",
      "True negative rate: 98.628% (122923/124633)\n",
      "False positive rate: 1.372% (1710/124633)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 97/100: Loss: 0.1092 | Train Acc: 95.803% (130100/135800) | Strict Acc: 60.804% (5898/9700)\n",
      "True positive rate: 59.749% (5896/9868)\n",
      "False negative rate: 40.251% (3972/9868)\n",
      "True negative rate: 98.628% (124204/125932)\n",
      "False positive rate: 1.372% (1728/125932)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 98/100: Loss: 0.1092 | Train Acc: 95.800% (131437/137200) | Strict Acc: 60.765% (5955/9800)\n",
      "True positive rate: 59.747% (5952/9962)\n",
      "False negative rate: 40.253% (4010/9962)\n",
      "True negative rate: 98.622% (125485/127238)\n",
      "False positive rate: 1.378% (1753/127238)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 99/100: Loss: 0.1091 | Train Acc: 95.802% (132782/138600) | Strict Acc: 60.808% (6020/9900)\n",
      "True positive rate: 59.714% (6003/10053)\n",
      "False negative rate: 40.286% (4050/10053)\n",
      "True negative rate: 98.625% (126779/128547)\n",
      "False positive rate: 1.375% (1768/128547)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 2 - Batch 100/100: Loss: 0.1091 | Train Acc: 95.802% (132916/138740) | Strict Acc: 60.807% (6026/9910)\n",
      "True positive rate: 59.714% (6009/10063)\n",
      "False negative rate: 40.286% (4054/10063)\n",
      "True negative rate: 98.624% (126907/128677)\n",
      "False positive rate: 1.376% (1770/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1121 | Dev Acc: 95.800% (67999/70980) | Strict Acc: 60.513% (3068/5070)\n",
      "True positive rate: 59.150% (3048/5153)\n",
      "False negative rate: 40.850% (2105/5153)\n",
      "True negative rate: 98.669% (64951/65827)\n",
      "False positive rate: 1.331% (876/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 1/100: Loss: 0.0879 | Train Acc: 96.714% (1354/1400) | Strict Acc: 65.000% (65/100)\n",
      "True positive rate: 70.408% (69/98)\n",
      "False negative rate: 29.592% (29/98)\n",
      "True negative rate: 98.694% (1285/1302)\n",
      "False positive rate: 1.306% (17/1302)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 2/100: Loss: 0.0965 | Train Acc: 96.393% (2699/2800) | Strict Acc: 62.000% (124/200)\n",
      "True positive rate: 65.581% (141/215)\n",
      "False negative rate: 34.419% (74/215)\n",
      "True negative rate: 98.956% (2558/2585)\n",
      "False positive rate: 1.044% (27/2585)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 3/100: Loss: 0.0888 | Train Acc: 96.738% (4063/4200) | Strict Acc: 65.333% (196/300)\n",
      "True positive rate: 68.153% (214/314)\n",
      "False negative rate: 31.847% (100/314)\n",
      "True negative rate: 99.048% (3849/3886)\n",
      "False positive rate: 0.952% (37/3886)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 4/100: Loss: 0.0874 | Train Acc: 96.768% (5419/5600) | Strict Acc: 66.500% (266/400)\n",
      "True positive rate: 70.047% (297/424)\n",
      "False negative rate: 29.953% (127/424)\n",
      "True negative rate: 98.957% (5122/5176)\n",
      "False positive rate: 1.043% (54/5176)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 5/100: Loss: 0.0872 | Train Acc: 96.800% (6776/7000) | Strict Acc: 66.800% (334/500)\n",
      "True positive rate: 71.563% (380/531)\n",
      "False negative rate: 28.437% (151/531)\n",
      "True negative rate: 98.872% (6396/6469)\n",
      "False positive rate: 1.128% (73/6469)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 6/100: Loss: 0.0901 | Train Acc: 96.655% (8119/8400) | Strict Acc: 65.667% (394/600)\n",
      "True positive rate: 71.290% (442/620)\n",
      "False negative rate: 28.710% (178/620)\n",
      "True negative rate: 98.676% (7677/7780)\n",
      "False positive rate: 1.324% (103/7780)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 7/100: Loss: 0.0936 | Train Acc: 96.480% (9455/9800) | Strict Acc: 65.143% (456/700)\n",
      "True positive rate: 70.365% (501/712)\n",
      "False negative rate: 29.635% (211/712)\n",
      "True negative rate: 98.526% (8954/9088)\n",
      "False positive rate: 1.474% (134/9088)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 8/100: Loss: 0.0942 | Train Acc: 96.473% (10805/11200) | Strict Acc: 64.750% (518/800)\n",
      "True positive rate: 70.173% (567/808)\n",
      "False negative rate: 29.827% (241/808)\n",
      "True negative rate: 98.518% (10238/10392)\n",
      "False positive rate: 1.482% (154/10392)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 9/100: Loss: 0.0937 | Train Acc: 96.484% (12157/12600) | Strict Acc: 64.778% (583/900)\n",
      "True positive rate: 70.055% (634/905)\n",
      "False negative rate: 29.945% (271/905)\n",
      "True negative rate: 98.529% (11523/11695)\n",
      "False positive rate: 1.471% (172/11695)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 10/100: Loss: 0.0956 | Train Acc: 96.407% (13497/14000) | Strict Acc: 64.400% (644/1000)\n",
      "True positive rate: 69.307% (700/1010)\n",
      "False negative rate: 30.693% (310/1010)\n",
      "True negative rate: 98.514% (12797/12990)\n",
      "False positive rate: 1.486% (193/12990)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 11/100: Loss: 0.0976 | Train Acc: 96.351% (14838/15400) | Strict Acc: 63.909% (703/1100)\n",
      "True positive rate: 68.487% (765/1117)\n",
      "False negative rate: 31.513% (352/1117)\n",
      "True negative rate: 98.530% (14073/14283)\n",
      "False positive rate: 1.470% (210/14283)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 12/100: Loss: 0.0989 | Train Acc: 96.274% (16174/16800) | Strict Acc: 63.333% (760/1200)\n",
      "True positive rate: 67.514% (823/1219)\n",
      "False negative rate: 32.486% (396/1219)\n",
      "True negative rate: 98.524% (15351/15581)\n",
      "False positive rate: 1.476% (230/15581)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 13/100: Loss: 0.0986 | Train Acc: 96.302% (17527/18200) | Strict Acc: 63.385% (824/1300)\n",
      "True positive rate: 67.224% (884/1315)\n",
      "False negative rate: 32.776% (431/1315)\n",
      "True negative rate: 98.567% (16643/16885)\n",
      "False positive rate: 1.433% (242/16885)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 14/100: Loss: 0.0981 | Train Acc: 96.316% (18878/19600) | Strict Acc: 63.500% (889/1400)\n",
      "True positive rate: 66.906% (932/1393)\n",
      "False negative rate: 33.094% (461/1393)\n",
      "True negative rate: 98.566% (17946/18207)\n",
      "False positive rate: 1.434% (261/18207)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 15/100: Loss: 0.0984 | Train Acc: 96.248% (20212/21000) | Strict Acc: 62.867% (943/1500)\n",
      "True positive rate: 66.265% (990/1494)\n",
      "False negative rate: 33.735% (504/1494)\n",
      "True negative rate: 98.544% (19222/19506)\n",
      "False positive rate: 1.456% (284/19506)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 16/100: Loss: 0.0983 | Train Acc: 96.228% (21555/22400) | Strict Acc: 62.750% (1004/1600)\n",
      "True positive rate: 65.789% (1050/1596)\n",
      "False negative rate: 34.211% (546/1596)\n",
      "True negative rate: 98.563% (20505/20804)\n",
      "False positive rate: 1.437% (299/20804)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 17/100: Loss: 0.1002 | Train Acc: 96.193% (22894/23800) | Strict Acc: 62.471% (1062/1700)\n",
      "True positive rate: 65.041% (1107/1702)\n",
      "False negative rate: 34.959% (595/1702)\n",
      "True negative rate: 98.593% (21787/22098)\n",
      "False positive rate: 1.407% (311/22098)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 18/100: Loss: 0.0998 | Train Acc: 96.214% (24246/25200) | Strict Acc: 62.778% (1130/1800)\n",
      "True positive rate: 64.814% (1166/1799)\n",
      "False negative rate: 35.186% (633/1799)\n",
      "True negative rate: 98.628% (23080/23401)\n",
      "False positive rate: 1.372% (321/23401)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 19/100: Loss: 0.0995 | Train Acc: 96.226% (25596/26600) | Strict Acc: 63.000% (1197/1900)\n",
      "True positive rate: 64.465% (1230/1908)\n",
      "False negative rate: 35.535% (678/1908)\n",
      "True negative rate: 98.680% (24366/24692)\n",
      "False positive rate: 1.320% (326/24692)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 20/100: Loss: 0.0995 | Train Acc: 96.221% (26942/28000) | Strict Acc: 63.100% (1262/2000)\n",
      "True positive rate: 64.332% (1295/2013)\n",
      "False negative rate: 35.668% (718/2013)\n",
      "True negative rate: 98.692% (25647/25987)\n",
      "False positive rate: 1.308% (340/25987)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 21/100: Loss: 0.0995 | Train Acc: 96.238% (28294/29400) | Strict Acc: 63.333% (1330/2100)\n",
      "True positive rate: 64.444% (1363/2115)\n",
      "False negative rate: 35.556% (752/2115)\n",
      "True negative rate: 98.703% (26931/27285)\n",
      "False positive rate: 1.297% (354/27285)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 22/100: Loss: 0.0997 | Train Acc: 96.218% (29635/30800) | Strict Acc: 63.273% (1392/2200)\n",
      "True positive rate: 64.150% (1419/2212)\n",
      "False negative rate: 35.850% (793/2212)\n",
      "True negative rate: 98.699% (28216/28588)\n",
      "False positive rate: 1.301% (372/28588)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 23/100: Loss: 0.0997 | Train Acc: 96.224% (30984/32200) | Strict Acc: 63.522% (1461/2300)\n",
      "True positive rate: 64.215% (1484/2311)\n",
      "False negative rate: 35.785% (827/2311)\n",
      "True negative rate: 98.699% (29500/29889)\n",
      "False positive rate: 1.301% (389/29889)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 24/100: Loss: 0.1004 | Train Acc: 96.196% (32322/33600) | Strict Acc: 63.292% (1519/2400)\n",
      "True positive rate: 64.044% (1555/2428)\n",
      "False negative rate: 35.956% (873/2428)\n",
      "True negative rate: 98.701% (30767/31172)\n",
      "False positive rate: 1.299% (405/31172)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 25/100: Loss: 0.1004 | Train Acc: 96.183% (33664/35000) | Strict Acc: 63.200% (1580/2500)\n",
      "True positive rate: 64.319% (1635/2542)\n",
      "False negative rate: 35.681% (907/2542)\n",
      "True negative rate: 98.678% (32029/32458)\n",
      "False positive rate: 1.322% (429/32458)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 26/100: Loss: 0.1003 | Train Acc: 96.195% (35015/36400) | Strict Acc: 63.231% (1644/2600)\n",
      "True positive rate: 64.644% (1715/2653)\n",
      "False negative rate: 35.356% (938/2653)\n",
      "True negative rate: 98.675% (33300/33747)\n",
      "False positive rate: 1.325% (447/33747)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 27/100: Loss: 0.0998 | Train Acc: 96.201% (36364/37800) | Strict Acc: 63.148% (1705/2700)\n",
      "True positive rate: 64.987% (1780/2739)\n",
      "False negative rate: 35.013% (959/2739)\n",
      "True negative rate: 98.640% (34584/35061)\n",
      "False positive rate: 1.360% (477/35061)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 28/100: Loss: 0.1002 | Train Acc: 96.191% (37707/39200) | Strict Acc: 62.964% (1763/2800)\n",
      "True positive rate: 64.886% (1846/2845)\n",
      "False negative rate: 35.114% (999/2845)\n",
      "True negative rate: 98.641% (35861/36355)\n",
      "False positive rate: 1.359% (494/36355)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 29/100: Loss: 0.1005 | Train Acc: 96.182% (39050/40600) | Strict Acc: 62.966% (1826/2900)\n",
      "True positive rate: 64.808% (1906/2941)\n",
      "False negative rate: 35.192% (1035/2941)\n",
      "True negative rate: 98.632% (37144/37659)\n",
      "False positive rate: 1.368% (515/37659)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 30/100: Loss: 0.1012 | Train Acc: 96.131% (40375/42000) | Strict Acc: 62.733% (1882/3000)\n",
      "True positive rate: 64.223% (1962/3055)\n",
      "False negative rate: 35.777% (1093/3055)\n",
      "True negative rate: 98.634% (38413/38945)\n",
      "False positive rate: 1.366% (532/38945)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 31/100: Loss: 0.1010 | Train Acc: 96.131% (41721/43400) | Strict Acc: 62.806% (1947/3100)\n",
      "True positive rate: 64.041% (2016/3148)\n",
      "False negative rate: 35.959% (1132/3148)\n",
      "True negative rate: 98.641% (39705/40252)\n",
      "False positive rate: 1.359% (547/40252)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 32/100: Loss: 0.1004 | Train Acc: 96.165% (43082/44800) | Strict Acc: 63.000% (2016/3200)\n",
      "True positive rate: 64.189% (2081/3242)\n",
      "False negative rate: 35.811% (1161/3242)\n",
      "True negative rate: 98.660% (41001/41558)\n",
      "False positive rate: 1.340% (557/41558)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 33/100: Loss: 0.1010 | Train Acc: 96.130% (44412/46200) | Strict Acc: 62.727% (2070/3300)\n",
      "True positive rate: 63.672% (2126/3339)\n",
      "False negative rate: 36.328% (1213/3339)\n",
      "True negative rate: 98.658% (42286/42861)\n",
      "False positive rate: 1.342% (575/42861)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 34/100: Loss: 0.1008 | Train Acc: 96.132% (45759/47600) | Strict Acc: 62.853% (2137/3400)\n",
      "True positive rate: 63.718% (2197/3448)\n",
      "False negative rate: 36.282% (1251/3448)\n",
      "True negative rate: 98.664% (43562/44152)\n",
      "False positive rate: 1.336% (590/44152)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 35/100: Loss: 0.1008 | Train Acc: 96.122% (47100/49000) | Strict Acc: 62.800% (2198/3500)\n",
      "True positive rate: 63.588% (2258/3551)\n",
      "False negative rate: 36.412% (1293/3551)\n",
      "True negative rate: 98.664% (44842/45449)\n",
      "False positive rate: 1.336% (607/45449)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 36/100: Loss: 0.1002 | Train Acc: 96.147% (48458/50400) | Strict Acc: 63.000% (2268/3600)\n",
      "True positive rate: 63.784% (2323/3642)\n",
      "False negative rate: 36.216% (1319/3642)\n",
      "True negative rate: 98.668% (46135/46758)\n",
      "False positive rate: 1.332% (623/46758)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 37/100: Loss: 0.1002 | Train Acc: 96.151% (49806/51800) | Strict Acc: 63.135% (2336/3700)\n",
      "True positive rate: 63.796% (2393/3751)\n",
      "False negative rate: 36.204% (1358/3751)\n",
      "True negative rate: 98.676% (47413/48049)\n",
      "False positive rate: 1.324% (636/48049)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 38/100: Loss: 0.0998 | Train Acc: 96.165% (51160/53200) | Strict Acc: 63.263% (2404/3800)\n",
      "True positive rate: 63.925% (2456/3842)\n",
      "False negative rate: 36.075% (1386/3842)\n",
      "True negative rate: 98.675% (48704/49358)\n",
      "False positive rate: 1.325% (654/49358)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 39/100: Loss: 0.1000 | Train Acc: 96.159% (52503/54600) | Strict Acc: 63.231% (2466/3900)\n",
      "True positive rate: 63.752% (2508/3934)\n",
      "False negative rate: 36.248% (1426/3934)\n",
      "True negative rate: 98.676% (49995/50666)\n",
      "False positive rate: 1.324% (671/50666)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 40/100: Loss: 0.1003 | Train Acc: 96.154% (53846/56000) | Strict Acc: 63.250% (2530/4000)\n",
      "True positive rate: 63.809% (2590/4059)\n",
      "False negative rate: 36.191% (1469/4059)\n",
      "True negative rate: 98.681% (51256/51941)\n",
      "False positive rate: 1.319% (685/51941)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 41/100: Loss: 0.1003 | Train Acc: 96.166% (55199/57400) | Strict Acc: 63.317% (2596/4100)\n",
      "True positive rate: 63.846% (2656/4160)\n",
      "False negative rate: 36.154% (1504/4160)\n",
      "True negative rate: 98.691% (52543/53240)\n",
      "False positive rate: 1.309% (697/53240)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 42/100: Loss: 0.1001 | Train Acc: 96.177% (56552/58800) | Strict Acc: 63.429% (2664/4200)\n",
      "True positive rate: 63.964% (2730/4268)\n",
      "False negative rate: 36.036% (1538/4268)\n",
      "True negative rate: 98.698% (53822/54532)\n",
      "False positive rate: 1.302% (710/54532)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 43/100: Loss: 0.0999 | Train Acc: 96.174% (57897/60200) | Strict Acc: 63.349% (2724/4300)\n",
      "True positive rate: 63.992% (2783/4349)\n",
      "False negative rate: 36.008% (1566/4349)\n",
      "True negative rate: 98.680% (55114/55851)\n",
      "False positive rate: 1.320% (737/55851)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 44/100: Loss: 0.1002 | Train Acc: 96.174% (59243/61600) | Strict Acc: 63.364% (2788/4400)\n",
      "True positive rate: 64.094% (2849/4445)\n",
      "False negative rate: 35.906% (1596/4445)\n",
      "True negative rate: 98.669% (56394/57155)\n",
      "False positive rate: 1.331% (761/57155)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 45/100: Loss: 0.0998 | Train Acc: 96.197% (60604/63000) | Strict Acc: 63.556% (2860/4500)\n",
      "True positive rate: 64.213% (2914/4538)\n",
      "False negative rate: 35.787% (1624/4538)\n",
      "True negative rate: 98.679% (57690/58462)\n",
      "False positive rate: 1.321% (772/58462)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 46/100: Loss: 0.0993 | Train Acc: 96.217% (61964/64400) | Strict Acc: 63.739% (2932/4600)\n",
      "True positive rate: 64.318% (2985/4641)\n",
      "False negative rate: 35.682% (1656/4641)\n",
      "True negative rate: 98.695% (58979/59759)\n",
      "False positive rate: 1.305% (780/59759)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 47/100: Loss: 0.0993 | Train Acc: 96.214% (63309/65800) | Strict Acc: 63.702% (2994/4700)\n",
      "True positive rate: 64.030% (3028/4729)\n",
      "False negative rate: 35.970% (1701/4729)\n",
      "True negative rate: 98.706% (60281/61071)\n",
      "False positive rate: 1.294% (790/61071)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 48/100: Loss: 0.0992 | Train Acc: 96.216% (64657/67200) | Strict Acc: 63.750% (3060/4800)\n",
      "True positive rate: 64.041% (3106/4850)\n",
      "False negative rate: 35.959% (1744/4850)\n",
      "True negative rate: 98.719% (61551/62350)\n",
      "False positive rate: 1.281% (799/62350)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 49/100: Loss: 0.0991 | Train Acc: 96.220% (66007/68600) | Strict Acc: 63.857% (3129/4900)\n",
      "True positive rate: 64.062% (3173/4953)\n",
      "False negative rate: 35.938% (1780/4953)\n",
      "True negative rate: 98.723% (62834/63647)\n",
      "False positive rate: 1.277% (813/63647)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 50/100: Loss: 0.0992 | Train Acc: 96.223% (67356/70000) | Strict Acc: 63.860% (3193/5000)\n",
      "True positive rate: 63.981% (3224/5039)\n",
      "False negative rate: 36.019% (1815/5039)\n",
      "True negative rate: 98.724% (64132/64961)\n",
      "False positive rate: 1.276% (829/64961)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 51/100: Loss: 0.0990 | Train Acc: 96.234% (68711/71400) | Strict Acc: 63.941% (3261/5100)\n",
      "True positive rate: 63.933% (3274/5121)\n",
      "False negative rate: 36.067% (1847/5121)\n",
      "True negative rate: 98.730% (65437/66279)\n",
      "False positive rate: 1.270% (842/66279)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 52/100: Loss: 0.0990 | Train Acc: 96.228% (70054/72800) | Strict Acc: 63.788% (3317/5200)\n",
      "True positive rate: 63.885% (3338/5225)\n",
      "False negative rate: 36.115% (1887/5225)\n",
      "True negative rate: 98.729% (66716/67575)\n",
      "False positive rate: 1.271% (859/67575)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 53/100: Loss: 0.0990 | Train Acc: 96.224% (71398/74200) | Strict Acc: 63.774% (3380/5300)\n",
      "True positive rate: 63.916% (3408/5332)\n",
      "False negative rate: 36.084% (1924/5332)\n",
      "True negative rate: 98.725% (67990/68868)\n",
      "False positive rate: 1.275% (878/68868)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 54/100: Loss: 0.0994 | Train Acc: 96.208% (72733/75600) | Strict Acc: 63.574% (3433/5400)\n",
      "True positive rate: 63.855% (3482/5453)\n",
      "False negative rate: 36.145% (1971/5453)\n",
      "True negative rate: 98.723% (69251/70147)\n",
      "False positive rate: 1.277% (896/70147)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 55/100: Loss: 0.0992 | Train Acc: 96.201% (74075/77000) | Strict Acc: 63.527% (3494/5500)\n",
      "True positive rate: 63.924% (3551/5555)\n",
      "False negative rate: 36.076% (2004/5555)\n",
      "True negative rate: 98.711% (70524/71445)\n",
      "False positive rate: 1.289% (921/71445)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 56/100: Loss: 0.0992 | Train Acc: 96.189% (75412/78400) | Strict Acc: 63.429% (3552/5600)\n",
      "True positive rate: 64.003% (3620/5656)\n",
      "False negative rate: 35.997% (2036/5656)\n",
      "True negative rate: 98.691% (71792/72744)\n",
      "False positive rate: 1.309% (952/72744)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 57/100: Loss: 0.0993 | Train Acc: 96.195% (76764/79800) | Strict Acc: 63.526% (3621/5700)\n",
      "True positive rate: 64.120% (3685/5747)\n",
      "False negative rate: 35.880% (2062/5747)\n",
      "True negative rate: 98.685% (73079/74053)\n",
      "False positive rate: 1.315% (974/74053)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 58/100: Loss: 0.0991 | Train Acc: 96.195% (78110/81200) | Strict Acc: 63.586% (3688/5800)\n",
      "True positive rate: 64.166% (3746/5838)\n",
      "False negative rate: 35.834% (2092/5838)\n",
      "True negative rate: 98.676% (74364/75362)\n",
      "False positive rate: 1.324% (998/75362)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 59/100: Loss: 0.0992 | Train Acc: 96.191% (79454/82600) | Strict Acc: 63.542% (3749/5900)\n",
      "True positive rate: 64.116% (3813/5947)\n",
      "False negative rate: 35.884% (2134/5947)\n",
      "True negative rate: 98.680% (75641/76653)\n",
      "False positive rate: 1.320% (1012/76653)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 60/100: Loss: 0.0995 | Train Acc: 96.181% (80792/84000) | Strict Acc: 63.533% (3812/6000)\n",
      "True positive rate: 63.962% (3878/6063)\n",
      "False negative rate: 36.038% (2185/6063)\n",
      "True negative rate: 98.687% (76914/77937)\n",
      "False positive rate: 1.313% (1023/77937)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 61/100: Loss: 0.0995 | Train Acc: 96.179% (82137/85400) | Strict Acc: 63.557% (3877/6100)\n",
      "True positive rate: 63.915% (3941/6166)\n",
      "False negative rate: 36.085% (2225/6166)\n",
      "True negative rate: 98.690% (78196/79234)\n",
      "False positive rate: 1.310% (1038/79234)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 62/100: Loss: 0.0998 | Train Acc: 96.160% (83467/86800) | Strict Acc: 63.452% (3934/6200)\n",
      "True positive rate: 63.762% (4017/6300)\n",
      "False negative rate: 36.238% (2283/6300)\n",
      "True negative rate: 98.696% (79450/80500)\n",
      "False positive rate: 1.304% (1050/80500)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 63/100: Loss: 0.1002 | Train Acc: 96.138% (84794/88200) | Strict Acc: 63.365% (3992/6300)\n",
      "True positive rate: 63.534% (4070/6406)\n",
      "False negative rate: 36.466% (2336/6406)\n",
      "True negative rate: 98.692% (80724/81794)\n",
      "False positive rate: 1.308% (1070/81794)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 64/100: Loss: 0.1005 | Train Acc: 96.119% (86123/89600) | Strict Acc: 63.281% (4050/6400)\n",
      "True positive rate: 63.581% (4141/6513)\n",
      "False negative rate: 36.419% (2372/6513)\n",
      "True negative rate: 98.670% (81982/83087)\n",
      "False positive rate: 1.330% (1105/83087)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 65/100: Loss: 0.1008 | Train Acc: 96.110% (87460/91000) | Strict Acc: 63.200% (4108/6500)\n",
      "True positive rate: 63.723% (4235/6646)\n",
      "False negative rate: 36.277% (2411/6646)\n",
      "True negative rate: 98.662% (83225/84354)\n",
      "False positive rate: 1.338% (1129/84354)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 66/100: Loss: 0.1010 | Train Acc: 96.100% (88796/92400) | Strict Acc: 63.076% (4163/6600)\n",
      "True positive rate: 63.773% (4297/6738)\n",
      "False negative rate: 36.227% (2441/6738)\n",
      "True negative rate: 98.642% (84499/85662)\n",
      "False positive rate: 1.358% (1163/85662)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 67/100: Loss: 0.1015 | Train Acc: 96.081% (90124/93800) | Strict Acc: 62.896% (4214/6700)\n",
      "True positive rate: 63.782% (4371/6853)\n",
      "False negative rate: 36.218% (2482/6853)\n",
      "True negative rate: 98.627% (85753/86947)\n",
      "False positive rate: 1.373% (1194/86947)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 68/100: Loss: 0.1015 | Train Acc: 96.085% (91473/95200) | Strict Acc: 62.926% (4279/6800)\n",
      "True positive rate: 63.838% (4431/6941)\n",
      "False negative rate: 36.162% (2510/6941)\n",
      "True negative rate: 98.621% (87042/88259)\n",
      "False positive rate: 1.379% (1217/88259)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 69/100: Loss: 0.1015 | Train Acc: 96.087% (92820/96600) | Strict Acc: 62.884% (4339/6900)\n",
      "True positive rate: 63.830% (4500/7050)\n",
      "False negative rate: 36.170% (2550/7050)\n",
      "True negative rate: 98.626% (88320/89550)\n",
      "False positive rate: 1.374% (1230/89550)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 70/100: Loss: 0.1014 | Train Acc: 96.096% (94174/98000) | Strict Acc: 62.986% (4409/7000)\n",
      "True positive rate: 63.760% (4548/7133)\n",
      "False negative rate: 36.240% (2585/7133)\n",
      "True negative rate: 98.634% (89626/90867)\n",
      "False positive rate: 1.366% (1241/90867)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 71/100: Loss: 0.1014 | Train Acc: 96.093% (95516/99400) | Strict Acc: 62.958% (4470/7100)\n",
      "True positive rate: 63.636% (4606/7238)\n",
      "False negative rate: 36.364% (2632/7238)\n",
      "True negative rate: 98.642% (90910/92162)\n",
      "False positive rate: 1.358% (1252/92162)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 72/100: Loss: 0.1017 | Train Acc: 96.079% (96848/100800) | Strict Acc: 62.875% (4527/7200)\n",
      "True positive rate: 63.352% (4645/7332)\n",
      "False negative rate: 36.648% (2687/7332)\n",
      "True negative rate: 98.647% (92203/93468)\n",
      "False positive rate: 1.353% (1265/93468)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 73/100: Loss: 0.1023 | Train Acc: 96.062% (98175/102200) | Strict Acc: 62.712% (4578/7300)\n",
      "True positive rate: 63.096% (4700/7449)\n",
      "False negative rate: 36.904% (2749/7449)\n",
      "True negative rate: 98.653% (93475/94751)\n",
      "False positive rate: 1.347% (1276/94751)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 74/100: Loss: 0.1026 | Train Acc: 96.046% (99504/103600) | Strict Acc: 62.595% (4632/7400)\n",
      "True positive rate: 62.859% (4744/7547)\n",
      "False negative rate: 37.141% (2803/7547)\n",
      "True negative rate: 98.654% (94760/96053)\n",
      "False positive rate: 1.346% (1293/96053)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 75/100: Loss: 0.1026 | Train Acc: 96.049% (100851/105000) | Strict Acc: 62.600% (4695/7500)\n",
      "True positive rate: 62.774% (4789/7629)\n",
      "False negative rate: 37.226% (2840/7629)\n",
      "True negative rate: 98.656% (96062/97371)\n",
      "False positive rate: 1.344% (1309/97371)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 76/100: Loss: 0.1027 | Train Acc: 96.052% (102199/106400) | Strict Acc: 62.645% (4761/7600)\n",
      "True positive rate: 62.763% (4856/7737)\n",
      "False negative rate: 37.237% (2881/7737)\n",
      "True negative rate: 98.662% (97343/98663)\n",
      "False positive rate: 1.338% (1320/98663)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 77/100: Loss: 0.1027 | Train Acc: 96.051% (103543/107800) | Strict Acc: 62.649% (4824/7700)\n",
      "True positive rate: 62.813% (4917/7828)\n",
      "False negative rate: 37.187% (2911/7828)\n",
      "True negative rate: 98.654% (98626/99972)\n",
      "False positive rate: 1.346% (1346/99972)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 78/100: Loss: 0.1028 | Train Acc: 96.041% (104877/109200) | Strict Acc: 62.538% (4878/7800)\n",
      "True positive rate: 62.762% (4994/7957)\n",
      "False negative rate: 37.238% (2963/7957)\n",
      "True negative rate: 98.657% (99883/101243)\n",
      "False positive rate: 1.343% (1360/101243)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 79/100: Loss: 0.1026 | Train Acc: 96.052% (106233/110600) | Strict Acc: 62.570% (4943/7900)\n",
      "True positive rate: 62.922% (5064/8048)\n",
      "False negative rate: 37.078% (2984/8048)\n",
      "True negative rate: 98.651% (101169/102552)\n",
      "False positive rate: 1.349% (1383/102552)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 80/100: Loss: 0.1024 | Train Acc: 96.052% (107578/112000) | Strict Acc: 62.587% (5007/8000)\n",
      "True positive rate: 63.040% (5134/8144)\n",
      "False negative rate: 36.960% (3010/8144)\n",
      "True negative rate: 98.640% (102444/103856)\n",
      "False positive rate: 1.360% (1412/103856)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 81/100: Loss: 0.1026 | Train Acc: 96.040% (108909/113400) | Strict Acc: 62.432% (5057/8100)\n",
      "True positive rate: 63.006% (5203/8258)\n",
      "False negative rate: 36.994% (3055/8258)\n",
      "True negative rate: 98.634% (103706/105142)\n",
      "False positive rate: 1.366% (1436/105142)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 82/100: Loss: 0.1027 | Train Acc: 96.037% (110250/114800) | Strict Acc: 62.402% (5117/8200)\n",
      "True positive rate: 63.005% (5271/8366)\n",
      "False negative rate: 36.995% (3095/8366)\n",
      "True negative rate: 98.633% (104979/106434)\n",
      "False positive rate: 1.367% (1455/106434)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 83/100: Loss: 0.1025 | Train Acc: 96.047% (111607/116200) | Strict Acc: 62.482% (5186/8300)\n",
      "True positive rate: 63.060% (5338/8465)\n",
      "False negative rate: 36.940% (3127/8465)\n",
      "True negative rate: 98.639% (106269/107735)\n",
      "False positive rate: 1.361% (1466/107735)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 84/100: Loss: 0.1026 | Train Acc: 96.041% (112944/117600) | Strict Acc: 62.452% (5246/8400)\n",
      "True positive rate: 62.945% (5395/8571)\n",
      "False negative rate: 37.055% (3176/8571)\n",
      "True negative rate: 98.643% (107549/109029)\n",
      "False positive rate: 1.357% (1480/109029)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 85/100: Loss: 0.1025 | Train Acc: 96.040% (114288/119000) | Strict Acc: 62.424% (5306/8500)\n",
      "True positive rate: 62.948% (5457/8669)\n",
      "False negative rate: 37.052% (3212/8669)\n",
      "True negative rate: 98.640% (108831/110331)\n",
      "False positive rate: 1.360% (1500/110331)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 86/100: Loss: 0.1022 | Train Acc: 96.048% (115642/120400) | Strict Acc: 62.523% (5377/8600)\n",
      "True positive rate: 63.014% (5520/8760)\n",
      "False negative rate: 36.986% (3240/8760)\n",
      "True negative rate: 98.640% (110122/111640)\n",
      "False positive rate: 1.360% (1518/111640)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 87/100: Loss: 0.1023 | Train Acc: 96.043% (116980/121800) | Strict Acc: 62.517% (5439/8700)\n",
      "True positive rate: 62.971% (5578/8858)\n",
      "False negative rate: 37.029% (3280/8858)\n",
      "True negative rate: 98.636% (111402/112942)\n",
      "False positive rate: 1.364% (1540/112942)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 88/100: Loss: 0.1021 | Train Acc: 96.043% (118325/123200) | Strict Acc: 62.500% (5500/8800)\n",
      "True positive rate: 62.956% (5639/8957)\n",
      "False negative rate: 37.044% (3318/8957)\n",
      "True negative rate: 98.637% (112686/114243)\n",
      "False positive rate: 1.363% (1557/114243)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 89/100: Loss: 0.1021 | Train Acc: 96.036% (119661/124600) | Strict Acc: 62.449% (5558/8900)\n",
      "True positive rate: 62.952% (5706/9064)\n",
      "False negative rate: 37.048% (3358/9064)\n",
      "True negative rate: 98.632% (113955/115536)\n",
      "False positive rate: 1.368% (1581/115536)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 90/100: Loss: 0.1022 | Train Acc: 96.031% (120999/126000) | Strict Acc: 62.456% (5621/9000)\n",
      "True positive rate: 62.900% (5761/9159)\n",
      "False negative rate: 37.100% (3398/9159)\n",
      "True negative rate: 98.628% (115238/116841)\n",
      "False positive rate: 1.372% (1603/116841)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 91/100: Loss: 0.1021 | Train Acc: 96.038% (122352/127400) | Strict Acc: 62.484% (5686/9100)\n",
      "True positive rate: 62.988% (5827/9251)\n",
      "False negative rate: 37.012% (3424/9251)\n",
      "True negative rate: 98.625% (116525/118149)\n",
      "False positive rate: 1.375% (1624/118149)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 92/100: Loss: 0.1021 | Train Acc: 96.040% (123699/128800) | Strict Acc: 62.478% (5748/9200)\n",
      "True positive rate: 63.014% (5888/9344)\n",
      "False negative rate: 36.986% (3456/9344)\n",
      "True negative rate: 98.623% (117811/119456)\n",
      "False positive rate: 1.377% (1645/119456)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 93/100: Loss: 0.1020 | Train Acc: 96.051% (125059/130200) | Strict Acc: 62.581% (5820/9300)\n",
      "True positive rate: 63.087% (5963/9452)\n",
      "False negative rate: 36.913% (3489/9452)\n",
      "True negative rate: 98.632% (119096/120748)\n",
      "False positive rate: 1.368% (1652/120748)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 94/100: Loss: 0.1017 | Train Acc: 96.062% (126417/131600) | Strict Acc: 62.702% (5894/9400)\n",
      "True positive rate: 63.167% (6023/9535)\n",
      "False negative rate: 36.833% (3512/9535)\n",
      "True negative rate: 98.631% (120394/122065)\n",
      "False positive rate: 1.369% (1671/122065)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 95/100: Loss: 0.1017 | Train Acc: 96.060% (127760/133000) | Strict Acc: 62.726% (5959/9500)\n",
      "True positive rate: 63.103% (6080/9635)\n",
      "False negative rate: 36.897% (3555/9635)\n",
      "True negative rate: 98.634% (121680/123365)\n",
      "False positive rate: 1.366% (1685/123365)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 96/100: Loss: 0.1019 | Train Acc: 96.048% (129089/134400) | Strict Acc: 62.646% (6014/9600)\n",
      "True positive rate: 62.975% (6135/9742)\n",
      "False negative rate: 37.025% (3607/9742)\n",
      "True negative rate: 98.633% (122954/124658)\n",
      "False positive rate: 1.367% (1704/124658)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 97/100: Loss: 0.1020 | Train Acc: 96.046% (130430/135800) | Strict Acc: 62.619% (6074/9700)\n",
      "True positive rate: 62.893% (6188/9839)\n",
      "False negative rate: 37.107% (3651/9839)\n",
      "True negative rate: 98.635% (124242/125961)\n",
      "False positive rate: 1.365% (1719/125961)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 98/100: Loss: 0.1021 | Train Acc: 96.039% (131766/137200) | Strict Acc: 62.622% (6137/9800)\n",
      "True positive rate: 62.833% (6250/9947)\n",
      "False negative rate: 37.167% (3697/9947)\n",
      "True negative rate: 98.635% (125516/127253)\n",
      "False positive rate: 1.365% (1737/127253)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 99/100: Loss: 0.1019 | Train Acc: 96.043% (133116/138600) | Strict Acc: 62.616% (6199/9900)\n",
      "True positive rate: 62.837% (6317/10053)\n",
      "False negative rate: 37.163% (3736/10053)\n",
      "True negative rate: 98.640% (126799/128547)\n",
      "False positive rate: 1.360% (1748/128547)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 3 - Batch 100/100: Loss: 0.1021 | Train Acc: 96.042% (133249/138740) | Strict Acc: 62.614% (6205/9910)\n",
      "True positive rate: 62.834% (6323/10063)\n",
      "False negative rate: 37.166% (3740/10063)\n",
      "True negative rate: 98.639% (126926/128677)\n",
      "False positive rate: 1.361% (1751/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1112 | Dev Acc: 95.697% (67926/70980) | Strict Acc: 61.262% (3106/5070)\n",
      "True positive rate: 63.575% (3276/5153)\n",
      "False negative rate: 36.425% (1877/5153)\n",
      "True negative rate: 98.212% (64650/65827)\n",
      "False positive rate: 1.788% (1177/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 1/100: Loss: 0.0958 | Train Acc: 95.714% (1340/1400) | Strict Acc: 62.000% (62/100)\n",
      "True positive rate: 63.158% (72/114)\n",
      "False negative rate: 36.842% (42/114)\n",
      "True negative rate: 98.600% (1268/1286)\n",
      "False positive rate: 1.400% (18/1286)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 2/100: Loss: 0.0987 | Train Acc: 95.857% (2684/2800) | Strict Acc: 61.000% (122/200)\n",
      "True positive rate: 64.423% (134/208)\n",
      "False negative rate: 35.577% (74/208)\n",
      "True negative rate: 98.380% (2550/2592)\n",
      "False positive rate: 1.620% (42/2592)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 3/100: Loss: 0.0994 | Train Acc: 95.952% (4030/4200) | Strict Acc: 62.333% (187/300)\n",
      "True positive rate: 66.667% (208/312)\n",
      "False negative rate: 33.333% (104/312)\n",
      "True negative rate: 98.302% (3822/3888)\n",
      "False positive rate: 1.698% (66/3888)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 4/100: Loss: 0.0997 | Train Acc: 95.982% (5375/5600) | Strict Acc: 62.000% (248/400)\n",
      "True positive rate: 65.686% (268/408)\n",
      "False negative rate: 34.314% (140/408)\n",
      "True negative rate: 98.363% (5107/5192)\n",
      "False positive rate: 1.637% (85/5192)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 5/100: Loss: 0.1038 | Train Acc: 95.900% (6713/7000) | Strict Acc: 61.000% (305/500)\n",
      "True positive rate: 64.683% (337/521)\n",
      "False negative rate: 35.317% (184/521)\n",
      "True negative rate: 98.410% (6376/6479)\n",
      "False positive rate: 1.590% (103/6479)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 6/100: Loss: 0.1006 | Train Acc: 96.119% (8074/8400) | Strict Acc: 63.000% (378/600)\n",
      "True positive rate: 66.007% (400/606)\n",
      "False negative rate: 33.993% (206/606)\n",
      "True negative rate: 98.460% (7674/7794)\n",
      "False positive rate: 1.540% (120/7794)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 7/100: Loss: 0.1008 | Train Acc: 96.061% (9414/9800) | Strict Acc: 62.714% (439/700)\n",
      "True positive rate: 64.476% (461/715)\n",
      "False negative rate: 35.524% (254/715)\n",
      "True negative rate: 98.547% (8953/9085)\n",
      "False positive rate: 1.453% (132/9085)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 8/100: Loss: 0.0996 | Train Acc: 96.107% (10764/11200) | Strict Acc: 63.000% (504/800)\n",
      "True positive rate: 65.079% (533/819)\n",
      "False negative rate: 34.921% (286/819)\n",
      "True negative rate: 98.555% (10231/10381)\n",
      "False positive rate: 1.445% (150/10381)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 9/100: Loss: 0.1011 | Train Acc: 96.056% (12103/12600) | Strict Acc: 63.333% (570/900)\n",
      "True positive rate: 64.125% (597/931)\n",
      "False negative rate: 35.875% (334/931)\n",
      "True negative rate: 98.603% (11506/11669)\n",
      "False positive rate: 1.397% (163/11669)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 10/100: Loss: 0.1014 | Train Acc: 96.057% (13448/14000) | Strict Acc: 63.000% (630/1000)\n",
      "True positive rate: 63.583% (646/1016)\n",
      "False negative rate: 36.417% (370/1016)\n",
      "True negative rate: 98.598% (12802/12984)\n",
      "False positive rate: 1.402% (182/12984)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 11/100: Loss: 0.1012 | Train Acc: 96.104% (14800/15400) | Strict Acc: 63.091% (694/1100)\n",
      "True positive rate: 63.481% (704/1109)\n",
      "False negative rate: 36.519% (405/1109)\n",
      "True negative rate: 98.636% (14096/14291)\n",
      "False positive rate: 1.364% (195/14291)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 12/100: Loss: 0.1018 | Train Acc: 96.089% (16143/16800) | Strict Acc: 62.833% (754/1200)\n",
      "True positive rate: 62.779% (759/1209)\n",
      "False negative rate: 37.221% (450/1209)\n",
      "True negative rate: 98.672% (15384/15591)\n",
      "False positive rate: 1.328% (207/15591)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 13/100: Loss: 0.1023 | Train Acc: 96.082% (17487/18200) | Strict Acc: 63.000% (819/1300)\n",
      "True positive rate: 63.095% (848/1344)\n",
      "False negative rate: 36.905% (496/1344)\n",
      "True negative rate: 98.713% (16639/16856)\n",
      "False positive rate: 1.287% (217/16856)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 14/100: Loss: 0.1012 | Train Acc: 96.138% (18843/19600) | Strict Acc: 63.214% (885/1400)\n",
      "True positive rate: 63.473% (921/1451)\n",
      "False negative rate: 36.527% (530/1451)\n",
      "True negative rate: 98.749% (17922/18149)\n",
      "False positive rate: 1.251% (227/18149)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 15/100: Loss: 0.1013 | Train Acc: 96.157% (20193/21000) | Strict Acc: 63.467% (952/1500)\n",
      "True positive rate: 63.508% (992/1562)\n",
      "False negative rate: 36.492% (570/1562)\n",
      "True negative rate: 98.781% (19201/19438)\n",
      "False positive rate: 1.219% (237/19438)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 16/100: Loss: 0.1017 | Train Acc: 96.156% (21539/22400) | Strict Acc: 63.562% (1017/1600)\n",
      "True positive rate: 63.924% (1072/1677)\n",
      "False negative rate: 36.076% (605/1677)\n",
      "True negative rate: 98.765% (20467/20723)\n",
      "False positive rate: 1.235% (256/20723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 17/100: Loss: 0.1016 | Train Acc: 96.189% (22893/23800) | Strict Acc: 63.765% (1084/1700)\n",
      "True positive rate: 64.294% (1138/1770)\n",
      "False negative rate: 35.706% (632/1770)\n",
      "True negative rate: 98.752% (21755/22030)\n",
      "False positive rate: 1.248% (275/22030)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 18/100: Loss: 0.1010 | Train Acc: 96.214% (24246/25200) | Strict Acc: 64.000% (1152/1800)\n",
      "True positive rate: 65.037% (1224/1882)\n",
      "False negative rate: 34.963% (658/1882)\n",
      "True negative rate: 98.731% (23022/23318)\n",
      "False positive rate: 1.269% (296/23318)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 19/100: Loss: 0.1010 | Train Acc: 96.177% (25583/26600) | Strict Acc: 63.737% (1211/1900)\n",
      "True positive rate: 64.572% (1274/1973)\n",
      "False negative rate: 35.428% (699/1973)\n",
      "True negative rate: 98.709% (24309/24627)\n",
      "False positive rate: 1.291% (318/24627)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 20/100: Loss: 0.1001 | Train Acc: 96.196% (26935/28000) | Strict Acc: 63.900% (1278/2000)\n",
      "True positive rate: 64.805% (1346/2077)\n",
      "False negative rate: 35.195% (731/2077)\n",
      "True negative rate: 98.712% (25589/25923)\n",
      "False positive rate: 1.288% (334/25923)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 21/100: Loss: 0.0997 | Train Acc: 96.221% (28289/29400) | Strict Acc: 64.048% (1345/2100)\n",
      "True positive rate: 64.911% (1417/2183)\n",
      "False negative rate: 35.089% (766/2183)\n",
      "True negative rate: 98.732% (26872/27217)\n",
      "False positive rate: 1.268% (345/27217)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 22/100: Loss: 0.1001 | Train Acc: 96.185% (29625/30800) | Strict Acc: 63.818% (1404/2200)\n",
      "True positive rate: 64.455% (1467/2276)\n",
      "False negative rate: 35.545% (809/2276)\n",
      "True negative rate: 98.717% (28158/28524)\n",
      "False positive rate: 1.283% (366/28524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 23/100: Loss: 0.0995 | Train Acc: 96.214% (30981/32200) | Strict Acc: 64.000% (1472/2300)\n",
      "True positive rate: 64.617% (1534/2374)\n",
      "False negative rate: 35.383% (840/2374)\n",
      "True negative rate: 98.729% (29447/29826)\n",
      "False positive rate: 1.271% (379/29826)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 24/100: Loss: 0.0997 | Train Acc: 96.205% (32325/33600) | Strict Acc: 64.042% (1537/2400)\n",
      "True positive rate: 64.326% (1603/2492)\n",
      "False negative rate: 35.674% (889/2492)\n",
      "True negative rate: 98.759% (30722/31108)\n",
      "False positive rate: 1.241% (386/31108)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 25/100: Loss: 0.0986 | Train Acc: 96.257% (33690/35000) | Strict Acc: 64.520% (1613/2500)\n",
      "True positive rate: 64.656% (1672/2586)\n",
      "False negative rate: 35.344% (914/2586)\n",
      "True negative rate: 98.778% (32018/32414)\n",
      "False positive rate: 1.222% (396/32414)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 26/100: Loss: 0.0983 | Train Acc: 96.272% (35043/36400) | Strict Acc: 64.500% (1677/2600)\n",
      "True positive rate: 64.627% (1732/2680)\n",
      "False negative rate: 35.373% (948/2680)\n",
      "True negative rate: 98.787% (33311/33720)\n",
      "False positive rate: 1.213% (409/33720)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 27/100: Loss: 0.0982 | Train Acc: 96.270% (36390/37800) | Strict Acc: 64.519% (1742/2700)\n",
      "True positive rate: 64.761% (1790/2764)\n",
      "False negative rate: 35.239% (974/2764)\n",
      "True negative rate: 98.756% (34600/35036)\n",
      "False positive rate: 1.244% (436/35036)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 28/100: Loss: 0.0978 | Train Acc: 96.283% (37743/39200) | Strict Acc: 64.429% (1804/2800)\n",
      "True positive rate: 64.996% (1855/2854)\n",
      "False negative rate: 35.004% (999/2854)\n",
      "True negative rate: 98.740% (35888/36346)\n",
      "False positive rate: 1.260% (458/36346)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 29/100: Loss: 0.0978 | Train Acc: 96.291% (39094/40600) | Strict Acc: 64.345% (1866/2900)\n",
      "True positive rate: 65.112% (1913/2938)\n",
      "False negative rate: 34.888% (1025/2938)\n",
      "True negative rate: 98.723% (37181/37662)\n",
      "False positive rate: 1.277% (481/37662)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 30/100: Loss: 0.0979 | Train Acc: 96.269% (40433/42000) | Strict Acc: 64.167% (1925/3000)\n",
      "True positive rate: 65.052% (1988/3056)\n",
      "False negative rate: 34.948% (1068/3056)\n",
      "True negative rate: 98.719% (38445/38944)\n",
      "False positive rate: 1.281% (499/38944)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 31/100: Loss: 0.0984 | Train Acc: 96.249% (41772/43400) | Strict Acc: 63.935% (1982/3100)\n",
      "True positive rate: 64.867% (2055/3168)\n",
      "False negative rate: 35.133% (1113/3168)\n",
      "True negative rate: 98.720% (39717/40232)\n",
      "False positive rate: 1.280% (515/40232)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 32/100: Loss: 0.0982 | Train Acc: 96.272% (43130/44800) | Strict Acc: 64.094% (2051/3200)\n",
      "True positive rate: 65.014% (2124/3267)\n",
      "False negative rate: 34.986% (1143/3267)\n",
      "True negative rate: 98.731% (41006/41533)\n",
      "False positive rate: 1.269% (527/41533)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 33/100: Loss: 0.0974 | Train Acc: 96.303% (44492/46200) | Strict Acc: 64.333% (2123/3300)\n",
      "True positive rate: 65.161% (2192/3364)\n",
      "False negative rate: 34.839% (1172/3364)\n",
      "True negative rate: 98.749% (42300/42836)\n",
      "False positive rate: 1.251% (536/42836)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 34/100: Loss: 0.0973 | Train Acc: 96.298% (45838/47600) | Strict Acc: 64.324% (2187/3400)\n",
      "True positive rate: 64.942% (2247/3460)\n",
      "False negative rate: 35.058% (1213/3460)\n",
      "True negative rate: 98.756% (43591/44140)\n",
      "False positive rate: 1.244% (549/44140)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 35/100: Loss: 0.0973 | Train Acc: 96.302% (47188/49000) | Strict Acc: 64.343% (2252/3500)\n",
      "True positive rate: 65.046% (2328/3579)\n",
      "False negative rate: 34.954% (1251/3579)\n",
      "True negative rate: 98.765% (44860/45421)\n",
      "False positive rate: 1.235% (561/45421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 36/100: Loss: 0.0970 | Train Acc: 96.317% (48544/50400) | Strict Acc: 64.472% (2321/3600)\n",
      "True positive rate: 65.191% (2386/3660)\n",
      "False negative rate: 34.809% (1274/3660)\n",
      "True negative rate: 98.755% (46158/46740)\n",
      "False positive rate: 1.245% (582/46740)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 37/100: Loss: 0.0972 | Train Acc: 96.319% (49893/51800) | Strict Acc: 64.486% (2386/3700)\n",
      "True positive rate: 65.216% (2458/3769)\n",
      "False negative rate: 34.784% (1311/3769)\n",
      "True negative rate: 98.759% (47435/48031)\n",
      "False positive rate: 1.241% (596/48031)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 38/100: Loss: 0.0968 | Train Acc: 96.331% (51248/53200) | Strict Acc: 64.553% (2453/3800)\n",
      "True positive rate: 65.247% (2512/3850)\n",
      "False negative rate: 34.753% (1338/3850)\n",
      "True negative rate: 98.756% (48736/49350)\n",
      "False positive rate: 1.244% (614/49350)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 39/100: Loss: 0.0969 | Train Acc: 96.332% (52597/54600) | Strict Acc: 64.410% (2512/3900)\n",
      "True positive rate: 65.077% (2566/3943)\n",
      "False negative rate: 34.923% (1377/3943)\n",
      "True negative rate: 98.764% (50031/50657)\n",
      "False positive rate: 1.236% (626/50657)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 40/100: Loss: 0.0969 | Train Acc: 96.321% (53940/56000) | Strict Acc: 64.300% (2572/4000)\n",
      "True positive rate: 64.922% (2630/4051)\n",
      "False negative rate: 35.078% (1421/4051)\n",
      "True negative rate: 98.770% (51310/51949)\n",
      "False positive rate: 1.230% (639/51949)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 41/100: Loss: 0.0969 | Train Acc: 96.314% (55284/57400) | Strict Acc: 64.195% (2632/4100)\n",
      "True positive rate: 64.856% (2698/4160)\n",
      "False negative rate: 35.144% (1462/4160)\n",
      "True negative rate: 98.772% (52586/53240)\n",
      "False positive rate: 1.228% (654/53240)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 42/100: Loss: 0.0970 | Train Acc: 96.310% (56630/58800) | Strict Acc: 64.143% (2694/4200)\n",
      "True positive rate: 64.793% (2766/4269)\n",
      "False negative rate: 35.207% (1503/4269)\n",
      "True negative rate: 98.777% (53864/54531)\n",
      "False positive rate: 1.223% (667/54531)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 43/100: Loss: 0.0970 | Train Acc: 96.311% (57979/60200) | Strict Acc: 64.186% (2760/4300)\n",
      "True positive rate: 64.802% (2826/4361)\n",
      "False negative rate: 35.198% (1535/4361)\n",
      "True negative rate: 98.771% (55153/55839)\n",
      "False positive rate: 1.229% (686/55839)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 44/100: Loss: 0.0972 | Train Acc: 96.304% (59323/61600) | Strict Acc: 64.091% (2820/4400)\n",
      "True positive rate: 64.842% (2890/4457)\n",
      "False negative rate: 35.158% (1567/4457)\n",
      "True negative rate: 98.758% (56433/57143)\n",
      "False positive rate: 1.242% (710/57143)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 45/100: Loss: 0.0967 | Train Acc: 96.321% (60682/63000) | Strict Acc: 64.267% (2892/4500)\n",
      "True positive rate: 65.009% (2967/4564)\n",
      "False negative rate: 34.991% (1597/4564)\n",
      "True negative rate: 98.766% (57715/58436)\n",
      "False positive rate: 1.234% (721/58436)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 46/100: Loss: 0.0965 | Train Acc: 96.340% (62043/64400) | Strict Acc: 64.435% (2964/4600)\n",
      "True positive rate: 65.094% (3036/4664)\n",
      "False negative rate: 34.906% (1628/4664)\n",
      "True negative rate: 98.780% (59007/59736)\n",
      "False positive rate: 1.220% (729/59736)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 47/100: Loss: 0.0965 | Train Acc: 96.334% (63388/65800) | Strict Acc: 64.319% (3023/4700)\n",
      "True positive rate: 65.130% (3108/4772)\n",
      "False negative rate: 34.870% (1664/4772)\n",
      "True negative rate: 98.774% (60280/61028)\n",
      "False positive rate: 1.226% (748/61028)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 48/100: Loss: 0.0964 | Train Acc: 96.324% (64730/67200) | Strict Acc: 64.354% (3089/4800)\n",
      "True positive rate: 64.972% (3157/4859)\n",
      "False negative rate: 35.028% (1702/4859)\n",
      "True negative rate: 98.768% (61573/62341)\n",
      "False positive rate: 1.232% (768/62341)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 49/100: Loss: 0.0964 | Train Acc: 96.328% (66081/68600) | Strict Acc: 64.388% (3155/4900)\n",
      "True positive rate: 64.937% (3228/4971)\n",
      "False negative rate: 35.063% (1743/4971)\n",
      "True negative rate: 98.780% (62853/63629)\n",
      "False positive rate: 1.220% (776/63629)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 50/100: Loss: 0.0964 | Train Acc: 96.334% (67434/70000) | Strict Acc: 64.540% (3227/5000)\n",
      "True positive rate: 65.009% (3294/5067)\n",
      "False negative rate: 34.991% (1773/5067)\n",
      "True negative rate: 98.779% (64140/64933)\n",
      "False positive rate: 1.221% (793/64933)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 51/100: Loss: 0.0961 | Train Acc: 96.343% (68789/71400) | Strict Acc: 64.588% (3294/5100)\n",
      "True positive rate: 65.033% (3357/5162)\n",
      "False negative rate: 34.967% (1805/5162)\n",
      "True negative rate: 98.783% (65432/66238)\n",
      "False positive rate: 1.217% (806/66238)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 52/100: Loss: 0.0956 | Train Acc: 96.360% (70150/72800) | Strict Acc: 64.712% (3365/5200)\n",
      "True positive rate: 65.169% (3422/5251)\n",
      "False negative rate: 34.831% (1829/5251)\n",
      "True negative rate: 98.785% (66728/67549)\n",
      "False positive rate: 1.215% (821/67549)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 53/100: Loss: 0.0953 | Train Acc: 96.375% (71510/74200) | Strict Acc: 64.792% (3434/5300)\n",
      "True positive rate: 65.287% (3502/5364)\n",
      "False negative rate: 34.713% (1862/5364)\n",
      "True negative rate: 98.797% (68008/68836)\n",
      "False positive rate: 1.203% (828/68836)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 54/100: Loss: 0.0950 | Train Acc: 96.381% (72864/75600) | Strict Acc: 64.852% (3502/5400)\n",
      "True positive rate: 65.477% (3579/5466)\n",
      "False negative rate: 34.523% (1887/5466)\n",
      "True negative rate: 98.789% (69285/70134)\n",
      "False positive rate: 1.211% (849/70134)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 55/100: Loss: 0.0948 | Train Acc: 96.392% (74222/77000) | Strict Acc: 64.909% (3570/5500)\n",
      "True positive rate: 65.625% (3654/5568)\n",
      "False negative rate: 34.375% (1914/5568)\n",
      "True negative rate: 98.790% (70568/71432)\n",
      "False positive rate: 1.210% (864/71432)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 56/100: Loss: 0.0951 | Train Acc: 96.372% (75556/78400) | Strict Acc: 64.821% (3630/5600)\n",
      "True positive rate: 65.558% (3727/5685)\n",
      "False negative rate: 34.442% (1958/5685)\n",
      "True negative rate: 98.782% (71829/72715)\n",
      "False positive rate: 1.218% (886/72715)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 57/100: Loss: 0.0951 | Train Acc: 96.381% (76912/79800) | Strict Acc: 64.860% (3697/5700)\n",
      "True positive rate: 65.699% (3802/5787)\n",
      "False negative rate: 34.301% (1985/5787)\n",
      "True negative rate: 98.780% (73110/74013)\n",
      "False positive rate: 1.220% (903/74013)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 58/100: Loss: 0.0948 | Train Acc: 96.392% (78270/81200) | Strict Acc: 64.914% (3765/5800)\n",
      "True positive rate: 65.900% (3867/5868)\n",
      "False negative rate: 34.100% (2001/5868)\n",
      "True negative rate: 98.767% (74403/75332)\n",
      "False positive rate: 1.233% (929/75332)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 59/100: Loss: 0.0949 | Train Acc: 96.381% (79611/82600) | Strict Acc: 64.797% (3823/5900)\n",
      "True positive rate: 65.835% (3933/5974)\n",
      "False negative rate: 34.165% (2041/5974)\n",
      "True negative rate: 98.763% (75678/76626)\n",
      "False positive rate: 1.237% (948/76626)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 60/100: Loss: 0.0947 | Train Acc: 96.375% (80955/84000) | Strict Acc: 64.733% (3884/6000)\n",
      "True positive rate: 65.832% (3996/6070)\n",
      "False negative rate: 34.168% (2074/6070)\n",
      "True negative rate: 98.754% (76959/77930)\n",
      "False positive rate: 1.246% (971/77930)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 61/100: Loss: 0.0948 | Train Acc: 96.368% (82298/85400) | Strict Acc: 64.672% (3945/6100)\n",
      "True positive rate: 65.722% (4059/6176)\n",
      "False negative rate: 34.278% (2117/6176)\n",
      "True negative rate: 98.757% (78239/79224)\n",
      "False positive rate: 1.243% (985/79224)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 62/100: Loss: 0.0952 | Train Acc: 96.357% (83638/86800) | Strict Acc: 64.613% (4006/6200)\n",
      "True positive rate: 65.610% (4117/6275)\n",
      "False negative rate: 34.390% (2158/6275)\n",
      "True negative rate: 98.753% (79521/80525)\n",
      "False positive rate: 1.247% (1004/80525)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 63/100: Loss: 0.0950 | Train Acc: 96.361% (84990/88200) | Strict Acc: 64.635% (4072/6300)\n",
      "True positive rate: 65.611% (4186/6380)\n",
      "False negative rate: 34.389% (2194/6380)\n",
      "True negative rate: 98.758% (80804/81820)\n",
      "False positive rate: 1.242% (1016/81820)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 64/100: Loss: 0.0952 | Train Acc: 96.350% (86330/89600) | Strict Acc: 64.578% (4133/6400)\n",
      "True positive rate: 65.485% (4248/6487)\n",
      "False negative rate: 34.515% (2239/6487)\n",
      "True negative rate: 98.760% (82082/83113)\n",
      "False positive rate: 1.240% (1031/83113)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 65/100: Loss: 0.0953 | Train Acc: 96.351% (87679/91000) | Strict Acc: 64.600% (4199/6500)\n",
      "True positive rate: 65.607% (4332/6603)\n",
      "False negative rate: 34.393% (2271/6603)\n",
      "True negative rate: 98.756% (83347/84397)\n",
      "False positive rate: 1.244% (1050/84397)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 66/100: Loss: 0.0952 | Train Acc: 96.351% (89028/92400) | Strict Acc: 64.591% (4263/6600)\n",
      "True positive rate: 65.659% (4409/6715)\n",
      "False negative rate: 34.341% (2306/6715)\n",
      "True negative rate: 98.756% (84619/85685)\n",
      "False positive rate: 1.244% (1066/85685)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 67/100: Loss: 0.0956 | Train Acc: 96.338% (90365/93800) | Strict Acc: 64.433% (4317/6700)\n",
      "True positive rate: 65.578% (4477/6827)\n",
      "False negative rate: 34.422% (2350/6827)\n",
      "True negative rate: 98.752% (85888/86973)\n",
      "False positive rate: 1.248% (1085/86973)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 68/100: Loss: 0.0958 | Train Acc: 96.326% (91702/95200) | Strict Acc: 64.353% (4376/6800)\n",
      "True positive rate: 65.548% (4530/6911)\n",
      "False negative rate: 34.452% (2381/6911)\n",
      "True negative rate: 98.735% (87172/88289)\n",
      "False positive rate: 1.265% (1117/88289)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 69/100: Loss: 0.0959 | Train Acc: 96.322% (93047/96600) | Strict Acc: 64.290% (4436/6900)\n",
      "True positive rate: 65.675% (4615/7027)\n",
      "False negative rate: 34.325% (2412/7027)\n",
      "True negative rate: 98.726% (88432/89573)\n",
      "False positive rate: 1.274% (1141/89573)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 70/100: Loss: 0.0959 | Train Acc: 96.318% (94392/98000) | Strict Acc: 64.257% (4498/7000)\n",
      "True positive rate: 65.737% (4691/7136)\n",
      "False negative rate: 34.263% (2445/7136)\n",
      "True negative rate: 98.720% (89701/90864)\n",
      "False positive rate: 1.280% (1163/90864)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 71/100: Loss: 0.0958 | Train Acc: 96.329% (95751/99400) | Strict Acc: 64.338% (4568/7100)\n",
      "True positive rate: 65.753% (4752/7227)\n",
      "False negative rate: 34.247% (2475/7227)\n",
      "True negative rate: 98.726% (90999/92173)\n",
      "False positive rate: 1.274% (1174/92173)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 72/100: Loss: 0.0959 | Train Acc: 96.324% (97095/100800) | Strict Acc: 64.333% (4632/7200)\n",
      "True positive rate: 65.685% (4820/7338)\n",
      "False negative rate: 34.315% (2518/7338)\n",
      "True negative rate: 98.730% (92275/93462)\n",
      "False positive rate: 1.270% (1187/93462)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 73/100: Loss: 0.0961 | Train Acc: 96.307% (98426/102200) | Strict Acc: 64.205% (4687/7300)\n",
      "True positive rate: 65.554% (4891/7461)\n",
      "False negative rate: 34.446% (2570/7461)\n",
      "True negative rate: 98.729% (93535/94739)\n",
      "False positive rate: 1.271% (1204/94739)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 74/100: Loss: 0.0963 | Train Acc: 96.293% (99760/103600) | Strict Acc: 64.135% (4746/7400)\n",
      "True positive rate: 65.394% (4949/7568)\n",
      "False negative rate: 34.606% (2619/7568)\n",
      "True negative rate: 98.729% (94811/96032)\n",
      "False positive rate: 1.271% (1221/96032)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 75/100: Loss: 0.0965 | Train Acc: 96.280% (101094/105000) | Strict Acc: 64.107% (4808/7500)\n",
      "True positive rate: 65.319% (5008/7667)\n",
      "False negative rate: 34.681% (2659/7667)\n",
      "True negative rate: 98.719% (96086/97333)\n",
      "False positive rate: 1.281% (1247/97333)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 76/100: Loss: 0.0964 | Train Acc: 96.286% (102448/106400) | Strict Acc: 64.158% (4876/7600)\n",
      "True positive rate: 65.397% (5082/7771)\n",
      "False negative rate: 34.603% (2689/7771)\n",
      "True negative rate: 98.719% (97366/98629)\n",
      "False positive rate: 1.281% (1263/98629)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 77/100: Loss: 0.0963 | Train Acc: 96.290% (103801/107800) | Strict Acc: 64.208% (4944/7700)\n",
      "True positive rate: 65.467% (5149/7865)\n",
      "False negative rate: 34.533% (2716/7865)\n",
      "True negative rate: 98.716% (98652/99935)\n",
      "False positive rate: 1.284% (1283/99935)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 78/100: Loss: 0.0964 | Train Acc: 96.280% (105138/109200) | Strict Acc: 64.141% (5003/7800)\n",
      "True positive rate: 65.320% (5208/7973)\n",
      "False negative rate: 34.680% (2765/7973)\n",
      "True negative rate: 98.719% (99930/101227)\n",
      "False positive rate: 1.281% (1297/101227)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 79/100: Loss: 0.0963 | Train Acc: 96.288% (106495/110600) | Strict Acc: 64.203% (5072/7900)\n",
      "True positive rate: 65.335% (5268/8063)\n",
      "False negative rate: 34.665% (2795/8063)\n",
      "True negative rate: 98.722% (101227/102537)\n",
      "False positive rate: 1.278% (1310/102537)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 80/100: Loss: 0.0964 | Train Acc: 96.277% (107830/112000) | Strict Acc: 64.138% (5131/8000)\n",
      "True positive rate: 65.285% (5341/8181)\n",
      "False negative rate: 34.715% (2840/8181)\n",
      "True negative rate: 98.719% (102489/103819)\n",
      "False positive rate: 1.281% (1330/103819)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 81/100: Loss: 0.0963 | Train Acc: 96.273% (109174/113400) | Strict Acc: 64.074% (5190/8100)\n",
      "True positive rate: 65.221% (5399/8278)\n",
      "False negative rate: 34.779% (2879/8278)\n",
      "True negative rate: 98.719% (103775/105122)\n",
      "False positive rate: 1.281% (1347/105122)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 82/100: Loss: 0.0964 | Train Acc: 96.274% (110522/114800) | Strict Acc: 64.061% (5253/8200)\n",
      "True positive rate: 65.246% (5467/8379)\n",
      "False negative rate: 34.754% (2912/8379)\n",
      "True negative rate: 98.716% (105055/106421)\n",
      "False positive rate: 1.284% (1366/106421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 83/100: Loss: 0.0964 | Train Acc: 96.268% (111863/116200) | Strict Acc: 64.072% (5318/8300)\n",
      "True positive rate: 65.191% (5523/8472)\n",
      "False negative rate: 34.809% (2949/8472)\n",
      "True negative rate: 98.712% (106340/107728)\n",
      "False positive rate: 1.288% (1388/107728)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 84/100: Loss: 0.0963 | Train Acc: 96.276% (113220/117600) | Strict Acc: 64.131% (5387/8400)\n",
      "True positive rate: 65.204% (5588/8570)\n",
      "False negative rate: 34.796% (2982/8570)\n",
      "True negative rate: 98.718% (107632/109030)\n",
      "False positive rate: 1.282% (1398/109030)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 85/100: Loss: 0.0963 | Train Acc: 96.276% (114568/119000) | Strict Acc: 64.071% (5446/8500)\n",
      "True positive rate: 65.219% (5646/8657)\n",
      "False negative rate: 34.781% (3011/8657)\n",
      "True negative rate: 98.712% (108922/110343)\n",
      "False positive rate: 1.288% (1421/110343)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 86/100: Loss: 0.0963 | Train Acc: 96.272% (115912/120400) | Strict Acc: 64.012% (5505/8600)\n",
      "True positive rate: 65.204% (5706/8751)\n",
      "False negative rate: 34.796% (3045/8751)\n",
      "True negative rate: 98.708% (110206/111649)\n",
      "False positive rate: 1.292% (1443/111649)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 87/100: Loss: 0.0963 | Train Acc: 96.274% (117262/121800) | Strict Acc: 64.057% (5573/8700)\n",
      "True positive rate: 65.218% (5777/8858)\n",
      "False negative rate: 34.782% (3081/8858)\n",
      "True negative rate: 98.710% (111485/112942)\n",
      "False positive rate: 1.290% (1457/112942)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 88/100: Loss: 0.0964 | Train Acc: 96.269% (118604/123200) | Strict Acc: 64.000% (5632/8800)\n",
      "True positive rate: 65.156% (5836/8957)\n",
      "False negative rate: 34.844% (3121/8957)\n",
      "True negative rate: 98.709% (112768/114243)\n",
      "False positive rate: 1.291% (1475/114243)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 89/100: Loss: 0.0964 | Train Acc: 96.272% (119955/124600) | Strict Acc: 64.045% (5700/8900)\n",
      "True positive rate: 65.151% (5902/9059)\n",
      "False negative rate: 34.849% (3157/9059)\n",
      "True negative rate: 98.712% (114053/115541)\n",
      "False positive rate: 1.288% (1488/115541)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 90/100: Loss: 0.0964 | Train Acc: 96.268% (121298/126000) | Strict Acc: 64.011% (5761/9000)\n",
      "True positive rate: 65.092% (5965/9164)\n",
      "False negative rate: 34.908% (3199/9164)\n",
      "True negative rate: 98.714% (115333/116836)\n",
      "False positive rate: 1.286% (1503/116836)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 91/100: Loss: 0.0964 | Train Acc: 96.271% (122649/127400) | Strict Acc: 64.033% (5827/9100)\n",
      "True positive rate: 65.084% (6032/9268)\n",
      "False negative rate: 34.916% (3236/9268)\n",
      "True negative rate: 98.718% (116617/118132)\n",
      "False positive rate: 1.282% (1515/118132)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 92/100: Loss: 0.0963 | Train Acc: 96.279% (124007/128800) | Strict Acc: 64.087% (5896/9200)\n",
      "True positive rate: 65.154% (6103/9367)\n",
      "False negative rate: 34.846% (3264/9367)\n",
      "True negative rate: 98.720% (117904/119433)\n",
      "False positive rate: 1.280% (1529/119433)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 93/100: Loss: 0.0964 | Train Acc: 96.270% (125344/130200) | Strict Acc: 64.032% (5955/9300)\n",
      "True positive rate: 65.137% (6173/9477)\n",
      "False negative rate: 34.863% (3304/9477)\n",
      "True negative rate: 98.714% (119171/120723)\n",
      "False positive rate: 1.286% (1552/120723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 94/100: Loss: 0.0963 | Train Acc: 96.272% (126694/131600) | Strict Acc: 64.011% (6017/9400)\n",
      "True positive rate: 65.192% (6235/9564)\n",
      "False negative rate: 34.808% (3329/9564)\n",
      "True negative rate: 98.708% (120459/122036)\n",
      "False positive rate: 1.292% (1577/122036)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 95/100: Loss: 0.0963 | Train Acc: 96.269% (128038/133000) | Strict Acc: 63.958% (6076/9500)\n",
      "True positive rate: 65.200% (6299/9661)\n",
      "False negative rate: 34.800% (3362/9661)\n",
      "True negative rate: 98.703% (121739/123339)\n",
      "False positive rate: 1.297% (1600/123339)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 96/100: Loss: 0.0963 | Train Acc: 96.270% (129387/134400) | Strict Acc: 63.958% (6140/9600)\n",
      "True positive rate: 65.184% (6360/9757)\n",
      "False negative rate: 34.816% (3397/9757)\n",
      "True negative rate: 98.703% (123027/124643)\n",
      "False positive rate: 1.297% (1616/124643)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 97/100: Loss: 0.0961 | Train Acc: 96.278% (130745/135800) | Strict Acc: 64.010% (6209/9700)\n",
      "True positive rate: 65.204% (6418/9843)\n",
      "False negative rate: 34.796% (3425/9843)\n",
      "True negative rate: 98.706% (124327/125957)\n",
      "False positive rate: 1.294% (1630/125957)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 98/100: Loss: 0.0962 | Train Acc: 96.266% (132077/137200) | Strict Acc: 63.949% (6267/9800)\n",
      "True positive rate: 65.051% (6470/9946)\n",
      "False negative rate: 34.949% (3476/9946)\n",
      "True negative rate: 98.706% (125607/127254)\n",
      "False positive rate: 1.294% (1647/127254)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 99/100: Loss: 0.0964 | Train Acc: 96.255% (133410/138600) | Strict Acc: 63.899% (6326/9900)\n",
      "True positive rate: 64.863% (6520/10052)\n",
      "False negative rate: 35.137% (3532/10052)\n",
      "True negative rate: 98.710% (126890/128548)\n",
      "False positive rate: 1.290% (1658/128548)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 4 - Batch 100/100: Loss: 0.0964 | Train Acc: 96.254% (133543/138740) | Strict Acc: 63.885% (6331/9910)\n",
      "True positive rate: 64.861% (6527/10063)\n",
      "False negative rate: 35.139% (3536/10063)\n",
      "True negative rate: 98.709% (127016/128677)\n",
      "False positive rate: 1.291% (1661/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1088 | Dev Acc: 95.852% (68036/70980) | Strict Acc: 61.223% (3104/5070)\n",
      "True positive rate: 60.935% (3140/5153)\n",
      "False negative rate: 39.065% (2013/5153)\n",
      "True negative rate: 98.586% (64896/65827)\n",
      "False positive rate: 1.414% (931/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 1/100: Loss: 0.0789 | Train Acc: 97.000% (1358/1400) | Strict Acc: 69.000% (69/100)\n",
      "True positive rate: 70.213% (66/94)\n",
      "False negative rate: 29.787% (28/94)\n",
      "True negative rate: 98.928% (1292/1306)\n",
      "False positive rate: 1.072% (14/1306)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 2/100: Loss: 0.0832 | Train Acc: 96.536% (2703/2800) | Strict Acc: 66.500% (133/200)\n",
      "True positive rate: 65.896% (114/173)\n",
      "False negative rate: 34.104% (59/173)\n",
      "True negative rate: 98.553% (2589/2627)\n",
      "False positive rate: 1.447% (38/2627)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 3/100: Loss: 0.0868 | Train Acc: 96.357% (4047/4200) | Strict Acc: 64.000% (192/300)\n",
      "True positive rate: 65.818% (181/275)\n",
      "False negative rate: 34.182% (94/275)\n",
      "True negative rate: 98.497% (3866/3925)\n",
      "False positive rate: 1.503% (59/3925)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 4/100: Loss: 0.0911 | Train Acc: 96.143% (5384/5600) | Strict Acc: 63.000% (252/400)\n",
      "True positive rate: 63.802% (245/384)\n",
      "False negative rate: 36.198% (139/384)\n",
      "True negative rate: 98.524% (5139/5216)\n",
      "False positive rate: 1.476% (77/5216)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 5/100: Loss: 0.0926 | Train Acc: 96.271% (6739/7000) | Strict Acc: 63.800% (319/500)\n",
      "True positive rate: 64.706% (319/493)\n",
      "False negative rate: 35.294% (174/493)\n",
      "True negative rate: 98.663% (6420/6507)\n",
      "False positive rate: 1.337% (87/6507)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 6/100: Loss: 0.0942 | Train Acc: 96.179% (8079/8400) | Strict Acc: 63.333% (380/600)\n",
      "True positive rate: 64.448% (397/616)\n",
      "False negative rate: 35.552% (219/616)\n",
      "True negative rate: 98.690% (7682/7784)\n",
      "False positive rate: 1.310% (102/7784)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 7/100: Loss: 0.0903 | Train Acc: 96.388% (9446/9800) | Strict Acc: 65.286% (457/700)\n",
      "True positive rate: 65.867% (467/709)\n",
      "False negative rate: 34.133% (242/709)\n",
      "True negative rate: 98.768% (8979/9091)\n",
      "False positive rate: 1.232% (112/9091)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 8/100: Loss: 0.0908 | Train Acc: 96.330% (10789/11200) | Strict Acc: 65.125% (521/800)\n",
      "True positive rate: 66.418% (534/804)\n",
      "False negative rate: 33.582% (270/804)\n",
      "True negative rate: 98.644% (10255/10396)\n",
      "False positive rate: 1.356% (141/10396)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 9/100: Loss: 0.0900 | Train Acc: 96.373% (12143/12600) | Strict Acc: 65.333% (588/900)\n",
      "True positive rate: 67.408% (606/899)\n",
      "False negative rate: 32.592% (293/899)\n",
      "True negative rate: 98.598% (11537/11701)\n",
      "False positive rate: 1.402% (164/11701)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 10/100: Loss: 0.0919 | Train Acc: 96.321% (13485/14000) | Strict Acc: 65.100% (651/1000)\n",
      "True positive rate: 67.624% (683/1010)\n",
      "False negative rate: 32.376% (327/1010)\n",
      "True negative rate: 98.553% (12802/12990)\n",
      "False positive rate: 1.447% (188/12990)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 11/100: Loss: 0.0932 | Train Acc: 96.253% (14823/15400) | Strict Acc: 64.727% (712/1100)\n",
      "True positive rate: 67.551% (764/1131)\n",
      "False negative rate: 32.449% (367/1131)\n",
      "True negative rate: 98.528% (14059/14269)\n",
      "False positive rate: 1.472% (210/14269)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 12/100: Loss: 0.0930 | Train Acc: 96.262% (16172/16800) | Strict Acc: 64.667% (776/1200)\n",
      "True positive rate: 67.404% (823/1221)\n",
      "False negative rate: 32.596% (398/1221)\n",
      "True negative rate: 98.524% (15349/15579)\n",
      "False positive rate: 1.476% (230/15579)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 13/100: Loss: 0.0925 | Train Acc: 96.258% (17519/18200) | Strict Acc: 64.385% (837/1300)\n",
      "True positive rate: 66.818% (884/1323)\n",
      "False negative rate: 33.182% (439/1323)\n",
      "True negative rate: 98.566% (16635/16877)\n",
      "False positive rate: 1.434% (242/16877)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 14/100: Loss: 0.0927 | Train Acc: 96.265% (18868/19600) | Strict Acc: 64.500% (903/1400)\n",
      "True positive rate: 66.200% (946/1429)\n",
      "False negative rate: 33.800% (483/1429)\n",
      "True negative rate: 98.630% (17922/18171)\n",
      "False positive rate: 1.370% (249/18171)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 15/100: Loss: 0.0923 | Train Acc: 96.300% (20223/21000) | Strict Acc: 64.867% (973/1500)\n",
      "True positive rate: 66.429% (1025/1543)\n",
      "False negative rate: 33.571% (518/1543)\n",
      "True negative rate: 98.669% (19198/19457)\n",
      "False positive rate: 1.331% (259/19457)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 16/100: Loss: 0.0933 | Train Acc: 96.295% (21570/22400) | Strict Acc: 64.688% (1035/1600)\n",
      "True positive rate: 66.486% (1103/1659)\n",
      "False negative rate: 33.514% (556/1659)\n",
      "True negative rate: 98.679% (20467/20741)\n",
      "False positive rate: 1.321% (274/20741)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 17/100: Loss: 0.0938 | Train Acc: 96.298% (22919/23800) | Strict Acc: 64.471% (1096/1700)\n",
      "True positive rate: 66.816% (1190/1781)\n",
      "False negative rate: 33.184% (591/1781)\n",
      "True negative rate: 98.683% (21729/22019)\n",
      "False positive rate: 1.317% (290/22019)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 18/100: Loss: 0.0935 | Train Acc: 96.317% (24272/25200) | Strict Acc: 64.556% (1162/1800)\n",
      "True positive rate: 67.146% (1261/1878)\n",
      "False negative rate: 32.854% (617/1878)\n",
      "True negative rate: 98.666% (23011/23322)\n",
      "False positive rate: 1.334% (311/23322)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 19/100: Loss: 0.0928 | Train Acc: 96.346% (25628/26600) | Strict Acc: 64.842% (1232/1900)\n",
      "True positive rate: 67.495% (1331/1972)\n",
      "False negative rate: 32.505% (641/1972)\n",
      "True negative rate: 98.656% (24297/24628)\n",
      "False positive rate: 1.344% (331/24628)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 20/100: Loss: 0.0932 | Train Acc: 96.321% (26970/28000) | Strict Acc: 64.600% (1292/2000)\n",
      "True positive rate: 67.493% (1389/2058)\n",
      "False negative rate: 32.507% (669/2058)\n",
      "True negative rate: 98.608% (25581/25942)\n",
      "False positive rate: 1.392% (361/25942)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 21/100: Loss: 0.0930 | Train Acc: 96.347% (28326/29400) | Strict Acc: 64.857% (1362/2100)\n",
      "True positive rate: 67.425% (1453/2155)\n",
      "False negative rate: 32.575% (702/2155)\n",
      "True negative rate: 98.635% (26873/27245)\n",
      "False positive rate: 1.365% (372/27245)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 22/100: Loss: 0.0922 | Train Acc: 96.390% (29688/30800) | Strict Acc: 65.364% (1438/2200)\n",
      "True positive rate: 67.672% (1526/2255)\n",
      "False negative rate: 32.328% (729/2255)\n",
      "True negative rate: 98.658% (28162/28545)\n",
      "False positive rate: 1.342% (383/28545)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 23/100: Loss: 0.0923 | Train Acc: 96.394% (31039/32200) | Strict Acc: 65.435% (1505/2300)\n",
      "True positive rate: 67.357% (1593/2365)\n",
      "False negative rate: 32.643% (772/2365)\n",
      "True negative rate: 98.696% (29446/29835)\n",
      "False positive rate: 1.304% (389/29835)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 24/100: Loss: 0.0920 | Train Acc: 96.411% (32394/33600) | Strict Acc: 65.458% (1571/2400)\n",
      "True positive rate: 67.301% (1661/2468)\n",
      "False negative rate: 32.699% (807/2468)\n",
      "True negative rate: 98.718% (30733/31132)\n",
      "False positive rate: 1.282% (399/31132)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 25/100: Loss: 0.0917 | Train Acc: 96.411% (33744/35000) | Strict Acc: 65.720% (1643/2500)\n",
      "True positive rate: 66.837% (1705/2551)\n",
      "False negative rate: 33.163% (846/2551)\n",
      "True negative rate: 98.736% (32039/32449)\n",
      "False positive rate: 1.264% (410/32449)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 26/100: Loss: 0.0915 | Train Acc: 96.407% (35092/36400) | Strict Acc: 65.654% (1707/2600)\n",
      "True positive rate: 66.830% (1773/2653)\n",
      "False negative rate: 33.170% (880/2653)\n",
      "True negative rate: 98.732% (33319/33747)\n",
      "False positive rate: 1.268% (428/33747)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 27/100: Loss: 0.0913 | Train Acc: 96.415% (36445/37800) | Strict Acc: 65.741% (1775/2700)\n",
      "True positive rate: 66.933% (1840/2749)\n",
      "False negative rate: 33.067% (909/2749)\n",
      "True negative rate: 98.728% (34605/35051)\n",
      "False positive rate: 1.272% (446/35051)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 28/100: Loss: 0.0912 | Train Acc: 96.418% (37796/39200) | Strict Acc: 65.893% (1845/2800)\n",
      "True positive rate: 66.900% (1910/2855)\n",
      "False negative rate: 33.100% (945/2855)\n",
      "True negative rate: 98.737% (35886/36345)\n",
      "False positive rate: 1.263% (459/36345)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 29/100: Loss: 0.0910 | Train Acc: 96.421% (39147/40600) | Strict Acc: 66.000% (1914/2900)\n",
      "True positive rate: 67.030% (1966/2933)\n",
      "False negative rate: 32.970% (967/2933)\n",
      "True negative rate: 98.710% (37181/37667)\n",
      "False positive rate: 1.290% (486/37667)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 30/100: Loss: 0.0907 | Train Acc: 96.433% (40502/42000) | Strict Acc: 66.000% (1980/3000)\n",
      "True positive rate: 67.053% (2027/3023)\n",
      "False negative rate: 32.947% (996/3023)\n",
      "True negative rate: 98.712% (38475/38977)\n",
      "False positive rate: 1.288% (502/38977)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 31/100: Loss: 0.0903 | Train Acc: 96.447% (41858/43400) | Strict Acc: 66.194% (2052/3100)\n",
      "True positive rate: 67.331% (2094/3110)\n",
      "False negative rate: 32.669% (1016/3110)\n",
      "True negative rate: 98.694% (39764/40290)\n",
      "False positive rate: 1.306% (526/40290)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 32/100: Loss: 0.0901 | Train Acc: 96.455% (43212/44800) | Strict Acc: 66.156% (2117/3200)\n",
      "True positive rate: 67.381% (2171/3222)\n",
      "False negative rate: 32.619% (1051/3222)\n",
      "True negative rate: 98.708% (41041/41578)\n",
      "False positive rate: 1.292% (537/41578)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 33/100: Loss: 0.0902 | Train Acc: 96.472% (44570/46200) | Strict Acc: 66.364% (2190/3300)\n",
      "True positive rate: 67.367% (2244/3331)\n",
      "False negative rate: 32.633% (1087/3331)\n",
      "True negative rate: 98.733% (42326/42869)\n",
      "False positive rate: 1.267% (543/42869)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 34/100: Loss: 0.0903 | Train Acc: 96.460% (45915/47600) | Strict Acc: 66.206% (2251/3400)\n",
      "True positive rate: 67.422% (2320/3441)\n",
      "False negative rate: 32.578% (1121/3441)\n",
      "True negative rate: 98.723% (43595/44159)\n",
      "False positive rate: 1.277% (564/44159)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 35/100: Loss: 0.0904 | Train Acc: 96.453% (47262/49000) | Strict Acc: 66.229% (2318/3500)\n",
      "True positive rate: 67.466% (2391/3544)\n",
      "False negative rate: 32.534% (1153/3544)\n",
      "True negative rate: 98.713% (44871/45456)\n",
      "False positive rate: 1.287% (585/45456)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 36/100: Loss: 0.0909 | Train Acc: 96.450% (48611/50400) | Strict Acc: 66.139% (2381/3600)\n",
      "True positive rate: 67.368% (2467/3662)\n",
      "False negative rate: 32.632% (1195/3662)\n",
      "True negative rate: 98.729% (46144/46738)\n",
      "False positive rate: 1.271% (594/46738)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 37/100: Loss: 0.0907 | Train Acc: 96.448% (49960/51800) | Strict Acc: 66.027% (2443/3700)\n",
      "True positive rate: 67.541% (2549/3774)\n",
      "False negative rate: 32.459% (1225/3774)\n",
      "True negative rate: 98.719% (47411/48026)\n",
      "False positive rate: 1.281% (615/48026)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 38/100: Loss: 0.0908 | Train Acc: 96.444% (51308/53200) | Strict Acc: 65.974% (2507/3800)\n",
      "True positive rate: 67.621% (2623/3879)\n",
      "False negative rate: 32.379% (1256/3879)\n",
      "True negative rate: 98.710% (48685/49321)\n",
      "False positive rate: 1.290% (636/49321)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 39/100: Loss: 0.0905 | Train Acc: 96.449% (52661/54600) | Strict Acc: 65.974% (2573/3900)\n",
      "True positive rate: 67.757% (2694/3976)\n",
      "False negative rate: 32.243% (1282/3976)\n",
      "True negative rate: 98.702% (49967/50624)\n",
      "False positive rate: 1.298% (657/50624)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 40/100: Loss: 0.0900 | Train Acc: 96.461% (54018/56000) | Strict Acc: 66.075% (2643/4000)\n",
      "True positive rate: 68.016% (2773/4077)\n",
      "False negative rate: 31.984% (1304/4077)\n",
      "True negative rate: 98.694% (51245/51923)\n",
      "False positive rate: 1.306% (678/51923)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 41/100: Loss: 0.0898 | Train Acc: 96.470% (55374/57400) | Strict Acc: 66.171% (2713/4100)\n",
      "True positive rate: 67.961% (2817/4145)\n",
      "False negative rate: 32.039% (1328/4145)\n",
      "True negative rate: 98.689% (52557/53255)\n",
      "False positive rate: 1.311% (698/53255)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 42/100: Loss: 0.0900 | Train Acc: 96.468% (56723/58800) | Strict Acc: 66.048% (2774/4200)\n",
      "True positive rate: 67.689% (2868/4237)\n",
      "False negative rate: 32.311% (1369/4237)\n",
      "True negative rate: 98.702% (53855/54563)\n",
      "False positive rate: 1.298% (708/54563)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 43/100: Loss: 0.0898 | Train Acc: 96.460% (58069/60200) | Strict Acc: 66.000% (2838/4300)\n",
      "True positive rate: 67.619% (2934/4339)\n",
      "False negative rate: 32.381% (1405/4339)\n",
      "True negative rate: 98.700% (55135/55861)\n",
      "False positive rate: 1.300% (726/55861)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 44/100: Loss: 0.0898 | Train Acc: 96.458% (59418/61600) | Strict Acc: 65.932% (2901/4400)\n",
      "True positive rate: 67.410% (2993/4440)\n",
      "False negative rate: 32.590% (1447/4440)\n",
      "True negative rate: 98.714% (56425/57160)\n",
      "False positive rate: 1.286% (735/57160)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 45/100: Loss: 0.0900 | Train Acc: 96.449% (60763/63000) | Strict Acc: 65.978% (2969/4500)\n",
      "True positive rate: 67.086% (3039/4530)\n",
      "False negative rate: 32.914% (1491/4530)\n",
      "True negative rate: 98.724% (57724/58470)\n",
      "False positive rate: 1.276% (746/58470)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 46/100: Loss: 0.0898 | Train Acc: 96.464% (62123/64400) | Strict Acc: 66.000% (3036/4600)\n",
      "True positive rate: 66.985% (3090/4613)\n",
      "False negative rate: 33.015% (1523/4613)\n",
      "True negative rate: 98.739% (59033/59787)\n",
      "False positive rate: 1.261% (754/59787)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 47/100: Loss: 0.0898 | Train Acc: 96.465% (63474/65800) | Strict Acc: 66.000% (3102/4700)\n",
      "True positive rate: 67.033% (3168/4726)\n",
      "False negative rate: 32.967% (1558/4726)\n",
      "True negative rate: 98.743% (60306/61074)\n",
      "False positive rate: 1.257% (768/61074)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 48/100: Loss: 0.0898 | Train Acc: 96.470% (64828/67200) | Strict Acc: 66.021% (3169/4800)\n",
      "True positive rate: 67.074% (3235/4823)\n",
      "False negative rate: 32.926% (1588/4823)\n",
      "True negative rate: 98.743% (61593/62377)\n",
      "False positive rate: 1.257% (784/62377)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 49/100: Loss: 0.0899 | Train Acc: 96.471% (66179/68600) | Strict Acc: 66.020% (3235/4900)\n",
      "True positive rate: 67.005% (3302/4928)\n",
      "False negative rate: 32.995% (1626/4928)\n",
      "True negative rate: 98.751% (62877/63672)\n",
      "False positive rate: 1.249% (795/63672)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 50/100: Loss: 0.0895 | Train Acc: 96.490% (67543/70000) | Strict Acc: 66.140% (3307/5000)\n",
      "True positive rate: 67.270% (3381/5026)\n",
      "False negative rate: 32.730% (1645/5026)\n",
      "True negative rate: 98.750% (64162/64974)\n",
      "False positive rate: 1.250% (812/64974)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 51/100: Loss: 0.0894 | Train Acc: 96.494% (68897/71400) | Strict Acc: 66.176% (3375/5100)\n",
      "True positive rate: 67.346% (3438/5105)\n",
      "False negative rate: 32.654% (1667/5105)\n",
      "True negative rate: 98.739% (65459/66295)\n",
      "False positive rate: 1.261% (836/66295)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 52/100: Loss: 0.0895 | Train Acc: 96.495% (70248/72800) | Strict Acc: 66.154% (3440/5200)\n",
      "True positive rate: 67.433% (3522/5223)\n",
      "False negative rate: 32.567% (1701/5223)\n",
      "True negative rate: 98.741% (66726/67577)\n",
      "False positive rate: 1.259% (851/67577)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 53/100: Loss: 0.0895 | Train Acc: 96.497% (71601/74200) | Strict Acc: 66.151% (3506/5300)\n",
      "True positive rate: 67.612% (3599/5323)\n",
      "False negative rate: 32.388% (1724/5323)\n",
      "True negative rate: 98.730% (68002/68877)\n",
      "False positive rate: 1.270% (875/68877)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 54/100: Loss: 0.0896 | Train Acc: 96.493% (72949/75600) | Strict Acc: 66.074% (3568/5400)\n",
      "True positive rate: 67.620% (3665/5420)\n",
      "False negative rate: 32.380% (1755/5420)\n",
      "True negative rate: 98.723% (69284/70180)\n",
      "False positive rate: 1.277% (896/70180)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 55/100: Loss: 0.0900 | Train Acc: 96.471% (74283/77000) | Strict Acc: 65.927% (3626/5500)\n",
      "True positive rate: 67.419% (3733/5537)\n",
      "False negative rate: 32.581% (1804/5537)\n",
      "True negative rate: 98.722% (70550/71463)\n",
      "False positive rate: 1.278% (913/71463)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 56/100: Loss: 0.0900 | Train Acc: 96.476% (75637/78400) | Strict Acc: 65.946% (3693/5600)\n",
      "True positive rate: 67.483% (3802/5634)\n",
      "False negative rate: 32.517% (1832/5634)\n",
      "True negative rate: 98.721% (71835/72766)\n",
      "False positive rate: 1.279% (931/72766)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 57/100: Loss: 0.0898 | Train Acc: 96.477% (76989/79800) | Strict Acc: 66.000% (3762/5700)\n",
      "True positive rate: 67.534% (3867/5726)\n",
      "False negative rate: 32.466% (1859/5726)\n",
      "True negative rate: 98.715% (73122/74074)\n",
      "False positive rate: 1.285% (952/74074)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 58/100: Loss: 0.0898 | Train Acc: 96.479% (78341/81200) | Strict Acc: 66.000% (3828/5800)\n",
      "True positive rate: 67.446% (3922/5815)\n",
      "False negative rate: 32.554% (1893/5815)\n",
      "True negative rate: 98.719% (74419/75385)\n",
      "False positive rate: 1.281% (966/75385)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 59/100: Loss: 0.0897 | Train Acc: 96.485% (79697/82600) | Strict Acc: 66.017% (3895/5900)\n",
      "True positive rate: 67.472% (3993/5918)\n",
      "False negative rate: 32.528% (1925/5918)\n",
      "True negative rate: 98.725% (75704/76682)\n",
      "False positive rate: 1.275% (978/76682)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 60/100: Loss: 0.0896 | Train Acc: 96.492% (81053/84000) | Strict Acc: 66.083% (3965/6000)\n",
      "True positive rate: 67.564% (4068/6021)\n",
      "False negative rate: 32.436% (1953/6021)\n",
      "True negative rate: 98.725% (76985/77979)\n",
      "False positive rate: 1.275% (994/77979)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 61/100: Loss: 0.0899 | Train Acc: 96.482% (82396/85400) | Strict Acc: 66.066% (4030/6100)\n",
      "True positive rate: 67.456% (4129/6121)\n",
      "False negative rate: 32.544% (1992/6121)\n",
      "True negative rate: 98.723% (78267/79279)\n",
      "False positive rate: 1.277% (1012/79279)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 62/100: Loss: 0.0897 | Train Acc: 96.487% (83751/86800) | Strict Acc: 66.113% (4099/6200)\n",
      "True positive rate: 67.524% (4200/6220)\n",
      "False negative rate: 32.476% (2020/6220)\n",
      "True negative rate: 98.723% (79551/80580)\n",
      "False positive rate: 1.277% (1029/80580)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 63/100: Loss: 0.0896 | Train Acc: 96.491% (85105/88200) | Strict Acc: 66.079% (4163/6300)\n",
      "True positive rate: 67.664% (4273/6315)\n",
      "False negative rate: 32.336% (2042/6315)\n",
      "True negative rate: 98.714% (80832/81885)\n",
      "False positive rate: 1.286% (1053/81885)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 64/100: Loss: 0.0899 | Train Acc: 96.480% (86446/89600) | Strict Acc: 66.016% (4225/6400)\n",
      "True positive rate: 67.588% (4352/6439)\n",
      "False negative rate: 32.412% (2087/6439)\n",
      "True negative rate: 98.717% (82094/83161)\n",
      "False positive rate: 1.283% (1067/83161)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 65/100: Loss: 0.0900 | Train Acc: 96.476% (87793/91000) | Strict Acc: 66.031% (4292/6500)\n",
      "True positive rate: 67.460% (4420/6552)\n",
      "False negative rate: 32.540% (2132/6552)\n",
      "True negative rate: 98.727% (83373/84448)\n",
      "False positive rate: 1.273% (1075/84448)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 66/100: Loss: 0.0902 | Train Acc: 96.463% (89132/92400) | Strict Acc: 65.924% (4351/6600)\n",
      "True positive rate: 67.406% (4498/6673)\n",
      "False negative rate: 32.594% (2175/6673)\n",
      "True negative rate: 98.725% (84634/85727)\n",
      "False positive rate: 1.275% (1093/85727)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 67/100: Loss: 0.0903 | Train Acc: 96.468% (90487/93800) | Strict Acc: 65.940% (4418/6700)\n",
      "True positive rate: 67.453% (4574/6781)\n",
      "False negative rate: 32.547% (2207/6781)\n",
      "True negative rate: 98.729% (85913/87019)\n",
      "False positive rate: 1.271% (1106/87019)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 68/100: Loss: 0.0904 | Train Acc: 96.465% (91835/95200) | Strict Acc: 65.956% (4485/6800)\n",
      "True positive rate: 67.561% (4657/6893)\n",
      "False negative rate: 32.439% (2236/6893)\n",
      "True negative rate: 98.722% (87178/88307)\n",
      "False positive rate: 1.278% (1129/88307)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 69/100: Loss: 0.0904 | Train Acc: 96.462% (93182/96600) | Strict Acc: 65.913% (4548/6900)\n",
      "True positive rate: 67.558% (4725/6994)\n",
      "False negative rate: 32.442% (2269/6994)\n",
      "True negative rate: 98.718% (88457/89606)\n",
      "False positive rate: 1.282% (1149/89606)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 70/100: Loss: 0.0903 | Train Acc: 96.468% (94539/98000) | Strict Acc: 66.000% (4620/7000)\n",
      "True positive rate: 67.686% (4803/7096)\n",
      "False negative rate: 32.314% (2293/7096)\n",
      "True negative rate: 98.715% (89736/90904)\n",
      "False positive rate: 1.285% (1168/90904)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 71/100: Loss: 0.0905 | Train Acc: 96.467% (95888/99400) | Strict Acc: 65.958% (4683/7100)\n",
      "True positive rate: 67.630% (4866/7195)\n",
      "False negative rate: 32.370% (2329/7195)\n",
      "True negative rate: 98.717% (91022/92205)\n",
      "False positive rate: 1.283% (1183/92205)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 72/100: Loss: 0.0905 | Train Acc: 96.469% (97241/100800) | Strict Acc: 65.944% (4748/7200)\n",
      "True positive rate: 67.695% (4939/7296)\n",
      "False negative rate: 32.305% (2357/7296)\n",
      "True negative rate: 98.714% (92302/93504)\n",
      "False positive rate: 1.286% (1202/93504)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 73/100: Loss: 0.0906 | Train Acc: 96.465% (98587/102200) | Strict Acc: 65.904% (4811/7300)\n",
      "True positive rate: 67.555% (4995/7394)\n",
      "False negative rate: 32.445% (2399/7394)\n",
      "True negative rate: 98.719% (93592/94806)\n",
      "False positive rate: 1.281% (1214/94806)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 74/100: Loss: 0.0907 | Train Acc: 96.453% (99925/103600) | Strict Acc: 65.878% (4875/7400)\n",
      "True positive rate: 67.311% (5047/7498)\n",
      "False negative rate: 32.689% (2451/7498)\n",
      "True negative rate: 98.726% (94878/96102)\n",
      "False positive rate: 1.274% (1224/96102)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 75/100: Loss: 0.0907 | Train Acc: 96.449% (101271/105000) | Strict Acc: 65.880% (4941/7500)\n",
      "True positive rate: 67.136% (5097/7592)\n",
      "False negative rate: 32.864% (2495/7592)\n",
      "True negative rate: 98.733% (96174/97408)\n",
      "False positive rate: 1.267% (1234/97408)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 76/100: Loss: 0.0908 | Train Acc: 96.447% (102620/106400) | Strict Acc: 65.895% (5008/7600)\n",
      "True positive rate: 67.143% (5166/7694)\n",
      "False negative rate: 32.857% (2528/7694)\n",
      "True negative rate: 98.732% (97454/98706)\n",
      "False positive rate: 1.268% (1252/98706)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 77/100: Loss: 0.0912 | Train Acc: 96.425% (103946/107800) | Strict Acc: 65.753% (5063/7700)\n",
      "True positive rate: 67.008% (5232/7808)\n",
      "False negative rate: 32.992% (2576/7808)\n",
      "True negative rate: 98.722% (98714/99992)\n",
      "False positive rate: 1.278% (1278/99992)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 78/100: Loss: 0.0912 | Train Acc: 96.425% (105296/109200) | Strict Acc: 65.756% (5129/7800)\n",
      "True positive rate: 67.074% (5319/7930)\n",
      "False negative rate: 32.926% (2611/7930)\n",
      "True negative rate: 98.723% (99977/101270)\n",
      "False positive rate: 1.277% (1293/101270)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 79/100: Loss: 0.0911 | Train Acc: 96.433% (106655/110600) | Strict Acc: 65.835% (5201/7900)\n",
      "True positive rate: 67.173% (5400/8039)\n",
      "False negative rate: 32.827% (2639/8039)\n",
      "True negative rate: 98.727% (101255/102561)\n",
      "False positive rate: 1.273% (1306/102561)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 80/100: Loss: 0.0911 | Train Acc: 96.431% (108003/112000) | Strict Acc: 65.787% (5263/8000)\n",
      "True positive rate: 67.264% (5480/8147)\n",
      "False negative rate: 32.736% (2667/8147)\n",
      "True negative rate: 98.719% (102523/103853)\n",
      "False positive rate: 1.281% (1330/103853)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 81/100: Loss: 0.0913 | Train Acc: 96.422% (109342/113400) | Strict Acc: 65.704% (5322/8100)\n",
      "True positive rate: 67.293% (5555/8255)\n",
      "False negative rate: 32.707% (2700/8255)\n",
      "True negative rate: 98.708% (103787/105145)\n",
      "False positive rate: 1.292% (1358/105145)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 82/100: Loss: 0.0912 | Train Acc: 96.418% (110688/114800) | Strict Acc: 65.646% (5383/8200)\n",
      "True positive rate: 67.415% (5646/8375)\n",
      "False negative rate: 32.585% (2729/8375)\n",
      "True negative rate: 98.700% (105042/106425)\n",
      "False positive rate: 1.300% (1383/106425)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 83/100: Loss: 0.0915 | Train Acc: 96.404% (112021/116200) | Strict Acc: 65.518% (5438/8300)\n",
      "True positive rate: 67.315% (5711/8484)\n",
      "False negative rate: 32.685% (2773/8484)\n",
      "True negative rate: 98.695% (106310/107716)\n",
      "False positive rate: 1.305% (1406/107716)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 84/100: Loss: 0.0915 | Train Acc: 96.401% (113367/117600) | Strict Acc: 65.524% (5504/8400)\n",
      "True positive rate: 67.249% (5772/8583)\n",
      "False negative rate: 32.751% (2811/8583)\n",
      "True negative rate: 98.696% (107595/109017)\n",
      "False positive rate: 1.304% (1422/109017)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 85/100: Loss: 0.0915 | Train Acc: 96.402% (114718/119000) | Strict Acc: 65.541% (5571/8500)\n",
      "True positive rate: 67.226% (5848/8699)\n",
      "False negative rate: 32.774% (2851/8699)\n",
      "True negative rate: 98.703% (108870/110301)\n",
      "False positive rate: 1.297% (1431/110301)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 86/100: Loss: 0.0914 | Train Acc: 96.411% (116079/120400) | Strict Acc: 65.663% (5647/8600)\n",
      "True positive rate: 67.221% (5904/8783)\n",
      "False negative rate: 32.779% (2879/8783)\n",
      "True negative rate: 98.708% (110175/111617)\n",
      "False positive rate: 1.292% (1442/111617)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 87/100: Loss: 0.0915 | Train Acc: 96.412% (117430/121800) | Strict Acc: 65.701% (5716/8700)\n",
      "True positive rate: 67.180% (5971/8888)\n",
      "False negative rate: 32.820% (2917/8888)\n",
      "True negative rate: 98.713% (111459/112912)\n",
      "False positive rate: 1.287% (1453/112912)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 88/100: Loss: 0.0915 | Train Acc: 96.411% (118778/123200) | Strict Acc: 65.659% (5778/8800)\n",
      "True positive rate: 67.153% (6025/8972)\n",
      "False negative rate: 32.847% (2947/8972)\n",
      "True negative rate: 98.709% (112753/114228)\n",
      "False positive rate: 1.291% (1475/114228)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 89/100: Loss: 0.0914 | Train Acc: 96.412% (120129/124600) | Strict Acc: 65.640% (5842/8900)\n",
      "True positive rate: 67.174% (6092/9069)\n",
      "False negative rate: 32.826% (2977/9069)\n",
      "True negative rate: 98.707% (114037/115531)\n",
      "False positive rate: 1.293% (1494/115531)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 90/100: Loss: 0.0914 | Train Acc: 96.411% (121478/126000) | Strict Acc: 65.644% (5908/9000)\n",
      "True positive rate: 67.158% (6153/9162)\n",
      "False negative rate: 32.842% (3009/9162)\n",
      "True negative rate: 98.705% (115325/116838)\n",
      "False positive rate: 1.295% (1513/116838)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 91/100: Loss: 0.0914 | Train Acc: 96.407% (122822/127400) | Strict Acc: 65.571% (5967/9100)\n",
      "True positive rate: 67.131% (6213/9255)\n",
      "False negative rate: 32.869% (3042/9255)\n",
      "True negative rate: 98.700% (116609/118145)\n",
      "False positive rate: 1.300% (1536/118145)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 92/100: Loss: 0.0915 | Train Acc: 96.403% (124167/128800) | Strict Acc: 65.500% (6026/9200)\n",
      "True positive rate: 67.134% (6275/9347)\n",
      "False negative rate: 32.866% (3072/9347)\n",
      "True negative rate: 98.693% (117892/119453)\n",
      "False positive rate: 1.307% (1561/119453)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 93/100: Loss: 0.0917 | Train Acc: 96.399% (125512/130200) | Strict Acc: 65.473% (6089/9300)\n",
      "True positive rate: 67.136% (6347/9454)\n",
      "False negative rate: 32.864% (3107/9454)\n",
      "True negative rate: 98.691% (119165/120746)\n",
      "False positive rate: 1.309% (1581/120746)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 94/100: Loss: 0.0919 | Train Acc: 96.396% (126857/131600) | Strict Acc: 65.436% (6151/9400)\n",
      "True positive rate: 67.109% (6423/9571)\n",
      "False negative rate: 32.891% (3148/9571)\n",
      "True negative rate: 98.693% (120434/122029)\n",
      "False positive rate: 1.307% (1595/122029)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 95/100: Loss: 0.0920 | Train Acc: 96.386% (128194/133000) | Strict Acc: 65.326% (6206/9500)\n",
      "True positive rate: 67.077% (6487/9671)\n",
      "False negative rate: 32.923% (3184/9671)\n",
      "True negative rate: 98.685% (121707/123329)\n",
      "False positive rate: 1.315% (1622/123329)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 96/100: Loss: 0.0921 | Train Acc: 96.382% (129538/134400) | Strict Acc: 65.198% (6259/9600)\n",
      "True positive rate: 67.070% (6548/9763)\n",
      "False negative rate: 32.930% (3215/9763)\n",
      "True negative rate: 98.679% (122990/124637)\n",
      "False positive rate: 1.321% (1647/124637)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 97/100: Loss: 0.0921 | Train Acc: 96.388% (130895/135800) | Strict Acc: 65.227% (6327/9700)\n",
      "True positive rate: 67.025% (6608/9859)\n",
      "False negative rate: 32.975% (3251/9859)\n",
      "True negative rate: 98.687% (124287/125941)\n",
      "False positive rate: 1.313% (1654/125941)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 98/100: Loss: 0.0921 | Train Acc: 96.381% (132235/137200) | Strict Acc: 65.173% (6387/9800)\n",
      "True positive rate: 66.948% (6668/9960)\n",
      "False negative rate: 33.052% (3292/9960)\n",
      "True negative rate: 98.685% (125567/127240)\n",
      "False positive rate: 1.315% (1673/127240)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 99/100: Loss: 0.0921 | Train Acc: 96.380% (133582/138600) | Strict Acc: 65.152% (6450/9900)\n",
      "True positive rate: 66.885% (6726/10056)\n",
      "False negative rate: 33.115% (3330/10056)\n",
      "True negative rate: 98.687% (126856/128544)\n",
      "False positive rate: 1.313% (1688/128544)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 5 - Batch 100/100: Loss: 0.0922 | Train Acc: 96.379% (133716/138740) | Strict Acc: 65.136% (6455/9910)\n",
      "True positive rate: 66.869% (6729/10063)\n",
      "False negative rate: 33.131% (3334/10063)\n",
      "True negative rate: 98.687% (126987/128677)\n",
      "False positive rate: 1.313% (1690/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1148 | Dev Acc: 95.631% (67879/70980) | Strict Acc: 60.513% (3068/5070)\n",
      "True positive rate: 51.155% (2636/5153)\n",
      "False negative rate: 48.845% (2517/5153)\n",
      "True negative rate: 99.113% (65243/65827)\n",
      "False positive rate: 0.887% (584/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 1/100: Loss: 0.0879 | Train Acc: 96.357% (1349/1400) | Strict Acc: 69.000% (69/100)\n",
      "True positive rate: 61.111% (66/108)\n",
      "False negative rate: 38.889% (42/108)\n",
      "True negative rate: 99.303% (1283/1292)\n",
      "False positive rate: 0.697% (9/1292)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 2/100: Loss: 0.0917 | Train Acc: 96.143% (2692/2800) | Strict Acc: 67.000% (134/200)\n",
      "True positive rate: 54.067% (113/209)\n",
      "False negative rate: 45.933% (96/209)\n",
      "True negative rate: 99.537% (2579/2591)\n",
      "False positive rate: 0.463% (12/2591)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 3/100: Loss: 0.0998 | Train Acc: 95.667% (4018/4200) | Strict Acc: 63.667% (191/300)\n",
      "True positive rate: 50.000% (163/326)\n",
      "False negative rate: 50.000% (163/326)\n",
      "True negative rate: 99.510% (3855/3874)\n",
      "False positive rate: 0.490% (19/3874)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 4/100: Loss: 0.0959 | Train Acc: 95.875% (5369/5600) | Strict Acc: 64.750% (259/400)\n",
      "True positive rate: 52.681% (226/429)\n",
      "False negative rate: 47.319% (203/429)\n",
      "True negative rate: 99.459% (5143/5171)\n",
      "False positive rate: 0.541% (28/5171)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 5/100: Loss: 0.0971 | Train Acc: 95.829% (6708/7000) | Strict Acc: 64.000% (320/500)\n",
      "True positive rate: 52.031% (269/517)\n",
      "False negative rate: 47.969% (248/517)\n",
      "True negative rate: 99.321% (6439/6483)\n",
      "False positive rate: 0.679% (44/6483)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 6/100: Loss: 0.0955 | Train Acc: 95.976% (8062/8400) | Strict Acc: 64.333% (386/600)\n",
      "True positive rate: 53.566% (323/603)\n",
      "False negative rate: 46.434% (280/603)\n",
      "True negative rate: 99.256% (7739/7797)\n",
      "False positive rate: 0.744% (58/7797)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 7/100: Loss: 0.0936 | Train Acc: 96.133% (9421/9800) | Strict Acc: 64.857% (454/700)\n",
      "True positive rate: 56.403% (392/695)\n",
      "False negative rate: 43.597% (303/695)\n",
      "True negative rate: 99.165% (9029/9105)\n",
      "False positive rate: 0.835% (76/9105)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 8/100: Loss: 0.0940 | Train Acc: 96.107% (10764/11200) | Strict Acc: 64.500% (516/800)\n",
      "True positive rate: 58.650% (478/815)\n",
      "False negative rate: 41.350% (337/815)\n",
      "True negative rate: 99.047% (10286/10385)\n",
      "False positive rate: 0.953% (99/10385)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 9/100: Loss: 0.0928 | Train Acc: 96.175% (12118/12600) | Strict Acc: 65.000% (585/900)\n",
      "True positive rate: 60.432% (559/925)\n",
      "False negative rate: 39.568% (366/925)\n",
      "True negative rate: 99.006% (11559/11675)\n",
      "False positive rate: 0.994% (116/11675)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 10/100: Loss: 0.0905 | Train Acc: 96.243% (13474/14000) | Strict Acc: 65.600% (656/1000)\n",
      "True positive rate: 61.546% (629/1022)\n",
      "False negative rate: 38.454% (393/1022)\n",
      "True negative rate: 98.975% (12845/12978)\n",
      "False positive rate: 1.025% (133/12978)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 11/100: Loss: 0.0904 | Train Acc: 96.260% (14824/15400) | Strict Acc: 65.364% (719/1100)\n",
      "True positive rate: 62.246% (704/1131)\n",
      "False negative rate: 37.754% (427/1131)\n",
      "True negative rate: 98.956% (14120/14269)\n",
      "False positive rate: 1.044% (149/14269)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 12/100: Loss: 0.0907 | Train Acc: 96.268% (16173/16800) | Strict Acc: 65.167% (782/1200)\n",
      "True positive rate: 62.480% (776/1242)\n",
      "False negative rate: 37.520% (466/1242)\n",
      "True negative rate: 98.965% (15397/15558)\n",
      "False positive rate: 1.035% (161/15558)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 13/100: Loss: 0.0902 | Train Acc: 96.319% (17530/18200) | Strict Acc: 65.538% (852/1300)\n",
      "True positive rate: 63.205% (852/1348)\n",
      "False negative rate: 36.795% (496/1348)\n",
      "True negative rate: 98.967% (16678/16852)\n",
      "False positive rate: 1.033% (174/16852)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 14/100: Loss: 0.0912 | Train Acc: 96.265% (18868/19600) | Strict Acc: 65.143% (912/1400)\n",
      "True positive rate: 63.322% (934/1475)\n",
      "False negative rate: 36.678% (541/1475)\n",
      "True negative rate: 98.946% (17934/18125)\n",
      "False positive rate: 1.054% (191/18125)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 15/100: Loss: 0.0905 | Train Acc: 96.319% (20227/21000) | Strict Acc: 65.267% (979/1500)\n",
      "True positive rate: 64.005% (1010/1578)\n",
      "False negative rate: 35.995% (568/1578)\n",
      "True negative rate: 98.944% (19217/19422)\n",
      "False positive rate: 1.056% (205/19422)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 16/100: Loss: 0.0904 | Train Acc: 96.317% (21575/22400) | Strict Acc: 65.312% (1045/1600)\n",
      "True positive rate: 64.375% (1086/1687)\n",
      "False negative rate: 35.625% (601/1687)\n",
      "True negative rate: 98.919% (20489/20713)\n",
      "False positive rate: 1.081% (224/20713)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 17/100: Loss: 0.0903 | Train Acc: 96.319% (22924/23800) | Strict Acc: 65.294% (1110/1700)\n",
      "True positive rate: 64.907% (1156/1781)\n",
      "False negative rate: 35.093% (625/1781)\n",
      "True negative rate: 98.860% (21768/22019)\n",
      "False positive rate: 1.140% (251/22019)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 18/100: Loss: 0.0904 | Train Acc: 96.325% (24274/25200) | Strict Acc: 65.000% (1170/1800)\n",
      "True positive rate: 65.109% (1226/1883)\n",
      "False negative rate: 34.891% (657/1883)\n",
      "True negative rate: 98.846% (23048/23317)\n",
      "False positive rate: 1.154% (269/23317)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 19/100: Loss: 0.0903 | Train Acc: 96.338% (25626/26600) | Strict Acc: 65.053% (1236/1900)\n",
      "True positive rate: 65.406% (1297/1983)\n",
      "False negative rate: 34.594% (686/1983)\n",
      "True negative rate: 98.830% (24329/24617)\n",
      "False positive rate: 1.170% (288/24617)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 20/100: Loss: 0.0894 | Train Acc: 96.386% (26988/28000) | Strict Acc: 65.300% (1306/2000)\n",
      "True positive rate: 65.913% (1371/2080)\n",
      "False negative rate: 34.087% (709/2080)\n",
      "True negative rate: 98.831% (25617/25920)\n",
      "False positive rate: 1.169% (303/25920)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 21/100: Loss: 0.0892 | Train Acc: 96.391% (28339/29400) | Strict Acc: 65.714% (1380/2100)\n",
      "True positive rate: 65.908% (1448/2197)\n",
      "False negative rate: 34.092% (749/2197)\n",
      "True negative rate: 98.853% (26891/27203)\n",
      "False positive rate: 1.147% (312/27203)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 22/100: Loss: 0.0889 | Train Acc: 96.409% (29694/30800) | Strict Acc: 65.864% (1449/2200)\n",
      "True positive rate: 65.881% (1510/2292)\n",
      "False negative rate: 34.119% (782/2292)\n",
      "True negative rate: 98.863% (28184/28508)\n",
      "False positive rate: 1.137% (324/28508)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 23/100: Loss: 0.0892 | Train Acc: 96.416% (31046/32200) | Strict Acc: 65.826% (1514/2300)\n",
      "True positive rate: 65.708% (1577/2400)\n",
      "False negative rate: 34.292% (823/2400)\n",
      "True negative rate: 98.889% (29469/29800)\n",
      "False positive rate: 1.111% (331/29800)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 24/100: Loss: 0.0887 | Train Acc: 96.449% (32407/33600) | Strict Acc: 65.958% (1583/2400)\n",
      "True positive rate: 65.905% (1643/2493)\n",
      "False negative rate: 34.095% (850/2493)\n",
      "True negative rate: 98.897% (30764/31107)\n",
      "False positive rate: 1.103% (343/31107)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 25/100: Loss: 0.0882 | Train Acc: 96.463% (33762/35000) | Strict Acc: 66.000% (1650/2500)\n",
      "True positive rate: 65.854% (1701/2583)\n",
      "False negative rate: 34.146% (882/2583)\n",
      "True negative rate: 98.902% (32061/32417)\n",
      "False positive rate: 1.098% (356/32417)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 26/100: Loss: 0.0880 | Train Acc: 96.478% (35118/36400) | Strict Acc: 66.000% (1716/2600)\n",
      "True positive rate: 66.196% (1782/2692)\n",
      "False negative rate: 33.804% (910/2692)\n",
      "True negative rate: 98.896% (33336/33708)\n",
      "False positive rate: 1.104% (372/33708)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 27/100: Loss: 0.0874 | Train Acc: 96.505% (36479/37800) | Strict Acc: 66.259% (1789/2700)\n",
      "True positive rate: 66.449% (1834/2760)\n",
      "False negative rate: 33.551% (926/2760)\n",
      "True negative rate: 98.873% (34645/35040)\n",
      "False positive rate: 1.127% (395/35040)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 28/100: Loss: 0.0871 | Train Acc: 96.520% (37836/39200) | Strict Acc: 66.321% (1857/2800)\n",
      "True positive rate: 66.479% (1894/2849)\n",
      "False negative rate: 33.521% (955/2849)\n",
      "True negative rate: 98.875% (35942/36351)\n",
      "False positive rate: 1.125% (409/36351)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 29/100: Loss: 0.0872 | Train Acc: 96.517% (39186/40600) | Strict Acc: 66.241% (1921/2900)\n",
      "True positive rate: 66.553% (1954/2936)\n",
      "False negative rate: 33.447% (982/2936)\n",
      "True negative rate: 98.853% (37232/37664)\n",
      "False positive rate: 1.147% (432/37664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 30/100: Loss: 0.0869 | Train Acc: 96.531% (40543/42000) | Strict Acc: 66.633% (1999/3000)\n",
      "True positive rate: 66.312% (1994/3007)\n",
      "False negative rate: 33.688% (1013/3007)\n",
      "True negative rate: 98.861% (38549/38993)\n",
      "False positive rate: 1.139% (444/38993)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 31/100: Loss: 0.0862 | Train Acc: 96.555% (41905/43400) | Strict Acc: 66.774% (2070/3100)\n",
      "True positive rate: 66.376% (2055/3096)\n",
      "False negative rate: 33.624% (1041/3096)\n",
      "True negative rate: 98.874% (39850/40304)\n",
      "False positive rate: 1.126% (454/40304)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 32/100: Loss: 0.0857 | Train Acc: 96.592% (43273/44800) | Strict Acc: 67.000% (2144/3200)\n",
      "True positive rate: 66.698% (2131/3195)\n",
      "False negative rate: 33.302% (1064/3195)\n",
      "True negative rate: 98.887% (41142/41605)\n",
      "False positive rate: 1.113% (463/41605)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 33/100: Loss: 0.0861 | Train Acc: 96.580% (44620/46200) | Strict Acc: 66.909% (2208/3300)\n",
      "True positive rate: 66.424% (2192/3300)\n",
      "False negative rate: 33.576% (1108/3300)\n",
      "True negative rate: 98.900% (42428/42900)\n",
      "False positive rate: 1.100% (472/42900)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 34/100: Loss: 0.0863 | Train Acc: 96.569% (45967/47600) | Strict Acc: 66.882% (2274/3400)\n",
      "True positive rate: 66.274% (2252/3398)\n",
      "False negative rate: 33.726% (1146/3398)\n",
      "True negative rate: 98.898% (43715/44202)\n",
      "False positive rate: 1.102% (487/44202)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 35/100: Loss: 0.0860 | Train Acc: 96.578% (47323/49000) | Strict Acc: 67.000% (2345/3500)\n",
      "True positive rate: 66.209% (2314/3495)\n",
      "False negative rate: 33.791% (1181/3495)\n",
      "True negative rate: 98.910% (45009/45505)\n",
      "False positive rate: 1.090% (496/45505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 36/100: Loss: 0.0862 | Train Acc: 96.575% (48674/50400) | Strict Acc: 66.972% (2411/3600)\n",
      "True positive rate: 66.436% (2405/3620)\n",
      "False negative rate: 33.564% (1215/3620)\n",
      "True negative rate: 98.908% (46269/46780)\n",
      "False positive rate: 1.092% (511/46780)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 37/100: Loss: 0.0857 | Train Acc: 96.579% (50028/51800) | Strict Acc: 66.919% (2476/3700)\n",
      "True positive rate: 66.837% (2491/3727)\n",
      "False negative rate: 33.163% (1236/3727)\n",
      "True negative rate: 98.885% (47537/48073)\n",
      "False positive rate: 1.115% (536/48073)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 38/100: Loss: 0.0862 | Train Acc: 96.566% (51373/53200) | Strict Acc: 66.789% (2538/3800)\n",
      "True positive rate: 67.041% (2565/3826)\n",
      "False negative rate: 32.959% (1261/3826)\n",
      "True negative rate: 98.854% (48808/49374)\n",
      "False positive rate: 1.146% (566/49374)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 39/100: Loss: 0.0862 | Train Acc: 96.551% (52717/54600) | Strict Acc: 66.667% (2600/3900)\n",
      "True positive rate: 67.276% (2648/3936)\n",
      "False negative rate: 32.724% (1288/3936)\n",
      "True negative rate: 98.826% (50069/50664)\n",
      "False positive rate: 1.174% (595/50664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 40/100: Loss: 0.0862 | Train Acc: 96.554% (54070/56000) | Strict Acc: 66.625% (2665/4000)\n",
      "True positive rate: 67.450% (2727/4043)\n",
      "False negative rate: 32.550% (1316/4043)\n",
      "True negative rate: 98.818% (51343/51957)\n",
      "False positive rate: 1.182% (614/51957)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 41/100: Loss: 0.0860 | Train Acc: 96.568% (55430/57400) | Strict Acc: 66.707% (2735/4100)\n",
      "True positive rate: 67.758% (2814/4153)\n",
      "False negative rate: 32.242% (1339/4153)\n",
      "True negative rate: 98.815% (52616/53247)\n",
      "False positive rate: 1.185% (631/53247)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 42/100: Loss: 0.0861 | Train Acc: 96.568% (56782/58800) | Strict Acc: 66.595% (2797/4200)\n",
      "True positive rate: 67.740% (2883/4256)\n",
      "False negative rate: 32.260% (1373/4256)\n",
      "True negative rate: 98.817% (53899/54544)\n",
      "False positive rate: 1.183% (645/54544)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 43/100: Loss: 0.0858 | Train Acc: 96.580% (58141/60200) | Strict Acc: 66.674% (2867/4300)\n",
      "True positive rate: 67.807% (2953/4355)\n",
      "False negative rate: 32.193% (1402/4355)\n",
      "True negative rate: 98.824% (55188/55845)\n",
      "False positive rate: 1.176% (657/55845)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 44/100: Loss: 0.0858 | Train Acc: 96.576% (59491/61600) | Strict Acc: 66.614% (2931/4400)\n",
      "True positive rate: 67.618% (3009/4450)\n",
      "False negative rate: 32.382% (1441/4450)\n",
      "True negative rate: 98.831% (56482/57150)\n",
      "False positive rate: 1.169% (668/57150)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 45/100: Loss: 0.0862 | Train Acc: 96.570% (60839/63000) | Strict Acc: 66.556% (2995/4500)\n",
      "True positive rate: 67.473% (3070/4550)\n",
      "False negative rate: 32.527% (1480/4550)\n",
      "True negative rate: 98.835% (57769/58450)\n",
      "False positive rate: 1.165% (681/58450)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 46/100: Loss: 0.0858 | Train Acc: 96.582% (62199/64400) | Strict Acc: 66.717% (3069/4600)\n",
      "True positive rate: 67.522% (3133/4640)\n",
      "False negative rate: 32.478% (1507/4640)\n",
      "True negative rate: 98.839% (59066/59760)\n",
      "False positive rate: 1.161% (694/59760)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 47/100: Loss: 0.0861 | Train Acc: 96.568% (63542/65800) | Strict Acc: 66.553% (3128/4700)\n",
      "True positive rate: 67.347% (3199/4750)\n",
      "False negative rate: 32.653% (1551/4750)\n",
      "True negative rate: 98.842% (60343/61050)\n",
      "False positive rate: 1.158% (707/61050)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 48/100: Loss: 0.0863 | Train Acc: 96.560% (64888/67200) | Strict Acc: 66.417% (3188/4800)\n",
      "True positive rate: 67.291% (3269/4858)\n",
      "False negative rate: 32.709% (1589/4858)\n",
      "True negative rate: 98.840% (61619/62342)\n",
      "False positive rate: 1.160% (723/62342)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 49/100: Loss: 0.0864 | Train Acc: 96.547% (66231/68600) | Strict Acc: 66.429% (3255/4900)\n",
      "True positive rate: 67.256% (3348/4978)\n",
      "False negative rate: 32.744% (1630/4978)\n",
      "True negative rate: 98.838% (62883/63622)\n",
      "False positive rate: 1.162% (739/63622)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 50/100: Loss: 0.0865 | Train Acc: 96.540% (67578/70000) | Strict Acc: 66.380% (3319/5000)\n",
      "True positive rate: 67.385% (3438/5102)\n",
      "False negative rate: 32.615% (1664/5102)\n",
      "True negative rate: 98.832% (64140/64898)\n",
      "False positive rate: 1.168% (758/64898)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 51/100: Loss: 0.0869 | Train Acc: 96.539% (68929/71400) | Strict Acc: 66.392% (3386/5100)\n",
      "True positive rate: 67.549% (3520/5211)\n",
      "False negative rate: 32.451% (1691/5211)\n",
      "True negative rate: 98.822% (65409/66189)\n",
      "False positive rate: 1.178% (780/66189)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 52/100: Loss: 0.0869 | Train Acc: 96.540% (70281/72800) | Strict Acc: 66.346% (3450/5200)\n",
      "True positive rate: 67.860% (3602/5308)\n",
      "False negative rate: 32.140% (1706/5308)\n",
      "True negative rate: 98.795% (66679/67492)\n",
      "False positive rate: 1.205% (813/67492)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 53/100: Loss: 0.0868 | Train Acc: 96.530% (71625/74200) | Strict Acc: 66.321% (3515/5300)\n",
      "True positive rate: 68.015% (3683/5415)\n",
      "False negative rate: 31.985% (1732/5415)\n",
      "True negative rate: 98.774% (67942/68785)\n",
      "False positive rate: 1.226% (843/68785)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 54/100: Loss: 0.0868 | Train Acc: 96.532% (72978/75600) | Strict Acc: 66.333% (3582/5400)\n",
      "True positive rate: 68.105% (3771/5537)\n",
      "False negative rate: 31.895% (1766/5537)\n",
      "True negative rate: 98.778% (69207/70063)\n",
      "False positive rate: 1.222% (856/70063)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 55/100: Loss: 0.0867 | Train Acc: 96.544% (74339/77000) | Strict Acc: 66.436% (3654/5500)\n",
      "True positive rate: 68.292% (3851/5639)\n",
      "False negative rate: 31.708% (1788/5639)\n",
      "True negative rate: 98.777% (70488/71361)\n",
      "False positive rate: 1.223% (873/71361)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 56/100: Loss: 0.0869 | Train Acc: 96.533% (75682/78400) | Strict Acc: 66.411% (3719/5600)\n",
      "True positive rate: 68.133% (3919/5752)\n",
      "False negative rate: 31.867% (1833/5752)\n",
      "True negative rate: 98.782% (71763/72648)\n",
      "False positive rate: 1.218% (885/72648)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 57/100: Loss: 0.0870 | Train Acc: 96.530% (77031/79800) | Strict Acc: 66.386% (3784/5700)\n",
      "True positive rate: 68.057% (3982/5851)\n",
      "False negative rate: 31.943% (1869/5851)\n",
      "True negative rate: 98.783% (73049/73949)\n",
      "False positive rate: 1.217% (900/73949)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 58/100: Loss: 0.0869 | Train Acc: 96.536% (78387/81200) | Strict Acc: 66.483% (3856/5800)\n",
      "True positive rate: 68.030% (4043/5943)\n",
      "False negative rate: 31.970% (1900/5943)\n",
      "True negative rate: 98.787% (74344/75257)\n",
      "False positive rate: 1.213% (913/75257)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 59/100: Loss: 0.0869 | Train Acc: 96.528% (79732/82600) | Strict Acc: 66.407% (3918/5900)\n",
      "True positive rate: 67.979% (4110/6046)\n",
      "False negative rate: 32.021% (1936/6046)\n",
      "True negative rate: 98.783% (75622/76554)\n",
      "False positive rate: 1.217% (932/76554)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 60/100: Loss: 0.0870 | Train Acc: 96.518% (81075/84000) | Strict Acc: 66.383% (3983/6000)\n",
      "True positive rate: 67.863% (4179/6158)\n",
      "False negative rate: 32.137% (1979/6158)\n",
      "True negative rate: 98.785% (76896/77842)\n",
      "False positive rate: 1.215% (946/77842)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 61/100: Loss: 0.0871 | Train Acc: 96.518% (82426/85400) | Strict Acc: 66.361% (4048/6100)\n",
      "True positive rate: 67.913% (4250/6258)\n",
      "False negative rate: 32.087% (2008/6258)\n",
      "True negative rate: 98.779% (78176/79142)\n",
      "False positive rate: 1.221% (966/79142)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 62/100: Loss: 0.0872 | Train Acc: 96.518% (83778/86800) | Strict Acc: 66.290% (4110/6200)\n",
      "True positive rate: 67.958% (4299/6326)\n",
      "False negative rate: 32.042% (2027/6326)\n",
      "True negative rate: 98.764% (79479/80474)\n",
      "False positive rate: 1.236% (995/80474)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 63/100: Loss: 0.0871 | Train Acc: 96.517% (85128/88200) | Strict Acc: 66.270% (4175/6300)\n",
      "True positive rate: 67.938% (4365/6425)\n",
      "False negative rate: 32.062% (2060/6425)\n",
      "True negative rate: 98.762% (80763/81775)\n",
      "False positive rate: 1.238% (1012/81775)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 64/100: Loss: 0.0873 | Train Acc: 96.508% (86471/89600) | Strict Acc: 66.156% (4234/6400)\n",
      "True positive rate: 67.925% (4443/6541)\n",
      "False negative rate: 32.075% (2098/6541)\n",
      "True negative rate: 98.759% (82028/83059)\n",
      "False positive rate: 1.241% (1031/83059)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 65/100: Loss: 0.0874 | Train Acc: 96.503% (87818/91000) | Strict Acc: 66.108% (4297/6500)\n",
      "True positive rate: 67.954% (4506/6631)\n",
      "False negative rate: 32.046% (2125/6631)\n",
      "True negative rate: 98.747% (83312/84369)\n",
      "False positive rate: 1.253% (1057/84369)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 66/100: Loss: 0.0873 | Train Acc: 96.504% (89170/92400) | Strict Acc: 66.121% (4364/6600)\n",
      "True positive rate: 67.976% (4585/6745)\n",
      "False negative rate: 32.024% (2160/6745)\n",
      "True negative rate: 98.751% (84585/85655)\n",
      "False positive rate: 1.249% (1070/85655)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 67/100: Loss: 0.0874 | Train Acc: 96.506% (90523/93800) | Strict Acc: 66.149% (4432/6700)\n",
      "True positive rate: 67.953% (4650/6843)\n",
      "False negative rate: 32.047% (2193/6843)\n",
      "True negative rate: 98.753% (85873/86957)\n",
      "False positive rate: 1.247% (1084/86957)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 68/100: Loss: 0.0871 | Train Acc: 96.513% (91880/95200) | Strict Acc: 66.176% (4500/6800)\n",
      "True positive rate: 67.940% (4713/6937)\n",
      "False negative rate: 32.060% (2224/6937)\n",
      "True negative rate: 98.758% (87167/88263)\n",
      "False positive rate: 1.242% (1096/88263)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 69/100: Loss: 0.0875 | Train Acc: 96.486% (93205/96600) | Strict Acc: 66.014% (4555/6900)\n",
      "True positive rate: 67.626% (4769/7052)\n",
      "False negative rate: 32.374% (2283/7052)\n",
      "True negative rate: 98.758% (88436/89548)\n",
      "False positive rate: 1.242% (1112/89548)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 70/100: Loss: 0.0878 | Train Acc: 96.473% (94544/98000) | Strict Acc: 65.943% (4616/7000)\n",
      "True positive rate: 67.490% (4839/7170)\n",
      "False negative rate: 32.510% (2331/7170)\n",
      "True negative rate: 98.761% (89705/90830)\n",
      "False positive rate: 1.239% (1125/90830)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 71/100: Loss: 0.0880 | Train Acc: 96.468% (95889/99400) | Strict Acc: 65.887% (4678/7100)\n",
      "True positive rate: 67.432% (4903/7271)\n",
      "False negative rate: 32.568% (2368/7271)\n",
      "True negative rate: 98.759% (90986/92129)\n",
      "False positive rate: 1.241% (1143/92129)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 72/100: Loss: 0.0880 | Train Acc: 96.467% (97239/100800) | Strict Acc: 65.889% (4744/7200)\n",
      "True positive rate: 67.587% (4992/7386)\n",
      "False negative rate: 32.413% (2394/7386)\n",
      "True negative rate: 98.751% (92247/93414)\n",
      "False positive rate: 1.249% (1167/93414)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 73/100: Loss: 0.0878 | Train Acc: 96.477% (98599/102200) | Strict Acc: 65.945% (4814/7300)\n",
      "True positive rate: 67.767% (5071/7483)\n",
      "False negative rate: 32.233% (2412/7483)\n",
      "True negative rate: 98.745% (93528/94717)\n",
      "False positive rate: 1.255% (1189/94717)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 74/100: Loss: 0.0879 | Train Acc: 96.475% (99948/103600) | Strict Acc: 65.973% (4882/7400)\n",
      "True positive rate: 67.885% (5145/7579)\n",
      "False negative rate: 32.115% (2434/7579)\n",
      "True negative rate: 98.732% (94803/96021)\n",
      "False positive rate: 1.268% (1218/96021)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 75/100: Loss: 0.0880 | Train Acc: 96.467% (101290/105000) | Strict Acc: 66.000% (4950/7500)\n",
      "True positive rate: 67.985% (5224/7684)\n",
      "False negative rate: 32.015% (2460/7684)\n",
      "True negative rate: 98.716% (96066/97316)\n",
      "False positive rate: 1.284% (1250/97316)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 76/100: Loss: 0.0879 | Train Acc: 96.464% (102638/106400) | Strict Acc: 66.013% (5017/7600)\n",
      "True positive rate: 68.050% (5295/7781)\n",
      "False negative rate: 31.950% (2486/7781)\n",
      "True negative rate: 98.706% (97343/98619)\n",
      "False positive rate: 1.294% (1276/98619)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 77/100: Loss: 0.0878 | Train Acc: 96.472% (103997/107800) | Strict Acc: 66.104% (5090/7700)\n",
      "True positive rate: 68.051% (5359/7875)\n",
      "False negative rate: 31.949% (2516/7875)\n",
      "True negative rate: 98.712% (98638/99925)\n",
      "False positive rate: 1.288% (1287/99925)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 78/100: Loss: 0.0877 | Train Acc: 96.469% (105344/109200) | Strict Acc: 66.103% (5156/7800)\n",
      "True positive rate: 67.963% (5416/7969)\n",
      "False negative rate: 32.037% (2553/7969)\n",
      "True negative rate: 98.713% (99928/101231)\n",
      "False positive rate: 1.287% (1303/101231)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 79/100: Loss: 0.0878 | Train Acc: 96.466% (106691/110600) | Strict Acc: 66.089% (5221/7900)\n",
      "True positive rate: 67.865% (5474/8066)\n",
      "False negative rate: 32.135% (2592/8066)\n",
      "True negative rate: 98.716% (101217/102534)\n",
      "False positive rate: 1.284% (1317/102534)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 80/100: Loss: 0.0878 | Train Acc: 96.468% (108044/112000) | Strict Acc: 66.125% (5290/8000)\n",
      "True positive rate: 67.848% (5550/8180)\n",
      "False negative rate: 32.152% (2630/8180)\n",
      "True negative rate: 98.723% (102494/103820)\n",
      "False positive rate: 1.277% (1326/103820)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 81/100: Loss: 0.0876 | Train Acc: 96.481% (109409/113400) | Strict Acc: 66.173% (5360/8100)\n",
      "True positive rate: 67.922% (5628/8286)\n",
      "False negative rate: 32.078% (2658/8286)\n",
      "True negative rate: 98.732% (103781/105114)\n",
      "False positive rate: 1.268% (1333/105114)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 82/100: Loss: 0.0874 | Train Acc: 96.490% (110771/114800) | Strict Acc: 66.256% (5433/8200)\n",
      "True positive rate: 67.957% (5686/8367)\n",
      "False negative rate: 32.043% (2681/8367)\n",
      "True negative rate: 98.733% (105085/106433)\n",
      "False positive rate: 1.267% (1348/106433)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 83/100: Loss: 0.0876 | Train Acc: 96.478% (112107/116200) | Strict Acc: 66.120% (5488/8300)\n",
      "True positive rate: 67.815% (5750/8479)\n",
      "False negative rate: 32.185% (2729/8479)\n",
      "True negative rate: 98.734% (106357/107721)\n",
      "False positive rate: 1.266% (1364/107721)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 84/100: Loss: 0.0879 | Train Acc: 96.463% (113441/117600) | Strict Acc: 66.083% (5551/8400)\n",
      "True positive rate: 67.730% (5820/8593)\n",
      "False negative rate: 32.270% (2773/8593)\n",
      "True negative rate: 98.729% (107621/109007)\n",
      "False positive rate: 1.271% (1386/109007)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 85/100: Loss: 0.0878 | Train Acc: 96.471% (114800/119000) | Strict Acc: 66.176% (5625/8500)\n",
      "True positive rate: 67.878% (5904/8698)\n",
      "False negative rate: 32.122% (2794/8698)\n",
      "True negative rate: 98.725% (108896/110302)\n",
      "False positive rate: 1.275% (1406/110302)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 86/100: Loss: 0.0879 | Train Acc: 96.467% (116146/120400) | Strict Acc: 66.163% (5690/8600)\n",
      "True positive rate: 67.917% (5976/8799)\n",
      "False negative rate: 32.083% (2823/8799)\n",
      "True negative rate: 98.718% (110170/111601)\n",
      "False positive rate: 1.282% (1431/111601)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 87/100: Loss: 0.0876 | Train Acc: 96.484% (117517/121800) | Strict Acc: 66.299% (5768/8700)\n",
      "True positive rate: 68.030% (6039/8877)\n",
      "False negative rate: 31.970% (2838/8877)\n",
      "True negative rate: 98.720% (111478/112923)\n",
      "False positive rate: 1.280% (1445/112923)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 88/100: Loss: 0.0874 | Train Acc: 96.490% (118876/123200) | Strict Acc: 66.341% (5838/8800)\n",
      "True positive rate: 68.118% (6119/8983)\n",
      "False negative rate: 31.882% (2864/8983)\n",
      "True negative rate: 98.722% (112757/114217)\n",
      "False positive rate: 1.278% (1460/114217)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 89/100: Loss: 0.0874 | Train Acc: 96.488% (120224/124600) | Strict Acc: 66.348% (5905/8900)\n",
      "True positive rate: 68.094% (6187/9086)\n",
      "False negative rate: 31.906% (2899/9086)\n",
      "True negative rate: 98.721% (114037/115514)\n",
      "False positive rate: 1.279% (1477/115514)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 90/100: Loss: 0.0873 | Train Acc: 96.494% (121582/126000) | Strict Acc: 66.411% (5977/9000)\n",
      "True positive rate: 68.101% (6253/9182)\n",
      "False negative rate: 31.899% (2929/9182)\n",
      "True negative rate: 98.725% (115329/116818)\n",
      "False positive rate: 1.275% (1489/116818)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 91/100: Loss: 0.0872 | Train Acc: 96.498% (122938/127400) | Strict Acc: 66.429% (6045/9100)\n",
      "True positive rate: 68.091% (6310/9267)\n",
      "False negative rate: 31.909% (2957/9267)\n",
      "True negative rate: 98.726% (116628/118133)\n",
      "False positive rate: 1.274% (1505/118133)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 92/100: Loss: 0.0870 | Train Acc: 96.504% (124297/128800) | Strict Acc: 66.522% (6120/9200)\n",
      "True positive rate: 68.124% (6388/9377)\n",
      "False negative rate: 31.876% (2989/9377)\n",
      "True negative rate: 98.732% (117909/119423)\n",
      "False positive rate: 1.268% (1514/119423)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 93/100: Loss: 0.0872 | Train Acc: 96.504% (125648/130200) | Strict Acc: 66.516% (6186/9300)\n",
      "True positive rate: 68.070% (6436/9455)\n",
      "False negative rate: 31.930% (3019/9455)\n",
      "True negative rate: 98.730% (119212/120745)\n",
      "False positive rate: 1.270% (1533/120745)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 94/100: Loss: 0.0872 | Train Acc: 96.507% (127003/131600) | Strict Acc: 66.511% (6252/9400)\n",
      "True positive rate: 68.100% (6511/9561)\n",
      "False negative rate: 31.900% (3050/9561)\n",
      "True negative rate: 98.732% (120492/122039)\n",
      "False positive rate: 1.268% (1547/122039)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 95/100: Loss: 0.0870 | Train Acc: 96.515% (128365/133000) | Strict Acc: 66.579% (6325/9500)\n",
      "True positive rate: 68.118% (6572/9648)\n",
      "False negative rate: 31.882% (3076/9648)\n",
      "True negative rate: 98.736% (121793/123352)\n",
      "False positive rate: 1.264% (1559/123352)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 96/100: Loss: 0.0868 | Train Acc: 96.526% (129731/134400) | Strict Acc: 66.656% (6399/9600)\n",
      "True positive rate: 68.178% (6646/9748)\n",
      "False negative rate: 31.822% (3102/9748)\n",
      "True negative rate: 98.743% (123085/124652)\n",
      "False positive rate: 1.257% (1567/124652)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 97/100: Loss: 0.0866 | Train Acc: 96.533% (131092/135800) | Strict Acc: 66.742% (6474/9700)\n",
      "True positive rate: 68.155% (6699/9829)\n",
      "False negative rate: 31.845% (3130/9829)\n",
      "True negative rate: 98.747% (124393/125971)\n",
      "False positive rate: 1.253% (1578/125971)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 98/100: Loss: 0.0866 | Train Acc: 96.534% (132444/137200) | Strict Acc: 66.776% (6544/9800)\n",
      "True positive rate: 68.137% (6766/9930)\n",
      "False negative rate: 31.863% (3164/9930)\n",
      "True negative rate: 98.749% (125678/127270)\n",
      "False positive rate: 1.251% (1592/127270)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 99/100: Loss: 0.0866 | Train Acc: 96.529% (133789/138600) | Strict Acc: 66.677% (6601/9900)\n",
      "True positive rate: 68.139% (6848/10050)\n",
      "False negative rate: 31.861% (3202/10050)\n",
      "True negative rate: 98.748% (126941/128550)\n",
      "False positive rate: 1.252% (1609/128550)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 6 - Batch 100/100: Loss: 0.0869 | Train Acc: 96.528% (133923/138740) | Strict Acc: 66.680% (6608/9910)\n",
      "True positive rate: 68.141% (6857/10063)\n",
      "False negative rate: 31.859% (3206/10063)\n",
      "True negative rate: 98.748% (127066/128677)\n",
      "False positive rate: 1.252% (1611/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1114 | Dev Acc: 95.830% (68020/70980) | Strict Acc: 61.440% (3115/5070)\n",
      "True positive rate: 66.932% (3449/5153)\n",
      "False negative rate: 33.068% (1704/5153)\n",
      "True negative rate: 98.092% (64571/65827)\n",
      "False positive rate: 1.908% (1256/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 1/100: Loss: 0.0959 | Train Acc: 96.143% (1346/1400) | Strict Acc: 64.000% (64/100)\n",
      "True positive rate: 64.912% (74/114)\n",
      "False negative rate: 35.088% (40/114)\n",
      "True negative rate: 98.911% (1272/1286)\n",
      "False positive rate: 1.089% (14/1286)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 2/100: Loss: 0.0923 | Train Acc: 96.036% (2689/2800) | Strict Acc: 63.000% (126/200)\n",
      "True positive rate: 66.116% (160/242)\n",
      "False negative rate: 33.884% (82/242)\n",
      "True negative rate: 98.866% (2529/2558)\n",
      "False positive rate: 1.134% (29/2558)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 3/100: Loss: 0.0866 | Train Acc: 96.476% (4052/4200) | Strict Acc: 66.000% (198/300)\n",
      "True positive rate: 69.628% (243/349)\n",
      "False negative rate: 30.372% (106/349)\n",
      "True negative rate: 98.909% (3809/3851)\n",
      "False positive rate: 1.091% (42/3851)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 4/100: Loss: 0.0833 | Train Acc: 96.643% (5412/5600) | Strict Acc: 66.750% (267/400)\n",
      "True positive rate: 71.526% (314/439)\n",
      "False negative rate: 28.474% (125/439)\n",
      "True negative rate: 98.779% (5098/5161)\n",
      "False positive rate: 1.221% (63/5161)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 5/100: Loss: 0.0833 | Train Acc: 96.671% (6767/7000) | Strict Acc: 67.800% (339/500)\n",
      "True positive rate: 71.751% (381/531)\n",
      "False negative rate: 28.249% (150/531)\n",
      "True negative rate: 98.717% (6386/6469)\n",
      "False positive rate: 1.283% (83/6469)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 6/100: Loss: 0.0809 | Train Acc: 96.726% (8125/8400) | Strict Acc: 67.833% (407/600)\n",
      "True positive rate: 72.082% (457/634)\n",
      "False negative rate: 27.918% (177/634)\n",
      "True negative rate: 98.738% (7668/7766)\n",
      "False positive rate: 1.262% (98/7766)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 7/100: Loss: 0.0783 | Train Acc: 96.827% (9489/9800) | Strict Acc: 68.429% (479/700)\n",
      "True positive rate: 72.470% (537/741)\n",
      "False negative rate: 27.530% (204/741)\n",
      "True negative rate: 98.819% (8952/9059)\n",
      "False positive rate: 1.181% (107/9059)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 8/100: Loss: 0.0786 | Train Acc: 96.777% (10839/11200) | Strict Acc: 68.500% (548/800)\n",
      "True positive rate: 71.698% (608/848)\n",
      "False negative rate: 28.302% (240/848)\n",
      "True negative rate: 98.831% (10231/10352)\n",
      "False positive rate: 1.169% (121/10352)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 9/100: Loss: 0.0799 | Train Acc: 96.778% (12194/12600) | Strict Acc: 68.778% (619/900)\n",
      "True positive rate: 71.158% (676/950)\n",
      "False negative rate: 28.842% (274/950)\n",
      "True negative rate: 98.867% (11518/11650)\n",
      "False positive rate: 1.133% (132/11650)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 10/100: Loss: 0.0813 | Train Acc: 96.714% (13540/14000) | Strict Acc: 68.500% (685/1000)\n",
      "True positive rate: 70.725% (761/1076)\n",
      "False negative rate: 29.275% (315/1076)\n",
      "True negative rate: 98.878% (12779/12924)\n",
      "False positive rate: 1.122% (145/12924)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 11/100: Loss: 0.0812 | Train Acc: 96.721% (14895/15400) | Strict Acc: 68.455% (753/1100)\n",
      "True positive rate: 70.684% (827/1170)\n",
      "False negative rate: 29.316% (343/1170)\n",
      "True negative rate: 98.862% (14068/14230)\n",
      "False positive rate: 1.138% (162/14230)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 12/100: Loss: 0.0816 | Train Acc: 96.702% (16246/16800) | Strict Acc: 68.167% (818/1200)\n",
      "True positive rate: 71.057% (901/1268)\n",
      "False negative rate: 28.943% (367/1268)\n",
      "True negative rate: 98.796% (15345/15532)\n",
      "False positive rate: 1.204% (187/15532)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 13/100: Loss: 0.0801 | Train Acc: 96.764% (17611/18200) | Strict Acc: 68.615% (892/1300)\n",
      "True positive rate: 71.555% (971/1357)\n",
      "False negative rate: 28.445% (386/1357)\n",
      "True negative rate: 98.795% (16640/16843)\n",
      "False positive rate: 1.205% (203/16843)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 14/100: Loss: 0.0797 | Train Acc: 96.796% (18972/19600) | Strict Acc: 68.714% (962/1400)\n",
      "True positive rate: 71.864% (1037/1443)\n",
      "False negative rate: 28.136% (406/1443)\n",
      "True negative rate: 98.777% (17935/18157)\n",
      "False positive rate: 1.223% (222/18157)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 15/100: Loss: 0.0798 | Train Acc: 96.810% (20330/21000) | Strict Acc: 68.667% (1030/1500)\n",
      "True positive rate: 71.889% (1115/1551)\n",
      "False negative rate: 28.111% (436/1551)\n",
      "True negative rate: 98.797% (19215/19449)\n",
      "False positive rate: 1.203% (234/19449)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 16/100: Loss: 0.0793 | Train Acc: 96.826% (21689/22400) | Strict Acc: 68.875% (1102/1600)\n",
      "True positive rate: 72.101% (1194/1656)\n",
      "False negative rate: 27.899% (462/1656)\n",
      "True negative rate: 98.800% (20495/20744)\n",
      "False positive rate: 1.200% (249/20744)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 17/100: Loss: 0.0794 | Train Acc: 96.824% (23044/23800) | Strict Acc: 68.765% (1169/1700)\n",
      "True positive rate: 71.632% (1255/1752)\n",
      "False negative rate: 28.368% (497/1752)\n",
      "True negative rate: 98.825% (21789/22048)\n",
      "False positive rate: 1.175% (259/22048)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 18/100: Loss: 0.0803 | Train Acc: 96.754% (24382/25200) | Strict Acc: 68.389% (1231/1800)\n",
      "True positive rate: 70.909% (1326/1870)\n",
      "False negative rate: 29.091% (544/1870)\n",
      "True negative rate: 98.826% (23056/23330)\n",
      "False positive rate: 1.174% (274/23330)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 19/100: Loss: 0.0796 | Train Acc: 96.748% (25735/26600) | Strict Acc: 68.316% (1298/1900)\n",
      "True positive rate: 71.113% (1418/1994)\n",
      "False negative rate: 28.887% (576/1994)\n",
      "True negative rate: 98.825% (24317/24606)\n",
      "False positive rate: 1.175% (289/24606)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 20/100: Loss: 0.0781 | Train Acc: 96.814% (27108/28000) | Strict Acc: 68.850% (1377/2000)\n",
      "True positive rate: 71.668% (1495/2086)\n",
      "False negative rate: 28.332% (591/2086)\n",
      "True negative rate: 98.838% (25613/25914)\n",
      "False positive rate: 1.162% (301/25914)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 21/100: Loss: 0.0774 | Train Acc: 96.857% (28476/29400) | Strict Acc: 69.143% (1452/2100)\n",
      "True positive rate: 72.436% (1582/2184)\n",
      "False negative rate: 27.564% (602/2184)\n",
      "True negative rate: 98.817% (26894/27216)\n",
      "False positive rate: 1.183% (322/27216)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 22/100: Loss: 0.0773 | Train Acc: 96.864% (29834/30800) | Strict Acc: 69.136% (1521/2200)\n",
      "True positive rate: 72.576% (1654/2279)\n",
      "False negative rate: 27.424% (625/2279)\n",
      "True negative rate: 98.804% (28180/28521)\n",
      "False positive rate: 1.196% (341/28521)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 23/100: Loss: 0.0770 | Train Acc: 96.891% (31199/32200) | Strict Acc: 69.304% (1594/2300)\n",
      "True positive rate: 72.758% (1728/2375)\n",
      "False negative rate: 27.242% (647/2375)\n",
      "True negative rate: 98.813% (29471/29825)\n",
      "False positive rate: 1.187% (354/29825)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 24/100: Loss: 0.0769 | Train Acc: 96.902% (32559/33600) | Strict Acc: 69.417% (1666/2400)\n",
      "True positive rate: 72.886% (1793/2460)\n",
      "False negative rate: 27.114% (667/2460)\n",
      "True negative rate: 98.799% (30766/31140)\n",
      "False positive rate: 1.201% (374/31140)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 25/100: Loss: 0.0771 | Train Acc: 96.886% (33910/35000) | Strict Acc: 69.240% (1731/2500)\n",
      "True positive rate: 72.858% (1879/2579)\n",
      "False negative rate: 27.142% (700/2579)\n",
      "True negative rate: 98.797% (32031/32421)\n",
      "False positive rate: 1.203% (390/32421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 26/100: Loss: 0.0771 | Train Acc: 96.885% (35266/36400) | Strict Acc: 69.192% (1799/2600)\n",
      "True positive rate: 72.646% (1944/2676)\n",
      "False negative rate: 27.354% (732/2676)\n",
      "True negative rate: 98.808% (33322/33724)\n",
      "False positive rate: 1.192% (402/33724)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 27/100: Loss: 0.0771 | Train Acc: 96.889% (36624/37800) | Strict Acc: 69.259% (1870/2700)\n",
      "True positive rate: 72.461% (2005/2767)\n",
      "False negative rate: 27.539% (762/2767)\n",
      "True negative rate: 98.818% (34619/35033)\n",
      "False positive rate: 1.182% (414/35033)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 28/100: Loss: 0.0767 | Train Acc: 96.895% (37983/39200) | Strict Acc: 69.214% (1938/2800)\n",
      "True positive rate: 72.391% (2074/2865)\n",
      "False negative rate: 27.609% (791/2865)\n",
      "True negative rate: 98.828% (35909/36335)\n",
      "False positive rate: 1.172% (426/36335)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 29/100: Loss: 0.0765 | Train Acc: 96.926% (39352/40600) | Strict Acc: 69.517% (2016/2900)\n",
      "True positive rate: 72.506% (2144/2957)\n",
      "False negative rate: 27.494% (813/2957)\n",
      "True negative rate: 98.844% (37208/37643)\n",
      "False positive rate: 1.156% (435/37643)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 30/100: Loss: 0.0766 | Train Acc: 96.929% (40710/42000) | Strict Acc: 69.467% (2084/3000)\n",
      "True positive rate: 72.399% (2206/3047)\n",
      "False negative rate: 27.601% (841/3047)\n",
      "True negative rate: 98.847% (38504/38953)\n",
      "False positive rate: 1.153% (449/38953)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 31/100: Loss: 0.0773 | Train Acc: 96.896% (42053/43400) | Strict Acc: 69.129% (2143/3100)\n",
      "True positive rate: 72.301% (2284/3159)\n",
      "False negative rate: 27.699% (875/3159)\n",
      "True negative rate: 98.827% (39769/40241)\n",
      "False positive rate: 1.173% (472/40241)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 32/100: Loss: 0.0775 | Train Acc: 96.879% (43402/44800) | Strict Acc: 68.875% (2204/3200)\n",
      "True positive rate: 72.075% (2359/3273)\n",
      "False negative rate: 27.925% (914/3273)\n",
      "True negative rate: 98.834% (41043/41527)\n",
      "False positive rate: 1.166% (484/41527)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 33/100: Loss: 0.0775 | Train Acc: 96.870% (44754/46200) | Strict Acc: 68.758% (2269/3300)\n",
      "True positive rate: 72.017% (2432/3377)\n",
      "False negative rate: 27.983% (945/3377)\n",
      "True negative rate: 98.830% (42322/42823)\n",
      "False positive rate: 1.170% (501/42823)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 34/100: Loss: 0.0781 | Train Acc: 96.842% (46097/47600) | Strict Acc: 68.647% (2334/3400)\n",
      "True positive rate: 71.861% (2495/3472)\n",
      "False negative rate: 28.139% (977/3472)\n",
      "True negative rate: 98.808% (43602/44128)\n",
      "False positive rate: 1.192% (526/44128)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 35/100: Loss: 0.0781 | Train Acc: 96.847% (47455/49000) | Strict Acc: 68.886% (2411/3500)\n",
      "True positive rate: 71.862% (2559/3561)\n",
      "False negative rate: 28.138% (1002/3561)\n",
      "True negative rate: 98.805% (44896/45439)\n",
      "False positive rate: 1.195% (543/45439)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 36/100: Loss: 0.0784 | Train Acc: 96.813% (48794/50400) | Strict Acc: 68.667% (2472/3600)\n",
      "True positive rate: 71.553% (2631/3677)\n",
      "False negative rate: 28.447% (1046/3677)\n",
      "True negative rate: 98.801% (46163/46723)\n",
      "False positive rate: 1.199% (560/46723)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 37/100: Loss: 0.0782 | Train Acc: 96.822% (50154/51800) | Strict Acc: 68.811% (2546/3700)\n",
      "True positive rate: 71.607% (2701/3772)\n",
      "False negative rate: 28.393% (1071/3772)\n",
      "True negative rate: 98.803% (47453/48028)\n",
      "False positive rate: 1.197% (575/48028)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 38/100: Loss: 0.0784 | Train Acc: 96.812% (51504/53200) | Strict Acc: 68.737% (2612/3800)\n",
      "True positive rate: 71.550% (2774/3877)\n",
      "False negative rate: 28.450% (1103/3877)\n",
      "True negative rate: 98.798% (48730/49323)\n",
      "False positive rate: 1.202% (593/49323)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 39/100: Loss: 0.0781 | Train Acc: 96.830% (52869/54600) | Strict Acc: 68.872% (2686/3900)\n",
      "True positive rate: 71.616% (2836/3960)\n",
      "False negative rate: 28.384% (1124/3960)\n",
      "True negative rate: 98.801% (50033/50640)\n",
      "False positive rate: 1.199% (607/50640)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 40/100: Loss: 0.0780 | Train Acc: 96.825% (54222/56000) | Strict Acc: 68.900% (2756/4000)\n",
      "True positive rate: 71.608% (2908/4061)\n",
      "False negative rate: 28.392% (1153/4061)\n",
      "True negative rate: 98.797% (51314/51939)\n",
      "False positive rate: 1.203% (625/51939)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 41/100: Loss: 0.0780 | Train Acc: 96.841% (55587/57400) | Strict Acc: 69.049% (2831/4100)\n",
      "True positive rate: 71.730% (2989/4167)\n",
      "False negative rate: 28.270% (1178/4167)\n",
      "True negative rate: 98.807% (52598/53233)\n",
      "False positive rate: 1.193% (635/53233)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 42/100: Loss: 0.0778 | Train Acc: 96.847% (56946/58800) | Strict Acc: 69.095% (2902/4200)\n",
      "True positive rate: 71.770% (3066/4272)\n",
      "False negative rate: 28.230% (1206/4272)\n",
      "True negative rate: 98.812% (53880/54528)\n",
      "False positive rate: 1.188% (648/54528)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 43/100: Loss: 0.0776 | Train Acc: 96.846% (58301/60200) | Strict Acc: 69.093% (2971/4300)\n",
      "True positive rate: 71.768% (3137/4371)\n",
      "False negative rate: 28.232% (1234/4371)\n",
      "True negative rate: 98.809% (55164/55829)\n",
      "False positive rate: 1.191% (665/55829)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 44/100: Loss: 0.0778 | Train Acc: 96.834% (59650/61600) | Strict Acc: 68.955% (3034/4400)\n",
      "True positive rate: 71.659% (3196/4460)\n",
      "False negative rate: 28.341% (1264/4460)\n",
      "True negative rate: 98.799% (56454/57140)\n",
      "False positive rate: 1.201% (686/57140)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 45/100: Loss: 0.0779 | Train Acc: 96.835% (61006/63000) | Strict Acc: 68.956% (3103/4500)\n",
      "True positive rate: 71.598% (3262/4556)\n",
      "False negative rate: 28.402% (1294/4556)\n",
      "True negative rate: 98.802% (57744/58444)\n",
      "False positive rate: 1.198% (700/58444)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 46/100: Loss: 0.0779 | Train Acc: 96.834% (62361/64400) | Strict Acc: 68.891% (3169/4600)\n",
      "True positive rate: 71.582% (3335/4659)\n",
      "False negative rate: 28.418% (1324/4659)\n",
      "True negative rate: 98.803% (59026/59741)\n",
      "False positive rate: 1.197% (715/59741)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 47/100: Loss: 0.0779 | Train Acc: 96.853% (63729/65800) | Strict Acc: 69.000% (3243/4700)\n",
      "True positive rate: 71.657% (3408/4756)\n",
      "False negative rate: 28.343% (1348/4756)\n",
      "True negative rate: 98.816% (60321/61044)\n",
      "False positive rate: 1.184% (723/61044)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 48/100: Loss: 0.0783 | Train Acc: 96.829% (65069/67200) | Strict Acc: 68.854% (3305/4800)\n",
      "True positive rate: 71.540% (3479/4863)\n",
      "False negative rate: 28.460% (1384/4863)\n",
      "True negative rate: 98.802% (61590/62337)\n",
      "False positive rate: 1.198% (747/62337)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 49/100: Loss: 0.0781 | Train Acc: 96.850% (66439/68600) | Strict Acc: 69.082% (3385/4900)\n",
      "True positive rate: 71.761% (3573/4979)\n",
      "False negative rate: 28.239% (1406/4979)\n",
      "True negative rate: 98.813% (62866/63621)\n",
      "False positive rate: 1.187% (755/63621)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 50/100: Loss: 0.0780 | Train Acc: 96.857% (67800/70000) | Strict Acc: 69.120% (3456/5000)\n",
      "True positive rate: 71.743% (3646/5082)\n",
      "False negative rate: 28.257% (1436/5082)\n",
      "True negative rate: 98.823% (64154/64918)\n",
      "False positive rate: 1.177% (764/64918)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 51/100: Loss: 0.0779 | Train Acc: 96.861% (69159/71400) | Strict Acc: 69.137% (3526/5100)\n",
      "True positive rate: 71.807% (3716/5175)\n",
      "False negative rate: 28.193% (1459/5175)\n",
      "True negative rate: 98.819% (65443/66225)\n",
      "False positive rate: 1.181% (782/66225)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 52/100: Loss: 0.0780 | Train Acc: 96.860% (70514/72800) | Strict Acc: 69.077% (3592/5200)\n",
      "True positive rate: 71.828% (3781/5264)\n",
      "False negative rate: 28.172% (1483/5264)\n",
      "True negative rate: 98.811% (66733/67536)\n",
      "False positive rate: 1.189% (803/67536)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 53/100: Loss: 0.0781 | Train Acc: 96.845% (71859/74200) | Strict Acc: 68.925% (3653/5300)\n",
      "True positive rate: 71.748% (3850/5366)\n",
      "False negative rate: 28.252% (1516/5366)\n",
      "True negative rate: 98.801% (68009/68834)\n",
      "False positive rate: 1.199% (825/68834)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 54/100: Loss: 0.0782 | Train Acc: 96.841% (73212/75600) | Strict Acc: 68.926% (3722/5400)\n",
      "True positive rate: 71.687% (3917/5464)\n",
      "False negative rate: 28.313% (1547/5464)\n",
      "True negative rate: 98.801% (69295/70136)\n",
      "False positive rate: 1.199% (841/70136)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 55/100: Loss: 0.0782 | Train Acc: 96.843% (74569/77000) | Strict Acc: 68.873% (3788/5500)\n",
      "True positive rate: 71.573% (3978/5558)\n",
      "False negative rate: 28.427% (1580/5558)\n",
      "True negative rate: 98.809% (70591/71442)\n",
      "False positive rate: 1.191% (851/71442)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 56/100: Loss: 0.0780 | Train Acc: 96.851% (75931/78400) | Strict Acc: 68.964% (3862/5600)\n",
      "True positive rate: 71.560% (4041/5647)\n",
      "False negative rate: 28.440% (1606/5647)\n",
      "True negative rate: 98.814% (71890/72753)\n",
      "False positive rate: 1.186% (863/72753)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 57/100: Loss: 0.0779 | Train Acc: 96.858% (77293/79800) | Strict Acc: 69.035% (3935/5700)\n",
      "True positive rate: 71.553% (4115/5751)\n",
      "False negative rate: 28.447% (1636/5751)\n",
      "True negative rate: 98.824% (73178/74049)\n",
      "False positive rate: 1.176% (871/74049)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 58/100: Loss: 0.0777 | Train Acc: 96.869% (78658/81200) | Strict Acc: 69.103% (4008/5800)\n",
      "True positive rate: 71.541% (4178/5840)\n",
      "False negative rate: 28.459% (1662/5840)\n",
      "True negative rate: 98.832% (74480/75360)\n",
      "False positive rate: 1.168% (880/75360)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 59/100: Loss: 0.0779 | Train Acc: 96.855% (80002/82600) | Strict Acc: 68.966% (4069/5900)\n",
      "True positive rate: 71.395% (4253/5957)\n",
      "False negative rate: 28.605% (1704/5957)\n",
      "True negative rate: 98.834% (75749/76643)\n",
      "False positive rate: 1.166% (894/76643)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 60/100: Loss: 0.0780 | Train Acc: 96.849% (81353/84000) | Strict Acc: 68.917% (4135/6000)\n",
      "True positive rate: 71.346% (4325/6062)\n",
      "False negative rate: 28.654% (1737/6062)\n",
      "True negative rate: 98.832% (77028/77938)\n",
      "False positive rate: 1.168% (910/77938)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 61/100: Loss: 0.0778 | Train Acc: 96.855% (82714/85400) | Strict Acc: 69.033% (4211/6100)\n",
      "True positive rate: 71.329% (4396/6163)\n",
      "False negative rate: 28.671% (1767/6163)\n",
      "True negative rate: 98.840% (78318/79237)\n",
      "False positive rate: 1.160% (919/79237)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 62/100: Loss: 0.0777 | Train Acc: 96.861% (84075/86800) | Strict Acc: 69.113% (4285/6200)\n",
      "True positive rate: 71.415% (4472/6262)\n",
      "False negative rate: 28.585% (1790/6262)\n",
      "True negative rate: 98.839% (79603/80538)\n",
      "False positive rate: 1.161% (935/80538)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 63/100: Loss: 0.0779 | Train Acc: 96.863% (85433/88200) | Strict Acc: 69.111% (4354/6300)\n",
      "True positive rate: 71.451% (4550/6368)\n",
      "False negative rate: 28.549% (1818/6368)\n",
      "True negative rate: 98.840% (80883/81832)\n",
      "False positive rate: 1.160% (949/81832)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 64/100: Loss: 0.0778 | Train Acc: 96.868% (86794/89600) | Strict Acc: 69.156% (4426/6400)\n",
      "True positive rate: 71.493% (4617/6458)\n",
      "False negative rate: 28.507% (1841/6458)\n",
      "True negative rate: 98.839% (82177/83142)\n",
      "False positive rate: 1.161% (965/83142)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 65/100: Loss: 0.0779 | Train Acc: 96.865% (88147/91000) | Strict Acc: 69.123% (4493/6500)\n",
      "True positive rate: 71.498% (4701/6575)\n",
      "False negative rate: 28.502% (1874/6575)\n",
      "True negative rate: 98.840% (83446/84425)\n",
      "False positive rate: 1.160% (979/84425)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 66/100: Loss: 0.0778 | Train Acc: 96.867% (89505/92400) | Strict Acc: 69.152% (4564/6600)\n",
      "True positive rate: 71.538% (4773/6672)\n",
      "False negative rate: 28.462% (1899/6672)\n",
      "True negative rate: 98.838% (84732/85728)\n",
      "False positive rate: 1.162% (996/85728)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 67/100: Loss: 0.0778 | Train Acc: 96.864% (90858/93800) | Strict Acc: 69.134% (4632/6700)\n",
      "True positive rate: 71.684% (4853/6770)\n",
      "False negative rate: 28.316% (1917/6770)\n",
      "True negative rate: 98.822% (86005/87030)\n",
      "False positive rate: 1.178% (1025/87030)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 68/100: Loss: 0.0782 | Train Acc: 96.854% (92205/95200) | Strict Acc: 69.059% (4696/6800)\n",
      "True positive rate: 71.658% (4943/6898)\n",
      "False negative rate: 28.342% (1955/6898)\n",
      "True negative rate: 98.822% (87262/88302)\n",
      "False positive rate: 1.178% (1040/88302)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 69/100: Loss: 0.0779 | Train Acc: 96.865% (93572/96600) | Strict Acc: 69.145% (4771/6900)\n",
      "True positive rate: 71.781% (5029/7006)\n",
      "False negative rate: 28.219% (1977/7006)\n",
      "True negative rate: 98.827% (88543/89594)\n",
      "False positive rate: 1.173% (1051/89594)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 70/100: Loss: 0.0780 | Train Acc: 96.851% (94914/98000) | Strict Acc: 69.000% (4830/7000)\n",
      "True positive rate: 71.749% (5087/7090)\n",
      "False negative rate: 28.251% (2003/7090)\n",
      "True negative rate: 98.809% (89827/90910)\n",
      "False positive rate: 1.191% (1083/90910)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 71/100: Loss: 0.0780 | Train Acc: 96.853% (96272/99400) | Strict Acc: 69.070% (4904/7100)\n",
      "True positive rate: 71.721% (5146/7175)\n",
      "False negative rate: 28.279% (2029/7175)\n",
      "True negative rate: 98.808% (91126/92225)\n",
      "False positive rate: 1.192% (1099/92225)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 72/100: Loss: 0.0781 | Train Acc: 96.842% (97617/100800) | Strict Acc: 68.972% (4966/7200)\n",
      "True positive rate: 71.582% (5194/7256)\n",
      "False negative rate: 28.418% (2062/7256)\n",
      "True negative rate: 98.802% (92423/93544)\n",
      "False positive rate: 1.198% (1121/93544)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 73/100: Loss: 0.0784 | Train Acc: 96.833% (98963/102200) | Strict Acc: 68.890% (5029/7300)\n",
      "True positive rate: 71.473% (5274/7379)\n",
      "False negative rate: 28.527% (2105/7379)\n",
      "True negative rate: 98.806% (93689/94821)\n",
      "False positive rate: 1.194% (1132/94821)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 74/100: Loss: 0.0783 | Train Acc: 96.835% (100321/103600) | Strict Acc: 68.892% (5098/7400)\n",
      "True positive rate: 71.369% (5327/7464)\n",
      "False negative rate: 28.631% (2137/7464)\n",
      "True negative rate: 98.812% (94994/96136)\n",
      "False positive rate: 1.188% (1142/96136)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 75/100: Loss: 0.0783 | Train Acc: 96.837% (101679/105000) | Strict Acc: 68.867% (5165/7500)\n",
      "True positive rate: 71.376% (5406/7574)\n",
      "False negative rate: 28.624% (2168/7574)\n",
      "True negative rate: 98.817% (96273/97426)\n",
      "False positive rate: 1.183% (1153/97426)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 76/100: Loss: 0.0787 | Train Acc: 96.826% (103023/106400) | Strict Acc: 68.789% (5228/7600)\n",
      "True positive rate: 71.194% (5467/7679)\n",
      "False negative rate: 28.806% (2212/7679)\n",
      "True negative rate: 98.820% (97556/98721)\n",
      "False positive rate: 1.180% (1165/98721)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 77/100: Loss: 0.0786 | Train Acc: 96.833% (104386/107800) | Strict Acc: 68.857% (5302/7700)\n",
      "True positive rate: 71.284% (5548/7783)\n",
      "False negative rate: 28.716% (2235/7783)\n",
      "True negative rate: 98.821% (98838/100017)\n",
      "False positive rate: 1.179% (1179/100017)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 78/100: Loss: 0.0787 | Train Acc: 96.828% (105736/109200) | Strict Acc: 68.808% (5367/7800)\n",
      "True positive rate: 71.333% (5626/7887)\n",
      "False negative rate: 28.667% (2261/7887)\n",
      "True negative rate: 98.813% (100110/101313)\n",
      "False positive rate: 1.187% (1203/101313)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 79/100: Loss: 0.0787 | Train Acc: 96.835% (107099/110600) | Strict Acc: 68.873% (5441/7900)\n",
      "True positive rate: 71.445% (5707/7988)\n",
      "False negative rate: 28.555% (2281/7988)\n",
      "True negative rate: 98.811% (101392/102612)\n",
      "False positive rate: 1.189% (1220/102612)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 80/100: Loss: 0.0787 | Train Acc: 96.839% (108460/112000) | Strict Acc: 68.888% (5511/8000)\n",
      "True positive rate: 71.542% (5782/8082)\n",
      "False negative rate: 28.458% (2300/8082)\n",
      "True negative rate: 98.807% (102678/103918)\n",
      "False positive rate: 1.193% (1240/103918)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 81/100: Loss: 0.0785 | Train Acc: 96.844% (109821/113400) | Strict Acc: 68.963% (5586/8100)\n",
      "True positive rate: 71.641% (5866/8188)\n",
      "False negative rate: 28.359% (2322/8188)\n",
      "True negative rate: 98.805% (103955/105212)\n",
      "False positive rate: 1.195% (1257/105212)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 82/100: Loss: 0.0786 | Train Acc: 96.847% (111180/114800) | Strict Acc: 68.988% (5657/8200)\n",
      "True positive rate: 71.682% (5941/8288)\n",
      "False negative rate: 28.318% (2347/8288)\n",
      "True negative rate: 98.805% (105239/106512)\n",
      "False positive rate: 1.195% (1273/106512)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 83/100: Loss: 0.0785 | Train Acc: 96.843% (112532/116200) | Strict Acc: 68.988% (5726/8300)\n",
      "True positive rate: 71.641% (6010/8389)\n",
      "False negative rate: 28.359% (2379/8389)\n",
      "True negative rate: 98.804% (106522/107811)\n",
      "False positive rate: 1.196% (1289/107811)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 84/100: Loss: 0.0789 | Train Acc: 96.832% (113874/117600) | Strict Acc: 68.917% (5789/8400)\n",
      "True positive rate: 71.489% (6083/8509)\n",
      "False negative rate: 28.511% (2426/8509)\n",
      "True negative rate: 98.808% (107791/109091)\n",
      "False positive rate: 1.192% (1300/109091)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 85/100: Loss: 0.0792 | Train Acc: 96.823% (115219/119000) | Strict Acc: 68.859% (5853/8500)\n",
      "True positive rate: 71.326% (6144/8614)\n",
      "False negative rate: 28.674% (2470/8614)\n",
      "True negative rate: 98.812% (109075/110386)\n",
      "False positive rate: 1.188% (1311/110386)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 86/100: Loss: 0.0793 | Train Acc: 96.817% (116568/120400) | Strict Acc: 68.826% (5919/8600)\n",
      "True positive rate: 71.249% (6220/8730)\n",
      "False negative rate: 28.751% (2510/8730)\n",
      "True negative rate: 98.816% (110348/111670)\n",
      "False positive rate: 1.184% (1322/111670)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 87/100: Loss: 0.0794 | Train Acc: 96.806% (117910/121800) | Strict Acc: 68.816% (5987/8700)\n",
      "True positive rate: 71.138% (6285/8835)\n",
      "False negative rate: 28.862% (2550/8835)\n",
      "True negative rate: 98.814% (111625/112965)\n",
      "False positive rate: 1.186% (1340/112965)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 88/100: Loss: 0.0793 | Train Acc: 96.811% (119271/123200) | Strict Acc: 68.864% (6060/8800)\n",
      "True positive rate: 71.255% (6383/8958)\n",
      "False negative rate: 28.745% (2575/8958)\n",
      "True negative rate: 98.815% (112888/114242)\n",
      "False positive rate: 1.185% (1354/114242)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 89/100: Loss: 0.0794 | Train Acc: 96.809% (120624/124600) | Strict Acc: 68.820% (6125/8900)\n",
      "True positive rate: 71.331% (6464/9062)\n",
      "False negative rate: 28.669% (2598/9062)\n",
      "True negative rate: 98.807% (114160/115538)\n",
      "False positive rate: 1.193% (1378/115538)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 90/100: Loss: 0.0796 | Train Acc: 96.807% (121977/126000) | Strict Acc: 68.800% (6192/9000)\n",
      "True positive rate: 71.333% (6532/9157)\n",
      "False negative rate: 28.667% (2625/9157)\n",
      "True negative rate: 98.804% (115445/116843)\n",
      "False positive rate: 1.196% (1398/116843)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 91/100: Loss: 0.0797 | Train Acc: 96.797% (123319/127400) | Strict Acc: 68.736% (6255/9100)\n",
      "True positive rate: 71.351% (6605/9257)\n",
      "False negative rate: 28.649% (2652/9257)\n",
      "True negative rate: 98.790% (116714/118143)\n",
      "False positive rate: 1.210% (1429/118143)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 92/100: Loss: 0.0798 | Train Acc: 96.799% (124677/128800) | Strict Acc: 68.739% (6324/9200)\n",
      "True positive rate: 71.447% (6691/9365)\n",
      "False negative rate: 28.553% (2674/9365)\n",
      "True negative rate: 98.787% (117986/119435)\n",
      "False positive rate: 1.213% (1449/119435)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 93/100: Loss: 0.0797 | Train Acc: 96.803% (126038/130200) | Strict Acc: 68.785% (6397/9300)\n",
      "True positive rate: 71.474% (6755/9451)\n",
      "False negative rate: 28.526% (2696/9451)\n",
      "True negative rate: 98.786% (119283/120749)\n",
      "False positive rate: 1.214% (1466/120749)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 94/100: Loss: 0.0799 | Train Acc: 96.800% (127389/131600) | Strict Acc: 68.713% (6459/9400)\n",
      "True positive rate: 71.394% (6821/9554)\n",
      "False negative rate: 28.606% (2733/9554)\n",
      "True negative rate: 98.789% (120568/122046)\n",
      "False positive rate: 1.211% (1478/122046)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 95/100: Loss: 0.0800 | Train Acc: 96.793% (128735/133000) | Strict Acc: 68.674% (6524/9500)\n",
      "True positive rate: 71.300% (6894/9669)\n",
      "False negative rate: 28.700% (2775/9669)\n",
      "True negative rate: 98.792% (121841/123331)\n",
      "False positive rate: 1.208% (1490/123331)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 96/100: Loss: 0.0799 | Train Acc: 96.796% (130094/134400) | Strict Acc: 68.667% (6592/9600)\n",
      "True positive rate: 71.284% (6968/9775)\n",
      "False negative rate: 28.716% (2807/9775)\n",
      "True negative rate: 98.797% (123126/124625)\n",
      "False positive rate: 1.203% (1499/124625)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 97/100: Loss: 0.0799 | Train Acc: 96.791% (131442/135800) | Strict Acc: 68.619% (6656/9700)\n",
      "True positive rate: 71.210% (7032/9875)\n",
      "False negative rate: 28.790% (2843/9875)\n",
      "True negative rate: 98.797% (124410/125925)\n",
      "False positive rate: 1.203% (1515/125925)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 98/100: Loss: 0.0801 | Train Acc: 96.786% (132790/137200) | Strict Acc: 68.592% (6722/9800)\n",
      "True positive rate: 71.146% (7094/9971)\n",
      "False negative rate: 28.854% (2877/9971)\n",
      "True negative rate: 98.795% (125696/127229)\n",
      "False positive rate: 1.205% (1533/127229)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 99/100: Loss: 0.0801 | Train Acc: 96.780% (134137/138600) | Strict Acc: 68.566% (6788/9900)\n",
      "True positive rate: 71.096% (7153/10061)\n",
      "False negative rate: 28.904% (2908/10061)\n",
      "True negative rate: 98.790% (126984/128539)\n",
      "False positive rate: 1.210% (1555/128539)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 7 - Batch 100/100: Loss: 0.0799 | Train Acc: 96.782% (134276/138740) | Strict Acc: 68.587% (6797/9910)\n",
      "True positive rate: 71.092% (7154/10063)\n",
      "False negative rate: 28.908% (2909/10063)\n",
      "True negative rate: 98.792% (127122/128677)\n",
      "False positive rate: 1.208% (1555/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1154 | Dev Acc: 95.778% (67983/70980) | Strict Acc: 61.834% (3135/5070)\n",
      "True positive rate: 62.701% (3231/5153)\n",
      "False negative rate: 37.299% (1922/5153)\n",
      "True negative rate: 98.367% (64752/65827)\n",
      "False positive rate: 1.633% (1075/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 1/100: Loss: 0.0619 | Train Acc: 97.286% (1362/1400) | Strict Acc: 74.000% (74/100)\n",
      "True positive rate: 72.449% (71/98)\n",
      "False negative rate: 27.551% (27/98)\n",
      "True negative rate: 99.155% (1291/1302)\n",
      "False positive rate: 0.845% (11/1302)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 2/100: Loss: 0.0702 | Train Acc: 96.964% (2715/2800) | Strict Acc: 71.500% (143/200)\n",
      "True positive rate: 69.378% (145/209)\n",
      "False negative rate: 30.622% (64/209)\n",
      "True negative rate: 99.190% (2570/2591)\n",
      "False positive rate: 0.810% (21/2591)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 3/100: Loss: 0.0668 | Train Acc: 97.238% (4084/4200) | Strict Acc: 72.667% (218/300)\n",
      "True positive rate: 70.903% (212/299)\n",
      "False negative rate: 29.097% (87/299)\n",
      "True negative rate: 99.257% (3872/3901)\n",
      "False positive rate: 0.743% (29/3901)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 4/100: Loss: 0.0711 | Train Acc: 97.089% (5437/5600) | Strict Acc: 71.500% (286/400)\n",
      "True positive rate: 69.118% (282/408)\n",
      "False negative rate: 30.882% (126/408)\n",
      "True negative rate: 99.287% (5155/5192)\n",
      "False positive rate: 0.713% (37/5192)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 5/100: Loss: 0.0720 | Train Acc: 97.143% (6800/7000) | Strict Acc: 72.200% (361/500)\n",
      "True positive rate: 69.034% (350/507)\n",
      "False negative rate: 30.966% (157/507)\n",
      "True negative rate: 99.338% (6450/6493)\n",
      "False positive rate: 0.662% (43/6493)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 6/100: Loss: 0.0731 | Train Acc: 97.071% (8154/8400) | Strict Acc: 71.167% (427/600)\n",
      "True positive rate: 70.521% (433/614)\n",
      "False negative rate: 29.479% (181/614)\n",
      "True negative rate: 99.165% (7721/7786)\n",
      "False positive rate: 0.835% (65/7786)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 7/100: Loss: 0.0766 | Train Acc: 96.949% (9501/9800) | Strict Acc: 70.000% (490/700)\n",
      "True positive rate: 71.218% (532/747)\n",
      "False negative rate: 28.782% (215/747)\n",
      "True negative rate: 99.072% (8969/9053)\n",
      "False positive rate: 0.928% (84/9053)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 8/100: Loss: 0.0769 | Train Acc: 96.911% (10854/11200) | Strict Acc: 69.375% (555/800)\n",
      "True positive rate: 72.333% (617/853)\n",
      "False negative rate: 27.667% (236/853)\n",
      "True negative rate: 98.937% (10237/10347)\n",
      "False positive rate: 1.063% (110/10347)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 9/100: Loss: 0.0766 | Train Acc: 96.968% (12218/12600) | Strict Acc: 69.333% (624/900)\n",
      "True positive rate: 73.611% (689/936)\n",
      "False negative rate: 26.389% (247/936)\n",
      "True negative rate: 98.843% (11529/11664)\n",
      "False positive rate: 1.157% (135/11664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 10/100: Loss: 0.0753 | Train Acc: 97.036% (13585/14000) | Strict Acc: 69.800% (698/1000)\n",
      "True positive rate: 74.190% (756/1019)\n",
      "False negative rate: 25.810% (263/1019)\n",
      "True negative rate: 98.829% (12829/12981)\n",
      "False positive rate: 1.171% (152/12981)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 11/100: Loss: 0.0758 | Train Acc: 96.981% (14935/15400) | Strict Acc: 69.636% (766/1100)\n",
      "True positive rate: 73.623% (829/1126)\n",
      "False negative rate: 26.377% (297/1126)\n",
      "True negative rate: 98.823% (14106/14274)\n",
      "False positive rate: 1.177% (168/14274)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 12/100: Loss: 0.0762 | Train Acc: 96.982% (16293/16800) | Strict Acc: 69.833% (838/1200)\n",
      "True positive rate: 73.769% (914/1239)\n",
      "False negative rate: 26.231% (325/1239)\n",
      "True negative rate: 98.830% (15379/15561)\n",
      "False positive rate: 1.170% (182/15561)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 13/100: Loss: 0.0760 | Train Acc: 96.962% (17647/18200) | Strict Acc: 69.923% (909/1300)\n",
      "True positive rate: 73.521% (994/1352)\n",
      "False negative rate: 26.479% (358/1352)\n",
      "True negative rate: 98.843% (16653/16848)\n",
      "False positive rate: 1.157% (195/16848)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 14/100: Loss: 0.0768 | Train Acc: 96.949% (19002/19600) | Strict Acc: 69.786% (977/1400)\n",
      "True positive rate: 73.487% (1081/1471)\n",
      "False negative rate: 26.513% (390/1471)\n",
      "True negative rate: 98.853% (17921/18129)\n",
      "False positive rate: 1.147% (208/18129)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 15/100: Loss: 0.0764 | Train Acc: 96.957% (20361/21000) | Strict Acc: 69.800% (1047/1500)\n",
      "True positive rate: 73.144% (1133/1549)\n",
      "False negative rate: 26.856% (416/1549)\n",
      "True negative rate: 98.854% (19228/19451)\n",
      "False positive rate: 1.146% (223/19451)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 16/100: Loss: 0.0764 | Train Acc: 96.955% (21718/22400) | Strict Acc: 69.875% (1118/1600)\n",
      "True positive rate: 72.794% (1196/1643)\n",
      "False negative rate: 27.206% (447/1643)\n",
      "True negative rate: 98.868% (20522/20757)\n",
      "False positive rate: 1.132% (235/20757)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 17/100: Loss: 0.0760 | Train Acc: 96.992% (23084/23800) | Strict Acc: 70.353% (1196/1700)\n",
      "True positive rate: 73.088% (1271/1739)\n",
      "False negative rate: 26.912% (468/1739)\n",
      "True negative rate: 98.876% (21813/22061)\n",
      "False positive rate: 1.124% (248/22061)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 18/100: Loss: 0.0761 | Train Acc: 96.992% (24442/25200) | Strict Acc: 70.222% (1264/1800)\n",
      "True positive rate: 72.653% (1339/1843)\n",
      "False negative rate: 27.347% (504/1843)\n",
      "True negative rate: 98.913% (23103/23357)\n",
      "False positive rate: 1.087% (254/23357)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 19/100: Loss: 0.0749 | Train Acc: 97.053% (25816/26600) | Strict Acc: 70.684% (1343/1900)\n",
      "True positive rate: 73.065% (1416/1938)\n",
      "False negative rate: 26.935% (522/1938)\n",
      "True negative rate: 98.938% (24400/24662)\n",
      "False positive rate: 1.062% (262/24662)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 20/100: Loss: 0.0745 | Train Acc: 97.075% (27181/28000) | Strict Acc: 70.850% (1417/2000)\n",
      "True positive rate: 73.409% (1488/2027)\n",
      "False negative rate: 26.591% (539/2027)\n",
      "True negative rate: 98.922% (25693/25973)\n",
      "False positive rate: 1.078% (280/25973)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 21/100: Loss: 0.0743 | Train Acc: 97.065% (28537/29400) | Strict Acc: 70.762% (1486/2100)\n",
      "True positive rate: 73.405% (1565/2132)\n",
      "False negative rate: 26.595% (567/2132)\n",
      "True negative rate: 98.914% (26972/27268)\n",
      "False positive rate: 1.086% (296/27268)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 22/100: Loss: 0.0736 | Train Acc: 97.084% (29902/30800) | Strict Acc: 70.773% (1557/2200)\n",
      "True positive rate: 73.411% (1629/2219)\n",
      "False negative rate: 26.589% (590/2219)\n",
      "True negative rate: 98.922% (28273/28581)\n",
      "False positive rate: 1.078% (308/28581)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 23/100: Loss: 0.0740 | Train Acc: 97.065% (31255/32200) | Strict Acc: 70.522% (1622/2300)\n",
      "True positive rate: 73.356% (1707/2327)\n",
      "False negative rate: 26.644% (620/2327)\n",
      "True negative rate: 98.912% (29548/29873)\n",
      "False positive rate: 1.088% (325/29873)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 24/100: Loss: 0.0740 | Train Acc: 97.068% (32615/33600) | Strict Acc: 70.625% (1695/2400)\n",
      "True positive rate: 73.199% (1778/2429)\n",
      "False negative rate: 26.801% (651/2429)\n",
      "True negative rate: 98.928% (30837/31171)\n",
      "False positive rate: 1.072% (334/31171)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 25/100: Loss: 0.0742 | Train Acc: 97.069% (33974/35000) | Strict Acc: 70.600% (1765/2500)\n",
      "True positive rate: 73.131% (1859/2542)\n",
      "False negative rate: 26.869% (683/2542)\n",
      "True negative rate: 98.943% (32115/32458)\n",
      "False positive rate: 1.057% (343/32458)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 26/100: Loss: 0.0740 | Train Acc: 97.093% (35342/36400) | Strict Acc: 70.846% (1842/2600)\n",
      "True positive rate: 73.189% (1930/2637)\n",
      "False negative rate: 26.811% (707/2637)\n",
      "True negative rate: 98.960% (33412/33763)\n",
      "False positive rate: 1.040% (351/33763)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 27/100: Loss: 0.0741 | Train Acc: 97.090% (36700/37800) | Strict Acc: 70.852% (1913/2700)\n",
      "True positive rate: 73.231% (2008/2742)\n",
      "False negative rate: 26.769% (734/2742)\n",
      "True negative rate: 98.956% (34692/35058)\n",
      "False positive rate: 1.044% (366/35058)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 28/100: Loss: 0.0745 | Train Acc: 97.059% (38047/39200) | Strict Acc: 70.607% (1977/2800)\n",
      "True positive rate: 73.062% (2083/2851)\n",
      "False negative rate: 26.938% (768/2851)\n",
      "True negative rate: 98.941% (35964/36349)\n",
      "False positive rate: 1.059% (385/36349)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 29/100: Loss: 0.0743 | Train Acc: 97.067% (39409/40600) | Strict Acc: 70.655% (2049/2900)\n",
      "True positive rate: 73.214% (2162/2953)\n",
      "False negative rate: 26.786% (791/2953)\n",
      "True negative rate: 98.937% (37247/37647)\n",
      "False positive rate: 1.063% (400/37647)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 30/100: Loss: 0.0738 | Train Acc: 97.088% (40777/42000) | Strict Acc: 70.833% (2125/3000)\n",
      "True positive rate: 73.662% (2243/3045)\n",
      "False negative rate: 26.338% (802/3045)\n",
      "True negative rate: 98.919% (38534/38955)\n",
      "False positive rate: 1.081% (421/38955)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 31/100: Loss: 0.0741 | Train Acc: 97.058% (42123/43400) | Strict Acc: 70.677% (2191/3100)\n",
      "True positive rate: 73.649% (2317/3146)\n",
      "False negative rate: 26.351% (829/3146)\n",
      "True negative rate: 98.887% (39806/40254)\n",
      "False positive rate: 1.113% (448/40254)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 32/100: Loss: 0.0739 | Train Acc: 97.065% (43485/44800) | Strict Acc: 70.656% (2261/3200)\n",
      "True positive rate: 73.652% (2390/3245)\n",
      "False negative rate: 26.348% (855/3245)\n",
      "True negative rate: 98.893% (41095/41555)\n",
      "False positive rate: 1.107% (460/41555)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 33/100: Loss: 0.0738 | Train Acc: 97.065% (44844/46200) | Strict Acc: 70.545% (2328/3300)\n",
      "True positive rate: 73.714% (2479/3363)\n",
      "False negative rate: 26.286% (884/3363)\n",
      "True negative rate: 98.898% (42365/42837)\n",
      "False positive rate: 1.102% (472/42837)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 34/100: Loss: 0.0739 | Train Acc: 97.057% (46199/47600) | Strict Acc: 70.500% (2397/3400)\n",
      "True positive rate: 73.651% (2566/3484)\n",
      "False negative rate: 26.349% (918/3484)\n",
      "True negative rate: 98.905% (43633/44116)\n",
      "False positive rate: 1.095% (483/44116)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 35/100: Loss: 0.0739 | Train Acc: 97.059% (47559/49000) | Strict Acc: 70.457% (2466/3500)\n",
      "True positive rate: 73.504% (2641/3593)\n",
      "False negative rate: 26.496% (952/3593)\n",
      "True negative rate: 98.923% (44918/45407)\n",
      "False positive rate: 1.077% (489/45407)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 36/100: Loss: 0.0741 | Train Acc: 97.048% (48912/50400) | Strict Acc: 70.361% (2533/3600)\n",
      "True positive rate: 73.359% (2715/3701)\n",
      "False negative rate: 26.641% (986/3701)\n",
      "True negative rate: 98.925% (46197/46699)\n",
      "False positive rate: 1.075% (502/46699)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 37/100: Loss: 0.0740 | Train Acc: 97.060% (50277/51800) | Strict Acc: 70.378% (2604/3700)\n",
      "True positive rate: 73.477% (2798/3808)\n",
      "False negative rate: 26.523% (1010/3808)\n",
      "True negative rate: 98.931% (47479/47992)\n",
      "False positive rate: 1.069% (513/47992)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 38/100: Loss: 0.0738 | Train Acc: 97.071% (51642/53200) | Strict Acc: 70.421% (2676/3800)\n",
      "True positive rate: 73.649% (2876/3905)\n",
      "False negative rate: 26.351% (1029/3905)\n",
      "True negative rate: 98.927% (48766/49295)\n",
      "False positive rate: 1.073% (529/49295)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 39/100: Loss: 0.0738 | Train Acc: 97.062% (52996/54600) | Strict Acc: 70.256% (2740/3900)\n",
      "True positive rate: 73.571% (2934/3988)\n",
      "False negative rate: 26.429% (1054/3988)\n",
      "True negative rate: 98.913% (50062/50612)\n",
      "False positive rate: 1.087% (550/50612)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 40/100: Loss: 0.0734 | Train Acc: 97.088% (54369/56000) | Strict Acc: 70.475% (2819/4000)\n",
      "True positive rate: 73.772% (3018/4091)\n",
      "False negative rate: 26.228% (1073/4091)\n",
      "True negative rate: 98.925% (51351/51909)\n",
      "False positive rate: 1.075% (558/51909)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 41/100: Loss: 0.0734 | Train Acc: 97.084% (55726/57400) | Strict Acc: 70.415% (2887/4100)\n",
      "True positive rate: 73.732% (3082/4180)\n",
      "False negative rate: 26.268% (1098/4180)\n",
      "True negative rate: 98.918% (52644/53220)\n",
      "False positive rate: 1.082% (576/53220)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 42/100: Loss: 0.0733 | Train Acc: 97.090% (57089/58800) | Strict Acc: 70.405% (2957/4200)\n",
      "True positive rate: 73.668% (3153/4280)\n",
      "False negative rate: 26.332% (1127/4280)\n",
      "True negative rate: 98.929% (53936/54520)\n",
      "False positive rate: 1.071% (584/54520)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 43/100: Loss: 0.0729 | Train Acc: 97.108% (58459/60200) | Strict Acc: 70.488% (3031/4300)\n",
      "True positive rate: 73.817% (3228/4373)\n",
      "False negative rate: 26.183% (1145/4373)\n",
      "True negative rate: 98.932% (55231/55827)\n",
      "False positive rate: 1.068% (596/55827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 44/100: Loss: 0.0731 | Train Acc: 97.097% (59812/61600) | Strict Acc: 70.364% (3096/4400)\n",
      "True positive rate: 73.582% (3295/4478)\n",
      "False negative rate: 26.418% (1183/4478)\n",
      "True negative rate: 98.941% (56517/57122)\n",
      "False positive rate: 1.059% (605/57122)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 45/100: Loss: 0.0730 | Train Acc: 97.095% (61170/63000) | Strict Acc: 70.267% (3162/4500)\n",
      "True positive rate: 73.575% (3369/4579)\n",
      "False negative rate: 26.425% (1210/4579)\n",
      "True negative rate: 98.939% (57801/58421)\n",
      "False positive rate: 1.061% (620/58421)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 46/100: Loss: 0.0729 | Train Acc: 97.092% (62527/64400) | Strict Acc: 70.239% (3231/4600)\n",
      "True positive rate: 73.471% (3448/4693)\n",
      "False negative rate: 26.529% (1245/4693)\n",
      "True negative rate: 98.948% (59079/59707)\n",
      "False positive rate: 1.052% (628/59707)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 47/100: Loss: 0.0729 | Train Acc: 97.090% (63885/65800) | Strict Acc: 70.298% (3304/4700)\n",
      "True positive rate: 73.440% (3531/4808)\n",
      "False negative rate: 26.560% (1277/4808)\n",
      "True negative rate: 98.954% (60354/60992)\n",
      "False positive rate: 1.046% (638/60992)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 48/100: Loss: 0.0735 | Train Acc: 97.055% (65221/67200) | Strict Acc: 70.167% (3368/4800)\n",
      "True positive rate: 73.248% (3595/4908)\n",
      "False negative rate: 26.752% (1313/4908)\n",
      "True negative rate: 98.931% (61626/62292)\n",
      "False positive rate: 1.069% (666/62292)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 49/100: Loss: 0.0734 | Train Acc: 97.055% (66580/68600) | Strict Acc: 70.163% (3438/4900)\n",
      "True positive rate: 73.315% (3665/4999)\n",
      "False negative rate: 26.685% (1334/4999)\n",
      "True negative rate: 98.921% (62915/63601)\n",
      "False positive rate: 1.079% (686/63601)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 50/100: Loss: 0.0733 | Train Acc: 97.061% (67943/70000) | Strict Acc: 70.200% (3510/5000)\n",
      "True positive rate: 73.521% (3754/5106)\n",
      "False negative rate: 26.479% (1352/5106)\n",
      "True negative rate: 98.914% (64189/64894)\n",
      "False positive rate: 1.086% (705/64894)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 51/100: Loss: 0.0731 | Train Acc: 97.063% (69303/71400) | Strict Acc: 70.216% (3581/5100)\n",
      "True positive rate: 73.723% (3838/5206)\n",
      "False negative rate: 26.277% (1368/5206)\n",
      "True negative rate: 98.899% (65465/66194)\n",
      "False positive rate: 1.101% (729/66194)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 52/100: Loss: 0.0732 | Train Acc: 97.055% (70656/72800) | Strict Acc: 70.135% (3647/5200)\n",
      "True positive rate: 73.773% (3924/5319)\n",
      "False negative rate: 26.227% (1395/5319)\n",
      "True negative rate: 98.890% (66732/67481)\n",
      "False positive rate: 1.110% (749/67481)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 53/100: Loss: 0.0733 | Train Acc: 97.053% (72013/74200) | Strict Acc: 70.170% (3719/5300)\n",
      "True positive rate: 73.777% (3995/5415)\n",
      "False negative rate: 26.223% (1420/5415)\n",
      "True negative rate: 98.885% (68018/68785)\n",
      "False positive rate: 1.115% (767/68785)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 54/100: Loss: 0.0737 | Train Acc: 97.042% (73364/75600) | Strict Acc: 70.093% (3785/5400)\n",
      "True positive rate: 73.669% (4068/5522)\n",
      "False negative rate: 26.331% (1454/5522)\n",
      "True negative rate: 98.884% (69296/70078)\n",
      "False positive rate: 1.116% (782/70078)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 55/100: Loss: 0.0743 | Train Acc: 97.025% (74709/77000) | Strict Acc: 69.964% (3848/5500)\n",
      "True positive rate: 73.485% (4146/5642)\n",
      "False negative rate: 26.515% (1496/5642)\n",
      "True negative rate: 98.886% (70563/71358)\n",
      "False positive rate: 1.114% (795/71358)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 56/100: Loss: 0.0743 | Train Acc: 97.022% (76065/78400) | Strict Acc: 69.875% (3913/5600)\n",
      "True positive rate: 73.467% (4242/5774)\n",
      "False negative rate: 26.533% (1532/5774)\n",
      "True negative rate: 98.894% (71823/72626)\n",
      "False positive rate: 1.106% (803/72626)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 57/100: Loss: 0.0744 | Train Acc: 97.023% (77424/79800) | Strict Acc: 69.930% (3986/5700)\n",
      "True positive rate: 73.556% (4331/5888)\n",
      "False negative rate: 26.444% (1557/5888)\n",
      "True negative rate: 98.892% (73093/73912)\n",
      "False positive rate: 1.108% (819/73912)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 58/100: Loss: 0.0749 | Train Acc: 96.994% (78759/81200) | Strict Acc: 69.724% (4044/5800)\n",
      "True positive rate: 73.430% (4397/5988)\n",
      "False negative rate: 26.570% (1591/5988)\n",
      "True negative rate: 98.870% (74362/75212)\n",
      "False positive rate: 1.130% (850/75212)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 59/100: Loss: 0.0750 | Train Acc: 96.989% (80113/82600) | Strict Acc: 69.661% (4110/5900)\n",
      "True positive rate: 73.412% (4473/6093)\n",
      "False negative rate: 26.588% (1620/6093)\n",
      "True negative rate: 98.867% (75640/76507)\n",
      "False positive rate: 1.133% (867/76507)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 60/100: Loss: 0.0751 | Train Acc: 96.980% (81463/84000) | Strict Acc: 69.550% (4173/6000)\n",
      "True positive rate: 73.347% (4538/6187)\n",
      "False negative rate: 26.653% (1649/6187)\n",
      "True negative rate: 98.859% (76925/77813)\n",
      "False positive rate: 1.141% (888/77813)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 61/100: Loss: 0.0752 | Train Acc: 96.984% (82824/85400) | Strict Acc: 69.557% (4243/6100)\n",
      "True positive rate: 73.372% (4621/6298)\n",
      "False negative rate: 26.628% (1677/6298)\n",
      "True negative rate: 98.863% (78203/79102)\n",
      "False positive rate: 1.137% (899/79102)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 62/100: Loss: 0.0751 | Train Acc: 96.977% (84176/86800) | Strict Acc: 69.500% (4309/6200)\n",
      "True positive rate: 73.381% (4692/6394)\n",
      "False negative rate: 26.619% (1702/6394)\n",
      "True negative rate: 98.853% (79484/80406)\n",
      "False positive rate: 1.147% (922/80406)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 63/100: Loss: 0.0749 | Train Acc: 96.989% (85544/88200) | Strict Acc: 69.698% (4391/6300)\n",
      "True positive rate: 73.400% (4749/6470)\n",
      "False negative rate: 26.600% (1721/6470)\n",
      "True negative rate: 98.856% (80795/81730)\n",
      "False positive rate: 1.144% (935/81730)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 64/100: Loss: 0.0750 | Train Acc: 96.983% (86897/89600) | Strict Acc: 69.719% (4462/6400)\n",
      "True positive rate: 73.334% (4821/6574)\n",
      "False negative rate: 26.666% (1753/6574)\n",
      "True negative rate: 98.856% (82076/83026)\n",
      "False positive rate: 1.144% (950/83026)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 65/100: Loss: 0.0747 | Train Acc: 97.001% (88271/91000) | Strict Acc: 69.846% (4540/6500)\n",
      "True positive rate: 73.395% (4894/6668)\n",
      "False negative rate: 26.605% (1774/6668)\n",
      "True negative rate: 98.868% (83377/84332)\n",
      "False positive rate: 1.132% (955/84332)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 66/100: Loss: 0.0750 | Train Acc: 96.990% (89619/92400) | Strict Acc: 69.773% (4605/6600)\n",
      "True positive rate: 73.283% (4973/6786)\n",
      "False negative rate: 26.717% (1813/6786)\n",
      "True negative rate: 98.869% (84646/85614)\n",
      "False positive rate: 1.131% (968/85614)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 67/100: Loss: 0.0750 | Train Acc: 96.989% (90976/93800) | Strict Acc: 69.746% (4673/6700)\n",
      "True positive rate: 73.227% (5038/6880)\n",
      "False negative rate: 26.773% (1842/6880)\n",
      "True negative rate: 98.870% (85938/86920)\n",
      "False positive rate: 1.130% (982/86920)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 68/100: Loss: 0.0749 | Train Acc: 96.999% (92343/95200) | Strict Acc: 69.824% (4748/6800)\n",
      "True positive rate: 73.273% (5113/6978)\n",
      "False negative rate: 26.727% (1865/6978)\n",
      "True negative rate: 98.876% (87230/88222)\n",
      "False positive rate: 1.124% (992/88222)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 69/100: Loss: 0.0751 | Train Acc: 96.989% (93691/96600) | Strict Acc: 69.768% (4814/6900)\n",
      "True positive rate: 73.211% (5176/7070)\n",
      "False negative rate: 26.789% (1894/7070)\n",
      "True negative rate: 98.866% (88515/89530)\n",
      "False positive rate: 1.134% (1015/89530)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 70/100: Loss: 0.0754 | Train Acc: 96.976% (95036/98000) | Strict Acc: 69.657% (4876/7000)\n",
      "True positive rate: 73.150% (5250/7177)\n",
      "False negative rate: 26.850% (1927/7177)\n",
      "True negative rate: 98.858% (89786/90823)\n",
      "False positive rate: 1.142% (1037/90823)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 71/100: Loss: 0.0755 | Train Acc: 96.969% (96387/99400) | Strict Acc: 69.549% (4938/7100)\n",
      "True positive rate: 73.153% (5327/7282)\n",
      "False negative rate: 26.847% (1955/7282)\n",
      "True negative rate: 98.851% (91060/92118)\n",
      "False positive rate: 1.149% (1058/92118)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 72/100: Loss: 0.0755 | Train Acc: 96.970% (97746/100800) | Strict Acc: 69.500% (5004/7200)\n",
      "True positive rate: 73.246% (5396/7367)\n",
      "False negative rate: 26.754% (1971/7367)\n",
      "True negative rate: 98.841% (92350/93433)\n",
      "False positive rate: 1.159% (1083/93433)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 73/100: Loss: 0.0755 | Train Acc: 96.970% (99103/102200) | Strict Acc: 69.507% (5074/7300)\n",
      "True positive rate: 73.237% (5462/7458)\n",
      "False negative rate: 26.763% (1996/7458)\n",
      "True negative rate: 98.838% (93641/94742)\n",
      "False positive rate: 1.162% (1101/94742)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 74/100: Loss: 0.0758 | Train Acc: 96.955% (100445/103600) | Strict Acc: 69.446% (5139/7400)\n",
      "True positive rate: 73.181% (5542/7573)\n",
      "False negative rate: 26.819% (2031/7573)\n",
      "True negative rate: 98.829% (94903/96027)\n",
      "False positive rate: 1.171% (1124/96027)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 75/100: Loss: 0.0756 | Train Acc: 96.962% (101810/105000) | Strict Acc: 69.507% (5213/7500)\n",
      "True positive rate: 73.236% (5615/7667)\n",
      "False negative rate: 26.764% (2052/7667)\n",
      "True negative rate: 98.831% (96195/97333)\n",
      "False positive rate: 1.169% (1138/97333)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 76/100: Loss: 0.0755 | Train Acc: 96.971% (103177/106400) | Strict Acc: 69.566% (5287/7600)\n",
      "True positive rate: 73.252% (5688/7765)\n",
      "False negative rate: 26.748% (2077/7765)\n",
      "True negative rate: 98.838% (97489/98635)\n",
      "False positive rate: 1.162% (1146/98635)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 77/100: Loss: 0.0756 | Train Acc: 96.964% (104527/107800) | Strict Acc: 69.532% (5354/7700)\n",
      "True positive rate: 73.139% (5748/7859)\n",
      "False negative rate: 26.861% (2111/7859)\n",
      "True negative rate: 98.837% (98779/99941)\n",
      "False positive rate: 1.163% (1162/99941)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 78/100: Loss: 0.0756 | Train Acc: 96.966% (105887/109200) | Strict Acc: 69.590% (5428/7800)\n",
      "True positive rate: 73.117% (5823/7964)\n",
      "False negative rate: 26.883% (2141/7964)\n",
      "True negative rate: 98.842% (100064/101236)\n",
      "False positive rate: 1.158% (1172/101236)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 79/100: Loss: 0.0752 | Train Acc: 96.985% (107265/110600) | Strict Acc: 69.759% (5511/7900)\n",
      "True positive rate: 73.310% (5900/8048)\n",
      "False negative rate: 26.690% (2148/8048)\n",
      "True negative rate: 98.843% (101365/102552)\n",
      "False positive rate: 1.157% (1187/102552)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 80/100: Loss: 0.0754 | Train Acc: 96.971% (108607/112000) | Strict Acc: 69.713% (5577/8000)\n",
      "True positive rate: 73.153% (5951/8135)\n",
      "False negative rate: 26.847% (2184/8135)\n",
      "True negative rate: 98.836% (102656/103865)\n",
      "False positive rate: 1.164% (1209/103865)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 81/100: Loss: 0.0753 | Train Acc: 96.966% (109959/113400) | Strict Acc: 69.728% (5648/8100)\n",
      "True positive rate: 73.085% (6020/8237)\n",
      "False negative rate: 26.915% (2217/8237)\n",
      "True negative rate: 98.836% (103939/105163)\n",
      "False positive rate: 1.164% (1224/105163)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 82/100: Loss: 0.0755 | Train Acc: 96.958% (111308/114800) | Strict Acc: 69.671% (5713/8200)\n",
      "True positive rate: 72.987% (6082/8333)\n",
      "False negative rate: 27.013% (2251/8333)\n",
      "True negative rate: 98.834% (105226/106467)\n",
      "False positive rate: 1.166% (1241/106467)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 83/100: Loss: 0.0756 | Train Acc: 96.945% (112650/116200) | Strict Acc: 69.602% (5777/8300)\n",
      "True positive rate: 72.957% (6159/8442)\n",
      "False negative rate: 27.043% (2283/8442)\n",
      "True negative rate: 98.824% (106491/107758)\n",
      "False positive rate: 1.176% (1267/107758)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 84/100: Loss: 0.0754 | Train Acc: 96.952% (114015/117600) | Strict Acc: 69.643% (5850/8400)\n",
      "True positive rate: 73.066% (6242/8543)\n",
      "False negative rate: 26.934% (2301/8543)\n",
      "True negative rate: 98.823% (107773/109057)\n",
      "False positive rate: 1.177% (1284/109057)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 85/100: Loss: 0.0756 | Train Acc: 96.946% (115366/119000) | Strict Acc: 69.588% (5915/8500)\n",
      "True positive rate: 73.038% (6328/8664)\n",
      "False negative rate: 26.962% (2336/8664)\n",
      "True negative rate: 98.824% (109038/110336)\n",
      "False positive rate: 1.176% (1298/110336)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 86/100: Loss: 0.0755 | Train Acc: 96.949% (116726/120400) | Strict Acc: 69.616% (5987/8600)\n",
      "True positive rate: 73.097% (6415/8776)\n",
      "False negative rate: 26.903% (2361/8776)\n",
      "True negative rate: 98.824% (110311/111624)\n",
      "False positive rate: 1.176% (1313/111624)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 87/100: Loss: 0.0757 | Train Acc: 96.941% (118074/121800) | Strict Acc: 69.529% (6049/8700)\n",
      "True positive rate: 73.066% (6497/8892)\n",
      "False negative rate: 26.934% (2395/8892)\n",
      "True negative rate: 98.821% (111577/112908)\n",
      "False positive rate: 1.179% (1331/112908)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 88/100: Loss: 0.0758 | Train Acc: 96.932% (119420/123200) | Strict Acc: 69.489% (6115/8800)\n",
      "True positive rate: 73.032% (6559/8981)\n",
      "False negative rate: 26.968% (2422/8981)\n",
      "True negative rate: 98.811% (112861/114219)\n",
      "False positive rate: 1.189% (1358/114219)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 89/100: Loss: 0.0758 | Train Acc: 96.933% (120779/124600) | Strict Acc: 69.494% (6185/8900)\n",
      "True positive rate: 73.053% (6631/9077)\n",
      "False negative rate: 26.947% (2446/9077)\n",
      "True negative rate: 98.810% (114148/115523)\n",
      "False positive rate: 1.190% (1375/115523)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 90/100: Loss: 0.0757 | Train Acc: 96.934% (122137/126000) | Strict Acc: 69.467% (6252/9000)\n",
      "True positive rate: 73.102% (6702/9168)\n",
      "False negative rate: 26.898% (2466/9168)\n",
      "True negative rate: 98.804% (115435/116832)\n",
      "False positive rate: 1.196% (1397/116832)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 91/100: Loss: 0.0756 | Train Acc: 96.945% (123508/127400) | Strict Acc: 69.527% (6327/9100)\n",
      "True positive rate: 73.131% (6769/9256)\n",
      "False negative rate: 26.869% (2487/9256)\n",
      "True negative rate: 98.811% (116739/118144)\n",
      "False positive rate: 1.189% (1405/118144)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 92/100: Loss: 0.0758 | Train Acc: 96.933% (124850/128800) | Strict Acc: 69.478% (6392/9200)\n",
      "True positive rate: 72.983% (6840/9372)\n",
      "False negative rate: 27.017% (2532/9372)\n",
      "True negative rate: 98.813% (118010/119428)\n",
      "False positive rate: 1.187% (1418/119428)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 93/100: Loss: 0.0757 | Train Acc: 96.939% (126215/130200) | Strict Acc: 69.548% (6468/9300)\n",
      "True positive rate: 72.970% (6911/9471)\n",
      "False negative rate: 27.030% (2560/9471)\n",
      "True negative rate: 98.820% (119304/120729)\n",
      "False positive rate: 1.180% (1425/120729)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 94/100: Loss: 0.0757 | Train Acc: 96.937% (127569/131600) | Strict Acc: 69.500% (6533/9400)\n",
      "True positive rate: 72.866% (6966/9560)\n",
      "False negative rate: 27.134% (2594/9560)\n",
      "True negative rate: 98.823% (120603/122040)\n",
      "False positive rate: 1.177% (1437/122040)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 95/100: Loss: 0.0758 | Train Acc: 96.931% (128918/133000) | Strict Acc: 69.432% (6596/9500)\n",
      "True positive rate: 72.832% (7045/9673)\n",
      "False negative rate: 27.168% (2628/9673)\n",
      "True negative rate: 98.821% (121873/123327)\n",
      "False positive rate: 1.179% (1454/123327)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 96/100: Loss: 0.0756 | Train Acc: 96.943% (130291/134400) | Strict Acc: 69.521% (6674/9600)\n",
      "True positive rate: 72.876% (7104/9748)\n",
      "False negative rate: 27.124% (2644/9748)\n",
      "True negative rate: 98.825% (123187/124652)\n",
      "False positive rate: 1.175% (1465/124652)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 97/100: Loss: 0.0757 | Train Acc: 96.941% (131646/135800) | Strict Acc: 69.515% (6743/9700)\n",
      "True positive rate: 72.898% (7187/9859)\n",
      "False negative rate: 27.102% (2672/9859)\n",
      "True negative rate: 98.823% (124459/125941)\n",
      "False positive rate: 1.177% (1482/125941)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 98/100: Loss: 0.0758 | Train Acc: 96.940% (133002/137200) | Strict Acc: 69.510% (6812/9800)\n",
      "True positive rate: 72.905% (7265/9965)\n",
      "False negative rate: 27.095% (2700/9965)\n",
      "True negative rate: 98.823% (125737/127235)\n",
      "False positive rate: 1.177% (1498/127235)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 99/100: Loss: 0.0757 | Train Acc: 96.945% (134366/138600) | Strict Acc: 69.556% (6886/9900)\n",
      "True positive rate: 72.924% (7331/10053)\n",
      "False negative rate: 27.076% (2722/10053)\n",
      "True negative rate: 98.824% (127035/128547)\n",
      "False positive rate: 1.176% (1512/128547)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 8 - Batch 100/100: Loss: 0.0759 | Train Acc: 96.942% (134498/138740) | Strict Acc: 69.536% (6891/9910)\n",
      "True positive rate: 72.921% (7338/10063)\n",
      "False negative rate: 27.079% (2725/10063)\n",
      "True negative rate: 98.821% (127160/128677)\n",
      "False positive rate: 1.179% (1517/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1133 | Dev Acc: 95.840% (68027/70980) | Strict Acc: 61.972% (3142/5070)\n",
      "True positive rate: 64.040% (3300/5153)\n",
      "False negative rate: 35.960% (1853/5153)\n",
      "True negative rate: 98.329% (64727/65827)\n",
      "False positive rate: 1.671% (1100/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 1/100: Loss: 0.0647 | Train Acc: 97.429% (1364/1400) | Strict Acc: 73.000% (73/100)\n",
      "True positive rate: 80.000% (84/105)\n",
      "False negative rate: 20.000% (21/105)\n",
      "True negative rate: 98.842% (1280/1295)\n",
      "False positive rate: 1.158% (15/1295)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 2/100: Loss: 0.0628 | Train Acc: 97.429% (2728/2800) | Strict Acc: 72.500% (145/200)\n",
      "True positive rate: 76.650% (151/197)\n",
      "False negative rate: 23.350% (46/197)\n",
      "True negative rate: 99.001% (2577/2603)\n",
      "False positive rate: 0.999% (26/2603)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 3/100: Loss: 0.0687 | Train Acc: 97.214% (4083/4200) | Strict Acc: 71.667% (215/300)\n",
      "True positive rate: 72.848% (220/302)\n",
      "False negative rate: 27.152% (82/302)\n",
      "True negative rate: 99.102% (3863/3898)\n",
      "False positive rate: 0.898% (35/3898)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 4/100: Loss: 0.0746 | Train Acc: 97.018% (5433/5600) | Strict Acc: 70.000% (280/400)\n",
      "True positive rate: 70.913% (295/416)\n",
      "False negative rate: 29.087% (121/416)\n",
      "True negative rate: 99.113% (5138/5184)\n",
      "False positive rate: 0.887% (46/5184)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 5/100: Loss: 0.0696 | Train Acc: 97.243% (6807/7000) | Strict Acc: 71.800% (359/500)\n",
      "True positive rate: 72.763% (366/503)\n",
      "False negative rate: 27.237% (137/503)\n",
      "True negative rate: 99.138% (6441/6497)\n",
      "False positive rate: 0.862% (56/6497)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 6/100: Loss: 0.0711 | Train Acc: 97.143% (8160/8400) | Strict Acc: 70.167% (421/600)\n",
      "True positive rate: 72.828% (461/633)\n",
      "False negative rate: 27.172% (172/633)\n",
      "True negative rate: 99.125% (7699/7767)\n",
      "False positive rate: 0.875% (68/7767)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 7/100: Loss: 0.0731 | Train Acc: 97.041% (9510/9800) | Strict Acc: 69.000% (483/700)\n",
      "True positive rate: 72.124% (533/739)\n",
      "False negative rate: 27.876% (206/739)\n",
      "True negative rate: 99.073% (8977/9061)\n",
      "False positive rate: 0.927% (84/9061)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 8/100: Loss: 0.0734 | Train Acc: 97.027% (10867/11200) | Strict Acc: 69.000% (552/800)\n",
      "True positive rate: 72.176% (607/841)\n",
      "False negative rate: 27.824% (234/841)\n",
      "True negative rate: 99.044% (10260/10359)\n",
      "False positive rate: 0.956% (99/10359)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 9/100: Loss: 0.0758 | Train Acc: 96.968% (12218/12600) | Strict Acc: 68.556% (617/900)\n",
      "True positive rate: 72.545% (687/947)\n",
      "False negative rate: 27.455% (260/947)\n",
      "True negative rate: 98.953% (11531/11653)\n",
      "False positive rate: 1.047% (122/11653)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 10/100: Loss: 0.0768 | Train Acc: 96.964% (13575/14000) | Strict Acc: 68.500% (685/1000)\n",
      "True positive rate: 73.051% (759/1039)\n",
      "False negative rate: 26.949% (280/1039)\n",
      "True negative rate: 98.881% (12816/12961)\n",
      "False positive rate: 1.119% (145/12961)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 11/100: Loss: 0.0776 | Train Acc: 96.922% (14926/15400) | Strict Acc: 68.091% (749/1100)\n",
      "True positive rate: 73.310% (835/1139)\n",
      "False negative rate: 26.690% (304/1139)\n",
      "True negative rate: 98.808% (14091/14261)\n",
      "False positive rate: 1.192% (170/14261)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 12/100: Loss: 0.0773 | Train Acc: 96.917% (16282/16800) | Strict Acc: 68.000% (816/1200)\n",
      "True positive rate: 73.548% (912/1240)\n",
      "False negative rate: 26.452% (328/1240)\n",
      "True negative rate: 98.779% (15370/15560)\n",
      "False positive rate: 1.221% (190/15560)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 13/100: Loss: 0.0767 | Train Acc: 96.934% (17642/18200) | Strict Acc: 68.308% (888/1300)\n",
      "True positive rate: 73.735% (991/1344)\n",
      "False negative rate: 26.265% (353/1344)\n",
      "True negative rate: 98.784% (16651/16856)\n",
      "False positive rate: 1.216% (205/16856)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 14/100: Loss: 0.0770 | Train Acc: 96.954% (19003/19600) | Strict Acc: 68.643% (961/1400)\n",
      "True positive rate: 73.659% (1071/1454)\n",
      "False negative rate: 26.341% (383/1454)\n",
      "True negative rate: 98.821% (17932/18146)\n",
      "False positive rate: 1.179% (214/18146)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 15/100: Loss: 0.0767 | Train Acc: 96.962% (20362/21000) | Strict Acc: 68.867% (1033/1500)\n",
      "True positive rate: 73.171% (1140/1558)\n",
      "False negative rate: 26.829% (418/1558)\n",
      "True negative rate: 98.868% (19222/19442)\n",
      "False positive rate: 1.132% (220/19442)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 16/100: Loss: 0.0772 | Train Acc: 96.969% (21721/22400) | Strict Acc: 69.000% (1104/1600)\n",
      "True positive rate: 72.973% (1215/1665)\n",
      "False negative rate: 27.027% (450/1665)\n",
      "True negative rate: 98.896% (20506/20735)\n",
      "False positive rate: 1.104% (229/20735)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 17/100: Loss: 0.0762 | Train Acc: 97.008% (23088/23800) | Strict Acc: 69.294% (1178/1700)\n",
      "True positive rate: 73.016% (1288/1764)\n",
      "False negative rate: 26.984% (476/1764)\n",
      "True negative rate: 98.929% (21800/22036)\n",
      "False positive rate: 1.071% (236/22036)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 18/100: Loss: 0.0756 | Train Acc: 97.040% (24454/25200) | Strict Acc: 69.667% (1254/1800)\n",
      "True positive rate: 73.566% (1372/1865)\n",
      "False negative rate: 26.434% (493/1865)\n",
      "True negative rate: 98.916% (23082/23335)\n",
      "False positive rate: 1.084% (253/23335)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 19/100: Loss: 0.0746 | Train Acc: 97.090% (25826/26600) | Strict Acc: 70.000% (1330/1900)\n",
      "True positive rate: 73.993% (1451/1961)\n",
      "False negative rate: 26.007% (510/1961)\n",
      "True negative rate: 98.929% (24375/24639)\n",
      "False positive rate: 1.071% (264/24639)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 20/100: Loss: 0.0743 | Train Acc: 97.075% (27181/28000) | Strict Acc: 70.050% (1401/2000)\n",
      "True positive rate: 73.892% (1517/2053)\n",
      "False negative rate: 26.108% (536/2053)\n",
      "True negative rate: 98.909% (25664/25947)\n",
      "False positive rate: 1.091% (283/25947)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 21/100: Loss: 0.0741 | Train Acc: 97.082% (28542/29400) | Strict Acc: 70.095% (1472/2100)\n",
      "True positive rate: 74.138% (1591/2146)\n",
      "False negative rate: 25.862% (555/2146)\n",
      "True negative rate: 98.888% (26951/27254)\n",
      "False positive rate: 1.112% (303/27254)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 22/100: Loss: 0.0739 | Train Acc: 97.091% (29904/30800) | Strict Acc: 70.273% (1546/2200)\n",
      "True positive rate: 74.039% (1657/2238)\n",
      "False negative rate: 25.961% (581/2238)\n",
      "True negative rate: 98.897% (28247/28562)\n",
      "False positive rate: 1.103% (315/28562)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 23/100: Loss: 0.0742 | Train Acc: 97.081% (31260/32200) | Strict Acc: 70.304% (1617/2300)\n",
      "True positive rate: 73.883% (1737/2351)\n",
      "False negative rate: 26.117% (614/2351)\n",
      "True negative rate: 98.908% (29523/29849)\n",
      "False positive rate: 1.092% (326/29849)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 24/100: Loss: 0.0738 | Train Acc: 97.092% (32623/33600) | Strict Acc: 70.417% (1690/2400)\n",
      "True positive rate: 74.076% (1823/2461)\n",
      "False negative rate: 25.924% (638/2461)\n",
      "True negative rate: 98.911% (30800/31139)\n",
      "False positive rate: 1.089% (339/31139)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 25/100: Loss: 0.0737 | Train Acc: 97.100% (33985/35000) | Strict Acc: 70.440% (1761/2500)\n",
      "True positive rate: 74.299% (1908/2568)\n",
      "False negative rate: 25.701% (660/2568)\n",
      "True negative rate: 98.905% (32077/32432)\n",
      "False positive rate: 1.095% (355/32432)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 26/100: Loss: 0.0731 | Train Acc: 97.104% (35346/36400) | Strict Acc: 70.577% (1835/2600)\n",
      "True positive rate: 74.439% (1992/2676)\n",
      "False negative rate: 25.561% (684/2676)\n",
      "True negative rate: 98.903% (33354/33724)\n",
      "False positive rate: 1.097% (370/33724)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 27/100: Loss: 0.0729 | Train Acc: 97.130% (36715/37800) | Strict Acc: 70.741% (1910/2700)\n",
      "True positive rate: 74.802% (2078/2778)\n",
      "False negative rate: 25.198% (700/2778)\n",
      "True negative rate: 98.901% (34637/35022)\n",
      "False positive rate: 1.099% (385/35022)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 28/100: Loss: 0.0722 | Train Acc: 97.151% (38083/39200) | Strict Acc: 70.857% (1984/2800)\n",
      "True positive rate: 75.061% (2158/2875)\n",
      "False negative rate: 24.939% (717/2875)\n",
      "True negative rate: 98.899% (35925/36325)\n",
      "False positive rate: 1.101% (400/36325)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 29/100: Loss: 0.0720 | Train Acc: 97.160% (39447/40600) | Strict Acc: 70.862% (2055/2900)\n",
      "True positive rate: 75.042% (2231/2973)\n",
      "False negative rate: 24.958% (742/2973)\n",
      "True negative rate: 98.908% (37216/37627)\n",
      "False positive rate: 1.092% (411/37627)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 30/100: Loss: 0.0712 | Train Acc: 97.193% (40821/42000) | Strict Acc: 71.100% (2133/3000)\n",
      "True positive rate: 75.350% (2317/3075)\n",
      "False negative rate: 24.650% (758/3075)\n",
      "True negative rate: 98.918% (38504/38925)\n",
      "False positive rate: 1.082% (421/38925)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 31/100: Loss: 0.0710 | Train Acc: 97.200% (42185/43400) | Strict Acc: 71.194% (2207/3100)\n",
      "True positive rate: 75.402% (2394/3175)\n",
      "False negative rate: 24.598% (781/3175)\n",
      "True negative rate: 98.921% (39791/40225)\n",
      "False positive rate: 1.079% (434/40225)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 32/100: Loss: 0.0712 | Train Acc: 97.192% (43542/44800) | Strict Acc: 71.062% (2274/3200)\n",
      "True positive rate: 75.114% (2466/3283)\n",
      "False negative rate: 24.886% (817/3283)\n",
      "True negative rate: 98.938% (41076/41517)\n",
      "False positive rate: 1.062% (441/41517)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 33/100: Loss: 0.0709 | Train Acc: 97.199% (44906/46200) | Strict Acc: 71.091% (2346/3300)\n",
      "True positive rate: 75.089% (2529/3368)\n",
      "False negative rate: 24.911% (839/3368)\n",
      "True negative rate: 98.938% (42377/42832)\n",
      "False positive rate: 1.062% (455/42832)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 34/100: Loss: 0.0709 | Train Acc: 97.189% (46262/47600) | Strict Acc: 71.088% (2417/3400)\n",
      "True positive rate: 75.129% (2622/3490)\n",
      "False negative rate: 24.871% (868/3490)\n",
      "True negative rate: 98.934% (43640/44110)\n",
      "False positive rate: 1.066% (470/44110)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 35/100: Loss: 0.0711 | Train Acc: 97.186% (47621/49000) | Strict Acc: 70.943% (2483/3500)\n",
      "True positive rate: 75.056% (2690/3584)\n",
      "False negative rate: 24.944% (894/3584)\n",
      "True negative rate: 98.932% (44931/45416)\n",
      "False positive rate: 1.068% (485/45416)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 36/100: Loss: 0.0714 | Train Acc: 97.171% (48974/50400) | Strict Acc: 70.889% (2552/3600)\n",
      "True positive rate: 75.203% (2778/3694)\n",
      "False negative rate: 24.797% (916/3694)\n",
      "True negative rate: 98.908% (46196/46706)\n",
      "False positive rate: 1.092% (510/46706)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 37/100: Loss: 0.0712 | Train Acc: 97.176% (50337/51800) | Strict Acc: 70.919% (2624/3700)\n",
      "True positive rate: 75.245% (2845/3781)\n",
      "False negative rate: 24.755% (936/3781)\n",
      "True negative rate: 98.903% (47492/48019)\n",
      "False positive rate: 1.097% (527/48019)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 38/100: Loss: 0.0712 | Train Acc: 97.177% (51698/53200) | Strict Acc: 70.868% (2693/3800)\n",
      "True positive rate: 75.270% (2922/3882)\n",
      "False negative rate: 24.730% (960/3882)\n",
      "True negative rate: 98.901% (48776/49318)\n",
      "False positive rate: 1.099% (542/49318)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 39/100: Loss: 0.0712 | Train Acc: 97.187% (53064/54600) | Strict Acc: 70.949% (2767/3900)\n",
      "True positive rate: 75.265% (2985/3966)\n",
      "False negative rate: 24.735% (981/3966)\n",
      "True negative rate: 98.904% (50079/50634)\n",
      "False positive rate: 1.096% (555/50634)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 40/100: Loss: 0.0712 | Train Acc: 97.193% (54428/56000) | Strict Acc: 71.025% (2841/4000)\n",
      "True positive rate: 75.288% (3074/4083)\n",
      "False negative rate: 24.712% (1009/4083)\n",
      "True negative rate: 98.916% (51354/51917)\n",
      "False positive rate: 1.084% (563/51917)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 41/100: Loss: 0.0711 | Train Acc: 97.190% (55787/57400) | Strict Acc: 70.927% (2908/4100)\n",
      "True positive rate: 75.262% (3155/4192)\n",
      "False negative rate: 24.738% (1037/4192)\n",
      "True negative rate: 98.917% (52632/53208)\n",
      "False positive rate: 1.083% (576/53208)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 42/100: Loss: 0.0708 | Train Acc: 97.197% (57152/58800) | Strict Acc: 70.929% (2979/4200)\n",
      "True positive rate: 75.210% (3219/4280)\n",
      "False negative rate: 24.790% (1061/4280)\n",
      "True negative rate: 98.923% (53933/54520)\n",
      "False positive rate: 1.077% (587/54520)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 43/100: Loss: 0.0709 | Train Acc: 97.181% (58503/60200) | Strict Acc: 70.953% (3051/4300)\n",
      "True positive rate: 75.068% (3291/4384)\n",
      "False negative rate: 24.932% (1093/4384)\n",
      "True negative rate: 98.918% (55212/55816)\n",
      "False positive rate: 1.082% (604/55816)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 44/100: Loss: 0.0707 | Train Acc: 97.190% (59869/61600) | Strict Acc: 71.000% (3124/4400)\n",
      "True positive rate: 75.039% (3361/4479)\n",
      "False negative rate: 24.961% (1118/4479)\n",
      "True negative rate: 98.927% (56508/57121)\n",
      "False positive rate: 1.073% (613/57121)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 45/100: Loss: 0.0707 | Train Acc: 97.205% (61239/63000) | Strict Acc: 71.156% (3202/4500)\n",
      "True positive rate: 75.185% (3451/4590)\n",
      "False negative rate: 24.815% (1139/4590)\n",
      "True negative rate: 98.935% (57788/58410)\n",
      "False positive rate: 1.065% (622/58410)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 46/100: Loss: 0.0708 | Train Acc: 97.200% (62597/64400) | Strict Acc: 71.261% (3278/4600)\n",
      "True positive rate: 75.272% (3531/4691)\n",
      "False negative rate: 24.728% (1160/4691)\n",
      "True negative rate: 98.923% (59066/59709)\n",
      "False positive rate: 1.077% (643/59709)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 47/100: Loss: 0.0706 | Train Acc: 97.210% (63964/65800) | Strict Acc: 71.362% (3354/4700)\n",
      "True positive rate: 75.272% (3601/4784)\n",
      "False negative rate: 24.728% (1183/4784)\n",
      "True negative rate: 98.930% (60363/61016)\n",
      "False positive rate: 1.070% (653/61016)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 48/100: Loss: 0.0711 | Train Acc: 97.174% (65301/67200) | Strict Acc: 71.125% (3414/4800)\n",
      "True positive rate: 74.868% (3676/4910)\n",
      "False negative rate: 25.132% (1234/4910)\n",
      "True negative rate: 98.932% (61625/62290)\n",
      "False positive rate: 1.068% (665/62290)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 49/100: Loss: 0.0711 | Train Acc: 97.176% (66663/68600) | Strict Acc: 71.204% (3489/4900)\n",
      "True positive rate: 74.865% (3747/5005)\n",
      "False negative rate: 25.135% (1258/5005)\n",
      "True negative rate: 98.932% (62916/63595)\n",
      "False positive rate: 1.068% (679/63595)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 50/100: Loss: 0.0708 | Train Acc: 97.181% (68027/70000) | Strict Acc: 71.260% (3563/5000)\n",
      "True positive rate: 74.936% (3821/5099)\n",
      "False negative rate: 25.064% (1278/5099)\n",
      "True negative rate: 98.929% (64206/64901)\n",
      "False positive rate: 1.071% (695/64901)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 51/100: Loss: 0.0712 | Train Acc: 97.169% (69379/71400) | Strict Acc: 71.157% (3629/5100)\n",
      "True positive rate: 74.904% (3886/5188)\n",
      "False negative rate: 25.096% (1302/5188)\n",
      "True negative rate: 98.914% (65493/66212)\n",
      "False positive rate: 1.086% (719/66212)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 52/100: Loss: 0.0712 | Train Acc: 97.162% (70734/72800) | Strict Acc: 71.154% (3700/5200)\n",
      "True positive rate: 74.868% (3962/5292)\n",
      "False negative rate: 25.132% (1330/5292)\n",
      "True negative rate: 98.910% (66772/67508)\n",
      "False positive rate: 1.090% (736/67508)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 53/100: Loss: 0.0711 | Train Acc: 97.167% (72098/74200) | Strict Acc: 71.151% (3771/5300)\n",
      "True positive rate: 74.995% (4049/5399)\n",
      "False negative rate: 25.005% (1350/5399)\n",
      "True negative rate: 98.907% (68049/68801)\n",
      "False positive rate: 1.093% (752/68801)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 54/100: Loss: 0.0711 | Train Acc: 97.168% (73459/75600) | Strict Acc: 71.056% (3837/5400)\n",
      "True positive rate: 75.204% (4140/5505)\n",
      "False negative rate: 24.796% (1365/5505)\n",
      "True negative rate: 98.893% (69319/70095)\n",
      "False positive rate: 1.107% (776/70095)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 55/100: Loss: 0.0709 | Train Acc: 97.171% (74822/77000) | Strict Acc: 71.073% (3909/5500)\n",
      "True positive rate: 75.277% (4214/5598)\n",
      "False negative rate: 24.723% (1384/5598)\n",
      "True negative rate: 98.888% (70608/71402)\n",
      "False positive rate: 1.112% (794/71402)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 56/100: Loss: 0.0708 | Train Acc: 97.180% (76189/78400) | Strict Acc: 71.179% (3986/5600)\n",
      "True positive rate: 75.360% (4297/5702)\n",
      "False negative rate: 24.640% (1405/5702)\n",
      "True negative rate: 98.891% (71892/72698)\n",
      "False positive rate: 1.109% (806/72698)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 57/100: Loss: 0.0709 | Train Acc: 97.170% (77542/79800) | Strict Acc: 71.105% (4053/5700)\n",
      "True positive rate: 75.280% (4367/5801)\n",
      "False negative rate: 24.720% (1434/5801)\n",
      "True negative rate: 98.886% (73175/73999)\n",
      "False positive rate: 1.114% (824/73999)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 58/100: Loss: 0.0706 | Train Acc: 97.176% (78907/81200) | Strict Acc: 71.155% (4127/5800)\n",
      "True positive rate: 75.284% (4447/5907)\n",
      "False negative rate: 24.716% (1460/5907)\n",
      "True negative rate: 98.894% (74460/75293)\n",
      "False positive rate: 1.106% (833/75293)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 59/100: Loss: 0.0705 | Train Acc: 97.183% (80273/82600) | Strict Acc: 71.203% (4201/5900)\n",
      "True positive rate: 75.295% (4535/6023)\n",
      "False negative rate: 24.705% (1488/6023)\n",
      "True negative rate: 98.904% (75738/76577)\n",
      "False positive rate: 1.096% (839/76577)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 60/100: Loss: 0.0706 | Train Acc: 97.182% (81633/84000) | Strict Acc: 71.167% (4270/6000)\n",
      "True positive rate: 75.290% (4607/6119)\n",
      "False negative rate: 24.710% (1512/6119)\n",
      "True negative rate: 98.902% (77026/77881)\n",
      "False positive rate: 1.098% (855/77881)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 61/100: Loss: 0.0707 | Train Acc: 97.177% (82989/85400) | Strict Acc: 71.164% (4341/6100)\n",
      "True positive rate: 75.325% (4689/6225)\n",
      "False negative rate: 24.675% (1536/6225)\n",
      "True negative rate: 98.895% (78300/79175)\n",
      "False positive rate: 1.105% (875/79175)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 62/100: Loss: 0.0706 | Train Acc: 97.182% (84354/86800) | Strict Acc: 71.177% (4413/6200)\n",
      "True positive rate: 75.434% (4778/6334)\n",
      "False negative rate: 24.566% (1556/6334)\n",
      "True negative rate: 98.894% (79576/80466)\n",
      "False positive rate: 1.106% (890/80466)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 63/100: Loss: 0.0704 | Train Acc: 97.180% (85713/88200) | Strict Acc: 71.143% (4482/6300)\n",
      "True positive rate: 75.451% (4847/6424)\n",
      "False negative rate: 24.549% (1577/6424)\n",
      "True negative rate: 98.887% (80866/81776)\n",
      "False positive rate: 1.113% (910/81776)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 64/100: Loss: 0.0706 | Train Acc: 97.170% (87064/89600) | Strict Acc: 71.031% (4546/6400)\n",
      "True positive rate: 75.386% (4925/6533)\n",
      "False negative rate: 24.614% (1608/6533)\n",
      "True negative rate: 98.883% (82139/83067)\n",
      "False positive rate: 1.117% (928/83067)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 65/100: Loss: 0.0704 | Train Acc: 97.177% (88431/91000) | Strict Acc: 71.092% (4621/6500)\n",
      "True positive rate: 75.465% (4995/6619)\n",
      "False negative rate: 24.535% (1624/6619)\n",
      "True negative rate: 98.880% (83436/84381)\n",
      "False positive rate: 1.120% (945/84381)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 66/100: Loss: 0.0704 | Train Acc: 97.177% (89792/92400) | Strict Acc: 71.061% (4690/6600)\n",
      "True positive rate: 75.453% (5081/6734)\n",
      "False negative rate: 24.547% (1653/6734)\n",
      "True negative rate: 98.885% (84711/85666)\n",
      "False positive rate: 1.115% (955/85666)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 67/100: Loss: 0.0703 | Train Acc: 97.178% (91153/93800) | Strict Acc: 71.060% (4761/6700)\n",
      "True positive rate: 75.552% (5167/6839)\n",
      "False negative rate: 24.448% (1672/6839)\n",
      "True negative rate: 98.879% (85986/86961)\n",
      "False positive rate: 1.121% (975/86961)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 68/100: Loss: 0.0703 | Train Acc: 97.181% (92516/95200) | Strict Acc: 71.074% (4833/6800)\n",
      "True positive rate: 75.579% (5258/6957)\n",
      "False negative rate: 24.421% (1699/6957)\n",
      "True negative rate: 98.884% (87258/88243)\n",
      "False positive rate: 1.116% (985/88243)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 69/100: Loss: 0.0701 | Train Acc: 97.192% (93887/96600) | Strict Acc: 71.203% (4913/6900)\n",
      "True positive rate: 75.646% (5330/7046)\n",
      "False negative rate: 24.354% (1716/7046)\n",
      "True negative rate: 98.887% (88557/89554)\n",
      "False positive rate: 1.113% (997/89554)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 70/100: Loss: 0.0703 | Train Acc: 97.179% (95235/98000) | Strict Acc: 71.143% (4980/7000)\n",
      "True positive rate: 75.550% (5392/7137)\n",
      "False negative rate: 24.450% (1745/7137)\n",
      "True negative rate: 98.877% (89843/90863)\n",
      "False positive rate: 1.123% (1020/90863)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 71/100: Loss: 0.0701 | Train Acc: 97.190% (96607/99400) | Strict Acc: 71.282% (5061/7100)\n",
      "True positive rate: 75.653% (5478/7241)\n",
      "False negative rate: 24.347% (1763/7241)\n",
      "True negative rate: 98.882% (91129/92159)\n",
      "False positive rate: 1.118% (1030/92159)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 72/100: Loss: 0.0702 | Train Acc: 97.190% (97968/100800) | Strict Acc: 71.292% (5133/7200)\n",
      "True positive rate: 75.647% (5557/7346)\n",
      "False negative rate: 24.353% (1789/7346)\n",
      "True negative rate: 98.884% (92411/93454)\n",
      "False positive rate: 1.116% (1043/93454)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 73/100: Loss: 0.0703 | Train Acc: 97.184% (99322/102200) | Strict Acc: 71.247% (5201/7300)\n",
      "True positive rate: 75.624% (5634/7450)\n",
      "False negative rate: 24.376% (1816/7450)\n",
      "True negative rate: 98.879% (93688/94750)\n",
      "False positive rate: 1.121% (1062/94750)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 74/100: Loss: 0.0702 | Train Acc: 97.190% (100689/103600) | Strict Acc: 71.311% (5277/7400)\n",
      "True positive rate: 75.666% (5712/7549)\n",
      "False negative rate: 24.334% (1837/7549)\n",
      "True negative rate: 98.882% (94977/96051)\n",
      "False positive rate: 1.118% (1074/96051)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 75/100: Loss: 0.0700 | Train Acc: 97.197% (102057/105000) | Strict Acc: 71.320% (5349/7500)\n",
      "True positive rate: 75.735% (5799/7657)\n",
      "False negative rate: 24.265% (1858/7657)\n",
      "True negative rate: 98.885% (96258/97343)\n",
      "False positive rate: 1.115% (1085/97343)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 76/100: Loss: 0.0700 | Train Acc: 97.198% (103419/106400) | Strict Acc: 71.342% (5422/7600)\n",
      "True positive rate: 75.788% (5888/7769)\n",
      "False negative rate: 24.212% (1881/7769)\n",
      "True negative rate: 98.885% (97531/98631)\n",
      "False positive rate: 1.115% (1100/98631)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 77/100: Loss: 0.0702 | Train Acc: 97.182% (104762/107800) | Strict Acc: 71.195% (5482/7700)\n",
      "True positive rate: 75.770% (5957/7862)\n",
      "False negative rate: 24.230% (1905/7862)\n",
      "True negative rate: 98.866% (98805/99938)\n",
      "False positive rate: 1.134% (1133/99938)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 78/100: Loss: 0.0701 | Train Acc: 97.185% (106126/109200) | Strict Acc: 71.218% (5555/7800)\n",
      "True positive rate: 75.805% (6028/7952)\n",
      "False negative rate: 24.195% (1924/7952)\n",
      "True negative rate: 98.864% (100098/101248)\n",
      "False positive rate: 1.136% (1150/101248)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 79/100: Loss: 0.0702 | Train Acc: 97.173% (107473/110600) | Strict Acc: 71.101% (5617/7900)\n",
      "True positive rate: 75.685% (6101/8061)\n",
      "False negative rate: 24.315% (1960/8061)\n",
      "True negative rate: 98.862% (101372/102539)\n",
      "False positive rate: 1.138% (1167/102539)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 80/100: Loss: 0.0701 | Train Acc: 97.185% (108847/112000) | Strict Acc: 71.237% (5699/8000)\n",
      "True positive rate: 75.720% (6175/8155)\n",
      "False negative rate: 24.280% (1980/8155)\n",
      "True negative rate: 98.870% (102672/103845)\n",
      "False positive rate: 1.130% (1173/103845)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 81/100: Loss: 0.0703 | Train Acc: 97.168% (110189/113400) | Strict Acc: 71.185% (5766/8100)\n",
      "True positive rate: 75.483% (6250/8280)\n",
      "False negative rate: 24.517% (2030/8280)\n",
      "True negative rate: 98.877% (103939/105120)\n",
      "False positive rate: 1.123% (1181/105120)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 82/100: Loss: 0.0703 | Train Acc: 97.171% (111552/114800) | Strict Acc: 71.220% (5840/8200)\n",
      "True positive rate: 75.438% (6327/8387)\n",
      "False negative rate: 24.562% (2060/8387)\n",
      "True negative rate: 98.884% (105225/106413)\n",
      "False positive rate: 1.116% (1188/106413)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 83/100: Loss: 0.0704 | Train Acc: 97.170% (112911/116200) | Strict Acc: 71.217% (5911/8300)\n",
      "True positive rate: 75.500% (6416/8498)\n",
      "False negative rate: 24.500% (2082/8498)\n",
      "True negative rate: 98.879% (106495/107702)\n",
      "False positive rate: 1.121% (1207/107702)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 84/100: Loss: 0.0702 | Train Acc: 97.174% (114277/117600) | Strict Acc: 71.250% (5985/8400)\n",
      "True positive rate: 75.564% (6494/8594)\n",
      "False negative rate: 24.436% (2100/8594)\n",
      "True negative rate: 98.878% (107783/109006)\n",
      "False positive rate: 1.122% (1223/109006)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 85/100: Loss: 0.0702 | Train Acc: 97.172% (115635/119000) | Strict Acc: 71.224% (6054/8500)\n",
      "True positive rate: 75.662% (6572/8686)\n",
      "False negative rate: 24.338% (2114/8686)\n",
      "True negative rate: 98.866% (109063/110314)\n",
      "False positive rate: 1.134% (1251/110314)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 86/100: Loss: 0.0702 | Train Acc: 97.176% (117000/120400) | Strict Acc: 71.267% (6129/8600)\n",
      "True positive rate: 75.734% (6629/8753)\n",
      "False negative rate: 24.266% (2124/8753)\n",
      "True negative rate: 98.857% (110371/111647)\n",
      "False positive rate: 1.143% (1276/111647)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 87/100: Loss: 0.0701 | Train Acc: 97.176% (118360/121800) | Strict Acc: 71.253% (6199/8700)\n",
      "True positive rate: 75.763% (6705/8850)\n",
      "False negative rate: 24.237% (2145/8850)\n",
      "True negative rate: 98.853% (111655/112950)\n",
      "False positive rate: 1.147% (1295/112950)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 88/100: Loss: 0.0701 | Train Acc: 97.177% (119722/123200) | Strict Acc: 71.250% (6270/8800)\n",
      "True positive rate: 75.747% (6790/8964)\n",
      "False negative rate: 24.253% (2174/8964)\n",
      "True negative rate: 98.859% (112932/114236)\n",
      "False positive rate: 1.141% (1304/114236)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 89/100: Loss: 0.0701 | Train Acc: 97.177% (121083/124600) | Strict Acc: 71.247% (6341/8900)\n",
      "True positive rate: 75.715% (6856/9055)\n",
      "False negative rate: 24.285% (2199/9055)\n",
      "True negative rate: 98.859% (114227/115545)\n",
      "False positive rate: 1.141% (1318/115545)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 90/100: Loss: 0.0701 | Train Acc: 97.179% (122445/126000) | Strict Acc: 71.278% (6415/9000)\n",
      "True positive rate: 75.677% (6932/9160)\n",
      "False negative rate: 24.323% (2228/9160)\n",
      "True negative rate: 98.864% (115513/116840)\n",
      "False positive rate: 1.136% (1327/116840)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 91/100: Loss: 0.0700 | Train Acc: 97.177% (123804/127400) | Strict Acc: 71.308% (6489/9100)\n",
      "True positive rate: 75.611% (6997/9254)\n",
      "False negative rate: 24.389% (2257/9254)\n",
      "True negative rate: 98.867% (116807/118146)\n",
      "False positive rate: 1.133% (1339/118146)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 92/100: Loss: 0.0698 | Train Acc: 97.184% (125173/128800) | Strict Acc: 71.348% (6564/9200)\n",
      "True positive rate: 75.632% (7061/9336)\n",
      "False negative rate: 24.368% (2275/9336)\n",
      "True negative rate: 98.868% (118112/119464)\n",
      "False positive rate: 1.132% (1352/119464)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 93/100: Loss: 0.0698 | Train Acc: 97.185% (126535/130200) | Strict Acc: 71.376% (6638/9300)\n",
      "True positive rate: 75.591% (7129/9431)\n",
      "False negative rate: 24.409% (2302/9431)\n",
      "True negative rate: 98.871% (119406/120769)\n",
      "False positive rate: 1.129% (1363/120769)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 94/100: Loss: 0.0699 | Train Acc: 97.174% (127881/131600) | Strict Acc: 71.277% (6700/9400)\n",
      "True positive rate: 75.566% (7206/9536)\n",
      "False negative rate: 24.434% (2330/9536)\n",
      "True negative rate: 98.862% (120675/122064)\n",
      "False positive rate: 1.138% (1389/122064)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 95/100: Loss: 0.0697 | Train Acc: 97.181% (129251/133000) | Strict Acc: 71.316% (6775/9500)\n",
      "True positive rate: 75.652% (7277/9619)\n",
      "False negative rate: 24.348% (2342/9619)\n",
      "True negative rate: 98.860% (121974/123381)\n",
      "False positive rate: 1.140% (1407/123381)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 96/100: Loss: 0.0697 | Train Acc: 97.182% (130613/134400) | Strict Acc: 71.281% (6843/9600)\n",
      "True positive rate: 75.635% (7351/9719)\n",
      "False negative rate: 24.365% (2368/9719)\n",
      "True negative rate: 98.862% (123262/124681)\n",
      "False positive rate: 1.138% (1419/124681)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 97/100: Loss: 0.0697 | Train Acc: 97.177% (131967/135800) | Strict Acc: 71.247% (6911/9700)\n",
      "True positive rate: 75.547% (7424/9827)\n",
      "False negative rate: 24.453% (2403/9827)\n",
      "True negative rate: 98.865% (124543/125973)\n",
      "False positive rate: 1.135% (1430/125973)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 98/100: Loss: 0.0697 | Train Acc: 97.177% (133327/137200) | Strict Acc: 71.224% (6980/9800)\n",
      "True positive rate: 75.598% (7522/9950)\n",
      "False negative rate: 24.402% (2428/9950)\n",
      "True negative rate: 98.864% (125805/127250)\n",
      "False positive rate: 1.136% (1445/127250)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 99/100: Loss: 0.0697 | Train Acc: 97.181% (134693/138600) | Strict Acc: 71.253% (7054/9900)\n",
      "True positive rate: 75.614% (7600/10051)\n",
      "False negative rate: 24.386% (2451/10051)\n",
      "True negative rate: 98.867% (127093/128549)\n",
      "False positive rate: 1.133% (1456/128549)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 9 - Batch 100/100: Loss: 0.0695 | Train Acc: 97.182% (134831/138740) | Strict Acc: 71.261% (7062/9910)\n",
      "True positive rate: 75.624% (7610/10063)\n",
      "False negative rate: 24.376% (2453/10063)\n",
      "True negative rate: 98.868% (127221/128677)\n",
      "False positive rate: 1.132% (1456/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1221 | Dev Acc: 95.635% (67882/70980) | Strict Acc: 59.803% (3032/5070)\n",
      "True positive rate: 68.698% (3540/5153)\n",
      "False negative rate: 31.302% (1613/5153)\n",
      "True negative rate: 97.744% (64342/65827)\n",
      "False positive rate: 2.256% (1485/65827)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 1/100: Loss: 0.0639 | Train Acc: 97.214% (1361/1400) | Strict Acc: 70.000% (70/100)\n",
      "True positive rate: 78.632% (92/117)\n",
      "False negative rate: 21.368% (25/117)\n",
      "True negative rate: 98.909% (1269/1283)\n",
      "False positive rate: 1.091% (14/1283)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 2/100: Loss: 0.0624 | Train Acc: 97.464% (2729/2800) | Strict Acc: 72.500% (145/200)\n",
      "True positive rate: 79.803% (162/203)\n",
      "False negative rate: 20.197% (41/203)\n",
      "True negative rate: 98.845% (2567/2597)\n",
      "False positive rate: 1.155% (30/2597)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 3/100: Loss: 0.0598 | Train Acc: 97.619% (4100/4200) | Strict Acc: 73.333% (220/300)\n",
      "True positive rate: 82.712% (244/295)\n",
      "False negative rate: 17.288% (51/295)\n",
      "True negative rate: 98.745% (3856/3905)\n",
      "False positive rate: 1.255% (49/3905)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 4/100: Loss: 0.0581 | Train Acc: 97.643% (5468/5600) | Strict Acc: 74.000% (296/400)\n",
      "True positive rate: 82.979% (351/423)\n",
      "False negative rate: 17.021% (72/423)\n",
      "True negative rate: 98.841% (5117/5177)\n",
      "False positive rate: 1.159% (60/5177)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 5/100: Loss: 0.0610 | Train Acc: 97.600% (6832/7000) | Strict Acc: 73.600% (368/500)\n",
      "True positive rate: 81.714% (429/525)\n",
      "False negative rate: 18.286% (96/525)\n",
      "True negative rate: 98.888% (6403/6475)\n",
      "False positive rate: 1.112% (72/6475)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 6/100: Loss: 0.0644 | Train Acc: 97.512% (8191/8400) | Strict Acc: 73.833% (443/600)\n",
      "True positive rate: 80.000% (492/615)\n",
      "False negative rate: 20.000% (123/615)\n",
      "True negative rate: 98.895% (7699/7785)\n",
      "False positive rate: 1.105% (86/7785)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 7/100: Loss: 0.0620 | Train Acc: 97.571% (9562/9800) | Strict Acc: 73.857% (517/700)\n",
      "True positive rate: 79.944% (570/713)\n",
      "False negative rate: 20.056% (143/713)\n",
      "True negative rate: 98.955% (8992/9087)\n",
      "False positive rate: 1.045% (95/9087)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 8/100: Loss: 0.0627 | Train Acc: 97.571% (10928/11200) | Strict Acc: 73.625% (589/800)\n",
      "True positive rate: 79.952% (662/828)\n",
      "False negative rate: 20.048% (166/828)\n",
      "True negative rate: 98.978% (10266/10372)\n",
      "False positive rate: 1.022% (106/10372)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 9/100: Loss: 0.0648 | Train Acc: 97.460% (12280/12600) | Strict Acc: 73.222% (659/900)\n",
      "True positive rate: 78.875% (743/942)\n",
      "False negative rate: 21.125% (199/942)\n",
      "True negative rate: 98.962% (11537/11658)\n",
      "False positive rate: 1.038% (121/11658)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 10/100: Loss: 0.0642 | Train Acc: 97.486% (13648/14000) | Strict Acc: 73.600% (736/1000)\n",
      "True positive rate: 78.791% (821/1042)\n",
      "False negative rate: 21.209% (221/1042)\n",
      "True negative rate: 98.989% (12827/12958)\n",
      "False positive rate: 1.011% (131/12958)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 11/100: Loss: 0.0637 | Train Acc: 97.519% (15018/15400) | Strict Acc: 74.000% (814/1100)\n",
      "True positive rate: 79.319% (909/1146)\n",
      "False negative rate: 20.681% (237/1146)\n",
      "True negative rate: 98.983% (14109/14254)\n",
      "False positive rate: 1.017% (145/14254)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 12/100: Loss: 0.0646 | Train Acc: 97.458% (16373/16800) | Strict Acc: 73.417% (881/1200)\n",
      "True positive rate: 79.545% (1015/1276)\n",
      "False negative rate: 20.455% (261/1276)\n",
      "True negative rate: 98.931% (15358/15524)\n",
      "False positive rate: 1.069% (166/15524)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 13/100: Loss: 0.0644 | Train Acc: 97.462% (17738/18200) | Strict Acc: 73.692% (958/1300)\n",
      "True positive rate: 79.665% (1093/1372)\n",
      "False negative rate: 20.335% (279/1372)\n",
      "True negative rate: 98.913% (16645/16828)\n",
      "False positive rate: 1.087% (183/16828)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 14/100: Loss: 0.0647 | Train Acc: 97.474% (19105/19600) | Strict Acc: 73.929% (1035/1400)\n",
      "True positive rate: 79.932% (1175/1470)\n",
      "False negative rate: 20.068% (295/1470)\n",
      "True negative rate: 98.897% (17930/18130)\n",
      "False positive rate: 1.103% (200/18130)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 15/100: Loss: 0.0649 | Train Acc: 97.452% (20465/21000) | Strict Acc: 73.800% (1107/1500)\n",
      "True positive rate: 79.440% (1248/1571)\n",
      "False negative rate: 20.560% (323/1571)\n",
      "True negative rate: 98.909% (19217/19429)\n",
      "False positive rate: 1.091% (212/19429)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 16/100: Loss: 0.0651 | Train Acc: 97.438% (21826/22400) | Strict Acc: 73.812% (1181/1600)\n",
      "True positive rate: 79.403% (1330/1675)\n",
      "False negative rate: 20.597% (345/1675)\n",
      "True negative rate: 98.895% (20496/20725)\n",
      "False positive rate: 1.105% (229/20725)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 17/100: Loss: 0.0647 | Train Acc: 97.458% (23195/23800) | Strict Acc: 74.000% (1258/1700)\n",
      "True positive rate: 79.752% (1414/1773)\n",
      "False negative rate: 20.248% (359/1773)\n",
      "True negative rate: 98.883% (21781/22027)\n",
      "False positive rate: 1.117% (246/22027)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 18/100: Loss: 0.0645 | Train Acc: 97.472% (24563/25200) | Strict Acc: 74.167% (1335/1800)\n",
      "True positive rate: 79.752% (1477/1852)\n",
      "False negative rate: 20.248% (375/1852)\n",
      "True negative rate: 98.878% (23086/23348)\n",
      "False positive rate: 1.122% (262/23348)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 19/100: Loss: 0.0638 | Train Acc: 97.492% (25933/26600) | Strict Acc: 74.316% (1412/1900)\n",
      "True positive rate: 79.664% (1563/1962)\n",
      "False negative rate: 20.336% (399/1962)\n",
      "True negative rate: 98.912% (24370/24638)\n",
      "False positive rate: 1.088% (268/24638)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 20/100: Loss: 0.0639 | Train Acc: 97.482% (27295/28000) | Strict Acc: 74.250% (1485/2000)\n",
      "True positive rate: 79.461% (1652/2079)\n",
      "False negative rate: 20.539% (427/2079)\n",
      "True negative rate: 98.928% (25643/25921)\n",
      "False positive rate: 1.072% (278/25921)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 21/100: Loss: 0.0640 | Train Acc: 97.463% (28654/29400) | Strict Acc: 74.143% (1557/2100)\n",
      "True positive rate: 79.078% (1716/2170)\n",
      "False negative rate: 20.922% (454/2170)\n",
      "True negative rate: 98.928% (26938/27230)\n",
      "False positive rate: 1.072% (292/27230)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 22/100: Loss: 0.0641 | Train Acc: 97.468% (30020/30800) | Strict Acc: 74.136% (1631/2200)\n",
      "True positive rate: 79.022% (1793/2269)\n",
      "False negative rate: 20.978% (476/2269)\n",
      "True negative rate: 98.934% (28227/28531)\n",
      "False positive rate: 1.066% (304/28531)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 23/100: Loss: 0.0636 | Train Acc: 97.497% (31394/32200) | Strict Acc: 74.348% (1710/2300)\n",
      "True positive rate: 79.290% (1876/2366)\n",
      "False negative rate: 20.710% (490/2366)\n",
      "True negative rate: 98.941% (29518/29834)\n",
      "False positive rate: 1.059% (316/29834)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 24/100: Loss: 0.0640 | Train Acc: 97.491% (32757/33600) | Strict Acc: 74.250% (1782/2400)\n",
      "True positive rate: 79.390% (1953/2460)\n",
      "False negative rate: 20.610% (507/2460)\n",
      "True negative rate: 98.921% (30804/31140)\n",
      "False positive rate: 1.079% (336/31140)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 25/100: Loss: 0.0635 | Train Acc: 97.520% (34132/35000) | Strict Acc: 74.520% (1863/2500)\n",
      "True positive rate: 79.515% (2034/2558)\n",
      "False negative rate: 20.485% (524/2558)\n",
      "True negative rate: 98.940% (32098/32442)\n",
      "False positive rate: 1.060% (344/32442)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 26/100: Loss: 0.0631 | Train Acc: 97.538% (35504/36400) | Strict Acc: 74.654% (1941/2600)\n",
      "True positive rate: 79.819% (2120/2656)\n",
      "False negative rate: 20.181% (536/2656)\n",
      "True negative rate: 98.933% (33384/33744)\n",
      "False positive rate: 1.067% (360/33744)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 27/100: Loss: 0.0630 | Train Acc: 97.534% (36868/37800) | Strict Acc: 74.556% (2013/2700)\n",
      "True positive rate: 79.740% (2204/2764)\n",
      "False negative rate: 20.260% (560/2764)\n",
      "True negative rate: 98.938% (34664/35036)\n",
      "False positive rate: 1.062% (372/35036)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 28/100: Loss: 0.0625 | Train Acc: 97.551% (38240/39200) | Strict Acc: 74.714% (2092/2800)\n",
      "True positive rate: 79.789% (2274/2850)\n",
      "False negative rate: 20.211% (576/2850)\n",
      "True negative rate: 98.944% (35966/36350)\n",
      "False positive rate: 1.056% (384/36350)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 29/100: Loss: 0.0620 | Train Acc: 97.557% (39608/40600) | Strict Acc: 74.690% (2166/2900)\n",
      "True positive rate: 79.764% (2361/2960)\n",
      "False negative rate: 20.236% (599/2960)\n",
      "True negative rate: 98.956% (37247/37640)\n",
      "False positive rate: 1.044% (393/37640)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 30/100: Loss: 0.0617 | Train Acc: 97.562% (40976/42000) | Strict Acc: 74.767% (2243/3000)\n",
      "True positive rate: 79.627% (2435/3058)\n",
      "False negative rate: 20.373% (623/3058)\n",
      "True negative rate: 98.970% (38541/38942)\n",
      "False positive rate: 1.030% (401/38942)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 31/100: Loss: 0.0613 | Train Acc: 97.581% (42350/43400) | Strict Acc: 75.000% (2325/3100)\n",
      "True positive rate: 79.618% (2500/3140)\n",
      "False negative rate: 20.382% (640/3140)\n",
      "True negative rate: 98.982% (39850/40260)\n",
      "False positive rate: 1.018% (410/40260)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 32/100: Loss: 0.0613 | Train Acc: 97.578% (43715/44800) | Strict Acc: 74.969% (2399/3200)\n",
      "True positive rate: 79.459% (2584/3252)\n",
      "False negative rate: 20.541% (668/3252)\n",
      "True negative rate: 98.996% (41131/41548)\n",
      "False positive rate: 1.004% (417/41548)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 33/100: Loss: 0.0613 | Train Acc: 97.571% (45078/46200) | Strict Acc: 74.970% (2474/3300)\n",
      "True positive rate: 79.505% (2665/3352)\n",
      "False negative rate: 20.495% (687/3352)\n",
      "True negative rate: 98.985% (42413/42848)\n",
      "False positive rate: 1.015% (435/42848)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 34/100: Loss: 0.0618 | Train Acc: 97.548% (46433/47600) | Strict Acc: 74.706% (2540/3400)\n",
      "True positive rate: 79.411% (2750/3463)\n",
      "False negative rate: 20.589% (713/3463)\n",
      "True negative rate: 98.971% (43683/44137)\n",
      "False positive rate: 1.029% (454/44137)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 35/100: Loss: 0.0612 | Train Acc: 97.573% (47811/49000) | Strict Acc: 74.943% (2623/3500)\n",
      "True positive rate: 79.780% (2829/3546)\n",
      "False negative rate: 20.220% (717/3546)\n",
      "True negative rate: 98.962% (44982/45454)\n",
      "False positive rate: 1.038% (472/45454)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 36/100: Loss: 0.0614 | Train Acc: 97.560% (49170/50400) | Strict Acc: 74.778% (2692/3600)\n",
      "True positive rate: 79.744% (2929/3673)\n",
      "False negative rate: 20.256% (744/3673)\n",
      "True negative rate: 98.960% (46241/46727)\n",
      "False positive rate: 1.040% (486/46727)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 37/100: Loss: 0.0615 | Train Acc: 97.544% (50528/51800) | Strict Acc: 74.703% (2764/3700)\n",
      "True positive rate: 79.814% (3001/3760)\n",
      "False negative rate: 20.186% (759/3760)\n",
      "True negative rate: 98.932% (47527/48040)\n",
      "False positive rate: 1.068% (513/48040)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 38/100: Loss: 0.0614 | Train Acc: 97.555% (51899/53200) | Strict Acc: 74.763% (2841/3800)\n",
      "True positive rate: 79.990% (3078/3848)\n",
      "False negative rate: 20.010% (770/3848)\n",
      "True negative rate: 98.924% (48821/49352)\n",
      "False positive rate: 1.076% (531/49352)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 39/100: Loss: 0.0616 | Train Acc: 97.560% (53268/54600) | Strict Acc: 74.769% (2916/3900)\n",
      "True positive rate: 80.066% (3161/3948)\n",
      "False negative rate: 19.934% (787/3948)\n",
      "True negative rate: 98.924% (50107/50652)\n",
      "False positive rate: 1.076% (545/50652)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 40/100: Loss: 0.0618 | Train Acc: 97.561% (54634/56000) | Strict Acc: 74.700% (2988/4000)\n",
      "True positive rate: 80.059% (3252/4062)\n",
      "False negative rate: 19.941% (810/4062)\n",
      "True negative rate: 98.929% (51382/51938)\n",
      "False positive rate: 1.071% (556/51938)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 41/100: Loss: 0.0619 | Train Acc: 97.557% (55998/57400) | Strict Acc: 74.634% (3060/4100)\n",
      "True positive rate: 79.981% (3328/4161)\n",
      "False negative rate: 20.019% (833/4161)\n",
      "True negative rate: 98.931% (52670/53239)\n",
      "False positive rate: 1.069% (569/53239)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 42/100: Loss: 0.0624 | Train Acc: 97.543% (57355/58800) | Strict Acc: 74.571% (3132/4200)\n",
      "True positive rate: 79.836% (3409/4270)\n",
      "False negative rate: 20.164% (861/4270)\n",
      "True negative rate: 98.929% (53946/54530)\n",
      "False positive rate: 1.071% (584/54530)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 43/100: Loss: 0.0624 | Train Acc: 97.540% (58719/60200) | Strict Acc: 74.558% (3206/4300)\n",
      "True positive rate: 79.661% (3478/4366)\n",
      "False negative rate: 20.339% (888/4366)\n",
      "True negative rate: 98.938% (55241/55834)\n",
      "False positive rate: 1.062% (593/55834)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 44/100: Loss: 0.0621 | Train Acc: 97.547% (60089/61600) | Strict Acc: 74.614% (3283/4400)\n",
      "True positive rate: 79.669% (3558/4466)\n",
      "False negative rate: 20.331% (908/4466)\n",
      "True negative rate: 98.945% (56531/57134)\n",
      "False positive rate: 1.055% (603/57134)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 45/100: Loss: 0.0620 | Train Acc: 97.546% (61454/63000) | Strict Acc: 74.622% (3358/4500)\n",
      "True positive rate: 79.598% (3640/4573)\n",
      "False negative rate: 20.402% (933/4573)\n",
      "True negative rate: 98.951% (57814/58427)\n",
      "False positive rate: 1.049% (613/58427)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 46/100: Loss: 0.0623 | Train Acc: 97.520% (62803/64400) | Strict Acc: 74.478% (3426/4600)\n",
      "True positive rate: 79.434% (3731/4697)\n",
      "False negative rate: 20.566% (966/4697)\n",
      "True negative rate: 98.943% (59072/59703)\n",
      "False positive rate: 1.057% (631/59703)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 47/100: Loss: 0.0624 | Train Acc: 97.518% (64167/65800) | Strict Acc: 74.489% (3501/4700)\n",
      "True positive rate: 79.320% (3805/4797)\n",
      "False negative rate: 20.680% (992/4797)\n",
      "True negative rate: 98.949% (60362/61003)\n",
      "False positive rate: 1.051% (641/61003)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 48/100: Loss: 0.0624 | Train Acc: 97.519% (65533/67200) | Strict Acc: 74.542% (3578/4800)\n",
      "True positive rate: 79.320% (3870/4879)\n",
      "False negative rate: 20.680% (1009/4879)\n",
      "True negative rate: 98.944% (61663/62321)\n",
      "False positive rate: 1.056% (658/62321)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 49/100: Loss: 0.0622 | Train Acc: 97.523% (66901/68600) | Strict Acc: 74.531% (3652/4900)\n",
      "True positive rate: 79.304% (3943/4972)\n",
      "False negative rate: 20.696% (1029/4972)\n",
      "True negative rate: 98.947% (62958/63628)\n",
      "False positive rate: 1.053% (670/63628)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 50/100: Loss: 0.0622 | Train Acc: 97.523% (68266/70000) | Strict Acc: 74.560% (3728/5000)\n",
      "True positive rate: 79.321% (4020/5068)\n",
      "False negative rate: 20.679% (1048/5068)\n",
      "True negative rate: 98.944% (64246/64932)\n",
      "False positive rate: 1.056% (686/64932)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 51/100: Loss: 0.0620 | Train Acc: 97.531% (69637/71400) | Strict Acc: 74.667% (3808/5100)\n",
      "True positive rate: 79.370% (4109/5177)\n",
      "False negative rate: 20.630% (1068/5177)\n",
      "True negative rate: 98.951% (65528/66223)\n",
      "False positive rate: 1.049% (695/66223)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 52/100: Loss: 0.0620 | Train Acc: 97.537% (71007/72800) | Strict Acc: 74.750% (3887/5200)\n",
      "True positive rate: 79.308% (4170/5258)\n",
      "False negative rate: 20.692% (1088/5258)\n",
      "True negative rate: 98.956% (66837/67542)\n",
      "False positive rate: 1.044% (705/67542)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 53/100: Loss: 0.0618 | Train Acc: 97.554% (72385/74200) | Strict Acc: 74.943% (3972/5300)\n",
      "True positive rate: 79.418% (4260/5364)\n",
      "False negative rate: 20.582% (1104/5364)\n",
      "True negative rate: 98.967% (68125/68836)\n",
      "False positive rate: 1.033% (711/68836)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 54/100: Loss: 0.0620 | Train Acc: 97.550% (73748/75600) | Strict Acc: 74.889% (4044/5400)\n",
      "True positive rate: 79.350% (4346/5477)\n",
      "False negative rate: 20.650% (1131/5477)\n",
      "True negative rate: 98.972% (69402/70123)\n",
      "False positive rate: 1.028% (721/70123)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 55/100: Loss: 0.0617 | Train Acc: 97.562% (75123/77000) | Strict Acc: 75.000% (4125/5500)\n",
      "True positive rate: 79.380% (4427/5577)\n",
      "False negative rate: 20.620% (1150/5577)\n",
      "True negative rate: 98.982% (70696/71423)\n",
      "False positive rate: 1.018% (727/71423)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 56/100: Loss: 0.0618 | Train Acc: 97.560% (76487/78400) | Strict Acc: 74.964% (4198/5600)\n",
      "True positive rate: 79.335% (4511/5686)\n",
      "False negative rate: 20.665% (1175/5686)\n",
      "True negative rate: 98.985% (71976/72714)\n",
      "False positive rate: 1.015% (738/72714)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 57/100: Loss: 0.0618 | Train Acc: 97.556% (77850/79800) | Strict Acc: 74.965% (4273/5700)\n",
      "True positive rate: 79.326% (4593/5790)\n",
      "False negative rate: 20.674% (1197/5790)\n",
      "True negative rate: 98.983% (73257/74010)\n",
      "False positive rate: 1.017% (753/74010)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 58/100: Loss: 0.0619 | Train Acc: 97.558% (79217/81200) | Strict Acc: 74.966% (4348/5800)\n",
      "True positive rate: 79.416% (4680/5893)\n",
      "False negative rate: 20.584% (1213/5893)\n",
      "True negative rate: 98.978% (74537/75307)\n",
      "False positive rate: 1.022% (770/75307)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 59/100: Loss: 0.0617 | Train Acc: 97.565% (80589/82600) | Strict Acc: 75.017% (4426/5900)\n",
      "True positive rate: 79.526% (4766/5993)\n",
      "False negative rate: 20.474% (1227/5993)\n",
      "True negative rate: 98.977% (75823/76607)\n",
      "False positive rate: 1.023% (784/76607)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 60/100: Loss: 0.0616 | Train Acc: 97.574% (81962/84000) | Strict Acc: 75.100% (4506/6000)\n",
      "True positive rate: 79.608% (4837/6076)\n",
      "False negative rate: 20.392% (1239/6076)\n",
      "True negative rate: 98.975% (77125/77924)\n",
      "False positive rate: 1.025% (799/77924)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 61/100: Loss: 0.0614 | Train Acc: 97.574% (83328/85400) | Strict Acc: 75.098% (4581/6100)\n",
      "True positive rate: 79.579% (4918/6180)\n",
      "False negative rate: 20.421% (1262/6180)\n",
      "True negative rate: 98.978% (78410/79220)\n",
      "False positive rate: 1.022% (810/79220)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 62/100: Loss: 0.0619 | Train Acc: 97.552% (84675/86800) | Strict Acc: 74.903% (4644/6200)\n",
      "True positive rate: 79.420% (5013/6312)\n",
      "False negative rate: 20.580% (1299/6312)\n",
      "True negative rate: 98.974% (79662/80488)\n",
      "False positive rate: 1.026% (826/80488)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 63/100: Loss: 0.0621 | Train Acc: 97.541% (86031/88200) | Strict Acc: 74.825% (4714/6300)\n",
      "True positive rate: 79.302% (5092/6421)\n",
      "False negative rate: 20.698% (1329/6421)\n",
      "True negative rate: 98.973% (80939/81779)\n",
      "False positive rate: 1.027% (840/81779)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 64/100: Loss: 0.0621 | Train Acc: 97.537% (87393/89600) | Strict Acc: 74.781% (4786/6400)\n",
      "True positive rate: 79.258% (5170/6523)\n",
      "False negative rate: 20.742% (1353/6523)\n",
      "True negative rate: 98.972% (82223/83077)\n",
      "False positive rate: 1.028% (854/83077)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 65/100: Loss: 0.0620 | Train Acc: 97.535% (88757/91000) | Strict Acc: 74.769% (4860/6500)\n",
      "True positive rate: 79.235% (5239/6612)\n",
      "False negative rate: 20.765% (1373/6612)\n",
      "True negative rate: 98.969% (83518/84388)\n",
      "False positive rate: 1.031% (870/84388)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 66/100: Loss: 0.0620 | Train Acc: 97.544% (90131/92400) | Strict Acc: 74.833% (4939/6600)\n",
      "True positive rate: 79.276% (5321/6712)\n",
      "False negative rate: 20.724% (1391/6712)\n",
      "True negative rate: 98.975% (84810/85688)\n",
      "False positive rate: 1.025% (878/85688)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 67/100: Loss: 0.0623 | Train Acc: 97.529% (91482/93800) | Strict Acc: 74.701% (5005/6700)\n",
      "True positive rate: 79.106% (5395/6820)\n",
      "False negative rate: 20.894% (1425/6820)\n",
      "True negative rate: 98.973% (86087/86980)\n",
      "False positive rate: 1.027% (893/86980)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 68/100: Loss: 0.0623 | Train Acc: 97.527% (92846/95200) | Strict Acc: 74.676% (5078/6800)\n",
      "True positive rate: 79.199% (5475/6913)\n",
      "False negative rate: 20.801% (1438/6913)\n",
      "True negative rate: 98.962% (87371/88287)\n",
      "False positive rate: 1.038% (916/88287)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 69/100: Loss: 0.0622 | Train Acc: 97.530% (94214/96600) | Strict Acc: 74.696% (5154/6900)\n",
      "True positive rate: 79.289% (5532/6977)\n",
      "False negative rate: 20.711% (1445/6977)\n",
      "True negative rate: 98.950% (88682/89623)\n",
      "False positive rate: 1.050% (941/89623)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 70/100: Loss: 0.0623 | Train Acc: 97.521% (95571/98000) | Strict Acc: 74.629% (5224/7000)\n",
      "True positive rate: 79.190% (5613/7088)\n",
      "False negative rate: 20.810% (1475/7088)\n",
      "True negative rate: 98.951% (89958/90912)\n",
      "False positive rate: 1.049% (954/90912)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 71/100: Loss: 0.0620 | Train Acc: 97.535% (96950/99400) | Strict Acc: 74.732% (5306/7100)\n",
      "True positive rate: 79.307% (5699/7186)\n",
      "False negative rate: 20.693% (1487/7186)\n",
      "True negative rate: 98.956% (91251/92214)\n",
      "False positive rate: 1.044% (963/92214)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 72/100: Loss: 0.0622 | Train Acc: 97.525% (98305/100800) | Strict Acc: 74.681% (5377/7200)\n",
      "True positive rate: 79.155% (5772/7292)\n",
      "False negative rate: 20.845% (1520/7292)\n",
      "True negative rate: 98.957% (92533/93508)\n",
      "False positive rate: 1.043% (975/93508)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 73/100: Loss: 0.0622 | Train Acc: 97.517% (99662/102200) | Strict Acc: 74.644% (5449/7300)\n",
      "True positive rate: 78.959% (5839/7395)\n",
      "False negative rate: 21.041% (1556/7395)\n",
      "True negative rate: 98.964% (93823/94805)\n",
      "False positive rate: 1.036% (982/94805)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 74/100: Loss: 0.0625 | Train Acc: 97.501% (101011/103600) | Strict Acc: 74.568% (5518/7400)\n",
      "True positive rate: 78.834% (5911/7498)\n",
      "False negative rate: 21.166% (1587/7498)\n",
      "True negative rate: 98.957% (95100/96102)\n",
      "False positive rate: 1.043% (1002/96102)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 75/100: Loss: 0.0625 | Train Acc: 97.497% (102372/105000) | Strict Acc: 74.547% (5591/7500)\n",
      "True positive rate: 78.744% (5983/7598)\n",
      "False negative rate: 21.256% (1615/7598)\n",
      "True negative rate: 98.960% (96389/97402)\n",
      "False positive rate: 1.040% (1013/97402)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 76/100: Loss: 0.0625 | Train Acc: 97.502% (103742/106400) | Strict Acc: 74.592% (5669/7600)\n",
      "True positive rate: 78.811% (6074/7707)\n",
      "False negative rate: 21.189% (1633/7707)\n",
      "True negative rate: 98.961% (97668/98693)\n",
      "False positive rate: 1.039% (1025/98693)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 77/100: Loss: 0.0625 | Train Acc: 97.498% (105103/107800) | Strict Acc: 74.571% (5742/7700)\n",
      "True positive rate: 78.769% (6144/7800)\n",
      "False negative rate: 21.231% (1656/7800)\n",
      "True negative rate: 98.959% (98959/100000)\n",
      "False positive rate: 1.041% (1041/100000)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 78/100: Loss: 0.0624 | Train Acc: 97.505% (106476/109200) | Strict Acc: 74.603% (5819/7800)\n",
      "True positive rate: 78.806% (6217/7889)\n",
      "False negative rate: 21.194% (1672/7889)\n",
      "True negative rate: 98.962% (100259/101311)\n",
      "False positive rate: 1.038% (1052/101311)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 79/100: Loss: 0.0624 | Train Acc: 97.508% (107844/110600) | Strict Acc: 74.620% (5895/7900)\n",
      "True positive rate: 78.847% (6303/7994)\n",
      "False negative rate: 21.153% (1691/7994)\n",
      "True negative rate: 98.962% (101541/102606)\n",
      "False positive rate: 1.038% (1065/102606)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 80/100: Loss: 0.0625 | Train Acc: 97.497% (109197/112000) | Strict Acc: 74.537% (5963/8000)\n",
      "True positive rate: 78.743% (6375/8096)\n",
      "False negative rate: 21.257% (1721/8096)\n",
      "True negative rate: 98.959% (102822/103904)\n",
      "False positive rate: 1.041% (1082/103904)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 81/100: Loss: 0.0624 | Train Acc: 97.504% (110570/113400) | Strict Acc: 74.605% (6043/8100)\n",
      "True positive rate: 78.788% (6448/8184)\n",
      "False negative rate: 21.212% (1736/8184)\n",
      "True negative rate: 98.960% (104122/105216)\n",
      "False positive rate: 1.040% (1094/105216)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 82/100: Loss: 0.0626 | Train Acc: 97.498% (111928/114800) | Strict Acc: 74.549% (6113/8200)\n",
      "True positive rate: 78.734% (6542/8309)\n",
      "False negative rate: 21.266% (1767/8309)\n",
      "True negative rate: 98.962% (105386/106491)\n",
      "False positive rate: 1.038% (1105/106491)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 83/100: Loss: 0.0627 | Train Acc: 97.489% (113282/116200) | Strict Acc: 74.506% (6184/8300)\n",
      "True positive rate: 78.701% (6618/8409)\n",
      "False negative rate: 21.299% (1791/8409)\n",
      "True negative rate: 98.954% (106664/107791)\n",
      "False positive rate: 1.046% (1127/107791)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 84/100: Loss: 0.0627 | Train Acc: 97.487% (114645/117600) | Strict Acc: 74.464% (6255/8400)\n",
      "True positive rate: 78.698% (6698/8511)\n",
      "False negative rate: 21.302% (1813/8511)\n",
      "True negative rate: 98.953% (107947/109089)\n",
      "False positive rate: 1.047% (1142/109089)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 85/100: Loss: 0.0626 | Train Acc: 97.488% (116011/119000) | Strict Acc: 74.482% (6331/8500)\n",
      "True positive rate: 78.714% (6756/8583)\n",
      "False negative rate: 21.286% (1827/8583)\n",
      "True negative rate: 98.948% (109255/110417)\n",
      "False positive rate: 1.052% (1162/110417)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 86/100: Loss: 0.0625 | Train Acc: 97.497% (117386/120400) | Strict Acc: 74.570% (6413/8600)\n",
      "True positive rate: 78.755% (6832/8675)\n",
      "False negative rate: 21.245% (1843/8675)\n",
      "True negative rate: 98.952% (110554/111725)\n",
      "False positive rate: 1.048% (1171/111725)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 87/100: Loss: 0.0624 | Train Acc: 97.503% (118759/121800) | Strict Acc: 74.621% (6492/8700)\n",
      "True positive rate: 78.778% (6897/8755)\n",
      "False negative rate: 21.222% (1858/8755)\n",
      "True negative rate: 98.954% (111862/113045)\n",
      "False positive rate: 1.046% (1183/113045)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 88/100: Loss: 0.0625 | Train Acc: 97.496% (120115/123200) | Strict Acc: 74.568% (6562/8800)\n",
      "True positive rate: 78.673% (6983/8876)\n",
      "False negative rate: 21.327% (1893/8876)\n",
      "True negative rate: 98.957% (113132/114324)\n",
      "False positive rate: 1.043% (1192/114324)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 89/100: Loss: 0.0625 | Train Acc: 97.498% (121482/124600) | Strict Acc: 74.551% (6635/8900)\n",
      "True positive rate: 78.670% (7063/8978)\n",
      "False negative rate: 21.330% (1915/8978)\n",
      "True negative rate: 98.960% (114419/115622)\n",
      "False positive rate: 1.040% (1203/115622)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 90/100: Loss: 0.0626 | Train Acc: 97.487% (122834/126000) | Strict Acc: 74.467% (6702/9000)\n",
      "True positive rate: 78.577% (7145/9093)\n",
      "False negative rate: 21.423% (1948/9093)\n",
      "True negative rate: 98.958% (115689/116907)\n",
      "False positive rate: 1.042% (1218/116907)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 91/100: Loss: 0.0626 | Train Acc: 97.487% (124199/127400) | Strict Acc: 74.451% (6775/9100)\n",
      "True positive rate: 78.571% (7216/9184)\n",
      "False negative rate: 21.429% (1968/9184)\n",
      "True negative rate: 98.957% (116983/118216)\n",
      "False positive rate: 1.043% (1233/118216)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 92/100: Loss: 0.0626 | Train Acc: 97.494% (125572/128800) | Strict Acc: 74.478% (6852/9200)\n",
      "True positive rate: 78.666% (7312/9295)\n",
      "False negative rate: 21.334% (1983/9295)\n",
      "True negative rate: 98.958% (118260/119505)\n",
      "False positive rate: 1.042% (1245/119505)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 93/100: Loss: 0.0627 | Train Acc: 97.485% (126926/130200) | Strict Acc: 74.366% (6916/9300)\n",
      "True positive rate: 78.656% (7407/9417)\n",
      "False negative rate: 21.344% (2010/9417)\n",
      "True negative rate: 98.953% (119519/120783)\n",
      "False positive rate: 1.047% (1264/120783)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 94/100: Loss: 0.0628 | Train Acc: 97.480% (128284/131600) | Strict Acc: 74.319% (6986/9400)\n",
      "True positive rate: 78.697% (7503/9534)\n",
      "False negative rate: 21.303% (2031/9534)\n",
      "True negative rate: 98.947% (120781/122066)\n",
      "False positive rate: 1.053% (1285/122066)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 95/100: Loss: 0.0629 | Train Acc: 97.472% (129638/133000) | Strict Acc: 74.221% (7051/9500)\n",
      "True positive rate: 78.727% (7572/9618)\n",
      "False negative rate: 21.273% (2046/9618)\n",
      "True negative rate: 98.933% (122066/123382)\n",
      "False positive rate: 1.067% (1316/123382)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 96/100: Loss: 0.0632 | Train Acc: 97.459% (130985/134400) | Strict Acc: 74.135% (7117/9600)\n",
      "True positive rate: 78.698% (7662/9736)\n",
      "False negative rate: 21.302% (2074/9736)\n",
      "True negative rate: 98.924% (123323/124664)\n",
      "False positive rate: 1.076% (1341/124664)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 97/100: Loss: 0.0635 | Train Acc: 97.448% (132334/135800) | Strict Acc: 74.000% (7178/9700)\n",
      "True positive rate: 78.668% (7748/9849)\n",
      "False negative rate: 21.332% (2101/9849)\n",
      "True negative rate: 98.916% (124586/125951)\n",
      "False positive rate: 1.084% (1365/125951)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 98/100: Loss: 0.0636 | Train Acc: 97.448% (133698/137200) | Strict Acc: 74.000% (7252/9800)\n",
      "True positive rate: 78.666% (7821/9942)\n",
      "False negative rate: 21.334% (2121/9942)\n",
      "True negative rate: 98.915% (125877/127258)\n",
      "False positive rate: 1.085% (1381/127258)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 99/100: Loss: 0.0635 | Train Acc: 97.448% (135063/138600) | Strict Acc: 74.010% (7327/9900)\n",
      "True positive rate: 78.684% (7907/10049)\n",
      "False negative rate: 21.316% (2142/10049)\n",
      "True negative rate: 98.915% (127156/128551)\n",
      "False positive rate: 1.085% (1395/128551)\n",
      "------------------------\n",
      "------------------------\n",
      "Training: Epoch 10 - Batch 100/100: Loss: 0.0639 | Train Acc: 97.448% (135199/138740) | Strict Acc: 73.996% (7333/9910)\n",
      "True positive rate: 78.674% (7917/10063)\n",
      "False negative rate: 21.326% (2146/10063)\n",
      "True negative rate: 98.916% (127282/128677)\n",
      "False positive rate: 1.084% (1395/128677)\n",
      "------------------------\n",
      "------------------------\n",
      "Evaluating: Batch 5070/5070: Loss: 0.1258 | Dev Acc: 95.714% (67938/70980) | Strict Acc: 61.006% (3093/5070)\n",
      "True positive rate: 65.418% (3371/5153)\n",
      "False negative rate: 34.582% (1782/5153)\n",
      "True negative rate: 98.086% (64567/65827)\n",
      "False positive rate: 1.914% (1260/65827)\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "#--- hyperparameters ---\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE_TRAIN = 100\n",
    "BATCH_SIZE_TEST = 100\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 0.00\n",
    "MOMENTUM = 0.1\n",
    "\n",
    "\n",
    "#--- fixed constants ---\n",
    "NUM_CLASSES = 14\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "\n",
    "\n",
    "# --- Dataset initialization ---\n",
    "\n",
    "# We transform image files' contents to tensors\n",
    "# Plus, we can add random transformations to the training data if we like\n",
    "# Think on what kind of transformations may be meaningful for this data.\n",
    "# Eg., horizontal-flip is definitely a bad idea for sign language data.\n",
    "# You can use another transformation here if you find a better one.\n",
    "\n",
    "\n",
    "# Create Pytorch data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=BATCH_SIZE_TEST, shuffle=False)\n",
    "dev_loader = torch.utils.data.DataLoader(dataset=dev_set, shuffle=False)\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "alexnet.train()\n",
    "resnet.train()\n",
    "\n",
    "#--- model ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.alex = alexnet\n",
    "        for p in self.alex.parameters():\n",
    "            p.requires_grad=False\n",
    "        \n",
    "        self.resnet = resnet\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad=False\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(NUM_CHANNELS, 20, (5,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2), stride = (2,2)),\n",
    "\n",
    "            nn.Conv2d(20, 50, (5,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2), stride = (2,2)),\n",
    "\n",
    "            nn.Conv2d(50, 100, (5,5)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2), stride = (2,2))\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin_conv = nn.Sequential(\n",
    "            nn.Linear(57600, 1000),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(3000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out_alex = self.alex(x)\n",
    "        out_resnet = self.resnet(x)\n",
    "        out_conv = self.conv(x)\n",
    "        out_conv = self.flatten(out_conv)\n",
    "        out_conv = self.lin_conv(out_conv)\n",
    "        \n",
    "        combined_output = torch.cat((out_alex, out_resnet, out_conv), dim=1)\n",
    "        \n",
    "        out = self.lin(combined_output)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "#--- set up ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "dev_loss = math.inf\n",
    "dev_losses = []\n",
    "dev_accuracies = []\n",
    "stop_early = False\n",
    "\n",
    "#--- training ---\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if stop_early:\n",
    "        break\n",
    "    train_loss = 0\n",
    "    train_correct = {annotation: [0,0] for annotation in annotations}\n",
    "    train_correct['tot'] = [0,0]\n",
    "    train_correct['tot_strict'] = [0,0]\n",
    "    evaluation = {\"true_positive\": 0,\n",
    "                    \"false_positive\": 0,\n",
    "                    \"true_negative\": 0,\n",
    "                    \"false_negative\": 0,\n",
    "                    \"negative\": 0,\n",
    "                    \"positive\": 0}\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += len(data)\n",
    "        train_loss += loss.item()\n",
    "        new_correct = calc_correct(pred, target)\n",
    "        for annotation in annotations:\n",
    "            new = new_correct[annotation]\n",
    "            train_correct[annotation][0] += new[0]\n",
    "            train_correct[annotation][1] += new[1]\n",
    "        train_correct['tot'][0] += new_correct['tot'][0]\n",
    "        train_correct['tot'][1] += new_correct['tot'][1]\n",
    "        train_correct['tot_strict'][0] += new_correct['tot_strict'][0]\n",
    "        train_correct['tot_strict'][1] += new_correct['tot_strict'][1]\n",
    "        \n",
    "        evaluations = class_evaluation(pred, target)\n",
    "        evaluation[\"true_positive\"] += evaluations[\"true_positive\"]\n",
    "        evaluation[\"false_positive\"] += evaluations[\"false_positive\"]\n",
    "        evaluation[\"true_negative\"] += evaluations[\"true_negative\"]\n",
    "        evaluation[\"false_negative\"] += evaluations[\"false_negative\"]\n",
    "        evaluation[\"positive\"] += evaluations[\"positive\"]\n",
    "        evaluation[\"negative\"] += evaluations[\"negative\"]\n",
    "\n",
    "        print(\"------------------------\")\n",
    "        print('Training: Epoch %d - Batch %d/%d: Loss: %.4f | Train Acc: %.3f%% (%d/%d) | Strict Acc: %.3f%% (%d/%d)' % \n",
    "              (epoch+1, batch_num+1, len(train_loader), train_loss / (batch_num + 1), \n",
    "               100. * train_correct['tot'][0] / train_correct['tot'][1], train_correct['tot'][0], train_correct['tot'][1],\n",
    "               100. * train_correct['tot_strict'][0] / train_correct['tot_strict'][1], train_correct['tot_strict'][0], train_correct['tot_strict'][1]))\n",
    "        print('True positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_positive\"] / evaluation[\"positive\"], evaluation[\"true_positive\"], evaluation[\"positive\"]) )\n",
    "        print('False negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_negative\"] / evaluation[\"positive\"], evaluation[\"false_negative\"], evaluation[\"positive\"]) )\n",
    "        print('True negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_negative\"] / evaluation[\"negative\"], evaluation[\"true_negative\"], evaluation[\"negative\"]) )\n",
    "        print('False positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_positive\"] / evaluation[\"negative\"], evaluation[\"false_positive\"], evaluation[\"negative\"]) )\n",
    "        print(\"------------------------\")\n",
    "\n",
    "    cur_dev_loss = 0\n",
    "    dev_correct = {annotation: [0,0] for annotation in annotations}\n",
    "    dev_correct['tot'] = [0,0]\n",
    "    dev_correct['tot_strict'] = [0,0]\n",
    "    evaluation = {\"true_positive\": 0,\n",
    "                    \"false_positive\": 0,\n",
    "                    \"true_negative\": 0,\n",
    "                    \"false_negative\": 0,\n",
    "                    \"negative\": 0,\n",
    "                    \"positive\": 0}\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (data, target) in enumerate(dev_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            pred = model(data)\n",
    "            loss = loss_function(pred, target)\n",
    "\n",
    "            cur_dev_loss += loss.item()\n",
    "            new_dev_correct = calc_correct(pred, target)\n",
    "            for annotation in annotations:\n",
    "                new = new_dev_correct[annotation]\n",
    "                dev_correct[annotation][0] += new[0]\n",
    "                dev_correct[annotation][1] += new[1]\n",
    "            dev_correct['tot'][0] += new_dev_correct['tot'][0]\n",
    "            dev_correct['tot'][1] += new_dev_correct['tot'][1]\n",
    "            dev_correct['tot_strict'][0] += new_dev_correct['tot_strict'][0]\n",
    "            dev_correct['tot_strict'][1] += new_dev_correct['tot_strict'][1]\n",
    "            \n",
    "            evaluations = class_evaluation(pred, target)\n",
    "            evaluation[\"true_positive\"] += evaluations[\"true_positive\"]\n",
    "            evaluation[\"false_positive\"] += evaluations[\"false_positive\"]\n",
    "            evaluation[\"true_negative\"] += evaluations[\"true_negative\"]\n",
    "            evaluation[\"false_negative\"] += evaluations[\"false_negative\"]\n",
    "            evaluation[\"positive\"] += evaluations[\"positive\"]\n",
    "            evaluation[\"negative\"] += evaluations[\"negative\"]\n",
    "\n",
    "        current_loss = cur_dev_loss / (len(dev_loader) + 1)\n",
    "        dev_losses.append(current_loss)\n",
    "        current_accuracy = {annotation: 100. * dev_correct[annotation][0] / dev_correct[annotation][1]  for annotation in annotations}  # Accuracies for all classes \n",
    "        current_accuracy['tot'] = 100. * dev_correct['tot'][0] / dev_correct['tot'][1]\n",
    "        current_accuracy['tot_strict'] = 100. * dev_correct['tot_strict'][0] / dev_correct['tot_strict'][1]\n",
    "        dev_accuracies.append(current_accuracy)\n",
    "\n",
    "        if current_loss <= dev_loss:\n",
    "            dev_loss = current_loss\n",
    "        # else:\n",
    "        #     stop_early = True\n",
    "\n",
    "        print(\"------------------------\")\n",
    "        print('Evaluating: Batch %d/%d: Loss: %.4f | Dev Acc: %.3f%% (%d/%d) | Strict Acc: %.3f%% (%d/%d)' % \n",
    "            (batch_num+1, len(dev_loader), cur_dev_loss / (len(dev_loader) + 1), \n",
    "            100. * dev_correct['tot'][0] / dev_correct['tot'][1], dev_correct['tot'][0], dev_correct['tot'][1],\n",
    "            100. * dev_correct['tot_strict'][0] / dev_correct['tot_strict'][1], dev_correct['tot_strict'][0], dev_correct['tot_strict'][1]))\n",
    "        print('True positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_positive\"] / evaluation[\"positive\"], evaluation[\"true_positive\"], evaluation[\"positive\"]) )\n",
    "        print('False negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_negative\"] / evaluation[\"positive\"], evaluation[\"false_negative\"], evaluation[\"positive\"]) )\n",
    "        print('True negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_negative\"] / evaluation[\"negative\"], evaluation[\"true_negative\"], evaluation[\"negative\"]) )\n",
    "        print('False positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_positive\"] / evaluation[\"negative\"], evaluation[\"false_positive\"], evaluation[\"negative\"]) )\n",
    "        print(\"------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe67945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baby': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'bird': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'car': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'clouds': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'dog': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'female': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'flower': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'male': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'night': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'people': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'portrait': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'river': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'sea': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}, 'tree': {'true_positive': 0, 'false_positive': 0, 'true_negative': 0, 'false_negative': 0, 'negative': 0, 'positive': 0}}\n",
      "------------------------\n",
      "Evaluating: Batch 1/51: Loss: 0.1553 | Test Acc: 94.643% (1325/1400) | Strict Acc: 55.000% (55/100)\n",
      "True positive rate: 50.485% (52/103)\n",
      "False negative rate: 49.515% (51/103)\n",
      "True negative rate: 98.150% (1273/1297)\n",
      "False positive rate: 1.850% (24/1297)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 0, 'false_positive': 0, 'true_negative': 100, 'false_negative': 0, 'negative': 100, 'positive': 0}, 'bird': {'true_positive': 0, 'false_positive': 0, 'true_negative': 98, 'false_negative': 2, 'negative': 98, 'positive': 2}, 'car': {'true_positive': 0, 'false_positive': 0, 'true_negative': 100, 'false_negative': 0, 'negative': 100, 'positive': 0}, 'clouds': {'true_positive': 2, 'false_positive': 0, 'true_negative': 94, 'false_negative': 4, 'negative': 94, 'positive': 6}, 'dog': {'true_positive': 0, 'false_positive': 0, 'true_negative': 99, 'false_negative': 1, 'negative': 99, 'positive': 1}, 'female': {'true_positive': 5, 'false_positive': 5, 'true_negative': 83, 'false_negative': 7, 'negative': 88, 'positive': 12}, 'flower': {'true_positive': 1, 'false_positive': 2, 'true_negative': 97, 'false_negative': 0, 'negative': 99, 'positive': 1}, 'male': {'true_positive': 8, 'false_positive': 4, 'true_negative': 73, 'false_negative': 15, 'negative': 77, 'positive': 23}, 'night': {'true_positive': 1, 'false_positive': 1, 'true_negative': 95, 'false_negative': 3, 'negative': 96, 'positive': 4}, 'people': {'true_positive': 24, 'false_positive': 5, 'true_negative': 59, 'false_negative': 12, 'negative': 64, 'positive': 36}, 'portrait': {'true_positive': 10, 'false_positive': 5, 'true_negative': 82, 'false_negative': 3, 'negative': 87, 'positive': 13}, 'river': {'true_positive': 0, 'false_positive': 0, 'true_negative': 100, 'false_negative': 0, 'negative': 100, 'positive': 0}, 'sea': {'true_positive': 0, 'false_positive': 0, 'true_negative': 99, 'false_negative': 1, 'negative': 99, 'positive': 1}, 'tree': {'true_positive': 1, 'false_positive': 2, 'true_negative': 94, 'false_negative': 3, 'negative': 96, 'positive': 4}}\n",
      "------------------------\n",
      "Evaluating: Batch 2/51: Loss: 0.1519 | Test Acc: 95.393% (2671/2800) | Strict Acc: 60.500% (121/200)\n",
      "True positive rate: 56.784% (113/199)\n",
      "False negative rate: 43.216% (86/199)\n",
      "True negative rate: 98.347% (2558/2601)\n",
      "False positive rate: 1.653% (43/2601)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 0, 'false_positive': 0, 'true_negative': 200, 'false_negative': 0, 'negative': 200, 'positive': 0}, 'bird': {'true_positive': 0, 'false_positive': 0, 'true_negative': 197, 'false_negative': 3, 'negative': 197, 'positive': 3}, 'car': {'true_positive': 1, 'false_positive': 0, 'true_negative': 199, 'false_negative': 0, 'negative': 199, 'positive': 1}, 'clouds': {'true_positive': 4, 'false_positive': 2, 'true_negative': 185, 'false_negative': 9, 'negative': 187, 'positive': 13}, 'dog': {'true_positive': 2, 'false_positive': 0, 'true_negative': 197, 'false_negative': 1, 'negative': 197, 'positive': 3}, 'female': {'true_positive': 14, 'false_positive': 9, 'true_negative': 165, 'false_negative': 12, 'negative': 174, 'positive': 26}, 'flower': {'true_positive': 2, 'false_positive': 3, 'true_negative': 195, 'false_negative': 0, 'negative': 198, 'positive': 2}, 'male': {'true_positive': 17, 'false_positive': 6, 'true_negative': 154, 'false_negative': 23, 'negative': 160, 'positive': 40}, 'night': {'true_positive': 2, 'false_positive': 1, 'true_negative': 192, 'false_negative': 5, 'negative': 193, 'positive': 7}, 'people': {'true_positive': 44, 'false_positive': 10, 'true_negative': 127, 'false_negative': 19, 'negative': 137, 'positive': 63}, 'portrait': {'true_positive': 23, 'false_positive': 9, 'true_negative': 162, 'false_negative': 6, 'negative': 171, 'positive': 29}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 198, 'false_negative': 1, 'negative': 199, 'positive': 1}, 'sea': {'true_positive': 1, 'false_positive': 0, 'true_negative': 198, 'false_negative': 1, 'negative': 198, 'positive': 2}, 'tree': {'true_positive': 3, 'false_positive': 2, 'true_negative': 189, 'false_negative': 6, 'negative': 191, 'positive': 9}}\n",
      "------------------------\n",
      "Evaluating: Batch 3/51: Loss: 0.1497 | Test Acc: 95.333% (4004/4200) | Strict Acc: 62.333% (187/300)\n",
      "True positive rate: 59.197% (177/299)\n",
      "False negative rate: 40.803% (122/299)\n",
      "True negative rate: 98.103% (3827/3901)\n",
      "False positive rate: 1.897% (74/3901)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 0, 'false_positive': 0, 'true_negative': 300, 'false_negative': 0, 'negative': 300, 'positive': 0}, 'bird': {'true_positive': 0, 'false_positive': 0, 'true_negative': 297, 'false_negative': 3, 'negative': 297, 'positive': 3}, 'car': {'true_positive': 2, 'false_positive': 0, 'true_negative': 298, 'false_negative': 0, 'negative': 298, 'positive': 2}, 'clouds': {'true_positive': 6, 'false_positive': 2, 'true_negative': 282, 'false_negative': 10, 'negative': 284, 'positive': 16}, 'dog': {'true_positive': 4, 'false_positive': 0, 'true_negative': 294, 'false_negative': 2, 'negative': 294, 'positive': 6}, 'female': {'true_positive': 25, 'false_positive': 20, 'true_negative': 235, 'false_negative': 20, 'negative': 255, 'positive': 45}, 'flower': {'true_positive': 4, 'false_positive': 3, 'true_negative': 292, 'false_negative': 1, 'negative': 295, 'positive': 5}, 'male': {'true_positive': 25, 'false_positive': 10, 'true_negative': 234, 'false_negative': 31, 'negative': 244, 'positive': 56}, 'night': {'true_positive': 2, 'false_positive': 1, 'true_negative': 292, 'false_negative': 5, 'negative': 293, 'positive': 7}, 'people': {'true_positive': 71, 'false_positive': 14, 'true_negative': 188, 'false_negative': 27, 'negative': 202, 'positive': 98}, 'portrait': {'true_positive': 33, 'false_positive': 20, 'true_negative': 235, 'false_negative': 12, 'negative': 255, 'positive': 45}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 298, 'false_negative': 1, 'negative': 299, 'positive': 1}, 'sea': {'true_positive': 1, 'false_positive': 0, 'true_negative': 296, 'false_negative': 3, 'negative': 296, 'positive': 4}, 'tree': {'true_positive': 4, 'false_positive': 3, 'true_negative': 286, 'false_negative': 7, 'negative': 289, 'positive': 11}}\n",
      "------------------------\n",
      "Evaluating: Batch 4/51: Loss: 0.1495 | Test Acc: 95.321% (5338/5600) | Strict Acc: 61.500% (246/400)\n",
      "True positive rate: 59.352% (238/401)\n",
      "False negative rate: 40.648% (163/401)\n",
      "True negative rate: 98.096% (5100/5199)\n",
      "False positive rate: 1.904% (99/5199)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 0, 'false_positive': 0, 'true_negative': 400, 'false_negative': 0, 'negative': 400, 'positive': 0}, 'bird': {'true_positive': 1, 'false_positive': 1, 'true_negative': 394, 'false_negative': 4, 'negative': 395, 'positive': 5}, 'car': {'true_positive': 5, 'false_positive': 1, 'true_negative': 393, 'false_negative': 1, 'negative': 394, 'positive': 6}, 'clouds': {'true_positive': 7, 'false_positive': 2, 'true_negative': 379, 'false_negative': 12, 'negative': 381, 'positive': 19}, 'dog': {'true_positive': 4, 'false_positive': 1, 'true_negative': 393, 'false_negative': 2, 'negative': 394, 'positive': 6}, 'female': {'true_positive': 38, 'false_positive': 27, 'true_negative': 310, 'false_negative': 25, 'negative': 337, 'positive': 63}, 'flower': {'true_positive': 7, 'false_positive': 3, 'true_negative': 387, 'false_negative': 3, 'negative': 390, 'positive': 10}, 'male': {'true_positive': 29, 'false_positive': 12, 'true_negative': 318, 'false_negative': 41, 'negative': 330, 'positive': 70}, 'night': {'true_positive': 2, 'false_positive': 1, 'true_negative': 390, 'false_negative': 7, 'negative': 391, 'positive': 9}, 'people': {'true_positive': 94, 'false_positive': 20, 'true_negative': 250, 'false_negative': 36, 'negative': 270, 'positive': 130}, 'portrait': {'true_positive': 44, 'false_positive': 26, 'true_negative': 312, 'false_negative': 18, 'negative': 338, 'positive': 62}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 397, 'false_negative': 2, 'negative': 398, 'positive': 2}, 'sea': {'true_positive': 1, 'false_positive': 0, 'true_negative': 396, 'false_negative': 3, 'negative': 396, 'positive': 4}, 'tree': {'true_positive': 6, 'false_positive': 4, 'true_negative': 381, 'false_negative': 9, 'negative': 385, 'positive': 15}}\n",
      "------------------------\n",
      "Evaluating: Batch 5/51: Loss: 0.1452 | Test Acc: 95.386% (6677/7000) | Strict Acc: 61.200% (306/500)\n",
      "True positive rate: 59.592% (292/490)\n",
      "False negative rate: 40.408% (198/490)\n",
      "True negative rate: 98.080% (6385/6510)\n",
      "False positive rate: 1.920% (125/6510)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 0, 'true_negative': 499, 'false_negative': 0, 'negative': 499, 'positive': 1}, 'bird': {'true_positive': 1, 'false_positive': 2, 'true_negative': 493, 'false_negative': 4, 'negative': 495, 'positive': 5}, 'car': {'true_positive': 6, 'false_positive': 1, 'true_negative': 491, 'false_negative': 2, 'negative': 492, 'positive': 8}, 'clouds': {'true_positive': 9, 'false_positive': 5, 'true_negative': 472, 'false_negative': 14, 'negative': 477, 'positive': 23}, 'dog': {'true_positive': 5, 'false_positive': 1, 'true_negative': 492, 'false_negative': 2, 'negative': 493, 'positive': 7}, 'female': {'true_positive': 46, 'false_positive': 34, 'true_negative': 386, 'false_negative': 34, 'negative': 420, 'positive': 80}, 'flower': {'true_positive': 8, 'false_positive': 5, 'true_negative': 484, 'false_negative': 3, 'negative': 489, 'positive': 11}, 'male': {'true_positive': 37, 'false_positive': 13, 'true_negative': 401, 'false_negative': 49, 'negative': 414, 'positive': 86}, 'night': {'true_positive': 2, 'false_positive': 2, 'true_negative': 488, 'false_negative': 8, 'negative': 490, 'positive': 10}, 'people': {'true_positive': 115, 'false_positive': 24, 'true_negative': 318, 'false_negative': 43, 'negative': 342, 'positive': 158}, 'portrait': {'true_positive': 54, 'false_positive': 32, 'true_negative': 395, 'false_negative': 19, 'negative': 427, 'positive': 73}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 493, 'false_negative': 6, 'negative': 494, 'positive': 6}, 'sea': {'true_positive': 1, 'false_positive': 0, 'true_negative': 496, 'false_negative': 3, 'negative': 496, 'positive': 4}, 'tree': {'true_positive': 7, 'false_positive': 5, 'true_negative': 477, 'false_negative': 11, 'negative': 482, 'positive': 18}}\n",
      "------------------------\n",
      "Evaluating: Batch 6/51: Loss: 0.1388 | Test Acc: 95.571% (8028/8400) | Strict Acc: 61.833% (371/600)\n",
      "True positive rate: 61.824% (366/592)\n",
      "False negative rate: 38.176% (226/592)\n",
      "True negative rate: 98.130% (7662/7808)\n",
      "False positive rate: 1.870% (146/7808)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 0, 'true_negative': 599, 'false_negative': 0, 'negative': 599, 'positive': 1}, 'bird': {'true_positive': 1, 'false_positive': 3, 'true_negative': 592, 'false_negative': 4, 'negative': 595, 'positive': 5}, 'car': {'true_positive': 7, 'false_positive': 2, 'true_negative': 588, 'false_negative': 3, 'negative': 590, 'positive': 10}, 'clouds': {'true_positive': 12, 'false_positive': 6, 'true_negative': 568, 'false_negative': 14, 'negative': 574, 'positive': 26}, 'dog': {'true_positive': 9, 'false_positive': 1, 'true_negative': 587, 'false_negative': 3, 'negative': 588, 'positive': 12}, 'female': {'true_positive': 60, 'false_positive': 37, 'true_negative': 461, 'false_negative': 42, 'negative': 498, 'positive': 102}, 'flower': {'true_positive': 8, 'false_positive': 6, 'true_negative': 582, 'false_negative': 4, 'negative': 588, 'positive': 12}, 'male': {'true_positive': 44, 'false_positive': 17, 'true_negative': 484, 'false_negative': 55, 'negative': 501, 'positive': 99}, 'night': {'true_positive': 2, 'false_positive': 2, 'true_negative': 588, 'false_negative': 8, 'negative': 590, 'positive': 10}, 'people': {'true_positive': 141, 'false_positive': 30, 'true_negative': 382, 'false_negative': 47, 'negative': 412, 'positive': 188}, 'portrait': {'true_positive': 71, 'false_positive': 35, 'true_negative': 473, 'false_negative': 21, 'negative': 508, 'positive': 92}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 591, 'false_negative': 8, 'negative': 592, 'positive': 8}, 'sea': {'true_positive': 2, 'false_positive': 0, 'true_negative': 595, 'false_negative': 3, 'negative': 595, 'positive': 5}, 'tree': {'true_positive': 8, 'false_positive': 6, 'true_negative': 572, 'false_negative': 14, 'negative': 578, 'positive': 22}}\n",
      "------------------------\n",
      "Evaluating: Batch 7/51: Loss: 0.1376 | Test Acc: 95.541% (9363/9800) | Strict Acc: 62.000% (434/700)\n",
      "True positive rate: 63.262% (446/705)\n",
      "False negative rate: 36.738% (259/705)\n",
      "True negative rate: 98.043% (8917/9095)\n",
      "False positive rate: 1.957% (178/9095)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 0, 'true_negative': 699, 'false_negative': 0, 'negative': 699, 'positive': 1}, 'bird': {'true_positive': 1, 'false_positive': 3, 'true_negative': 692, 'false_negative': 4, 'negative': 695, 'positive': 5}, 'car': {'true_positive': 8, 'false_positive': 2, 'true_negative': 685, 'false_negative': 5, 'negative': 687, 'positive': 13}, 'clouds': {'true_positive': 16, 'false_positive': 7, 'true_negative': 658, 'false_negative': 19, 'negative': 665, 'positive': 35}, 'dog': {'true_positive': 11, 'false_positive': 3, 'true_negative': 683, 'false_negative': 3, 'negative': 686, 'positive': 14}, 'female': {'true_positive': 73, 'false_positive': 48, 'true_negative': 534, 'false_negative': 45, 'negative': 582, 'positive': 118}, 'flower': {'true_positive': 9, 'false_positive': 7, 'true_negative': 680, 'false_negative': 4, 'negative': 687, 'positive': 13}, 'male': {'true_positive': 51, 'false_positive': 21, 'true_negative': 561, 'false_negative': 67, 'negative': 582, 'positive': 118}, 'night': {'true_positive': 4, 'false_positive': 2, 'true_negative': 684, 'false_negative': 10, 'negative': 686, 'positive': 14}, 'people': {'true_positive': 171, 'false_positive': 36, 'true_negative': 443, 'false_negative': 50, 'negative': 479, 'positive': 221}, 'portrait': {'true_positive': 87, 'false_positive': 42, 'true_negative': 549, 'false_negative': 22, 'negative': 591, 'positive': 109}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 691, 'false_negative': 8, 'negative': 692, 'positive': 8}, 'sea': {'true_positive': 2, 'false_positive': 0, 'true_negative': 693, 'false_negative': 5, 'negative': 693, 'positive': 7}, 'tree': {'true_positive': 12, 'false_positive': 6, 'true_negative': 665, 'false_negative': 17, 'negative': 671, 'positive': 29}}\n",
      "------------------------\n",
      "Evaluating: Batch 8/51: Loss: 0.1378 | Test Acc: 95.518% (10698/11200) | Strict Acc: 61.625% (493/800)\n",
      "True positive rate: 63.263% (508/803)\n",
      "False negative rate: 36.737% (295/803)\n",
      "True negative rate: 98.009% (10190/10397)\n",
      "False positive rate: 1.991% (207/10397)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 0, 'true_negative': 799, 'false_negative': 0, 'negative': 799, 'positive': 1}, 'bird': {'true_positive': 2, 'false_positive': 3, 'true_negative': 790, 'false_negative': 5, 'negative': 793, 'positive': 7}, 'car': {'true_positive': 9, 'false_positive': 2, 'true_negative': 783, 'false_negative': 6, 'negative': 785, 'positive': 15}, 'clouds': {'true_positive': 18, 'false_positive': 8, 'true_negative': 753, 'false_negative': 21, 'negative': 761, 'positive': 39}, 'dog': {'true_positive': 13, 'false_positive': 3, 'true_negative': 779, 'false_negative': 5, 'negative': 782, 'positive': 18}, 'female': {'true_positive': 86, 'false_positive': 54, 'true_negative': 608, 'false_negative': 52, 'negative': 662, 'positive': 138}, 'flower': {'true_positive': 13, 'false_positive': 8, 'true_negative': 775, 'false_negative': 4, 'negative': 783, 'positive': 17}, 'male': {'true_positive': 56, 'false_positive': 23, 'true_negative': 648, 'false_negative': 73, 'negative': 671, 'positive': 129}, 'night': {'true_positive': 4, 'false_positive': 3, 'true_negative': 780, 'false_negative': 13, 'negative': 783, 'positive': 17}, 'people': {'true_positive': 194, 'false_positive': 45, 'true_negative': 502, 'false_negative': 59, 'negative': 547, 'positive': 253}, 'portrait': {'true_positive': 97, 'false_positive': 50, 'true_negative': 629, 'false_negative': 24, 'negative': 679, 'positive': 121}, 'river': {'true_positive': 0, 'false_positive': 1, 'true_negative': 790, 'false_negative': 9, 'negative': 791, 'positive': 9}, 'sea': {'true_positive': 2, 'false_positive': 0, 'true_negative': 793, 'false_negative': 5, 'negative': 793, 'positive': 7}, 'tree': {'true_positive': 13, 'false_positive': 7, 'true_negative': 761, 'false_negative': 19, 'negative': 768, 'positive': 32}}\n",
      "------------------------\n",
      "Evaluating: Batch 9/51: Loss: 0.1375 | Test Acc: 95.556% (12040/12600) | Strict Acc: 61.444% (553/900)\n",
      "True positive rate: 62.655% (557/889)\n",
      "False negative rate: 37.345% (332/889)\n",
      "True negative rate: 98.053% (11483/11711)\n",
      "False positive rate: 1.947% (228/11711)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 0, 'true_negative': 899, 'false_negative': 0, 'negative': 899, 'positive': 1}, 'bird': {'true_positive': 5, 'false_positive': 3, 'true_negative': 886, 'false_negative': 6, 'negative': 889, 'positive': 11}, 'car': {'true_positive': 14, 'false_positive': 2, 'true_negative': 877, 'false_negative': 7, 'negative': 879, 'positive': 21}, 'clouds': {'true_positive': 19, 'false_positive': 9, 'true_negative': 846, 'false_negative': 26, 'negative': 855, 'positive': 45}, 'dog': {'true_positive': 14, 'false_positive': 3, 'true_negative': 878, 'false_negative': 5, 'negative': 881, 'positive': 19}, 'female': {'true_positive': 92, 'false_positive': 58, 'true_negative': 693, 'false_negative': 57, 'negative': 751, 'positive': 149}, 'flower': {'true_positive': 15, 'false_positive': 11, 'true_negative': 869, 'false_negative': 5, 'negative': 880, 'positive': 20}, 'male': {'true_positive': 62, 'false_positive': 27, 'true_negative': 731, 'false_negative': 80, 'negative': 758, 'positive': 142}, 'night': {'true_positive': 5, 'false_positive': 3, 'true_negative': 877, 'false_negative': 15, 'negative': 880, 'positive': 20}, 'people': {'true_positive': 209, 'false_positive': 49, 'true_negative': 575, 'false_negative': 67, 'negative': 624, 'positive': 276}, 'portrait': {'true_positive': 105, 'false_positive': 53, 'true_negative': 715, 'false_negative': 27, 'negative': 768, 'positive': 132}, 'river': {'true_positive': 0, 'false_positive': 2, 'true_negative': 888, 'false_negative': 10, 'negative': 890, 'positive': 10}, 'sea': {'true_positive': 2, 'false_positive': 0, 'true_negative': 891, 'false_negative': 7, 'negative': 891, 'positive': 9}, 'tree': {'true_positive': 14, 'false_positive': 8, 'true_negative': 858, 'false_negative': 20, 'negative': 866, 'positive': 34}}\n",
      "------------------------\n",
      "Evaluating: Batch 10/51: Loss: 0.1340 | Test Acc: 95.636% (13389/14000) | Strict Acc: 62.400% (624/1000)\n",
      "True positive rate: 62.526% (609/974)\n",
      "False negative rate: 37.474% (365/974)\n",
      "True negative rate: 98.111% (12780/13026)\n",
      "False positive rate: 1.889% (246/13026)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 0, 'true_negative': 999, 'false_negative': 0, 'negative': 999, 'positive': 1}, 'bird': {'true_positive': 6, 'false_positive': 4, 'true_negative': 984, 'false_negative': 6, 'negative': 988, 'positive': 12}, 'car': {'true_positive': 16, 'false_positive': 3, 'true_negative': 974, 'false_negative': 7, 'negative': 977, 'positive': 23}, 'clouds': {'true_positive': 21, 'false_positive': 10, 'true_negative': 942, 'false_negative': 27, 'negative': 952, 'positive': 48}, 'dog': {'true_positive': 15, 'false_positive': 4, 'true_negative': 976, 'false_negative': 5, 'negative': 980, 'positive': 20}, 'female': {'true_positive': 97, 'false_positive': 65, 'true_negative': 778, 'false_negative': 60, 'negative': 843, 'positive': 157}, 'flower': {'true_positive': 16, 'false_positive': 12, 'true_negative': 966, 'false_negative': 6, 'negative': 978, 'positive': 22}, 'male': {'true_positive': 67, 'false_positive': 27, 'true_negative': 816, 'false_negative': 90, 'negative': 843, 'positive': 157}, 'night': {'true_positive': 6, 'false_positive': 3, 'true_negative': 973, 'false_negative': 18, 'negative': 976, 'positive': 24}, 'people': {'true_positive': 230, 'false_positive': 52, 'true_negative': 640, 'false_negative': 78, 'negative': 692, 'positive': 308}, 'portrait': {'true_positive': 118, 'false_positive': 56, 'true_negative': 795, 'false_negative': 31, 'negative': 851, 'positive': 149}, 'river': {'true_positive': 0, 'false_positive': 2, 'true_negative': 988, 'false_negative': 10, 'negative': 990, 'positive': 10}, 'sea': {'true_positive': 2, 'false_positive': 0, 'true_negative': 991, 'false_negative': 7, 'negative': 991, 'positive': 9}, 'tree': {'true_positive': 14, 'false_positive': 8, 'true_negative': 958, 'false_negative': 20, 'negative': 966, 'positive': 34}}\n",
      "------------------------\n",
      "Evaluating: Batch 11/51: Loss: 0.1319 | Test Acc: 95.656% (14731/15400) | Strict Acc: 61.727% (679/1100)\n",
      "True positive rate: 63.265% (682/1078)\n",
      "False negative rate: 36.735% (396/1078)\n",
      "True negative rate: 98.094% (14049/14322)\n",
      "False positive rate: 1.906% (273/14322)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 1, 'true_negative': 1098, 'false_negative': 0, 'negative': 1099, 'positive': 1}, 'bird': {'true_positive': 7, 'false_positive': 4, 'true_negative': 1083, 'false_negative': 6, 'negative': 1087, 'positive': 13}, 'car': {'true_positive': 23, 'false_positive': 4, 'true_negative': 1066, 'false_negative': 7, 'negative': 1070, 'positive': 30}, 'clouds': {'true_positive': 22, 'false_positive': 13, 'true_negative': 1036, 'false_negative': 29, 'negative': 1049, 'positive': 51}, 'dog': {'true_positive': 16, 'false_positive': 6, 'true_negative': 1073, 'false_negative': 5, 'negative': 1079, 'positive': 21}, 'female': {'true_positive': 111, 'false_positive': 70, 'true_negative': 856, 'false_negative': 63, 'negative': 926, 'positive': 174}, 'flower': {'true_positive': 19, 'false_positive': 14, 'true_negative': 1060, 'false_negative': 7, 'negative': 1074, 'positive': 26}, 'male': {'true_positive': 73, 'false_positive': 30, 'true_negative': 900, 'false_negative': 97, 'negative': 930, 'positive': 170}, 'night': {'true_positive': 6, 'false_positive': 3, 'true_negative': 1068, 'false_negative': 23, 'negative': 1071, 'positive': 29}, 'people': {'true_positive': 255, 'false_positive': 60, 'true_negative': 700, 'false_negative': 85, 'negative': 760, 'positive': 340}, 'portrait': {'true_positive': 132, 'false_positive': 58, 'true_negative': 876, 'false_negative': 34, 'negative': 934, 'positive': 166}, 'river': {'true_positive': 0, 'false_positive': 2, 'true_negative': 1086, 'false_negative': 12, 'negative': 1088, 'positive': 12}, 'sea': {'true_positive': 3, 'false_positive': 0, 'true_negative': 1090, 'false_negative': 7, 'negative': 1090, 'positive': 10}, 'tree': {'true_positive': 14, 'false_positive': 8, 'true_negative': 1057, 'false_negative': 21, 'negative': 1065, 'positive': 35}}\n",
      "------------------------\n",
      "Evaluating: Batch 12/51: Loss: 0.1325 | Test Acc: 95.732% (16083/16800) | Strict Acc: 62.167% (746/1200)\n",
      "True positive rate: 63.667% (750/1178)\n",
      "False negative rate: 36.333% (428/1178)\n",
      "True negative rate: 98.150% (15333/15622)\n",
      "False positive rate: 1.850% (289/15622)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 1, 'true_negative': 1197, 'false_negative': 1, 'negative': 1198, 'positive': 2}, 'bird': {'true_positive': 8, 'false_positive': 4, 'true_negative': 1181, 'false_negative': 7, 'negative': 1185, 'positive': 15}, 'car': {'true_positive': 23, 'false_positive': 4, 'true_negative': 1166, 'false_negative': 7, 'negative': 1170, 'positive': 30}, 'clouds': {'true_positive': 23, 'false_positive': 14, 'true_negative': 1130, 'false_negative': 33, 'negative': 1144, 'positive': 56}, 'dog': {'true_positive': 17, 'false_positive': 6, 'true_negative': 1172, 'false_negative': 5, 'negative': 1178, 'positive': 22}, 'female': {'true_positive': 120, 'false_positive': 72, 'true_negative': 940, 'false_negative': 68, 'negative': 1012, 'positive': 188}, 'flower': {'true_positive': 28, 'false_positive': 15, 'true_negative': 1149, 'false_negative': 8, 'negative': 1164, 'positive': 36}, 'male': {'true_positive': 84, 'false_positive': 32, 'true_negative': 984, 'false_negative': 100, 'negative': 1016, 'positive': 184}, 'night': {'true_positive': 6, 'false_positive': 3, 'true_negative': 1163, 'false_negative': 28, 'negative': 1166, 'positive': 34}, 'people': {'true_positive': 282, 'false_positive': 61, 'true_negative': 766, 'false_negative': 91, 'negative': 827, 'positive': 373}, 'portrait': {'true_positive': 141, 'false_positive': 66, 'true_negative': 956, 'false_negative': 37, 'negative': 1022, 'positive': 178}, 'river': {'true_positive': 0, 'false_positive': 2, 'true_negative': 1186, 'false_negative': 12, 'negative': 1188, 'positive': 12}, 'sea': {'true_positive': 3, 'false_positive': 0, 'true_negative': 1189, 'false_negative': 8, 'negative': 1189, 'positive': 11}, 'tree': {'true_positive': 14, 'false_positive': 9, 'true_negative': 1154, 'false_negative': 23, 'negative': 1163, 'positive': 37}}\n",
      "------------------------\n",
      "Evaluating: Batch 13/51: Loss: 0.1300 | Test Acc: 95.786% (17433/18200) | Strict Acc: 62.231% (809/1300)\n",
      "True positive rate: 64.319% (822/1278)\n",
      "False negative rate: 35.681% (456/1278)\n",
      "True negative rate: 98.162% (16611/16922)\n",
      "False positive rate: 1.838% (311/16922)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 1, 'true_negative': 1297, 'false_negative': 1, 'negative': 1298, 'positive': 2}, 'bird': {'true_positive': 10, 'false_positive': 4, 'true_negative': 1278, 'false_negative': 8, 'negative': 1282, 'positive': 18}, 'car': {'true_positive': 26, 'false_positive': 5, 'true_negative': 1262, 'false_negative': 7, 'negative': 1267, 'positive': 33}, 'clouds': {'true_positive': 27, 'false_positive': 14, 'true_negative': 1226, 'false_negative': 33, 'negative': 1240, 'positive': 60}, 'dog': {'true_positive': 18, 'false_positive': 6, 'true_negative': 1270, 'false_negative': 6, 'negative': 1276, 'positive': 24}, 'female': {'true_positive': 134, 'false_positive': 78, 'true_negative': 1015, 'false_negative': 73, 'negative': 1093, 'positive': 207}, 'flower': {'true_positive': 30, 'false_positive': 15, 'true_negative': 1247, 'false_negative': 8, 'negative': 1262, 'positive': 38}, 'male': {'true_positive': 91, 'false_positive': 39, 'true_negative': 1066, 'false_negative': 104, 'negative': 1105, 'positive': 195}, 'night': {'true_positive': 6, 'false_positive': 3, 'true_negative': 1259, 'false_negative': 32, 'negative': 1262, 'positive': 38}, 'people': {'true_positive': 308, 'false_positive': 65, 'true_negative': 830, 'false_negative': 97, 'negative': 895, 'positive': 405}, 'portrait': {'true_positive': 153, 'false_positive': 69, 'true_negative': 1037, 'false_negative': 41, 'negative': 1106, 'positive': 194}, 'river': {'true_positive': 0, 'false_positive': 2, 'true_negative': 1286, 'false_negative': 12, 'negative': 1288, 'positive': 12}, 'sea': {'true_positive': 3, 'false_positive': 0, 'true_negative': 1289, 'false_negative': 8, 'negative': 1289, 'positive': 11}, 'tree': {'true_positive': 15, 'false_positive': 10, 'true_negative': 1249, 'false_negative': 26, 'negative': 1259, 'positive': 41}}\n",
      "------------------------\n",
      "Evaluating: Batch 14/51: Loss: 0.1286 | Test Acc: 95.847% (18786/19600) | Strict Acc: 62.857% (880/1400)\n",
      "True positive rate: 64.270% (867/1349)\n",
      "False negative rate: 35.730% (482/1349)\n",
      "True negative rate: 98.181% (17919/18251)\n",
      "False positive rate: 1.819% (332/18251)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 1, 'false_positive': 1, 'true_negative': 1397, 'false_negative': 1, 'negative': 1398, 'positive': 2}, 'bird': {'true_positive': 10, 'false_positive': 6, 'true_negative': 1376, 'false_negative': 8, 'negative': 1382, 'positive': 18}, 'car': {'true_positive': 29, 'false_positive': 5, 'true_negative': 1359, 'false_negative': 7, 'negative': 1364, 'positive': 36}, 'clouds': {'true_positive': 28, 'false_positive': 14, 'true_negative': 1323, 'false_negative': 35, 'negative': 1337, 'positive': 63}, 'dog': {'true_positive': 20, 'false_positive': 7, 'true_negative': 1367, 'false_negative': 6, 'negative': 1374, 'positive': 26}, 'female': {'true_positive': 141, 'false_positive': 82, 'true_negative': 1098, 'false_negative': 79, 'negative': 1180, 'positive': 220}, 'flower': {'true_positive': 31, 'false_positive': 16, 'true_negative': 1344, 'false_negative': 9, 'negative': 1360, 'positive': 40}, 'male': {'true_positive': 95, 'false_positive': 41, 'true_negative': 1155, 'false_negative': 109, 'negative': 1196, 'positive': 204}, 'night': {'true_positive': 8, 'false_positive': 3, 'true_negative': 1355, 'false_negative': 34, 'negative': 1358, 'positive': 42}, 'people': {'true_positive': 323, 'false_positive': 72, 'true_negative': 901, 'false_negative': 104, 'negative': 973, 'positive': 427}, 'portrait': {'true_positive': 162, 'false_positive': 73, 'true_negative': 1122, 'false_negative': 43, 'negative': 1195, 'positive': 205}, 'river': {'true_positive': 0, 'false_positive': 2, 'true_negative': 1386, 'false_negative': 12, 'negative': 1388, 'positive': 12}, 'sea': {'true_positive': 3, 'false_positive': 0, 'true_negative': 1389, 'false_negative': 8, 'negative': 1389, 'positive': 11}, 'tree': {'true_positive': 16, 'false_positive': 10, 'true_negative': 1347, 'false_negative': 27, 'negative': 1357, 'positive': 43}}\n",
      "------------------------\n",
      "Evaluating: Batch 15/51: Loss: 0.1291 | Test Acc: 95.795% (20117/21000) | Strict Acc: 62.267% (934/1500)\n",
      "True positive rate: 64.295% (940/1462)\n",
      "False negative rate: 35.705% (522/1462)\n",
      "True negative rate: 98.152% (19177/19538)\n",
      "False positive rate: 1.848% (361/19538)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 1, 'true_negative': 1496, 'false_negative': 1, 'negative': 1497, 'positive': 3}, 'bird': {'true_positive': 10, 'false_positive': 7, 'true_negative': 1474, 'false_negative': 9, 'negative': 1481, 'positive': 19}, 'car': {'true_positive': 31, 'false_positive': 5, 'true_negative': 1456, 'false_negative': 8, 'negative': 1461, 'positive': 39}, 'clouds': {'true_positive': 31, 'false_positive': 15, 'true_negative': 1414, 'false_negative': 40, 'negative': 1429, 'positive': 71}, 'dog': {'true_positive': 20, 'false_positive': 7, 'true_negative': 1467, 'false_negative': 6, 'negative': 1474, 'positive': 26}, 'female': {'true_positive': 155, 'false_positive': 89, 'true_negative': 1170, 'false_negative': 86, 'negative': 1259, 'positive': 241}, 'flower': {'true_positive': 31, 'false_positive': 16, 'true_negative': 1444, 'false_negative': 9, 'negative': 1460, 'positive': 40}, 'male': {'true_positive': 101, 'false_positive': 43, 'true_negative': 1239, 'false_negative': 117, 'negative': 1282, 'positive': 218}, 'night': {'true_positive': 9, 'false_positive': 5, 'true_negative': 1451, 'false_negative': 35, 'negative': 1456, 'positive': 44}, 'people': {'true_positive': 352, 'false_positive': 81, 'true_negative': 954, 'false_negative': 113, 'negative': 1035, 'positive': 465}, 'portrait': {'true_positive': 178, 'false_positive': 79, 'true_negative': 1195, 'false_negative': 48, 'negative': 1274, 'positive': 226}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 1483, 'false_negative': 14, 'negative': 1486, 'positive': 14}, 'sea': {'true_positive': 3, 'false_positive': 0, 'true_negative': 1488, 'false_negative': 9, 'negative': 1488, 'positive': 12}, 'tree': {'true_positive': 17, 'false_positive': 10, 'true_negative': 1446, 'false_negative': 27, 'negative': 1456, 'positive': 44}}\n",
      "------------------------\n",
      "Evaluating: Batch 16/51: Loss: 0.1292 | Test Acc: 95.799% (21459/22400) | Strict Acc: 62.438% (999/1600)\n",
      "True positive rate: 64.409% (1008/1565)\n",
      "False negative rate: 35.591% (557/1565)\n",
      "True negative rate: 98.157% (20451/20835)\n",
      "False positive rate: 1.843% (384/20835)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 1, 'true_negative': 1594, 'false_negative': 3, 'negative': 1595, 'positive': 5}, 'bird': {'true_positive': 11, 'false_positive': 7, 'true_negative': 1573, 'false_negative': 9, 'negative': 1580, 'positive': 20}, 'car': {'true_positive': 33, 'false_positive': 6, 'true_negative': 1553, 'false_negative': 8, 'negative': 1559, 'positive': 41}, 'clouds': {'true_positive': 33, 'false_positive': 15, 'true_negative': 1508, 'false_negative': 44, 'negative': 1523, 'positive': 77}, 'dog': {'true_positive': 24, 'false_positive': 8, 'true_negative': 1561, 'false_negative': 7, 'negative': 1569, 'positive': 31}, 'female': {'true_positive': 169, 'false_positive': 96, 'true_negative': 1247, 'false_negative': 88, 'negative': 1343, 'positive': 257}, 'flower': {'true_positive': 35, 'false_positive': 16, 'true_negative': 1538, 'false_negative': 11, 'negative': 1554, 'positive': 46}, 'male': {'true_positive': 105, 'false_positive': 46, 'true_negative': 1320, 'false_negative': 129, 'negative': 1366, 'positive': 234}, 'night': {'true_positive': 9, 'false_positive': 6, 'true_negative': 1549, 'false_negative': 36, 'negative': 1555, 'positive': 45}, 'people': {'true_positive': 376, 'false_positive': 85, 'true_negative': 1019, 'false_negative': 120, 'negative': 1104, 'positive': 496}, 'portrait': {'true_positive': 190, 'false_positive': 84, 'true_negative': 1276, 'false_negative': 50, 'negative': 1360, 'positive': 240}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 1582, 'false_negative': 15, 'negative': 1585, 'positive': 15}, 'sea': {'true_positive': 3, 'false_positive': 0, 'true_negative': 1587, 'false_negative': 10, 'negative': 1587, 'positive': 13}, 'tree': {'true_positive': 18, 'false_positive': 11, 'true_negative': 1544, 'false_negative': 27, 'negative': 1555, 'positive': 45}}\n",
      "------------------------\n",
      "Evaluating: Batch 17/51: Loss: 0.1285 | Test Acc: 95.819% (22805/23800) | Strict Acc: 62.412% (1061/1700)\n",
      "True positive rate: 64.450% (1066/1654)\n",
      "False negative rate: 35.550% (588/1654)\n",
      "True negative rate: 98.162% (21739/22146)\n",
      "False positive rate: 1.838% (407/22146)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 1, 'true_negative': 1694, 'false_negative': 3, 'negative': 1695, 'positive': 5}, 'bird': {'true_positive': 12, 'false_positive': 8, 'true_negative': 1670, 'false_negative': 10, 'negative': 1678, 'positive': 22}, 'car': {'true_positive': 36, 'false_positive': 6, 'true_negative': 1650, 'false_negative': 8, 'negative': 1656, 'positive': 44}, 'clouds': {'true_positive': 35, 'false_positive': 18, 'true_negative': 1597, 'false_negative': 50, 'negative': 1615, 'positive': 85}, 'dog': {'true_positive': 25, 'false_positive': 9, 'true_negative': 1658, 'false_negative': 8, 'negative': 1667, 'positive': 33}, 'female': {'true_positive': 178, 'false_positive': 100, 'true_negative': 1330, 'false_negative': 92, 'negative': 1430, 'positive': 270}, 'flower': {'true_positive': 38, 'false_positive': 18, 'true_negative': 1632, 'false_negative': 12, 'negative': 1650, 'positive': 50}, 'male': {'true_positive': 114, 'false_positive': 50, 'true_negative': 1404, 'false_negative': 132, 'negative': 1454, 'positive': 246}, 'night': {'true_positive': 9, 'false_positive': 6, 'true_negative': 1648, 'false_negative': 37, 'negative': 1654, 'positive': 46}, 'people': {'true_positive': 398, 'false_positive': 89, 'true_negative': 1085, 'false_negative': 128, 'negative': 1174, 'positive': 526}, 'portrait': {'true_positive': 197, 'false_positive': 86, 'true_negative': 1364, 'false_negative': 53, 'negative': 1450, 'positive': 250}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 1680, 'false_negative': 17, 'negative': 1683, 'positive': 17}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 1684, 'false_negative': 11, 'negative': 1686, 'positive': 14}, 'tree': {'true_positive': 19, 'false_positive': 11, 'true_negative': 1643, 'false_negative': 27, 'negative': 1654, 'positive': 46}}\n",
      "------------------------\n",
      "Evaluating: Batch 18/51: Loss: 0.1284 | Test Acc: 95.794% (24140/25200) | Strict Acc: 62.111% (1118/1800)\n",
      "True positive rate: 64.450% (1124/1744)\n",
      "False negative rate: 35.550% (620/1744)\n",
      "True negative rate: 98.124% (23016/23456)\n",
      "False positive rate: 1.876% (440/23456)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 1793, 'false_negative': 3, 'negative': 1795, 'positive': 5}, 'bird': {'true_positive': 12, 'false_positive': 10, 'true_negative': 1768, 'false_negative': 10, 'negative': 1778, 'positive': 22}, 'car': {'true_positive': 38, 'false_positive': 6, 'true_negative': 1747, 'false_negative': 9, 'negative': 1753, 'positive': 47}, 'clouds': {'true_positive': 37, 'false_positive': 20, 'true_negative': 1690, 'false_negative': 53, 'negative': 1710, 'positive': 90}, 'dog': {'true_positive': 25, 'false_positive': 10, 'true_negative': 1757, 'false_negative': 8, 'negative': 1767, 'positive': 33}, 'female': {'true_positive': 186, 'false_positive': 109, 'true_negative': 1410, 'false_negative': 95, 'negative': 1519, 'positive': 281}, 'flower': {'true_positive': 41, 'false_positive': 19, 'true_negative': 1724, 'false_negative': 16, 'negative': 1743, 'positive': 57}, 'male': {'true_positive': 122, 'false_positive': 54, 'true_negative': 1482, 'false_negative': 142, 'negative': 1536, 'positive': 264}, 'night': {'true_positive': 10, 'false_positive': 7, 'true_negative': 1746, 'false_negative': 37, 'negative': 1753, 'positive': 47}, 'people': {'true_positive': 420, 'false_positive': 96, 'true_negative': 1151, 'false_negative': 133, 'negative': 1247, 'positive': 553}, 'portrait': {'true_positive': 209, 'false_positive': 90, 'true_negative': 1444, 'false_negative': 57, 'negative': 1534, 'positive': 266}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 1780, 'false_negative': 17, 'negative': 1783, 'positive': 17}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 1783, 'false_negative': 12, 'negative': 1785, 'positive': 15}, 'tree': {'true_positive': 19, 'false_positive': 12, 'true_negative': 1741, 'false_negative': 28, 'negative': 1753, 'positive': 47}}\n",
      "------------------------\n",
      "Evaluating: Batch 19/51: Loss: 0.1290 | Test Acc: 95.786% (25479/26600) | Strict Acc: 62.000% (1178/1900)\n",
      "True positive rate: 64.763% (1202/1856)\n",
      "False negative rate: 35.237% (654/1856)\n",
      "True negative rate: 98.113% (24277/24744)\n",
      "False positive rate: 1.887% (467/24744)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 1893, 'false_negative': 3, 'negative': 1895, 'positive': 5}, 'bird': {'true_positive': 12, 'false_positive': 13, 'true_negative': 1865, 'false_negative': 10, 'negative': 1878, 'positive': 22}, 'car': {'true_positive': 40, 'false_positive': 6, 'true_negative': 1845, 'false_negative': 9, 'negative': 1851, 'positive': 49}, 'clouds': {'true_positive': 40, 'false_positive': 20, 'true_negative': 1784, 'false_negative': 56, 'negative': 1804, 'positive': 96}, 'dog': {'true_positive': 26, 'false_positive': 10, 'true_negative': 1854, 'false_negative': 10, 'negative': 1864, 'positive': 36}, 'female': {'true_positive': 201, 'false_positive': 116, 'true_negative': 1483, 'false_negative': 100, 'negative': 1599, 'positive': 301}, 'flower': {'true_positive': 46, 'false_positive': 20, 'true_negative': 1817, 'false_negative': 17, 'negative': 1837, 'positive': 63}, 'male': {'true_positive': 132, 'false_positive': 57, 'true_negative': 1563, 'false_negative': 148, 'negative': 1620, 'positive': 280}, 'night': {'true_positive': 10, 'false_positive': 7, 'true_negative': 1843, 'false_negative': 40, 'negative': 1850, 'positive': 50}, 'people': {'true_positive': 446, 'false_positive': 104, 'true_negative': 1212, 'false_negative': 138, 'negative': 1316, 'positive': 584}, 'portrait': {'true_positive': 223, 'false_positive': 95, 'true_negative': 1520, 'false_negative': 62, 'negative': 1615, 'positive': 285}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 1879, 'false_negative': 18, 'negative': 1882, 'positive': 18}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 1881, 'false_negative': 14, 'negative': 1883, 'positive': 17}, 'tree': {'true_positive': 21, 'false_positive': 12, 'true_negative': 1838, 'false_negative': 29, 'negative': 1850, 'positive': 50}}\n",
      "------------------------\n",
      "Evaluating: Batch 20/51: Loss: 0.1294 | Test Acc: 95.775% (26817/28000) | Strict Acc: 62.100% (1242/2000)\n",
      "True positive rate: 64.825% (1279/1973)\n",
      "False negative rate: 35.175% (694/1973)\n",
      "True negative rate: 98.121% (25538/26027)\n",
      "False positive rate: 1.879% (489/26027)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 1993, 'false_negative': 3, 'negative': 1995, 'positive': 5}, 'bird': {'true_positive': 14, 'false_positive': 15, 'true_negative': 1961, 'false_negative': 10, 'negative': 1976, 'positive': 24}, 'car': {'true_positive': 41, 'false_positive': 6, 'true_negative': 1944, 'false_negative': 9, 'negative': 1950, 'positive': 50}, 'clouds': {'true_positive': 41, 'false_positive': 20, 'true_negative': 1879, 'false_negative': 60, 'negative': 1899, 'positive': 101}, 'dog': {'true_positive': 26, 'false_positive': 10, 'true_negative': 1954, 'false_negative': 10, 'negative': 1964, 'positive': 36}, 'female': {'true_positive': 217, 'false_positive': 122, 'true_negative': 1555, 'false_negative': 106, 'negative': 1677, 'positive': 323}, 'flower': {'true_positive': 49, 'false_positive': 21, 'true_negative': 1913, 'false_negative': 17, 'negative': 1934, 'positive': 66}, 'male': {'true_positive': 140, 'false_positive': 58, 'true_negative': 1644, 'false_negative': 158, 'negative': 1702, 'positive': 298}, 'night': {'true_positive': 10, 'false_positive': 7, 'true_negative': 1943, 'false_negative': 40, 'negative': 1950, 'positive': 50}, 'people': {'true_positive': 476, 'false_positive': 111, 'true_negative': 1265, 'false_negative': 148, 'negative': 1376, 'positive': 624}, 'portrait': {'true_positive': 239, 'false_positive': 100, 'true_negative': 1593, 'false_negative': 68, 'negative': 1693, 'positive': 307}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 1977, 'false_negative': 20, 'negative': 1980, 'positive': 20}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 1980, 'false_negative': 15, 'negative': 1982, 'positive': 18}, 'tree': {'true_positive': 21, 'false_positive': 12, 'true_negative': 1937, 'false_negative': 30, 'negative': 1949, 'positive': 51}}\n",
      "------------------------\n",
      "Evaluating: Batch 21/51: Loss: 0.1295 | Test Acc: 95.765% (28155/29400) | Strict Acc: 62.048% (1303/2100)\n",
      "True positive rate: 64.810% (1350/2083)\n",
      "False negative rate: 35.190% (733/2083)\n",
      "True negative rate: 98.126% (26805/27317)\n",
      "False positive rate: 1.874% (512/27317)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 2092, 'false_negative': 4, 'negative': 2094, 'positive': 6}, 'bird': {'true_positive': 15, 'false_positive': 15, 'true_negative': 2060, 'false_negative': 10, 'negative': 2075, 'positive': 25}, 'car': {'true_positive': 42, 'false_positive': 7, 'true_negative': 2041, 'false_negative': 10, 'negative': 2048, 'positive': 52}, 'clouds': {'true_positive': 43, 'false_positive': 21, 'true_negative': 1974, 'false_negative': 62, 'negative': 1995, 'positive': 105}, 'dog': {'true_positive': 28, 'false_positive': 11, 'true_negative': 2049, 'false_negative': 12, 'negative': 2060, 'positive': 40}, 'female': {'true_positive': 228, 'false_positive': 128, 'true_negative': 1631, 'false_negative': 113, 'negative': 1759, 'positive': 341}, 'flower': {'true_positive': 52, 'false_positive': 21, 'true_negative': 2009, 'false_negative': 18, 'negative': 2030, 'positive': 70}, 'male': {'true_positive': 149, 'false_positive': 63, 'true_negative': 1724, 'false_negative': 164, 'negative': 1787, 'positive': 313}, 'night': {'true_positive': 11, 'false_positive': 8, 'true_negative': 2041, 'false_negative': 40, 'negative': 2049, 'positive': 51}, 'people': {'true_positive': 504, 'false_positive': 114, 'true_negative': 1325, 'false_negative': 157, 'negative': 1439, 'positive': 661}, 'portrait': {'true_positive': 252, 'false_positive': 105, 'true_negative': 1668, 'false_negative': 75, 'negative': 1773, 'positive': 327}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 2077, 'false_negative': 20, 'negative': 2080, 'positive': 20}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 2077, 'false_negative': 18, 'negative': 2079, 'positive': 21}, 'tree': {'true_positive': 21, 'false_positive': 12, 'true_negative': 2037, 'false_negative': 30, 'negative': 2049, 'positive': 51}}\n",
      "------------------------\n",
      "Evaluating: Batch 22/51: Loss: 0.1284 | Test Acc: 95.782% (29501/30800) | Strict Acc: 62.091% (1366/2200)\n",
      "True positive rate: 64.936% (1413/2176)\n",
      "False negative rate: 35.064% (763/2176)\n",
      "True negative rate: 98.127% (28088/28624)\n",
      "False positive rate: 1.873% (536/28624)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 2192, 'false_negative': 4, 'negative': 2194, 'positive': 6}, 'bird': {'true_positive': 15, 'false_positive': 17, 'true_negative': 2158, 'false_negative': 10, 'negative': 2175, 'positive': 25}, 'car': {'true_positive': 42, 'false_positive': 7, 'true_negative': 2141, 'false_negative': 10, 'negative': 2148, 'positive': 52}, 'clouds': {'true_positive': 46, 'false_positive': 22, 'true_negative': 2067, 'false_negative': 65, 'negative': 2089, 'positive': 111}, 'dog': {'true_positive': 29, 'false_positive': 11, 'true_negative': 2148, 'false_negative': 12, 'negative': 2159, 'positive': 41}, 'female': {'true_positive': 234, 'false_positive': 133, 'true_negative': 1718, 'false_negative': 115, 'negative': 1851, 'positive': 349}, 'flower': {'true_positive': 54, 'false_positive': 24, 'true_negative': 2102, 'false_negative': 20, 'negative': 2126, 'positive': 74}, 'male': {'true_positive': 160, 'false_positive': 68, 'true_negative': 1799, 'false_negative': 173, 'negative': 1867, 'positive': 333}, 'night': {'true_positive': 11, 'false_positive': 8, 'true_negative': 2139, 'false_negative': 42, 'negative': 2147, 'positive': 53}, 'people': {'true_positive': 527, 'false_positive': 120, 'true_negative': 1390, 'false_negative': 163, 'negative': 1510, 'positive': 690}, 'portrait': {'true_positive': 269, 'false_positive': 106, 'true_negative': 1747, 'false_negative': 78, 'negative': 1853, 'positive': 347}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 2175, 'false_negative': 22, 'negative': 2178, 'positive': 22}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 2177, 'false_negative': 18, 'negative': 2179, 'positive': 21}, 'tree': {'true_positive': 21, 'false_positive': 13, 'true_negative': 2135, 'false_negative': 31, 'negative': 2148, 'positive': 52}}\n",
      "------------------------\n",
      "Evaluating: Batch 23/51: Loss: 0.1289 | Test Acc: 95.776% (30840/32200) | Strict Acc: 61.957% (1425/2300)\n",
      "True positive rate: 64.320% (1462/2273)\n",
      "False negative rate: 35.680% (811/2273)\n",
      "True negative rate: 98.166% (29378/29927)\n",
      "False positive rate: 1.834% (549/29927)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 2292, 'false_negative': 4, 'negative': 2294, 'positive': 6}, 'bird': {'true_positive': 16, 'false_positive': 19, 'true_negative': 2254, 'false_negative': 11, 'negative': 2273, 'positive': 27}, 'car': {'true_positive': 44, 'false_positive': 7, 'true_negative': 2239, 'false_negative': 10, 'negative': 2246, 'positive': 54}, 'clouds': {'true_positive': 51, 'false_positive': 23, 'true_negative': 2156, 'false_negative': 70, 'negative': 2179, 'positive': 121}, 'dog': {'true_positive': 31, 'false_positive': 11, 'true_negative': 2245, 'false_negative': 13, 'negative': 2256, 'positive': 44}, 'female': {'true_positive': 241, 'false_positive': 133, 'true_negative': 1804, 'false_negative': 122, 'negative': 1937, 'positive': 363}, 'flower': {'true_positive': 58, 'false_positive': 25, 'true_negative': 2193, 'false_negative': 24, 'negative': 2218, 'positive': 82}, 'male': {'true_positive': 165, 'false_positive': 70, 'true_negative': 1887, 'false_negative': 178, 'negative': 1957, 'positive': 343}, 'night': {'true_positive': 11, 'false_positive': 9, 'true_negative': 2234, 'false_negative': 46, 'negative': 2243, 'positive': 57}, 'people': {'true_positive': 542, 'false_positive': 122, 'true_negative': 1459, 'false_negative': 177, 'negative': 1581, 'positive': 719}, 'portrait': {'true_positive': 277, 'false_positive': 110, 'true_negative': 1835, 'false_negative': 78, 'negative': 1945, 'positive': 355}, 'river': {'true_positive': 0, 'false_positive': 3, 'true_negative': 2274, 'false_negative': 23, 'negative': 2277, 'positive': 23}, 'sea': {'true_positive': 3, 'false_positive': 2, 'true_negative': 2274, 'false_negative': 21, 'negative': 2276, 'positive': 24}, 'tree': {'true_positive': 21, 'false_positive': 13, 'true_negative': 2232, 'false_negative': 34, 'negative': 2245, 'positive': 55}}\n",
      "------------------------\n",
      "Evaluating: Batch 24/51: Loss: 0.1277 | Test Acc: 95.815% (32194/33600) | Strict Acc: 62.208% (1493/2400)\n",
      "True positive rate: 64.539% (1527/2366)\n",
      "False negative rate: 35.461% (839/2366)\n",
      "True negative rate: 98.185% (30667/31234)\n",
      "False positive rate: 1.815% (567/31234)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 2392, 'false_negative': 4, 'negative': 2394, 'positive': 6}, 'bird': {'true_positive': 19, 'false_positive': 19, 'true_negative': 2351, 'false_negative': 11, 'negative': 2370, 'positive': 30}, 'car': {'true_positive': 48, 'false_positive': 7, 'true_negative': 2334, 'false_negative': 11, 'negative': 2341, 'positive': 59}, 'clouds': {'true_positive': 56, 'false_positive': 24, 'true_negative': 2248, 'false_negative': 72, 'negative': 2272, 'positive': 128}, 'dog': {'true_positive': 32, 'false_positive': 11, 'true_negative': 2344, 'false_negative': 13, 'negative': 2355, 'positive': 45}, 'female': {'true_positive': 249, 'false_positive': 139, 'true_negative': 1887, 'false_negative': 125, 'negative': 2026, 'positive': 374}, 'flower': {'true_positive': 61, 'false_positive': 27, 'true_negative': 2287, 'false_negative': 25, 'negative': 2314, 'positive': 86}, 'male': {'true_positive': 169, 'false_positive': 71, 'true_negative': 1973, 'false_negative': 187, 'negative': 2044, 'positive': 356}, 'night': {'true_positive': 12, 'false_positive': 10, 'true_negative': 2332, 'false_negative': 46, 'negative': 2342, 'positive': 58}, 'people': {'true_positive': 565, 'false_positive': 124, 'true_negative': 1528, 'false_negative': 183, 'negative': 1652, 'positive': 748}, 'portrait': {'true_positive': 288, 'false_positive': 113, 'true_negative': 1919, 'false_negative': 80, 'negative': 2032, 'positive': 368}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2372, 'false_negative': 24, 'negative': 2376, 'positive': 24}, 'sea': {'true_positive': 3, 'false_positive': 3, 'true_negative': 2373, 'false_negative': 21, 'negative': 2376, 'positive': 24}, 'tree': {'true_positive': 23, 'false_positive': 13, 'true_negative': 2327, 'false_negative': 37, 'negative': 2340, 'positive': 60}}\n",
      "------------------------\n",
      "Evaluating: Batch 25/51: Loss: 0.1282 | Test Acc: 95.797% (33529/35000) | Strict Acc: 62.080% (1552/2500)\n",
      "True positive rate: 64.297% (1583/2462)\n",
      "False negative rate: 35.703% (879/2462)\n",
      "True negative rate: 98.181% (31946/32538)\n",
      "False positive rate: 1.819% (592/32538)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 2, 'true_negative': 2491, 'false_negative': 5, 'negative': 2493, 'positive': 7}, 'bird': {'true_positive': 20, 'false_positive': 19, 'true_negative': 2448, 'false_negative': 13, 'negative': 2467, 'positive': 33}, 'car': {'true_positive': 51, 'false_positive': 7, 'true_negative': 2430, 'false_negative': 12, 'negative': 2437, 'positive': 63}, 'clouds': {'true_positive': 59, 'false_positive': 24, 'true_negative': 2341, 'false_negative': 76, 'negative': 2365, 'positive': 135}, 'dog': {'true_positive': 33, 'false_positive': 11, 'true_negative': 2442, 'false_negative': 14, 'negative': 2453, 'positive': 47}, 'female': {'true_positive': 255, 'false_positive': 147, 'true_negative': 1964, 'false_negative': 134, 'negative': 2111, 'positive': 389}, 'flower': {'true_positive': 65, 'false_positive': 28, 'true_negative': 2382, 'false_negative': 25, 'negative': 2410, 'positive': 90}, 'male': {'true_positive': 176, 'false_positive': 73, 'true_negative': 2058, 'false_negative': 193, 'negative': 2131, 'positive': 369}, 'night': {'true_positive': 14, 'false_positive': 10, 'true_negative': 2429, 'false_negative': 47, 'negative': 2439, 'positive': 61}, 'people': {'true_positive': 586, 'false_positive': 132, 'true_negative': 1592, 'false_negative': 190, 'negative': 1724, 'positive': 776}, 'portrait': {'true_positive': 295, 'false_positive': 118, 'true_negative': 2002, 'false_negative': 85, 'negative': 2120, 'positive': 380}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2471, 'false_negative': 25, 'negative': 2475, 'positive': 25}, 'sea': {'true_positive': 3, 'false_positive': 4, 'true_negative': 2472, 'false_negative': 21, 'negative': 2476, 'positive': 24}, 'tree': {'true_positive': 24, 'false_positive': 13, 'true_negative': 2424, 'false_negative': 39, 'negative': 2437, 'positive': 63}}\n",
      "------------------------\n",
      "Evaluating: Batch 26/51: Loss: 0.1282 | Test Acc: 95.802% (34872/36400) | Strict Acc: 61.923% (1610/2600)\n",
      "True positive rate: 64.536% (1656/2566)\n",
      "False negative rate: 35.464% (910/2566)\n",
      "True negative rate: 98.173% (33216/33834)\n",
      "False positive rate: 1.827% (618/33834)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 2590, 'false_negative': 5, 'negative': 2593, 'positive': 7}, 'bird': {'true_positive': 21, 'false_positive': 19, 'true_negative': 2546, 'false_negative': 14, 'negative': 2565, 'positive': 35}, 'car': {'true_positive': 53, 'false_positive': 8, 'true_negative': 2526, 'false_negative': 13, 'negative': 2534, 'positive': 66}, 'clouds': {'true_positive': 61, 'false_positive': 25, 'true_negative': 2436, 'false_negative': 78, 'negative': 2461, 'positive': 139}, 'dog': {'true_positive': 36, 'false_positive': 11, 'true_negative': 2537, 'false_negative': 16, 'negative': 2548, 'positive': 52}, 'female': {'true_positive': 269, 'false_positive': 152, 'true_negative': 2041, 'false_negative': 138, 'negative': 2193, 'positive': 407}, 'flower': {'true_positive': 68, 'false_positive': 29, 'true_negative': 2477, 'false_negative': 26, 'negative': 2506, 'positive': 94}, 'male': {'true_positive': 183, 'false_positive': 77, 'true_negative': 2143, 'false_negative': 197, 'negative': 2220, 'positive': 380}, 'night': {'true_positive': 16, 'false_positive': 10, 'true_negative': 2526, 'false_negative': 48, 'negative': 2536, 'positive': 64}, 'people': {'true_positive': 612, 'false_positive': 139, 'true_negative': 1649, 'false_negative': 200, 'negative': 1788, 'positive': 812}, 'portrait': {'true_positive': 308, 'false_positive': 124, 'true_negative': 2078, 'false_negative': 90, 'negative': 2202, 'positive': 398}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2571, 'false_negative': 25, 'negative': 2575, 'positive': 25}, 'sea': {'true_positive': 3, 'false_positive': 4, 'true_negative': 2572, 'false_negative': 21, 'negative': 2576, 'positive': 24}, 'tree': {'true_positive': 24, 'false_positive': 13, 'true_negative': 2524, 'false_negative': 39, 'negative': 2537, 'positive': 63}}\n",
      "------------------------\n",
      "Evaluating: Batch 27/51: Loss: 0.1277 | Test Acc: 95.780% (36205/37800) | Strict Acc: 61.704% (1666/2700)\n",
      "True positive rate: 64.541% (1731/2682)\n",
      "False negative rate: 35.459% (951/2682)\n",
      "True negative rate: 98.166% (34474/35118)\n",
      "False positive rate: 1.834% (644/35118)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 2687, 'false_negative': 8, 'negative': 2690, 'positive': 10}, 'bird': {'true_positive': 21, 'false_positive': 20, 'true_negative': 2644, 'false_negative': 15, 'negative': 2664, 'positive': 36}, 'car': {'true_positive': 53, 'false_positive': 9, 'true_negative': 2625, 'false_negative': 13, 'negative': 2634, 'positive': 66}, 'clouds': {'true_positive': 64, 'false_positive': 25, 'true_negative': 2532, 'false_negative': 79, 'negative': 2557, 'positive': 143}, 'dog': {'true_positive': 42, 'false_positive': 12, 'true_negative': 2630, 'false_negative': 16, 'negative': 2642, 'positive': 58}, 'female': {'true_positive': 279, 'false_positive': 162, 'true_negative': 2116, 'false_negative': 143, 'negative': 2278, 'positive': 422}, 'flower': {'true_positive': 68, 'false_positive': 31, 'true_negative': 2572, 'false_negative': 29, 'negative': 2603, 'positive': 97}, 'male': {'true_positive': 193, 'false_positive': 79, 'true_negative': 2221, 'false_negative': 207, 'negative': 2300, 'positive': 400}, 'night': {'true_positive': 16, 'false_positive': 12, 'true_negative': 2623, 'false_negative': 49, 'negative': 2635, 'positive': 65}, 'people': {'true_positive': 640, 'false_positive': 142, 'true_negative': 1705, 'false_negative': 213, 'negative': 1847, 'positive': 853}, 'portrait': {'true_positive': 326, 'false_positive': 127, 'true_negative': 2153, 'false_negative': 94, 'negative': 2280, 'positive': 420}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2671, 'false_negative': 25, 'negative': 2675, 'positive': 25}, 'sea': {'true_positive': 3, 'false_positive': 4, 'true_negative': 2672, 'false_negative': 21, 'negative': 2676, 'positive': 24}, 'tree': {'true_positive': 24, 'false_positive': 14, 'true_negative': 2623, 'false_negative': 39, 'negative': 2637, 'positive': 63}}\n",
      "------------------------\n",
      "Evaluating: Batch 28/51: Loss: 0.1265 | Test Acc: 95.824% (37563/39200) | Strict Acc: 62.000% (1736/2800)\n",
      "True positive rate: 64.759% (1788/2761)\n",
      "False negative rate: 35.241% (973/2761)\n",
      "True negative rate: 98.178% (35775/36439)\n",
      "False positive rate: 1.822% (664/36439)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 2787, 'false_negative': 8, 'negative': 2790, 'positive': 10}, 'bird': {'true_positive': 21, 'false_positive': 21, 'true_negative': 2742, 'false_negative': 16, 'negative': 2763, 'positive': 37}, 'car': {'true_positive': 53, 'false_positive': 9, 'true_negative': 2725, 'false_negative': 13, 'negative': 2734, 'positive': 66}, 'clouds': {'true_positive': 67, 'false_positive': 27, 'true_negative': 2625, 'false_negative': 81, 'negative': 2652, 'positive': 148}, 'dog': {'true_positive': 44, 'false_positive': 12, 'true_negative': 2728, 'false_negative': 16, 'negative': 2740, 'positive': 60}, 'female': {'true_positive': 288, 'false_positive': 167, 'true_negative': 2199, 'false_negative': 146, 'negative': 2366, 'positive': 434}, 'flower': {'true_positive': 72, 'false_positive': 33, 'true_negative': 2665, 'false_negative': 30, 'negative': 2698, 'positive': 102}, 'male': {'true_positive': 200, 'false_positive': 79, 'true_negative': 2308, 'false_negative': 213, 'negative': 2387, 'positive': 413}, 'night': {'true_positive': 18, 'false_positive': 13, 'true_negative': 2720, 'false_negative': 49, 'negative': 2733, 'positive': 67}, 'people': {'true_positive': 659, 'false_positive': 146, 'true_negative': 1777, 'false_negative': 218, 'negative': 1923, 'positive': 877}, 'portrait': {'true_positive': 337, 'false_positive': 131, 'true_negative': 2236, 'false_negative': 96, 'negative': 2367, 'positive': 433}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2770, 'false_negative': 26, 'negative': 2774, 'positive': 26}, 'sea': {'true_positive': 3, 'false_positive': 5, 'true_negative': 2771, 'false_negative': 21, 'negative': 2776, 'positive': 24}, 'tree': {'true_positive': 24, 'false_positive': 14, 'true_negative': 2722, 'false_negative': 40, 'negative': 2736, 'positive': 64}}\n",
      "------------------------\n",
      "Evaluating: Batch 29/51: Loss: 0.1264 | Test Acc: 95.808% (38898/40600) | Strict Acc: 61.931% (1796/2900)\n",
      "True positive rate: 65.066% (1870/2874)\n",
      "False negative rate: 34.934% (1004/2874)\n",
      "True negative rate: 98.150% (37028/37726)\n",
      "False positive rate: 1.850% (698/37726)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 2887, 'false_negative': 8, 'negative': 2890, 'positive': 10}, 'bird': {'true_positive': 22, 'false_positive': 21, 'true_negative': 2841, 'false_negative': 16, 'negative': 2862, 'positive': 38}, 'car': {'true_positive': 53, 'false_positive': 9, 'true_negative': 2825, 'false_negative': 13, 'negative': 2834, 'positive': 66}, 'clouds': {'true_positive': 68, 'false_positive': 28, 'true_negative': 2722, 'false_negative': 82, 'negative': 2750, 'positive': 150}, 'dog': {'true_positive': 45, 'false_positive': 13, 'true_negative': 2823, 'false_negative': 19, 'negative': 2836, 'positive': 64}, 'female': {'true_positive': 300, 'false_positive': 178, 'true_negative': 2272, 'false_negative': 150, 'negative': 2450, 'positive': 450}, 'flower': {'true_positive': 75, 'false_positive': 36, 'true_negative': 2756, 'false_negative': 33, 'negative': 2792, 'positive': 108}, 'male': {'true_positive': 212, 'false_positive': 85, 'true_negative': 2380, 'false_negative': 223, 'negative': 2465, 'positive': 435}, 'night': {'true_positive': 21, 'false_positive': 13, 'true_negative': 2816, 'false_negative': 50, 'negative': 2829, 'positive': 71}, 'people': {'true_positive': 689, 'false_positive': 152, 'true_negative': 1836, 'false_negative': 223, 'negative': 1988, 'positive': 912}, 'portrait': {'true_positive': 355, 'false_positive': 137, 'true_negative': 2309, 'false_negative': 99, 'negative': 2446, 'positive': 454}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2870, 'false_negative': 26, 'negative': 2874, 'positive': 26}, 'sea': {'true_positive': 3, 'false_positive': 5, 'true_negative': 2871, 'false_negative': 21, 'negative': 2876, 'positive': 24}, 'tree': {'true_positive': 25, 'false_positive': 14, 'true_negative': 2820, 'false_negative': 41, 'negative': 2834, 'positive': 66}}\n",
      "------------------------\n",
      "Evaluating: Batch 30/51: Loss: 0.1266 | Test Acc: 95.783% (40229/42000) | Strict Acc: 61.733% (1852/3000)\n",
      "True positive rate: 65.324% (1946/2979)\n",
      "False negative rate: 34.676% (1033/2979)\n",
      "True negative rate: 98.109% (38283/39021)\n",
      "False positive rate: 1.891% (738/39021)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 2986, 'false_negative': 9, 'negative': 2989, 'positive': 11}, 'bird': {'true_positive': 24, 'false_positive': 22, 'true_negative': 2938, 'false_negative': 16, 'negative': 2960, 'positive': 40}, 'car': {'true_positive': 54, 'false_positive': 9, 'true_negative': 2924, 'false_negative': 13, 'negative': 2933, 'positive': 67}, 'clouds': {'true_positive': 69, 'false_positive': 30, 'true_negative': 2817, 'false_negative': 84, 'negative': 2847, 'positive': 153}, 'dog': {'true_positive': 48, 'false_positive': 13, 'true_negative': 2919, 'false_negative': 20, 'negative': 2932, 'positive': 68}, 'female': {'true_positive': 312, 'false_positive': 186, 'true_negative': 2346, 'false_negative': 156, 'negative': 2532, 'positive': 468}, 'flower': {'true_positive': 77, 'false_positive': 38, 'true_negative': 2851, 'false_negative': 34, 'negative': 2889, 'positive': 111}, 'male': {'true_positive': 222, 'false_positive': 92, 'true_negative': 2455, 'false_negative': 231, 'negative': 2547, 'positive': 453}, 'night': {'true_positive': 21, 'false_positive': 13, 'true_negative': 2914, 'false_negative': 52, 'negative': 2927, 'positive': 73}, 'people': {'true_positive': 719, 'false_positive': 164, 'true_negative': 1891, 'false_negative': 226, 'negative': 2055, 'positive': 945}, 'portrait': {'true_positive': 366, 'false_positive': 145, 'true_negative': 2387, 'false_negative': 102, 'negative': 2532, 'positive': 468}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 2970, 'false_negative': 26, 'negative': 2974, 'positive': 26}, 'sea': {'true_positive': 4, 'false_positive': 5, 'true_negative': 2969, 'false_negative': 22, 'negative': 2974, 'positive': 26}, 'tree': {'true_positive': 28, 'false_positive': 14, 'true_negative': 2916, 'false_negative': 42, 'negative': 2930, 'positive': 70}}\n",
      "------------------------\n",
      "Evaluating: Batch 31/51: Loss: 0.1276 | Test Acc: 95.776% (41567/43400) | Strict Acc: 61.613% (1910/3100)\n",
      "True positive rate: 64.979% (2002/3081)\n",
      "False negative rate: 35.021% (1079/3081)\n",
      "True negative rate: 98.130% (39565/40319)\n",
      "False positive rate: 1.870% (754/40319)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3085, 'false_negative': 10, 'negative': 3088, 'positive': 12}, 'bird': {'true_positive': 27, 'false_positive': 23, 'true_negative': 3034, 'false_negative': 16, 'negative': 3057, 'positive': 43}, 'car': {'true_positive': 54, 'false_positive': 9, 'true_negative': 3023, 'false_negative': 14, 'negative': 3032, 'positive': 68}, 'clouds': {'true_positive': 71, 'false_positive': 30, 'true_negative': 2912, 'false_negative': 87, 'negative': 2942, 'positive': 158}, 'dog': {'true_positive': 50, 'false_positive': 13, 'true_negative': 3016, 'false_negative': 21, 'negative': 3029, 'positive': 71}, 'female': {'true_positive': 315, 'false_positive': 193, 'true_negative': 2430, 'false_negative': 162, 'negative': 2623, 'positive': 477}, 'flower': {'true_positive': 82, 'false_positive': 38, 'true_negative': 2944, 'false_negative': 36, 'negative': 2982, 'positive': 118}, 'male': {'true_positive': 232, 'false_positive': 93, 'true_negative': 2532, 'false_negative': 243, 'negative': 2625, 'positive': 475}, 'night': {'true_positive': 22, 'false_positive': 13, 'true_negative': 3012, 'false_negative': 53, 'negative': 3025, 'positive': 75}, 'people': {'true_positive': 741, 'false_positive': 166, 'true_negative': 1958, 'false_negative': 235, 'negative': 2124, 'positive': 976}, 'portrait': {'true_positive': 373, 'false_positive': 150, 'true_negative': 2471, 'false_negative': 106, 'negative': 2621, 'positive': 479}, 'river': {'true_positive': 0, 'false_positive': 4, 'true_negative': 3069, 'false_negative': 27, 'negative': 3073, 'positive': 27}, 'sea': {'true_positive': 4, 'false_positive': 5, 'true_negative': 3066, 'false_negative': 25, 'negative': 3071, 'positive': 29}, 'tree': {'true_positive': 29, 'false_positive': 14, 'true_negative': 3013, 'false_negative': 44, 'negative': 3027, 'positive': 73}}\n",
      "------------------------\n",
      "Evaluating: Batch 32/51: Loss: 0.1275 | Test Acc: 95.779% (42909/44800) | Strict Acc: 61.406% (1965/3200)\n",
      "True positive rate: 65.092% (2081/3197)\n",
      "False negative rate: 34.908% (1116/3197)\n",
      "True negative rate: 98.137% (40828/41603)\n",
      "False positive rate: 1.863% (775/41603)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3185, 'false_negative': 10, 'negative': 3188, 'positive': 12}, 'bird': {'true_positive': 29, 'false_positive': 23, 'true_negative': 3132, 'false_negative': 16, 'negative': 3155, 'positive': 45}, 'car': {'true_positive': 56, 'false_positive': 9, 'true_negative': 3121, 'false_negative': 14, 'negative': 3130, 'positive': 70}, 'clouds': {'true_positive': 75, 'false_positive': 30, 'true_negative': 3006, 'false_negative': 89, 'negative': 3036, 'positive': 164}, 'dog': {'true_positive': 51, 'false_positive': 15, 'true_negative': 3113, 'false_negative': 21, 'negative': 3128, 'positive': 72}, 'female': {'true_positive': 325, 'false_positive': 203, 'true_negative': 2507, 'false_negative': 165, 'negative': 2710, 'positive': 490}, 'flower': {'true_positive': 85, 'false_positive': 39, 'true_negative': 3037, 'false_negative': 39, 'negative': 3076, 'positive': 124}, 'male': {'true_positive': 243, 'false_positive': 93, 'true_negative': 2612, 'false_negative': 252, 'negative': 2705, 'positive': 495}, 'night': {'true_positive': 23, 'false_positive': 13, 'true_negative': 3107, 'false_negative': 57, 'negative': 3120, 'positive': 80}, 'people': {'true_positive': 772, 'false_positive': 168, 'true_negative': 2019, 'false_negative': 241, 'negative': 2187, 'positive': 1013}, 'portrait': {'true_positive': 384, 'false_positive': 154, 'true_negative': 2552, 'false_negative': 110, 'negative': 2706, 'positive': 494}, 'river': {'true_positive': 0, 'false_positive': 5, 'true_negative': 3168, 'false_negative': 27, 'negative': 3173, 'positive': 27}, 'sea': {'true_positive': 5, 'false_positive': 5, 'true_negative': 3161, 'false_negative': 29, 'negative': 3166, 'positive': 34}, 'tree': {'true_positive': 31, 'false_positive': 15, 'true_negative': 3108, 'false_negative': 46, 'negative': 3123, 'positive': 77}}\n",
      "------------------------\n",
      "Evaluating: Batch 33/51: Loss: 0.1274 | Test Acc: 95.801% (44260/46200) | Strict Acc: 61.606% (2033/3300)\n",
      "True positive rate: 65.213% (2154/3303)\n",
      "False negative rate: 34.787% (1149/3303)\n",
      "True negative rate: 98.156% (42106/42897)\n",
      "False positive rate: 1.844% (791/42897)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3285, 'false_negative': 10, 'negative': 3288, 'positive': 12}, 'bird': {'true_positive': 31, 'false_positive': 23, 'true_negative': 3229, 'false_negative': 17, 'negative': 3252, 'positive': 48}, 'car': {'true_positive': 56, 'false_positive': 9, 'true_negative': 3220, 'false_negative': 15, 'negative': 3229, 'positive': 71}, 'clouds': {'true_positive': 77, 'false_positive': 30, 'true_negative': 3103, 'false_negative': 90, 'negative': 3133, 'positive': 167}, 'dog': {'true_positive': 51, 'false_positive': 15, 'true_negative': 3213, 'false_negative': 21, 'negative': 3228, 'positive': 72}, 'female': {'true_positive': 333, 'false_positive': 207, 'true_negative': 2588, 'false_negative': 172, 'negative': 2795, 'positive': 505}, 'flower': {'true_positive': 88, 'false_positive': 42, 'true_negative': 3130, 'false_negative': 40, 'negative': 3172, 'positive': 128}, 'male': {'true_positive': 255, 'false_positive': 96, 'true_negative': 2689, 'false_negative': 260, 'negative': 2785, 'positive': 515}, 'night': {'true_positive': 24, 'false_positive': 13, 'true_negative': 3205, 'false_negative': 58, 'negative': 3218, 'positive': 82}, 'people': {'true_positive': 801, 'false_positive': 170, 'true_negative': 2083, 'false_negative': 246, 'negative': 2253, 'positive': 1047}, 'portrait': {'true_positive': 399, 'false_positive': 158, 'true_negative': 2630, 'false_negative': 113, 'negative': 2788, 'positive': 512}, 'river': {'true_positive': 0, 'false_positive': 5, 'true_negative': 3267, 'false_negative': 28, 'negative': 3272, 'positive': 28}, 'sea': {'true_positive': 6, 'false_positive': 5, 'true_negative': 3258, 'false_negative': 31, 'negative': 3263, 'positive': 37}, 'tree': {'true_positive': 31, 'false_positive': 15, 'true_negative': 3206, 'false_negative': 48, 'negative': 3221, 'positive': 79}}\n",
      "------------------------\n",
      "Evaluating: Batch 34/51: Loss: 0.1274 | Test Acc: 95.805% (45603/47600) | Strict Acc: 61.735% (2099/3400)\n",
      "True positive rate: 65.352% (2237/3423)\n",
      "False negative rate: 34.648% (1186/3423)\n",
      "True negative rate: 98.164% (43366/44177)\n",
      "False positive rate: 1.836% (811/44177)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3385, 'false_negative': 10, 'negative': 3388, 'positive': 12}, 'bird': {'true_positive': 34, 'false_positive': 23, 'true_negative': 3324, 'false_negative': 19, 'negative': 3347, 'positive': 53}, 'car': {'true_positive': 58, 'false_positive': 9, 'true_negative': 3318, 'false_negative': 15, 'negative': 3327, 'positive': 73}, 'clouds': {'true_positive': 80, 'false_positive': 31, 'true_negative': 3198, 'false_negative': 91, 'negative': 3229, 'positive': 171}, 'dog': {'true_positive': 51, 'false_positive': 15, 'true_negative': 3312, 'false_negative': 22, 'negative': 3327, 'positive': 73}, 'female': {'true_positive': 347, 'false_positive': 212, 'true_negative': 2662, 'false_negative': 179, 'negative': 2874, 'positive': 526}, 'flower': {'true_positive': 91, 'false_positive': 43, 'true_negative': 3225, 'false_negative': 41, 'negative': 3268, 'positive': 132}, 'male': {'true_positive': 266, 'false_positive': 98, 'true_negative': 2769, 'false_negative': 267, 'negative': 2867, 'positive': 533}, 'night': {'true_positive': 24, 'false_positive': 13, 'true_negative': 3304, 'false_negative': 59, 'negative': 3317, 'positive': 83}, 'people': {'true_positive': 831, 'false_positive': 175, 'true_negative': 2139, 'false_negative': 255, 'negative': 2314, 'positive': 1086}, 'portrait': {'true_positive': 413, 'false_positive': 163, 'true_negative': 2707, 'false_negative': 117, 'negative': 2870, 'positive': 530}, 'river': {'true_positive': 0, 'false_positive': 5, 'true_negative': 3366, 'false_negative': 29, 'negative': 3371, 'positive': 29}, 'sea': {'true_positive': 7, 'false_positive': 6, 'true_negative': 3356, 'false_negative': 31, 'negative': 3362, 'positive': 38}, 'tree': {'true_positive': 33, 'false_positive': 15, 'true_negative': 3301, 'false_negative': 51, 'negative': 3316, 'positive': 84}}\n",
      "------------------------\n",
      "Evaluating: Batch 35/51: Loss: 0.1277 | Test Acc: 95.767% (46926/49000) | Strict Acc: 61.429% (2150/3500)\n",
      "True positive rate: 65.124% (2308/3544)\n",
      "False negative rate: 34.876% (1236/3544)\n",
      "True negative rate: 98.156% (44618/45456)\n",
      "False positive rate: 1.844% (838/45456)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3484, 'false_negative': 11, 'negative': 3487, 'positive': 13}, 'bird': {'true_positive': 37, 'false_positive': 24, 'true_negative': 3419, 'false_negative': 20, 'negative': 3443, 'positive': 57}, 'car': {'true_positive': 59, 'false_positive': 9, 'true_negative': 3417, 'false_negative': 15, 'negative': 3426, 'positive': 74}, 'clouds': {'true_positive': 80, 'false_positive': 32, 'true_negative': 3295, 'false_negative': 93, 'negative': 3327, 'positive': 173}, 'dog': {'true_positive': 53, 'false_positive': 15, 'true_negative': 3409, 'false_negative': 23, 'negative': 3424, 'positive': 76}, 'female': {'true_positive': 359, 'false_positive': 220, 'true_negative': 2732, 'false_negative': 189, 'negative': 2952, 'positive': 548}, 'flower': {'true_positive': 93, 'false_positive': 43, 'true_negative': 3320, 'false_negative': 44, 'negative': 3363, 'positive': 137}, 'male': {'true_positive': 271, 'false_positive': 102, 'true_negative': 2850, 'false_negative': 277, 'negative': 2952, 'positive': 548}, 'night': {'true_positive': 25, 'false_positive': 13, 'true_negative': 3401, 'false_negative': 61, 'negative': 3414, 'positive': 86}, 'people': {'true_positive': 861, 'false_positive': 180, 'true_negative': 2196, 'false_negative': 263, 'negative': 2376, 'positive': 1124}, 'portrait': {'true_positive': 426, 'false_positive': 169, 'true_negative': 2780, 'false_negative': 125, 'negative': 2949, 'positive': 551}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 3465, 'false_negative': 29, 'negative': 3471, 'positive': 29}, 'sea': {'true_positive': 7, 'false_positive': 6, 'true_negative': 3455, 'false_negative': 32, 'negative': 3461, 'positive': 39}, 'tree': {'true_positive': 35, 'false_positive': 16, 'true_negative': 3395, 'false_negative': 54, 'negative': 3411, 'positive': 89}}\n",
      "------------------------\n",
      "Evaluating: Batch 36/51: Loss: 0.1269 | Test Acc: 95.782% (48274/50400) | Strict Acc: 61.611% (2218/3600)\n",
      "True positive rate: 65.209% (2371/3636)\n",
      "False negative rate: 34.791% (1265/3636)\n",
      "True negative rate: 98.159% (45903/46764)\n",
      "False positive rate: 1.841% (861/46764)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3584, 'false_negative': 11, 'negative': 3587, 'positive': 13}, 'bird': {'true_positive': 39, 'false_positive': 24, 'true_negative': 3516, 'false_negative': 21, 'negative': 3540, 'positive': 60}, 'car': {'true_positive': 62, 'false_positive': 9, 'true_negative': 3513, 'false_negative': 16, 'negative': 3522, 'positive': 78}, 'clouds': {'true_positive': 81, 'false_positive': 34, 'true_negative': 3389, 'false_negative': 96, 'negative': 3423, 'positive': 177}, 'dog': {'true_positive': 54, 'false_positive': 15, 'true_negative': 3508, 'false_negative': 23, 'negative': 3523, 'positive': 77}, 'female': {'true_positive': 367, 'false_positive': 229, 'true_negative': 2811, 'false_negative': 193, 'negative': 3040, 'positive': 560}, 'flower': {'true_positive': 95, 'false_positive': 44, 'true_negative': 3415, 'false_negative': 46, 'negative': 3459, 'positive': 141}, 'male': {'true_positive': 280, 'false_positive': 105, 'true_negative': 2930, 'false_negative': 285, 'negative': 3035, 'positive': 565}, 'night': {'true_positive': 25, 'false_positive': 13, 'true_negative': 3497, 'false_negative': 65, 'negative': 3510, 'positive': 90}, 'people': {'true_positive': 885, 'false_positive': 181, 'true_negative': 2267, 'false_negative': 267, 'negative': 2448, 'positive': 1152}, 'portrait': {'true_positive': 437, 'false_positive': 176, 'true_negative': 2861, 'false_negative': 126, 'negative': 3037, 'positive': 563}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 3565, 'false_negative': 29, 'negative': 3571, 'positive': 29}, 'sea': {'true_positive': 7, 'false_positive': 6, 'true_negative': 3555, 'false_negative': 32, 'negative': 3561, 'positive': 39}, 'tree': {'true_positive': 37, 'false_positive': 16, 'true_negative': 3492, 'false_negative': 55, 'negative': 3508, 'positive': 92}}\n",
      "------------------------\n",
      "Evaluating: Batch 37/51: Loss: 0.1267 | Test Acc: 95.792% (49620/51800) | Strict Acc: 61.541% (2277/3700)\n",
      "True positive rate: 65.414% (2436/3724)\n",
      "False negative rate: 34.586% (1288/3724)\n",
      "True negative rate: 98.145% (47184/48076)\n",
      "False positive rate: 1.855% (892/48076)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3684, 'false_negative': 11, 'negative': 3687, 'positive': 13}, 'bird': {'true_positive': 39, 'false_positive': 24, 'true_negative': 3616, 'false_negative': 21, 'negative': 3640, 'positive': 60}, 'car': {'true_positive': 63, 'false_positive': 9, 'true_negative': 3611, 'false_negative': 17, 'negative': 3620, 'positive': 80}, 'clouds': {'true_positive': 84, 'false_positive': 35, 'true_negative': 3481, 'false_negative': 100, 'negative': 3516, 'positive': 184}, 'dog': {'true_positive': 55, 'false_positive': 15, 'true_negative': 3607, 'false_negative': 23, 'negative': 3622, 'positive': 78}, 'female': {'true_positive': 373, 'false_positive': 236, 'true_negative': 2895, 'false_negative': 196, 'negative': 3131, 'positive': 569}, 'flower': {'true_positive': 102, 'false_positive': 45, 'true_negative': 3506, 'false_negative': 47, 'negative': 3551, 'positive': 149}, 'male': {'true_positive': 289, 'false_positive': 112, 'true_negative': 3011, 'false_negative': 288, 'negative': 3123, 'positive': 577}, 'night': {'true_positive': 25, 'false_positive': 13, 'true_negative': 3595, 'false_negative': 67, 'negative': 3608, 'positive': 92}, 'people': {'true_positive': 909, 'false_positive': 188, 'true_negative': 2331, 'false_negative': 272, 'negative': 2519, 'positive': 1181}, 'portrait': {'true_positive': 447, 'false_positive': 184, 'true_negative': 2941, 'false_negative': 128, 'negative': 3125, 'positive': 575}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 3664, 'false_negative': 30, 'negative': 3670, 'positive': 30}, 'sea': {'true_positive': 8, 'false_positive': 6, 'true_negative': 3653, 'false_negative': 33, 'negative': 3659, 'positive': 41}, 'tree': {'true_positive': 40, 'false_positive': 16, 'true_negative': 3589, 'false_negative': 55, 'negative': 3605, 'positive': 95}}\n",
      "------------------------\n",
      "Evaluating: Batch 38/51: Loss: 0.1271 | Test Acc: 95.803% (50967/53200) | Strict Acc: 61.500% (2337/3800)\n",
      "True positive rate: 65.493% (2511/3834)\n",
      "False negative rate: 34.507% (1323/3834)\n",
      "True negative rate: 98.157% (48456/49366)\n",
      "False positive rate: 1.843% (910/49366)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3784, 'false_negative': 11, 'negative': 3787, 'positive': 13}, 'bird': {'true_positive': 41, 'false_positive': 25, 'true_negative': 3713, 'false_negative': 21, 'negative': 3738, 'positive': 62}, 'car': {'true_positive': 67, 'false_positive': 9, 'true_negative': 3706, 'false_negative': 18, 'negative': 3715, 'positive': 85}, 'clouds': {'true_positive': 90, 'false_positive': 35, 'true_negative': 3573, 'false_negative': 102, 'negative': 3608, 'positive': 192}, 'dog': {'true_positive': 56, 'false_positive': 15, 'true_negative': 3705, 'false_negative': 24, 'negative': 3720, 'positive': 80}, 'female': {'true_positive': 381, 'false_positive': 241, 'true_negative': 2977, 'false_negative': 201, 'negative': 3218, 'positive': 582}, 'flower': {'true_positive': 105, 'false_positive': 47, 'true_negative': 3601, 'false_negative': 47, 'negative': 3648, 'positive': 152}, 'male': {'true_positive': 299, 'false_positive': 113, 'true_negative': 3089, 'false_negative': 299, 'negative': 3202, 'positive': 598}, 'night': {'true_positive': 26, 'false_positive': 14, 'true_negative': 3692, 'false_negative': 68, 'negative': 3706, 'positive': 94}, 'people': {'true_positive': 937, 'false_positive': 188, 'true_negative': 2395, 'false_negative': 280, 'negative': 2583, 'positive': 1217}, 'portrait': {'true_positive': 459, 'false_positive': 192, 'true_negative': 3020, 'false_negative': 129, 'negative': 3212, 'positive': 588}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 3764, 'false_negative': 30, 'negative': 3770, 'positive': 30}, 'sea': {'true_positive': 8, 'false_positive': 6, 'true_negative': 3751, 'false_negative': 35, 'negative': 3757, 'positive': 43}, 'tree': {'true_positive': 40, 'false_positive': 16, 'true_negative': 3686, 'false_negative': 58, 'negative': 3702, 'positive': 98}}\n",
      "------------------------\n",
      "Evaluating: Batch 39/51: Loss: 0.1269 | Test Acc: 95.830% (52323/54600) | Strict Acc: 61.795% (2410/3900)\n",
      "True positive rate: 65.414% (2559/3912)\n",
      "False negative rate: 34.586% (1353/3912)\n",
      "True negative rate: 98.177% (49764/50688)\n",
      "False positive rate: 1.823% (924/50688)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3884, 'false_negative': 11, 'negative': 3887, 'positive': 13}, 'bird': {'true_positive': 43, 'false_positive': 25, 'true_negative': 3809, 'false_negative': 23, 'negative': 3834, 'positive': 66}, 'car': {'true_positive': 68, 'false_positive': 9, 'true_negative': 3805, 'false_negative': 18, 'negative': 3814, 'positive': 86}, 'clouds': {'true_positive': 93, 'false_positive': 35, 'true_negative': 3669, 'false_negative': 103, 'negative': 3704, 'positive': 196}, 'dog': {'true_positive': 59, 'false_positive': 15, 'true_negative': 3802, 'false_negative': 24, 'negative': 3817, 'positive': 83}, 'female': {'true_positive': 384, 'false_positive': 244, 'true_negative': 3066, 'false_negative': 206, 'negative': 3310, 'positive': 590}, 'flower': {'true_positive': 107, 'false_positive': 49, 'true_negative': 3695, 'false_negative': 49, 'negative': 3744, 'positive': 156}, 'male': {'true_positive': 305, 'false_positive': 115, 'true_negative': 3177, 'false_negative': 303, 'negative': 3292, 'positive': 608}, 'night': {'true_positive': 30, 'false_positive': 14, 'true_negative': 3787, 'false_negative': 69, 'negative': 3801, 'positive': 99}, 'people': {'true_positive': 952, 'false_positive': 191, 'true_negative': 2471, 'false_negative': 286, 'negative': 2662, 'positive': 1238}, 'portrait': {'true_positive': 464, 'false_positive': 195, 'true_negative': 3108, 'false_negative': 133, 'negative': 3303, 'positive': 597}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 3863, 'false_negative': 31, 'negative': 3869, 'positive': 31}, 'sea': {'true_positive': 9, 'false_positive': 6, 'true_negative': 3850, 'false_negative': 35, 'negative': 3856, 'positive': 44}, 'tree': {'true_positive': 43, 'false_positive': 17, 'true_negative': 3778, 'false_negative': 62, 'negative': 3795, 'positive': 105}}\n",
      "------------------------\n",
      "Evaluating: Batch 40/51: Loss: 0.1265 | Test Acc: 95.834% (53667/56000) | Strict Acc: 61.850% (2474/4000)\n",
      "True positive rate: 65.425% (2617/4000)\n",
      "False negative rate: 34.575% (1383/4000)\n",
      "True negative rate: 98.173% (51050/52000)\n",
      "False positive rate: 1.827% (950/52000)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 2, 'false_positive': 3, 'true_negative': 3983, 'false_negative': 12, 'negative': 3986, 'positive': 14}, 'bird': {'true_positive': 44, 'false_positive': 25, 'true_negative': 3906, 'false_negative': 25, 'negative': 3931, 'positive': 69}, 'car': {'true_positive': 69, 'false_positive': 9, 'true_negative': 3904, 'false_negative': 18, 'negative': 3913, 'positive': 87}, 'clouds': {'true_positive': 94, 'false_positive': 36, 'true_negative': 3764, 'false_negative': 106, 'negative': 3800, 'positive': 200}, 'dog': {'true_positive': 60, 'false_positive': 15, 'true_negative': 3900, 'false_negative': 25, 'negative': 3915, 'positive': 85}, 'female': {'true_positive': 393, 'false_positive': 249, 'true_negative': 3147, 'false_negative': 211, 'negative': 3396, 'positive': 604}, 'flower': {'true_positive': 111, 'false_positive': 49, 'true_negative': 3791, 'false_negative': 49, 'negative': 3840, 'positive': 160}, 'male': {'true_positive': 312, 'false_positive': 121, 'true_negative': 3259, 'false_negative': 308, 'negative': 3380, 'positive': 620}, 'night': {'true_positive': 31, 'false_positive': 14, 'true_negative': 3880, 'false_negative': 75, 'negative': 3894, 'positive': 106}, 'people': {'true_positive': 975, 'false_positive': 199, 'true_negative': 2536, 'false_negative': 290, 'negative': 2735, 'positive': 1265}, 'portrait': {'true_positive': 474, 'false_positive': 201, 'true_negative': 3190, 'false_negative': 135, 'negative': 3391, 'positive': 609}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 3963, 'false_negative': 31, 'negative': 3969, 'positive': 31}, 'sea': {'true_positive': 9, 'false_positive': 6, 'true_negative': 3950, 'false_negative': 35, 'negative': 3956, 'positive': 44}, 'tree': {'true_positive': 43, 'false_positive': 17, 'true_negative': 3877, 'false_negative': 63, 'negative': 3894, 'positive': 106}}\n",
      "------------------------\n",
      "Evaluating: Batch 41/51: Loss: 0.1263 | Test Acc: 95.833% (55008/57400) | Strict Acc: 61.902% (2538/4100)\n",
      "True positive rate: 65.248% (2668/4089)\n",
      "False negative rate: 34.752% (1421/4089)\n",
      "True negative rate: 98.179% (52340/53311)\n",
      "False positive rate: 1.821% (971/53311)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4082, 'false_negative': 12, 'negative': 4085, 'positive': 15}, 'bird': {'true_positive': 45, 'false_positive': 26, 'true_negative': 4003, 'false_negative': 26, 'negative': 4029, 'positive': 71}, 'car': {'true_positive': 69, 'false_positive': 9, 'true_negative': 4004, 'false_negative': 18, 'negative': 4013, 'positive': 87}, 'clouds': {'true_positive': 95, 'false_positive': 38, 'true_negative': 3857, 'false_negative': 110, 'negative': 3895, 'positive': 205}, 'dog': {'true_positive': 61, 'false_positive': 15, 'true_negative': 3999, 'false_negative': 25, 'negative': 4014, 'positive': 86}, 'female': {'true_positive': 400, 'false_positive': 251, 'true_negative': 3231, 'false_negative': 218, 'negative': 3482, 'positive': 618}, 'flower': {'true_positive': 111, 'false_positive': 50, 'true_negative': 3887, 'false_negative': 52, 'negative': 3937, 'positive': 163}, 'male': {'true_positive': 317, 'false_positive': 124, 'true_negative': 3347, 'false_negative': 312, 'negative': 3471, 'positive': 629}, 'night': {'true_positive': 32, 'false_positive': 14, 'true_negative': 3973, 'false_negative': 81, 'negative': 3987, 'positive': 113}, 'people': {'true_positive': 992, 'false_positive': 205, 'true_negative': 2604, 'false_negative': 299, 'negative': 2809, 'positive': 1291}, 'portrait': {'true_positive': 488, 'false_positive': 204, 'true_negative': 3271, 'false_negative': 137, 'negative': 3475, 'positive': 625}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4063, 'false_negative': 31, 'negative': 4069, 'positive': 31}, 'sea': {'true_positive': 9, 'false_positive': 8, 'true_negative': 4047, 'false_negative': 36, 'negative': 4055, 'positive': 45}, 'tree': {'true_positive': 46, 'false_positive': 18, 'true_negative': 3972, 'false_negative': 64, 'negative': 3990, 'positive': 110}}\n",
      "------------------------\n",
      "Evaluating: Batch 42/51: Loss: 0.1266 | Test Acc: 95.815% (56339/58800) | Strict Acc: 61.833% (2597/4200)\n",
      "True positive rate: 65.219% (2734/4192)\n",
      "False negative rate: 34.781% (1458/4192)\n",
      "True negative rate: 98.163% (53605/54608)\n",
      "False positive rate: 1.837% (1003/54608)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4181, 'false_negative': 13, 'negative': 4184, 'positive': 16}, 'bird': {'true_positive': 46, 'false_positive': 27, 'true_negative': 4101, 'false_negative': 26, 'negative': 4128, 'positive': 72}, 'car': {'true_positive': 72, 'false_positive': 9, 'true_negative': 4100, 'false_negative': 19, 'negative': 4109, 'positive': 91}, 'clouds': {'true_positive': 100, 'false_positive': 40, 'true_negative': 3950, 'false_negative': 110, 'negative': 3990, 'positive': 210}, 'dog': {'true_positive': 62, 'false_positive': 17, 'true_negative': 4095, 'false_negative': 26, 'negative': 4112, 'positive': 88}, 'female': {'true_positive': 408, 'false_positive': 258, 'true_negative': 3309, 'false_negative': 225, 'negative': 3567, 'positive': 633}, 'flower': {'true_positive': 114, 'false_positive': 51, 'true_negative': 3981, 'false_negative': 54, 'negative': 4032, 'positive': 168}, 'male': {'true_positive': 323, 'false_positive': 127, 'true_negative': 3426, 'false_negative': 324, 'negative': 3553, 'positive': 647}, 'night': {'true_positive': 33, 'false_positive': 14, 'true_negative': 4072, 'false_negative': 81, 'negative': 4086, 'positive': 114}, 'people': {'true_positive': 1016, 'false_positive': 212, 'true_negative': 2662, 'false_negative': 310, 'negative': 2874, 'positive': 1326}, 'portrait': {'true_positive': 500, 'false_positive': 211, 'true_negative': 3350, 'false_negative': 139, 'negative': 3561, 'positive': 639}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4163, 'false_negative': 31, 'negative': 4169, 'positive': 31}, 'sea': {'true_positive': 9, 'false_positive': 9, 'true_negative': 4146, 'false_negative': 36, 'negative': 4155, 'positive': 45}, 'tree': {'true_positive': 48, 'false_positive': 19, 'true_negative': 4069, 'false_negative': 64, 'negative': 4088, 'positive': 112}}\n",
      "------------------------\n",
      "Evaluating: Batch 43/51: Loss: 0.1263 | Test Acc: 95.824% (57686/60200) | Strict Acc: 61.977% (2665/4300)\n",
      "True positive rate: 65.360% (2817/4310)\n",
      "False negative rate: 34.640% (1493/4310)\n",
      "True negative rate: 98.173% (54869/55890)\n",
      "False positive rate: 1.827% (1021/55890)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4281, 'false_negative': 13, 'negative': 4284, 'positive': 16}, 'bird': {'true_positive': 49, 'false_positive': 27, 'true_negative': 4197, 'false_negative': 27, 'negative': 4224, 'positive': 76}, 'car': {'true_positive': 72, 'false_positive': 9, 'true_negative': 4199, 'false_negative': 20, 'negative': 4208, 'positive': 92}, 'clouds': {'true_positive': 107, 'false_positive': 40, 'true_negative': 4040, 'false_negative': 113, 'negative': 4080, 'positive': 220}, 'dog': {'true_positive': 63, 'false_positive': 18, 'true_negative': 4193, 'false_negative': 26, 'negative': 4211, 'positive': 89}, 'female': {'true_positive': 421, 'false_positive': 265, 'true_negative': 3383, 'false_negative': 231, 'negative': 3648, 'positive': 652}, 'flower': {'true_positive': 116, 'false_positive': 51, 'true_negative': 4079, 'false_negative': 54, 'negative': 4130, 'positive': 170}, 'male': {'true_positive': 332, 'false_positive': 129, 'true_negative': 3506, 'false_negative': 333, 'negative': 3635, 'positive': 665}, 'night': {'true_positive': 34, 'false_positive': 14, 'true_negative': 4170, 'false_negative': 82, 'negative': 4184, 'positive': 116}, 'people': {'true_positive': 1046, 'false_positive': 215, 'true_negative': 2722, 'false_negative': 317, 'negative': 2937, 'positive': 1363}, 'portrait': {'true_positive': 516, 'false_positive': 215, 'true_negative': 3427, 'false_negative': 142, 'negative': 3642, 'positive': 658}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4261, 'false_negative': 33, 'negative': 4267, 'positive': 33}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4244, 'false_negative': 37, 'negative': 4253, 'positive': 47}, 'tree': {'true_positive': 48, 'false_positive': 20, 'true_negative': 4167, 'false_negative': 65, 'negative': 4187, 'positive': 113}}\n",
      "------------------------\n",
      "Evaluating: Batch 44/51: Loss: 0.1261 | Test Acc: 95.817% (59023/61600) | Strict Acc: 61.955% (2726/4400)\n",
      "True positive rate: 65.300% (2883/4415)\n",
      "False negative rate: 34.700% (1532/4415)\n",
      "True negative rate: 98.173% (56140/57185)\n",
      "False positive rate: 1.827% (1045/57185)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4381, 'false_negative': 13, 'negative': 4384, 'positive': 16}, 'bird': {'true_positive': 51, 'false_positive': 27, 'true_negative': 4294, 'false_negative': 28, 'negative': 4321, 'positive': 79}, 'car': {'true_positive': 73, 'false_positive': 9, 'true_negative': 4297, 'false_negative': 21, 'negative': 4306, 'positive': 94}, 'clouds': {'true_positive': 112, 'false_positive': 40, 'true_negative': 4133, 'false_negative': 115, 'negative': 4173, 'positive': 227}, 'dog': {'true_positive': 66, 'false_positive': 19, 'true_negative': 4289, 'false_negative': 26, 'negative': 4308, 'positive': 92}, 'female': {'true_positive': 433, 'false_positive': 271, 'true_negative': 3455, 'false_negative': 241, 'negative': 3726, 'positive': 674}, 'flower': {'true_positive': 119, 'false_positive': 51, 'true_negative': 4175, 'false_negative': 55, 'negative': 4226, 'positive': 174}, 'male': {'true_positive': 335, 'false_positive': 134, 'true_negative': 3591, 'false_negative': 340, 'negative': 3725, 'positive': 675}, 'night': {'true_positive': 35, 'false_positive': 14, 'true_negative': 4268, 'false_negative': 83, 'negative': 4282, 'positive': 118}, 'people': {'true_positive': 1071, 'false_positive': 217, 'true_negative': 2786, 'false_negative': 326, 'negative': 3003, 'positive': 1397}, 'portrait': {'true_positive': 526, 'false_positive': 223, 'true_negative': 3505, 'false_negative': 146, 'negative': 3728, 'positive': 672}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4360, 'false_negative': 34, 'negative': 4366, 'positive': 34}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4343, 'false_negative': 38, 'negative': 4352, 'positive': 48}, 'tree': {'true_positive': 49, 'false_positive': 22, 'true_negative': 4263, 'false_negative': 66, 'negative': 4285, 'positive': 115}}\n",
      "------------------------\n",
      "Evaluating: Batch 45/51: Loss: 0.1258 | Test Acc: 95.817% (60365/63000) | Strict Acc: 62.000% (2790/4500)\n",
      "True positive rate: 65.296% (2937/4498)\n",
      "False negative rate: 34.704% (1561/4498)\n",
      "True negative rate: 98.164% (57428/58502)\n",
      "False positive rate: 1.836% (1074/58502)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4481, 'false_negative': 13, 'negative': 4484, 'positive': 16}, 'bird': {'true_positive': 52, 'false_positive': 28, 'true_negative': 4392, 'false_negative': 28, 'negative': 4420, 'positive': 80}, 'car': {'true_positive': 73, 'false_positive': 9, 'true_negative': 4396, 'false_negative': 22, 'negative': 4405, 'positive': 95}, 'clouds': {'true_positive': 116, 'false_positive': 40, 'true_negative': 4228, 'false_negative': 116, 'negative': 4268, 'positive': 232}, 'dog': {'true_positive': 66, 'false_positive': 19, 'true_negative': 4386, 'false_negative': 29, 'negative': 4405, 'positive': 95}, 'female': {'true_positive': 442, 'false_positive': 278, 'true_negative': 3534, 'false_negative': 246, 'negative': 3812, 'positive': 688}, 'flower': {'true_positive': 121, 'false_positive': 51, 'true_negative': 4272, 'false_negative': 56, 'negative': 4323, 'positive': 177}, 'male': {'true_positive': 342, 'false_positive': 139, 'true_negative': 3672, 'false_negative': 347, 'negative': 3811, 'positive': 689}, 'night': {'true_positive': 35, 'false_positive': 14, 'true_negative': 4365, 'false_negative': 86, 'negative': 4379, 'positive': 121}, 'people': {'true_positive': 1091, 'false_positive': 226, 'true_negative': 2851, 'false_negative': 332, 'negative': 3077, 'positive': 1423}, 'portrait': {'true_positive': 536, 'false_positive': 229, 'true_negative': 3589, 'false_negative': 146, 'negative': 3818, 'positive': 682}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4460, 'false_negative': 34, 'negative': 4466, 'positive': 34}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4442, 'false_negative': 39, 'negative': 4451, 'positive': 49}, 'tree': {'true_positive': 50, 'false_positive': 23, 'true_negative': 4360, 'false_negative': 67, 'negative': 4383, 'positive': 117}}\n",
      "------------------------\n",
      "Evaluating: Batch 46/51: Loss: 0.1256 | Test Acc: 95.812% (61703/64400) | Strict Acc: 61.935% (2849/4600)\n",
      "True positive rate: 65.283% (3003/4600)\n",
      "False negative rate: 34.717% (1597/4600)\n",
      "True negative rate: 98.161% (58700/59800)\n",
      "False positive rate: 1.839% (1100/59800)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4581, 'false_negative': 13, 'negative': 4584, 'positive': 16}, 'bird': {'true_positive': 53, 'false_positive': 28, 'true_negative': 4490, 'false_negative': 29, 'negative': 4518, 'positive': 82}, 'car': {'true_positive': 76, 'false_positive': 9, 'true_negative': 4493, 'false_negative': 22, 'negative': 4502, 'positive': 98}, 'clouds': {'true_positive': 117, 'false_positive': 40, 'true_negative': 4325, 'false_negative': 118, 'negative': 4365, 'positive': 235}, 'dog': {'true_positive': 66, 'false_positive': 20, 'true_negative': 4485, 'false_negative': 29, 'negative': 4505, 'positive': 95}, 'female': {'true_positive': 453, 'false_positive': 287, 'true_negative': 3608, 'false_negative': 252, 'negative': 3895, 'positive': 705}, 'flower': {'true_positive': 123, 'false_positive': 53, 'true_negative': 4367, 'false_negative': 57, 'negative': 4420, 'positive': 180}, 'male': {'true_positive': 348, 'false_positive': 143, 'true_negative': 3757, 'false_negative': 352, 'negative': 3900, 'positive': 700}, 'night': {'true_positive': 36, 'false_positive': 14, 'true_negative': 4458, 'false_negative': 92, 'negative': 4472, 'positive': 128}, 'people': {'true_positive': 1115, 'false_positive': 230, 'true_negative': 2914, 'false_negative': 341, 'negative': 3144, 'positive': 1456}, 'portrait': {'true_positive': 548, 'false_positive': 234, 'true_negative': 3669, 'false_negative': 149, 'negative': 3903, 'positive': 697}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4560, 'false_negative': 34, 'negative': 4566, 'positive': 34}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4541, 'false_negative': 40, 'negative': 4550, 'positive': 50}, 'tree': {'true_positive': 55, 'false_positive': 24, 'true_negative': 4452, 'false_negative': 69, 'negative': 4476, 'positive': 124}}\n",
      "------------------------\n",
      "Evaluating: Batch 47/51: Loss: 0.1256 | Test Acc: 95.818% (63048/65800) | Strict Acc: 62.021% (2915/4700)\n",
      "True positive rate: 65.350% (3061/4684)\n",
      "False negative rate: 34.650% (1623/4684)\n",
      "True negative rate: 98.153% (59987/61116)\n",
      "False positive rate: 1.847% (1129/61116)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 3, 'false_positive': 3, 'true_negative': 4680, 'false_negative': 14, 'negative': 4683, 'positive': 17}, 'bird': {'true_positive': 53, 'false_positive': 28, 'true_negative': 4589, 'false_negative': 30, 'negative': 4617, 'positive': 83}, 'car': {'true_positive': 77, 'false_positive': 9, 'true_negative': 4592, 'false_negative': 22, 'negative': 4601, 'positive': 99}, 'clouds': {'true_positive': 121, 'false_positive': 40, 'true_negative': 4419, 'false_negative': 120, 'negative': 4459, 'positive': 241}, 'dog': {'true_positive': 68, 'false_positive': 20, 'true_negative': 4583, 'false_negative': 29, 'negative': 4603, 'positive': 97}, 'female': {'true_positive': 465, 'false_positive': 294, 'true_negative': 3685, 'false_negative': 256, 'negative': 3979, 'positive': 721}, 'flower': {'true_positive': 126, 'false_positive': 56, 'true_negative': 4461, 'false_negative': 57, 'negative': 4517, 'positive': 183}, 'male': {'true_positive': 351, 'false_positive': 149, 'true_negative': 3843, 'false_negative': 357, 'negative': 3992, 'positive': 708}, 'night': {'true_positive': 37, 'false_positive': 14, 'true_negative': 4553, 'false_negative': 96, 'negative': 4567, 'positive': 133}, 'people': {'true_positive': 1135, 'false_positive': 235, 'true_negative': 2986, 'false_negative': 344, 'negative': 3221, 'positive': 1479}, 'portrait': {'true_positive': 559, 'false_positive': 240, 'true_negative': 3750, 'false_negative': 151, 'negative': 3990, 'positive': 710}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4659, 'false_negative': 35, 'negative': 4665, 'positive': 35}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4640, 'false_negative': 41, 'negative': 4649, 'positive': 51}, 'tree': {'true_positive': 56, 'false_positive': 26, 'true_negative': 4547, 'false_negative': 71, 'negative': 4573, 'positive': 127}}\n",
      "------------------------\n",
      "Evaluating: Batch 48/51: Loss: 0.1258 | Test Acc: 95.812% (64386/67200) | Strict Acc: 61.979% (2975/4800)\n",
      "True positive rate: 65.340% (3120/4775)\n",
      "False negative rate: 34.660% (1655/4775)\n",
      "True negative rate: 98.143% (61266/62425)\n",
      "False positive rate: 1.857% (1159/62425)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 5, 'false_positive': 3, 'true_negative': 4778, 'false_negative': 14, 'negative': 4781, 'positive': 19}, 'bird': {'true_positive': 53, 'false_positive': 29, 'true_negative': 4688, 'false_negative': 30, 'negative': 4717, 'positive': 83}, 'car': {'true_positive': 77, 'false_positive': 9, 'true_negative': 4692, 'false_negative': 22, 'negative': 4701, 'positive': 99}, 'clouds': {'true_positive': 123, 'false_positive': 40, 'true_negative': 4516, 'false_negative': 121, 'negative': 4556, 'positive': 244}, 'dog': {'true_positive': 69, 'false_positive': 20, 'true_negative': 4680, 'false_negative': 31, 'negative': 4700, 'positive': 100}, 'female': {'true_positive': 474, 'false_positive': 301, 'true_negative': 3763, 'false_negative': 262, 'negative': 4064, 'positive': 736}, 'flower': {'true_positive': 128, 'false_positive': 57, 'true_negative': 4555, 'false_negative': 60, 'negative': 4612, 'positive': 188}, 'male': {'true_positive': 361, 'false_positive': 152, 'true_negative': 3927, 'false_negative': 360, 'negative': 4079, 'positive': 721}, 'night': {'true_positive': 40, 'false_positive': 15, 'true_negative': 4649, 'false_negative': 96, 'negative': 4664, 'positive': 136}, 'people': {'true_positive': 1159, 'false_positive': 241, 'true_negative': 3048, 'false_negative': 352, 'negative': 3289, 'positive': 1511}, 'portrait': {'true_positive': 565, 'false_positive': 250, 'true_negative': 3830, 'false_negative': 155, 'negative': 4080, 'positive': 720}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4757, 'false_negative': 37, 'negative': 4763, 'positive': 37}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4740, 'false_negative': 41, 'negative': 4749, 'positive': 51}, 'tree': {'true_positive': 56, 'false_positive': 27, 'true_negative': 4643, 'false_negative': 74, 'negative': 4670, 'positive': 130}}\n",
      "------------------------\n",
      "Evaluating: Batch 49/51: Loss: 0.1260 | Test Acc: 95.806% (65723/68600) | Strict Acc: 61.898% (3033/4900)\n",
      "True positive rate: 65.164% (3180/4880)\n",
      "False negative rate: 34.836% (1700/4880)\n",
      "True negative rate: 98.153% (62543/63720)\n",
      "False positive rate: 1.847% (1177/63720)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 5, 'false_positive': 3, 'true_negative': 4877, 'false_negative': 15, 'negative': 4880, 'positive': 20}, 'bird': {'true_positive': 55, 'false_positive': 30, 'true_negative': 4785, 'false_negative': 30, 'negative': 4815, 'positive': 85}, 'car': {'true_positive': 79, 'false_positive': 9, 'true_negative': 4788, 'false_negative': 24, 'negative': 4797, 'positive': 103}, 'clouds': {'true_positive': 123, 'false_positive': 42, 'true_negative': 4609, 'false_negative': 126, 'negative': 4651, 'positive': 249}, 'dog': {'true_positive': 71, 'false_positive': 20, 'true_negative': 4776, 'false_negative': 33, 'negative': 4796, 'positive': 104}, 'female': {'true_positive': 483, 'false_positive': 303, 'true_negative': 3847, 'false_negative': 267, 'negative': 4150, 'positive': 750}, 'flower': {'true_positive': 128, 'false_positive': 57, 'true_negative': 4654, 'false_negative': 61, 'negative': 4711, 'positive': 189}, 'male': {'true_positive': 369, 'false_positive': 155, 'true_negative': 4007, 'false_negative': 369, 'negative': 4162, 'positive': 738}, 'night': {'true_positive': 42, 'false_positive': 15, 'true_negative': 4744, 'false_negative': 99, 'negative': 4759, 'positive': 141}, 'people': {'true_positive': 1182, 'false_positive': 246, 'true_negative': 3108, 'false_negative': 364, 'negative': 3354, 'positive': 1546}, 'portrait': {'true_positive': 574, 'false_positive': 255, 'true_negative': 3912, 'false_negative': 159, 'negative': 4167, 'positive': 733}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4857, 'false_negative': 37, 'negative': 4863, 'positive': 37}, 'sea': {'true_positive': 10, 'false_positive': 9, 'true_negative': 4840, 'false_negative': 41, 'negative': 4849, 'positive': 51}, 'tree': {'true_positive': 59, 'false_positive': 27, 'true_negative': 4739, 'false_negative': 75, 'negative': 4766, 'positive': 134}}\n",
      "------------------------\n",
      "Evaluating: Batch 50/51: Loss: 0.1261 | Test Acc: 95.796% (67057/70000) | Strict Acc: 61.880% (3094/5000)\n",
      "True positive rate: 65.118% (3252/4994)\n",
      "False negative rate: 34.882% (1742/4994)\n",
      "True negative rate: 98.152% (63805/65006)\n",
      "False positive rate: 1.848% (1201/65006)\n",
      "------------------------\n",
      "{'baby': {'true_positive': 6, 'false_positive': 3, 'true_negative': 4975, 'false_negative': 16, 'negative': 4978, 'positive': 22}, 'bird': {'true_positive': 57, 'false_positive': 30, 'true_negative': 4883, 'false_negative': 30, 'negative': 4913, 'positive': 87}, 'car': {'true_positive': 79, 'false_positive': 9, 'true_negative': 4888, 'false_negative': 24, 'negative': 4897, 'positive': 103}, 'clouds': {'true_positive': 125, 'false_positive': 43, 'true_negative': 4703, 'false_negative': 129, 'negative': 4746, 'positive': 254}, 'dog': {'true_positive': 71, 'false_positive': 20, 'true_negative': 4876, 'false_negative': 33, 'negative': 4896, 'positive': 104}, 'female': {'true_positive': 495, 'false_positive': 307, 'true_negative': 3921, 'false_negative': 277, 'negative': 4228, 'positive': 772}, 'flower': {'true_positive': 130, 'false_positive': 57, 'true_negative': 4752, 'false_negative': 61, 'negative': 4809, 'positive': 191}, 'male': {'true_positive': 374, 'false_positive': 162, 'true_negative': 4086, 'false_negative': 378, 'negative': 4248, 'positive': 752}, 'night': {'true_positive': 43, 'false_positive': 15, 'true_negative': 4841, 'false_negative': 101, 'negative': 4856, 'positive': 144}, 'people': {'true_positive': 1209, 'false_positive': 252, 'true_negative': 3164, 'false_negative': 375, 'negative': 3416, 'positive': 1584}, 'portrait': {'true_positive': 591, 'false_positive': 260, 'true_negative': 3986, 'false_negative': 163, 'negative': 4246, 'positive': 754}, 'river': {'true_positive': 0, 'false_positive': 6, 'true_negative': 4957, 'false_negative': 37, 'negative': 4963, 'positive': 37}, 'sea': {'true_positive': 11, 'false_positive': 10, 'true_negative': 4936, 'false_negative': 43, 'negative': 4946, 'positive': 54}, 'tree': {'true_positive': 61, 'false_positive': 27, 'true_negative': 4837, 'false_negative': 75, 'negative': 4864, 'positive': 136}}\n",
      "------------------------\n",
      "Evaluating: Batch 51/51: Loss: 0.1254 | Test Acc: 95.793% (67323/70280) | Strict Acc: 61.873% (3106/5020)\n",
      "True positive rate: 65.136% (3262/5008)\n",
      "False negative rate: 34.864% (1746/5008)\n",
      "True negative rate: 98.145% (64061/65272)\n",
      "False positive rate: 1.855% (1211/65272)\n",
      "------------------------\n",
      "[0.1179958495976755, 0.11206239317716112, 0.1111855525270968, 0.1088119427045837, 0.11477059199752745, 0.1113738396632879, 0.11537785795787255, 0.11334448614410553, 0.12214362922964396, 0.12575293284260255]\n",
      "[{'baby': 99.38856015779093, 'bird': 98.50098619329388, 'car': 99.25049309664695, 'clouds': 94.51676528599606, 'dog': 98.77712031558185, 'female': 89.28994082840237, 'flower': 97.47534516765286, 'male': 87.81065088757397, 'night': 97.31755424063117, 'people': 86.5483234714004, 'portrait': 91.26232741617358, 'river': 99.48717948717949, 'sea': 99.19132149901381, 'tree': 97.7120315581854, 'tot': 95.46632854325162, 'tot_strict': 58.323471400394475}, {'baby': 99.38856015779093, 'bird': 99.05325443786982, 'car': 99.30966469428007, 'clouds': 95.70019723865877, 'dog': 98.69822485207101, 'female': 89.94082840236686, 'flower': 97.51479289940828, 'male': 87.94871794871794, 'night': 97.3767258382643, 'people': 87.55424063116371, 'portrait': 92.20907297830375, 'river': 99.48717948717949, 'sea': 99.19132149901381, 'tree': 97.83037475345168, 'tot': 95.80022541561003, 'tot_strict': 60.51282051282051}, {'baby': 99.38856015779093, 'bird': 99.13214990138067, 'car': 99.28994082840237, 'clouds': 94.45759368836292, 'dog': 98.83629191321499, 'female': 88.10650887573965, 'flower': 97.88954635108482, 'male': 87.85009861932939, 'night': 97.63313609467455, 'people': 87.65285996055226, 'portrait': 92.72189349112426, 'river': 99.48717948717949, 'sea': 99.17159763313609, 'tree': 98.14595660749507, 'tot': 95.69737954353339, 'tot_strict': 61.26232741617357}, {'baby': 99.38856015779093, 'bird': 99.19132149901381, 'car': 99.27021696252466, 'clouds': 95.2268244575937, 'dog': 98.91518737672584, 'female': 90.0, 'flower': 97.59368836291914, 'male': 88.28402366863905, 'night': 97.59368836291914, 'people': 88.14595660749507, 'portrait': 92.18934911242603, 'river': 99.48717948717949, 'sea': 99.15187376725838, 'tree': 97.49506903353057, 'tot': 95.8523527754297, 'tot_strict': 61.222879684418146}, {'baby': 99.42800788954635, 'bird': 99.15187376725838, 'car': 99.3293885601578, 'clouds': 96.01577909270218, 'dog': 98.24457593688363, 'female': 89.90138067061145, 'flower': 97.7120315581854, 'male': 86.84418145956607, 'night': 97.3767258382643, 'people': 86.64694280078895, 'portrait': 91.57790927021696, 'river': 99.42800788954635, 'sea': 99.03353057199212, 'tree': 98.14595660749507, 'tot': 95.63116370808679, 'tot_strict': 60.51282051282051}, {'baby': 99.44773175542406, 'bird': 99.11242603550296, 'car': 98.38264299802762, 'clouds': 96.11439842209073, 'dog': 98.97435897435898, 'female': 89.54635108481263, 'flower': 97.19921104536489, 'male': 88.08678500986193, 'night': 97.45562130177515, 'people': 87.59368836291914, 'portrait': 93.07692307692308, 'river': 99.38856015779093, 'sea': 99.15187376725838, 'tree': 98.08678500986193, 'tot': 95.8298112144266, 'tot_strict': 61.43984220907298}, {'baby': 99.42800788954635, 'bird': 99.03353057199212, 'car': 99.05325443786982, 'clouds': 95.75936883629191, 'dog': 99.03353057199212, 'female': 90.1577909270217, 'flower': 97.33727810650888, 'male': 88.2051282051282, 'night': 97.2189349112426, 'people': 87.57396449704142, 'portrait': 91.75542406311637, 'river': 99.15187376725838, 'sea': 99.19132149901381, 'tree': 97.98816568047337, 'tot': 95.77768385460693, 'tot_strict': 61.83431952662722}, {'baby': 99.64497041420118, 'bird': 99.15187376725838, 'car': 99.19132149901381, 'clouds': 95.83826429980276, 'dog': 98.87573964497041, 'female': 88.34319526627219, 'flower': 97.39644970414201, 'male': 88.08678500986193, 'night': 97.63313609467455, 'people': 88.22485207100591, 'portrait': 92.74161735700197, 'river': 99.48717948717949, 'sea': 99.07297830374753, 'tree': 98.06706114398422, 'tot': 95.83967314736546, 'tot_strict': 61.972386587771204}, {'baby': 99.44773175542406, 'bird': 98.79684418145956, 'car': 99.30966469428007, 'clouds': 95.4043392504931, 'dog': 98.93491124260355, 'female': 88.99408284023669, 'flower': 97.45562130177515, 'male': 88.06706114398422, 'night': 97.25838264299803, 'people': 87.10059171597634, 'portrait': 92.16962524654832, 'river': 99.25049309664695, 'sea': 98.75739644970415, 'tree': 97.94871794871794, 'tot': 95.63539025077486, 'tot_strict': 59.80276134122288}, {'baby': 99.62524654832347, 'bird': 99.0138067061144, 'car': 99.3293885601578, 'clouds': 95.95660749506904, 'dog': 98.97435897435898, 'female': 88.65877712031558, 'flower': 97.23865877712032, 'male': 88.0276134122288, 'night': 97.49506903353057, 'people': 87.81065088757397, 'portrait': 91.47928994082841, 'river': 99.48717948717949, 'sea': 99.09270216962524, 'tree': 97.81065088757397, 'tot': 95.71428571428571, 'tot_strict': 61.005917159763314}]\n"
     ]
    }
   ],
   "source": [
    "#--- test ---\n",
    "\n",
    "alexnet.eval()\n",
    "resnet.eval()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "test_correct = {annotation: [0,0] for annotation in annotations}\n",
    "test_correct['tot'] = [0,0]\n",
    "test_correct['tot_strict'] = [0,0]\n",
    "evaluation = {\"true_positive\": 0,\n",
    "                    \"false_positive\": 0,\n",
    "                    \"true_negative\": 0,\n",
    "                    \"false_negative\": 0,\n",
    "                    \"negative\": 0,\n",
    "                    \"positive\": 0}\n",
    "\n",
    "evaluation_by_annotation = {}\n",
    "for a in range(len(annotations)):\n",
    "    evaluation_by_annotation[annotations[a]] = {\"true_positive\": 0,\n",
    "                                                \"false_positive\": 0,\n",
    "                                                \"true_negative\": 0,\n",
    "                                                \"false_negative\": 0,\n",
    "                                                \"negative\": 0,\n",
    "                                                \"positive\": 0}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_num, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_function(pred, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        new_test_correct = calc_correct(pred, target)\n",
    "        for annotation in annotations:\n",
    "            new = new_test_correct[annotation]\n",
    "            test_correct[annotation][0] += new[0]\n",
    "            test_correct[annotation][1] += new[1]\n",
    "        test_correct['tot'][0] += new_test_correct['tot'][0]\n",
    "        test_correct['tot'][1] += new_test_correct['tot'][1]\n",
    "        test_correct['tot_strict'][0] += new_test_correct['tot_strict'][0]\n",
    "        test_correct['tot_strict'][1] += new_test_correct['tot_strict'][1]\n",
    "        \n",
    "        evaluations = class_evaluation(pred, target)\n",
    "        evaluation[\"true_positive\"] += evaluations[\"true_positive\"]\n",
    "        evaluation[\"false_positive\"] += evaluations[\"false_positive\"]\n",
    "        evaluation[\"true_negative\"] += evaluations[\"true_negative\"]\n",
    "        evaluation[\"false_negative\"] += evaluations[\"false_negative\"]\n",
    "        evaluation[\"positive\"] += evaluations[\"positive\"]\n",
    "        evaluation[\"negative\"] += evaluations[\"negative\"]\n",
    "        \n",
    "        evaluations_by_annotation = class_evaluation_by_annotation(pred, target)\n",
    "        print(evaluation_by_annotation)\n",
    "        \n",
    "        for a in range(len(annotations)):\n",
    "            evaluation_by_annotation[annotations[a]][\"true_positive\"] += evaluations_by_annotation[annotations[a]][\"true_positive\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"false_positive\"] += evaluations_by_annotation[annotations[a]][\"false_positive\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"true_negative\"] += evaluations_by_annotation[annotations[a]][\"true_negative\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"false_negative\"] += evaluations_by_annotation[annotations[a]][\"false_negative\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"positive\"] += evaluations_by_annotation[annotations[a]][\"positive\"]\n",
    "            evaluation_by_annotation[annotations[a]][\"negative\"] += evaluations_by_annotation[annotations[a]][\"negative\"]\n",
    "        \n",
    "        print(\"------------------------\")\n",
    "        print('Evaluating: Batch %d/%d: Loss: %.4f | Test Acc: %.3f%% (%d/%d) | Strict Acc: %.3f%% (%d/%d)' % \n",
    "              (batch_num+1, len(test_loader), test_loss / (batch_num + 1), \n",
    "               100. * test_correct['tot'][0] / test_correct['tot'][1], test_correct['tot'][0], test_correct['tot'][1],\n",
    "               100. * test_correct['tot_strict'][0] / test_correct['tot_strict'][1], test_correct['tot_strict'][0], test_correct['tot_strict'][1]))\n",
    "        print('True positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_positive\"] / evaluation[\"positive\"], evaluation[\"true_positive\"], evaluation[\"positive\"]) )\n",
    "        print('False negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_negative\"] / evaluation[\"positive\"], evaluation[\"false_negative\"], evaluation[\"positive\"]) )\n",
    "        print('True negative rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"true_negative\"] / evaluation[\"negative\"], evaluation[\"true_negative\"], evaluation[\"negative\"]) )\n",
    "        print('False positive rate: %.3f%% (%d/%d)' % \n",
    "              (100. * evaluation[\"false_positive\"] / evaluation[\"negative\"], evaluation[\"false_positive\"], evaluation[\"negative\"]) )\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "print(dev_losses)\n",
    "print(dev_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91378623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "baby:\n",
      "\n",
      "positive: 22\n",
      "true_positive: 6\n",
      "false_negative: 16\n",
      "\n",
      "negative: 4998\n",
      "true_negative: 4995\n",
      "false_positive: 3\n",
      "------------------------\n",
      "bird:\n",
      "\n",
      "positive: 87\n",
      "true_positive: 57\n",
      "false_negative: 30\n",
      "\n",
      "negative: 4933\n",
      "true_negative: 4903\n",
      "false_positive: 30\n",
      "------------------------\n",
      "car:\n",
      "\n",
      "positive: 103\n",
      "true_positive: 79\n",
      "false_negative: 24\n",
      "\n",
      "negative: 4917\n",
      "true_negative: 4908\n",
      "false_positive: 9\n",
      "------------------------\n",
      "clouds:\n",
      "\n",
      "positive: 255\n",
      "true_positive: 126\n",
      "false_negative: 129\n",
      "\n",
      "negative: 4765\n",
      "true_negative: 4721\n",
      "false_positive: 44\n",
      "------------------------\n",
      "dog:\n",
      "\n",
      "positive: 104\n",
      "true_positive: 71\n",
      "false_negative: 33\n",
      "\n",
      "negative: 4916\n",
      "true_negative: 4896\n",
      "false_positive: 20\n",
      "------------------------\n",
      "female:\n",
      "\n",
      "positive: 774\n",
      "true_positive: 496\n",
      "false_negative: 278\n",
      "\n",
      "negative: 4246\n",
      "true_negative: 3936\n",
      "false_positive: 310\n",
      "------------------------\n",
      "flower:\n",
      "\n",
      "positive: 191\n",
      "true_positive: 130\n",
      "false_negative: 61\n",
      "\n",
      "negative: 4829\n",
      "true_negative: 4771\n",
      "false_positive: 58\n",
      "------------------------\n",
      "male:\n",
      "\n",
      "positive: 754\n",
      "true_positive: 375\n",
      "false_negative: 379\n",
      "\n",
      "negative: 4266\n",
      "true_negative: 4102\n",
      "false_positive: 164\n",
      "------------------------\n",
      "night:\n",
      "\n",
      "positive: 145\n",
      "true_positive: 43\n",
      "false_negative: 102\n",
      "\n",
      "negative: 4875\n",
      "true_negative: 4860\n",
      "false_positive: 15\n",
      "------------------------\n",
      "people:\n",
      "\n",
      "positive: 1589\n",
      "true_positive: 1213\n",
      "false_negative: 376\n",
      "\n",
      "negative: 3431\n",
      "true_negative: 3178\n",
      "false_positive: 253\n",
      "------------------------\n",
      "portrait:\n",
      "\n",
      "positive: 755\n",
      "true_positive: 592\n",
      "false_negative: 163\n",
      "\n",
      "negative: 4265\n",
      "true_negative: 4004\n",
      "false_positive: 261\n",
      "------------------------\n",
      "river:\n",
      "\n",
      "positive: 37\n",
      "true_positive: 0\n",
      "false_negative: 37\n",
      "\n",
      "negative: 4983\n",
      "true_negative: 4977\n",
      "false_positive: 6\n",
      "------------------------\n",
      "sea:\n",
      "\n",
      "positive: 54\n",
      "true_positive: 11\n",
      "false_negative: 43\n",
      "\n",
      "negative: 4966\n",
      "true_negative: 4955\n",
      "false_positive: 11\n",
      "------------------------\n",
      "tree:\n",
      "\n",
      "positive: 138\n",
      "true_positive: 63\n",
      "false_negative: 75\n",
      "\n",
      "negative: 4882\n",
      "true_negative: 4855\n",
      "false_positive: 27\n"
     ]
    }
   ],
   "source": [
    "for i in evaluation_by_annotation:\n",
    "    print(\"------------------------\")\n",
    "    print(i + \":\")\n",
    "    print(\"\")\n",
    "    print(\"positive: \" + str(evaluation_by_annotation[i][\"positive\"]))\n",
    "    print(\"true_positive: \" + str(evaluation_by_annotation[i][\"true_positive\"]))\n",
    "    print(\"false_negative: \" + str(evaluation_by_annotation[i][\"false_negative\"]))\n",
    "    print(\"\")\n",
    "    print(\"negative: \" + str(evaluation_by_annotation[i][\"negative\"]))\n",
    "    print(\"true_negative: \" + str(evaluation_by_annotation[i][\"true_negative\"]))\n",
    "    print(\"false_positive: \" + str(evaluation_by_annotation[i][\"false_positive\"]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50ec63d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m PATH \u001b[39m=\u001b[39m DATA_DIR \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcnn_comb.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), PATH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "PATH = DATA_DIR + \"cnn_comb.pt\"\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "89158b9d33bcf602ad519c8651186fc3ff1789e005f6c1522704c91a500b7f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
